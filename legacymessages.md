---
layout: page
title: Legacy Assembla Messages
description: "Archive of Plus Assembla messages"
---

## Please post messages to GitHub
#### Posted by Andras Lasso on 2017-09-18 19:05

We are moving to GitHub. Please any post questions, bug reports, feature requests there, as "issues".

https://github.com/plusToolkit/pluslib/issues

#### 0 Comments

## Webcam Optical Marker Tracker Configuration File Error
#### Posted by Colleen.Ogilvie on 2017-09-18 18:36

Hi PLUS team,

I'm using the Plus Server Launcher with a configuration file based on the Optical Marker Tracker page on PLUS (http://www3.cs.queensu.ca/perk-software/plus/doc/nightly/user/DeviceOpticalMarkerTracker.html), and I am getting the following error:

|ERROR|2690.618000|SERVER> Unable to find required "CameraCalibrationFile" attribute in Device element in device set configuration| in :\D\PTNP64b\PlusLib\src\PlusDataCollection\OpticalMarkerTracking\vtkPlusOpticalMarkerTracker.cxx(140)
|ERROR|2690.653000|SERVER> Datacollector failed to read configuration| in :\D\PTNP64b\PlusLib\src\PlusServer\Tools\PlusServer.cxx(114)

Would you know what the issue might be? I believe my calibration file is the correct location based on the configuration directory. I've attached my configuration file.

Thank you!
opticaltrackerconfig.xml	3.74 KB

#### 1 Comments
#### By Andras Lasso on 2017-09-18 19:03
Sorry, this was a regression that was fixed a couple of days ago. Can you try if it works with the most recent development snapshot?

We are moving to github. Please submit follow-up questions on github, as issues (https://github.com/plusToolkit/pluslib/issues).

## Intel Realsense Support
#### Posted by 15025047 on 2017-08-25 21:33

Dear Plus Staff,

I can view the Intel Realsense tracker in the user manual page but it doesn't seem to be supported in either the stable or the nightly builds. From what I understand I can use the optical marker tracker but with no depth capabilities. Will it be supported soon?

Thanks in advance,
Ahmed

#### 8 Comments
#### By Adam Rankin on 2017-08-25 23:10
I believe that you have to build plus yourself as the Intel realsense sdk is required.

@lassoan will be able to tell you more
#### By Andras Lasso on 2017-08-25 23:59
It's still under development (in one of the branches in https://github.com/markasselin/PlusLib). It'll probably be merged into the trunk in a few weeks. What do you plan to use it for?
#### By 15025047 on 2017-08-28 21:32
Thanks, I'm building a small lab at the Royal College of Surgeons in Ireland to test potential clinical applications. I wont be able to build a plus version so I'm just going to look out for the new updates.
#### By Andras Lasso on 2017-08-29 13:20
Great. For now you can simply use a webcam and upgrade later to an Intel RealSense camera.

At some point you may also consider trying a somewhat more expensive but also more accurate tracker, such as an OptiTrack Duo - https://www.optitrack.com/products/v120-duo/.
#### By Ppandey on 2017-08-31 14:05
@lassoan If we built Plus from the master branch, can we enable RealSense tracking or should we wait for the merge?
#### By Andras Lasso on 2017-08-31 14:16
I would recommend to wait for the merge. If you want to try earlier then you can build the branch that I referred to.
#### By Colleen.Ogilvie on 2017-09-18 15:54
@lassoan Hi Andras,
We’re also interested in using the Intel RealSense for ultrasound probe tracking. Would it be possible to have some more details about when the merge might be?
Thank you!
#### By Andras Lasso on 2017-09-18 19:00
@markasselin is working on it right now. The part without sensor fusion (separate optical-camera-based and surface-based tracking) should be available within a couple of days. Full combined tracking will probably take 1-2 months to complete (followed by further testing and optimization).

We are moving to github. Please submit follow-up questions on github, as issues (https://github.com/plusToolkit/pluslib/issues).


Connecting to Optotrak Certus
#### Posted by ppandey on 2017-05-11 21:26

I'm trying to use PLUS to collect tracking data from the Optotrak, but I am unable to connect. When I run the server I can hear the machine communicating, but the connection fails.

The Info level log error is: "Optotrak: Invalid node version detected. (Node 0. Version 3.12.00)".

My config file is:

~~~~
<PlusConfiguration version="2.1">
  <DataCollection StartupDelaySec="1.0">
    <DeviceSet 
      Name="PlusServer: NDI Certus tracker"
      Description="Broadcasting tool tracking data through OpenIGTLink
Tracking a single needle.
The computer needs to be on the same local network as Certus SCU unit. The needle has to be plugged into the first slot"
    />
    <Device
      Id="TrackerDevice"
      Type="CertusTracker"      
      ToolReferenceFrame="Tracker" >
      <DataSources>
        <DataSource Type="Tool" Id="Stylus" PortName="0" />
        <!-- <DataSource Type="Tool" Id="Reference" PortName="1" />
        <DataSource Type="Tool" Id="Probe" PortName="2" />
        <DataSource Type="Tool" Id="Needle" PortName="3" /> -->
      </DataSources>
      <OutputChannels>
      <OutputChannel Id="TrackerStream" >
        <DataSource Id="Stylus"/>
        <!-- <DataSource Id="Reference"/>
        <DataSource Id="Probe"/> -->
      </OutputChannel>
      </OutputChannels>
    </Device>
    <Device
      Id="CaptureDevice"
      Type="VirtualDiscCapture"
      BaseFilename="RecordingTest.mha"
      EnableCapturingOnStart="FALSE" >
      <InputChannels>
        <InputChannel Id="TrackerStream" />
      </InputChannels>
    </Device>
  </DataCollection>
  <PlusOpenIGTLinkServer 
    MaxNumberOfIgtlMessagesToSend="1" 
    MaxTimeSpentWithProcessingMs="50" 
    ListeningPort="18944" 
    SendValidTransformsOnly="true" 
    OutputChannelId="TrackerStream" > 
    <DefaultClientInfo> 
      <MessageTypes> 
        <Message Type="TRANSFORM" />
      </MessageTypes>
      <TransformNames> 
        <Transform Name="StylusToTracker" />
      </TransformNames>
    </DefaultClientInfo>
  </PlusOpenIGTLinkServer>
</PlusConfiguration>
~~~~

#### 16 Comments
#### By Andras Lasso on 2017-05-11 21:34
Plus packages that you can download are built with NDI Oapi-3.0.0.66. Firmware of your Certus is version 3.12.00. There is a chance that if you replace binaries (etherlink.dll, oapi.dll, and PCIlink.dll) to your version will fix the connection problem. If not, then you have to rebuild Plus with NDI Oapi version that matches the version of your Certus firmware.
#### By Ppandey on 2017-05-12 21:00
Thanks, replacing the oapi.dll worked.

However I've run into a new problem now. I can use PLUS with the Optotrak tracking a wired tool (4 marker rigid body with a tooltip), but I can't seem to use PLUS with the smart markers provided by NDI (https://www.ndigital.com/msci/products/smart-markers/). Is it possible to use these markers with PLUS?

I've attached the info level log when I try to connect to smart markers on port 0.
051217_171506_PlusLog.txt	2.15 KB
#### By Andras Lasso on 2017-05-13 07:29
Do you have examples or specification of how using smart markers is different from standard wired markers?
#### By Ppandey on 2017-05-13 13:54
Standard wired markers (like the digitizing probe/rigid bodies) are attached to the SCU via a tool strober. These wired tools have a predefined SROM.

Smart markers are connected via a 'wireless' strober to the SCU, and are individual markers that can be configured into a rigid body if needed - see attachment. They can also be battery powered so that they don't have to be directly wired to the SCU.
optotraksmartmarkers.PNG	153 KB
#### By Ppandey on 2017-06-01 01:24
I'm pretty sure this is the same problem as the one here: https://app.assembla.com/spaces/plus/messages/5623233#comment_5623383

However, I am new at developing and I'm not sure which source files I would need to modify to be able to add .rig file support, and how to do this?
#### By Ppandey on 2017-09-06 00:26
I believe that the issue that is preventing smart markers from being used is vtkPlusNDICertusTracker does not have functionality to read a rigid body definition from file. I think that the functionality can be added in by using the RigidBodyAddFromFile() function from the ndi oapi, similar to how RigidBodyAddFromDeviceHandle is being used currently.

Unfortunately I'm not exactly sure how to do this... is someone willing to build in this functionality?
#### By Ppandey on 2017-09-13 16:23
I'm trying to solve this issue by building Plus following the developer's guide, but I'm running into build errors - any idea what's wrong?
~~~~
Error	1134	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\vtkPlusServer.lib' [C:\PlusLib\bin\PlusApp-bin\DiagnosticTools\TrackingDataServer.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1143	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\vtkPlusServer.lib' [C:\PlusLib\bin\PlusApp-bin\DiagnosticTools\TrackingDataServer.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1131	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\vtkPlusDataCollection.lib' [C:\PlusLib\bin\PlusApp-bin\DiagnosticTools\DiagDataCollection.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1140	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\vtkPlusDataCollection.lib' [C:\PlusLib\bin\PlusApp-bin\DiagnosticTools\DiagDataCollection.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1132	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\PlusServerLauncher\PlusServerLauncher.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1141	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\PlusServerLauncher\PlusServerLauncher.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1133	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\fCal\Testing\SegmentationParameterDialogTest.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1142	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\fCal\Testing\SegmentationParameterDialogTest.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1137	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\fCal\fCal.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1144	error LNK1104: cannot open file 'C:\PlusLib\bin\lib\Debug\PlusWidgets.lib' [C:\PlusLib\bin\PlusApp-bin\fCal\fCal.vcxproj]	C:\PlusLib\bin\LINK	PlusApp
Error	1129	error C1189: #error :  NDI Error - Host not defined. Options: PLATFORM_X86, PLATFORM_LINUX (C:\PlusLib\bin\PlusLib\src\PlusDataCollection\NDICertusTracking\vtkPlusNDICertusTracker.cxx) [C:\PlusLib\bin\PlusLib-bin\src\PlusDataCollection\vtkPlusDataCollection.vcxproj]	C:\NDIoapi\ndlib\include\ndhost.h	157	1	PlusLib
Error	1130	error C1189: #error :  NDI Error - Host not defined. Options: PLATFORM_X86, PLATFORM_LINUX (C:\PlusLib\bin\PlusLib\src\PlusDataCollection\NDICertusTracking\vtkPlusNDICertusTracker.cxx) [C:\PlusLib\bin\PlusLib-bin\src\PlusDataCollection\vtkPlusDataCollection.vcxproj]	C:\NDIoapi\ndlib\include\ndhost.h	157	1	PlusLib
~~~~
#### By Ppandey on 2017-09-13 16:27
i.e. for some reason I don't have the necessary .lib files and not sure why there is a NDI host error in the certus api
#### By Andras Lasso on 2017-09-13 17:53
What operating system do you use?
Do you have the oapi library corresponding to the software version of your Certus tracker?
#### By Ppandey on 2017-09-13 17:59
I'm building on Windows 10 64-bit, I have the oapi library (version 3.08) which works with our tracker.

One possible explanation is that I'm using Qt 5.6, which no longer has QtWebKit or QtWebKitWidgets, but I'm not sure if that is causing a problem.
#### By Ppandey on 2017-09-13 18:04
Also, Im using Visual Studio 2013
#### By Andras Lasso on 2017-09-13 18:05
Qt is unlikely to be the issue (you can build PlusServer without Qt). We build with Oapi-3.0.0.66. It may be possible that the API is slightly changed. Also, do you build 32-bit or 64-bit application?

Open the PlusLib.sln file in Visual Studio and try to build just then and send me the first error message. All the other error messages may be just consequences of the first error.
#### By Ppandey on 2017-09-13 18:06
Okay will do that, I'm building 32-bit because I need to use it with Ultrasonix.
#### By Ppandey on 2017-09-13 18:12
Just to double check - which files should the NDI Certus Binary dir contain? The one I have set in CMake is pointing to oapi.dll, NDItb.dll and ndservices.dll.

It does not contain the etherlink.dll, usblink.dll, etc. binaries
#### By Andras Lasso on 2017-09-13 18:15
It should be a folder with 3 subfolders:


Directory of c:\D\PLTools\NDI\Oapi-3.0.0.66


Directory of c:\D\PLTools\NDI\Oapi-3.0.0.66\bin

03/19/2016 07:16 PM 73,728 etherlink.dll
03/19/2016 07:16 PM 397,312 oapi.dll
03/19/2016 07:16 PM 53,248 PCIlink.dll

Directory of c:\D\PLTools\NDI\Oapi-3.0.0.66\inc

03/19/2016 07:16 PM 2,355 ndhost.h
03/19/2016 07:16 PM 102,935 ndopto.h
03/19/2016 07:16 PM 7,659 ndpack.h
03/19/2016 07:16 PM 5,435 ndtypes.h

Directory of c:\D\PLTools\NDI\Oapi-3.0.0.66\lib

03/19/2016 07:16 PM 32,508 oapi.lib
#### By Ppandey on 2017-09-13 18:29
The first build error is
Error	1	error C1189: #error :  NDI Error - Host not defined. Options: PLATFORM_X86, PLATFORM_LINUX (C:\PlusLib\bin\PlusLib\src\PlusDataCollection\NDICertusTracking\vtkPlusNDICertusTracker.cxx) [C:\PlusLib\bin\PlusLib-bin\src\PlusDataCollection\vtkPlusDataCollection.vcxproj]	C:\NDIoapi\oapi\include\ndhost.h	157	1	PlusLib

## Moving to GitHub
#### Posted by Andras Lasso on 2017-09-11 22:58

Hi all,

Due to recent price hike of Assembla hosting, we will move Plus project entirely to GitHub and remove users from the Assembla space in about a week.
All source code repositories are already on GitHub and we will move wiki pages and other information in the coming weeks.

See you on GitHub!
https://github.com/PlusToolkit

#### 0 Comments

## Build error
#### Posted by Dzenan Zukic on 2017-09-11 13:55

Just pulling the newest version of PlusLib, causes the below compile errors. Happens on VS2015 x64 and VS2013 x32.
~~~~
3>  EnhanceUsTrpSequence.cxx
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(142): error C2039: 'SetLinesImageFileName': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(143): error C2039: 'GetLinesFrameList': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(143): error C2227: left of '->SaveToSequenceMetafile' must point to class/struct/union/generic type
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(149): error C2039: 'SetShadowImageFileName': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(150): error C2039: 'GetShadowFrameList': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(150): error C2227: left of '->SaveToSequenceMetafile' must point to class/struct/union/generic type
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(157): error C2039: 'GetIntermediateFrameList': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(157): error C2227: left of '->SaveToSequenceMetafile' must point to class/struct/union/generic type
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(163): error C2039: 'SetProcessedLinesImageFileName': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(164): error C2039: 'GetProcessedLinesFrameList': is not a member of 'vtkPlusTransverseProcessEnhancer'
3>  C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\vtkPlusTransverseProcessEnhancer.h(36): note: see declaration of 'vtkPlusTransverseProcessEnhancer'
3>C:\Dev\PlusGit\bin64d\PlusLib\src\PlusImageProcessing\Tools\EnhanceUsTrpSequence.cxx(164): error C2227: left of '->SaveToSequenceMetafile' must point to class/struct/union/generic type
~~~~

#### 4 Comments
#### By Dzenan Zukic on 2017-09-11 13:56
@15bt1 You probably forgot to commit something.
#### By Csaba Pinter on 2017-09-11 14:50
Sorry about that! We were confident that the pull request at least compiled. I fixed the build error in this commit
https://github.com/PlusToolkit/PlusLib/commit/6468f65deb5f3dd2331cbb7666c990a049248c00
#### By Mark Asselin on 2017-09-11 15:12
@pinter Confirmed fixed on VS2017.
#### By Csaba Pinter on 2017-09-11 15:18
Thanks, @markasselin !

## Using Phantom Omni/Geomagic Touch Haptic device with PLUS
#### Posted by sam.horvath on 2017-08-29 12:51

Hi all:

I am planning to use an Omni phantom device (uses the OpenHaptics library) with 3D Slicer. Is it possible to use PLUS to communicate with the device?

#### 4 Comments
#### By Adam Rankin on 2017-08-29 12:55
Not at the moment, no. Haptic device collection has been something our lab has considered, but it has not been a high priority.
#### By Andras Lasso on 2017-08-29 12:59
It should not be difficult to add support for it. We don't have a device to test with, but otherwise we would be happy to help and get it into the toolkit if you implement it.
#### By Sam.Horvath on 2017-08-30 12:32
Ok! I will be working on this over the next week or so and will let you know when I have something ready for you to look at.
#### By Andras Lasso on 2017-08-30 13:47
Sounds good. Let us know if you need any help.

## low "actual" recording frame rate
#### Posted by Golafsoun Ameri on 2017-08-25 18:56

Hi all,

We experienced a low refresh rate when streaming ultrasound in Slicer (via the IGTLink). So we looked into the "actual recording frame rate" of the ultrasound image in fCal. It was around 10 FPS, regardless of the depth or auto-clipping settings in the config file. The requested recording frame rate and maximum recording frame rates are 30 FPS, as shown on the fCal GUI.

I was wondering if you have any suggestion on how to solve it.

Thank you!

#### 2 Comments
#### By Adam Rankin on 2017-08-26 11:08
vtkPlusSonixVideoSource::vtkPlusSonixVideoSourceNewFrameCallback
is being called at the rate indicated on the Sonix console (27 fps @ 9cm)

Continuing investigation
#### By Adam Rankin on 2017-08-28 12:28
Using PlusDeviceSet_fCal_Sim_SpatialCalibration_2.0.xml with

UseOriginalTimestamps="FALSE" and AcquisitionRate="40"

fCal was able to capture at 39.96 FPS

## probe calibration in fCal doesn't seem right in Slicer
#### Posted by Golafsoun Ameri on 2017-08-22 12:08

Hi all,

It looks like the image to probe calibration in fCal is not right in Slicer. Our guess is that this issue has to do with the image origin used by Ultrasonix.I was wondering if you could help with this issue.
Here's what we did:
- calibrated the ultrasound image (from SonixTouch) using fCal (PLUS)
- calibrated a needle using pivot calibration
- used slicer to visualize the ultrasound image and needle, after applying all the required transformations
Problem:
- the ultrasound image pose is not correct (The image does not intersect with the needle model at the right location)

What would you suggest we try to solve this problem?

#### 2 Comments
#### By Andras Lasso on 2017-08-22 17:30
Do you store needle calibration result (StylusTipToStylus) transform in the Plus device set config file or in the Slicer scene?
Does the needle tip in Slicer appear stationary when you are pivoting the needle around its tip?
#### By Golafsoun Ameri on 2017-08-25 18:39
Thank you Andras.
We redid the ultrasound calibration with the following changes in the config file: (1) AutoClipEnabled = "FALSE" (2) set the depth value (UsParameter name="DepthMm" value="90" )
These changes seem to have solved the issue. I will try clipping the image (and keep the depth in the config file) to see if I can get that to work as well. Thanks again:)


## 3D Ultrasound reconstruction using tracked motorized probe
#### Posted by ppandey on 2017-05-29 19:59

Hi all,

We are trying to perform volume reconstruction using a tracked 4DL14-5/38 Ultrasonix probe. We are able to do the reconstruction as the motor sweeps as given in the default 4DL14-5/38 configuration file. We also want the reconstructed volume to extend as we move the tracked probe into different positions (like this video but with a 3D probe).

We are getting the Image in the 'Reference' coordinate frame from PLUS, and then transforming it with ImageToProbe and ProbeToTracker transforms. But when we try to do volume reconstruction the volume is not extended and only the region where the transducer is in that moment is being reconstructed. Any ideas?

Thanks!

#### 113 Comments
#### By Andras Lasso on 2017-05-29 21:04
You need to specify a larger output volume for volume reconstruction. If you use 3D Slicer and PlusRemote module then either move the probe during scout scan to cover the full range of motion; or make the region of interest larger manually after the scout scan is completed.
#### By Ppandey on 2017-06-01 17:50
Hi Andras, I tried the above suggestion but it did not work. Only the volume encompassed by the probe's field of view was being reconstructed. I had to change 'Reference' to 'Tracker':

From
~~~~
ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Reference"
...
<Image Name="Image" EmbeddedTransformToFrame="Reference" />
~~~~

To
~~~~
ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Tracker"
...
<Image Name="Image" EmbeddedTransformToFrame="Tracker" />
~~~~

To reconstruct in the tracker's frame of reference. But this only works for 2D reconstruction and not when the motor is sweeping. I am not sure if I changing EmbeddedTransformToFrame to 'Tracker' is necessary - especially as I am not sure through which marker the image is being transformed to the tracker (ProbeToTracker or StylusToTracker, etc?). Could you shed some light on this?

Thanks
#### By Ppandey on 2017-06-06 02:30
Okay, I had to set in Volume Reconstructor Device

~~~~
ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Tracker"
~~~~

and at the end

~~~~
<Image Name="Image" EmbeddedTransformToFrame="Reference" />
~~~~

My question is, how does the volume reconstructor pick which marker to use to position the image in the tracker's coordinate frame? It can use the 'Probe', 'Phantom' or 'Stylus' markers, but there is no place to define which one it should use (in this case 'Probe').
#### By Andras Lasso on 2017-06-06 08:30
The volume reconstructor creates the volume in the coordinate system you request (ReferenceCoordinateFrame). You are then responsible to show this volume in the correct position in your application, by transforming it by ReferenceCoordinateFrame to RendererWorldCoordinateFrame. You can choose any coordinate system as RendererWorldCoordinate, just male sure any objects you add to the renderer are transformed to that coordinate system.

These are all thoroughly explained in tutorials at www.slicerigt.org.
#### By Ppandey on 2017-06-27 14:21
Okay, thanks. I have a basic question which I cannot find a full answer to in any of the tutorials and documentation. What exactly is the 'Reference' coordinate frame when I set EmbeddedTransformToFrame="Reference". I do not define this coordinate frame anywhere else in the config file, but I can see that it is necessary when I use the 3D motorized probe to see all the image slices from the sweep. When I set EmbeddedTransformToFrame="Probe", for example, I do not get the spatial relationship of each of the image slices during the motor sweep.
#### By Andras Lasso on 2017-06-27 16:49
It defines that the embedded transform in the image message will be ImageToReference transform ("To" component of the transform name is "Reference"; the "From" component is always the image coordinate system).
#### By Ppandey on 2017-06-27 20:07
Yes I understand, but where is "ImageToReference" transform being computed from - is this an ultrasonix transformation that is pre-defined?
#### By Andras Lasso on 2017-06-28 04:58
It is constructed from all the available transforms. For Ultrasonix systems you can configure Plus to automatically compute ImageToProbe, for other systems you just define a fixed ImageToProbe transform in the XML config file. Typically you get ProbeToTracker and ReferenceToTracker from your tracking device. From these, Plus can construct ImageToReference.
#### By Ppandey on 2017-06-28 17:06
What is confusing me is that I have not defined a 'Reference' coordinate frame or ReferenceToTracker anywhere in my config file, so there should be no way that plus should be able to derive the imageToreference transform. Even more confusingly when I use the 3D probe I don't get the correct motor transforms unless I use EmbedTransformToImage=Reference, even when 'Reference' itself does not exist in the config file...
How does PLUS calculate the motor transformations for each slice?
#### By Ppandey on 2017-07-03 19:58
I am trying to reconstruct volumes offline using the 3D probe and PlusRemote in Slicer. However, I need a high resolution volume (spacing = 0.1), which causes PLUS to crash.

Since I am using a 32-bit version of PLUS on an Ultrasonix machine, I decided to follow the advice of using an acquisition plus server on the 32-bit machine and a processing server on the 64-bit machine to achieve high resolution volume reconstruction.
However when I attempt to do this, no data (images or transforms) are sent through by the acquisition PlusServer, and frequently the 32-bit PlusServer crashes when I attempt this. Any idea how to make this work? I am using real hardware instead of a saved data file.

I've attached both my acquisition and processing config files.
PlusDeviceSet_Server_Polaris_Ultrasonix_4DL14-5_Porta-PrashAcquisitionOnly.xml	2.77 KB
PlusDeviceSet_Polaris_Ultrasonix_4DL14-5_Porta-ProcessingServerPrash.xml	3.63 KB
#### By Adam Rankin on 2017-07-03 20:17
The 169.254 address is the self-given address when DHCP fails. I'm not sure if it works as a local loopback. Try changing this to 127.0.0.1 (assuming it's on the same machine)
#### By Ppandey on 2017-07-03 20:41
The two computers are connected by an ethernet cable, but despite this using the 127.0.0.1 address does not allow the processing server to connect.

Would it make more sense to have the servers on the same machine? I was thinking that having them on different machines would allow the volume reconstruction to work faster
#### By Adam Rankin on 2017-07-03 20:58
If you have multiple computers, do not use 127.0.0.1, you will have to assign each machine an IP address (or connect them to a router so that they receive a DHCP ip address). Then, enter the ip address of the capturing machine in the config of the reconstruction machine.

I don't know if the Microsoft no DHCP addresses auto negotiate between connected computers.
#### By Ppandey on 2017-07-03 21:03
Yes, I have previously used 169.254 addresses before when using Plus between two computers connected with ethernet, so I don't think that's the problem.
#### By Adam Rankin on 2017-07-03 21:25
Ok, just making sure.

Can you upload the logs for a run where it crashes? Can you describe when/how it crashes (ie.: right after you click reconstruct, etc...)
#### By Ppandey on 2017-07-03 22:47
Unfortunately, PLUS crashes when I try to collect logs higher than the 'Info' level. I will upload the info log soon, but mostly the logs state that no data is being received when connected to the acquisition server.

The crash is not always repeatable, and it results in the blue screen of death. The acquisition computer (an Ultrasonix machine), slows down significantly when the processing computer connects to the acquisition Plus Server. It then sometimes crashes.
The main issue is that I can see in Slicer that data is not being sent, when I use OpenIGTLink and examine the connector.
#### By Andras Lasso on 2017-07-03 22:56
That crash related to logging has been fixed some time ago. Use the nightly builds.
#### By Ppandey on 2017-07-04 13:12
Here are the debug logs from both acquisition and processing servers.
070417_100442_PlusLog.txt	642 KB
070417_100140_PlusLog.txt	977 KB
#### By Adam Rankin on 2017-07-04 13:21
It appears that both of these instances are 32 bit processes. Could you confirm that your reconstruction is running with 64 bit Plus?
#### By Ppandey on 2017-07-04 13:44
Yes, sorry, I used the wrong server. Here is the acquisition debug log from the 32-bit server.
070417_103154_PlusLog.txt	2.45 MB
#### By Ppandey on 2017-07-04 13:46
And this is the debug log from the 64-bit processing server
070417_104055_PlusLog.txt	12.5 KB
#### By Adam Rankin on 2017-07-04 13:54
Ah I see, I misread. The 32 bit server is crashing.

I can see why, it looks like an increasing number of clients are connecting. PlusServer will try to send frames to each one. This will cause a slow decay in performance and an eventual out-of-memory crash.
#### By Ppandey on 2017-07-04 14:25
I've also tried setting ReconnectOnReceiveTimeout="FALSE" in the processing config file to prevent multiple client connections, and also increasing ReceiveTimeoutSec="5", but this does not work either, and no messages are being sent.
#### By Andras Lasso on 2017-07-04 19:17
We'll investigate this and give you an update by the end of the week.
#### By Ppandey on 2017-07-11 04:25
Any updates on this?
#### By Andras Lasso on 2017-07-11 10:24
I need a bit more time.
#### By Andras Lasso on 2017-07-16 19:55
Please try with today's nightly build. A related issue has been fixed (#1212).
#### By Ppandey on 2017-07-24 12:56
I can't seem to access the nightly builds, am I looking in the wrong place?
http://perk-software.cs.queensu.ca/plus/packages/nightly/
#### By Andras Lasso on 2017-07-24 14:37
Sorry for the inconvenience, there was a university-wide network connectivity issue. The problem has been mostly resolved now, so the nightly build should be generated correctly by tomorrow morning.
#### By Ppandey on 2017-07-25 20:24
Thanks, I managed to try today's nightly build. Unfortunately the above issue isn't fixed, and in fact the volume reconstructor does not work as it did before:

Working with the Sim_NwirePhantom configuration file as an example, the volume is no longer reconstructed in the correct coordinate reference, and its exact position is affected by the output spacing value (it seems as though scaling is being applied to the reconstructed volume incorrectly). I tried the same reconstruction task with a previous build (2.5.0.20170628 - Win 64) and it works as expected.
#### By Andras Lasso on 2017-07-25 23:08
Do you use it with the latest nightly version of Slicer?
#### By Ppandey on 2017-07-26 13:23
Yes I tried it with the latest nightly version of Slicer, and I am getting the same error as before for acquiring and processing data with two PLUS servers:
|WARNING|084.405000|SERVER> No data is broadcasted, as no data is available yet.| in :\D\PTNP64b\PlusLib\src\PlusServer\vtkPlusOpenIGTLinkServer.cxx(397)

In addition to the volume reconstruction not working as expected, I have found that the Polaris tracker that I am using is no longer being recognized as a tracking device by the latest nightly version of PLUS
#### By Adam Rankin on 2017-07-26 13:26
Please post the full log
#### By Ppandey on 2017-07-26 13:35
Here are the logs for the acquisition and processing server problem
072617_103125_PlusLog.txt	3.42 MB
072617_103136_PlusLog.txt	1.07 MB
#### By Ppandey on 2017-07-26 13:41
Here is the log for the tracker no longer being detected. I have double checked it is connected to the correct COM port
072617_103812_PlusLog.txt	14.2 KB
#### By Adam Rankin on 2017-07-27 12:02
Beginner question, does the device work with NDIs track?

I tested with our polaris and our vicra and both are working as expected.

Adam
#### By Ppandey on 2017-07-27 14:28
This is a fairly old Polaris system, and I don't have access to NDI track, however the Polaris is recognized by Tool Viewer. I know that it doesn't work with some of the newer NDI software, although plus had been previously working with it.
#### By Adam Rankin on 2017-07-27 14:30
Hmm, it may be worth a firmware update. What OS are you using?
#### By Ppandey on 2017-07-27 14:35
I am using windows 7. i had previously tried to remedy this problem, but unfortunately even NDIs firmware update software could not recognize the Polaris...
NDI support didn't have any further suggestions to fixing the issue.

you had earlier stated that the new PLUS fix is not necessarily going to fix the issue at hand as you had a colleague who did acquisition and processing on separate servers?
#### By Adam Rankin on 2017-07-27 14:40
It's possible that now we're using a command that isn't supported on the old firmware.

Are you willing to try again to update your firmware?
NDI_Toolbox_4_007_007.exe	30.6 MB
#### By Ppandey on 2017-07-27 14:44
I am willing to try again but to the best of my knowledge I have exhausted possible ways of doing so.
#### By Adam Rankin on 2017-07-27 14:45
First question, does your polaris have a serial or USB cable coming out of it?
#### By Ppandey on 2017-07-27 14:47
Serial cable, but I'm then using a serial to USB adapter to connect to the ultrasonix machine
#### By Adam Rankin on 2017-07-27 14:48
Is the ultrasonix Windows embedded? What's the make and model of the adapter?
#### By Ppandey on 2017-07-27 14:51
Yes it's windows embedded . The adapter is https://www.amazon.ca/dp/B00J4N9T9C/ref=pe_386430_121528420_TE_d
#### By Adam Rankin on 2017-07-27 14:52
Sorry, is it windows 7 or windows xp embedded?
#### By Ppandey on 2017-07-27 14:52
Windows 7
#### By Adam Rankin on 2017-07-27 14:53
Ok, and you've got an entry under Ports in Device Manager?
#### By Ppandey on 2017-07-27 14:55
Yes the drivers are installed correctly and recognized in device manager
#### By Adam Rankin on 2017-07-27 14:55
Ok, with the toolbox installed (see attachment above), launch Configure
#### By Adam Rankin on 2017-07-27 14:59
Does it auto connect to your device? If so, what combined firmware revision do you see? If not, go to Utilities->Console, then File->Trace Communications and File->Log to File
#### By Ppandey on 2017-07-27 15:33
Sorry, I am not with the machine at the moment - do you mind posting the full instructions and I will try it tomorrow?

I have tried the toolbox before, and I know that the firmware revision is 021.003 and the combined revision is 022.
#### By Adam Rankin on 2017-07-27 15:40
Hmm, 22 should be more than recent enough.

It would be helpful to see how your machine co-operates with Configure (app name). If it can query the necessary values, than Plus should be able to as well.
#### By Ppandey on 2017-07-27 15:43
Okay, I will try that tomorrow and get back to you. Which values exactly should it be able to query?
#### By Adam Rankin on 2017-07-27 15:48
Param.Firmware.CurrentVersion

Depends where the connect call is failing
#### By Ppandey on 2017-07-28 12:31
Okay, configure automatically recognizes the Polaris when started, but cannot query using the above command in the terminal.
Capture.PNG	25.7 KB
#### By Ppandey on 2017-07-28 12:38
And when using Track the system is recognized, but fails to track any of the tools.

I am using NDI ToolBox version 5

Edit: When I use ToolBox version 4, Track can track all the connected tools but the above command is still not recognized by Configure
#### By Adam Rankin on 2017-07-28 12:43
Can you do Console, Trace Communications?

Then, in configure, navigate to
~~~~
<Polaris>
<Features>
~~~~

Are all the values populated?

Could you paste the log from trace communications? (Or upload the file if you have Log to File enabled)
#### By Ppandey on 2017-07-28 12:49
All the values are populated, log attached.
PolarisConfigureLog.txt	1.6 KB
#### By Adam Rankin on 2017-07-28 12:49
Param.Firmware.CurrentVersion is not a command.

The full command would be GETINFO:Param.Firmware.CurrentVersion<CRC16>

If you look at the traced communications, you will see all of the underlying API calls. In toolbox 5, you will probably have to load the ROM file.
#### By Adam Rankin on 2017-07-28 12:51
That doesn't seem to be a complete log. It should start with

~~~~
Connecting to Polaris Vega (/192.168.0.101:8765)
>>APIREV 
<<G.003.0026239
>>send serial break
>>send serial break
>>send serial break
!!
>>VER:4A6EF
<<Polaris Vega Control Firmware
NDI S/N: P9-00312
Characterization Date: 05/26/17
Freeze Tag: Polaris Vega 008.003
Freeze Date: Jun 28 2017
(c) Northern Digital Inc.
CD9B
>>VER:5662E
<<0031A54
>>GETINFO:Config.*1110
<<Config.Combined Firmware Revision=003;3;1;0;8;;Combined firmware revision of the product
...
~~~~

Or similar
#### By Ppandey on 2017-07-28 12:58
How about this

~~~~
<<RESETBE6F
>>APIREV 
<<ERROR016BC2
!!
>>VER:4A6EF
<<Polaris Control Firmware
NDI S/N: P4-00019
Characterization Date: 03/05/99
Freeze Tag: POLARIS Rev 021.003
Freeze Date: 07/22/03
(C) Northern Digital Inc.
0AEA
>>COMM 50001
<<OKAYA896
>>VER:5662E
<<022BA94
>>GETINFO:Config.*1110
<<ERROR016BC2
Error 0x1 in command ndi.io.command.GetInfoCmd: Invalid command.
  COM9: command='GETINFO:Config.*1110
'
>>INIT:E3A5
<<OKAYA896
>>PHSR:0020FF
<<010100101AF
>>PINIT:0131EA
<<OKAYA896
>>PHSR:0020FF
<<010101191AE
>>PHINF:01003DD86D
<<02010001NDI         0023499CC01118700229             3108P4-00019000100704F
>>SENSEL:0601C
<<31540
>>VER:4A6EF
pkg=ndi.io.command
<<Polaris Control Firmware
NDI S/N: P4-00019
Characterization Date: 03/05/99
Freeze Tag: POLARIS Rev 021.003
Freeze Date: 07/22/03
(C) Northern Digital Inc.
0AEA
>>SFLIST:01918E
<<31540
>>SFLIST:0290CE
<<912C0
>>SFLIST:05528F
<<912C0
>>SFLIST:03500F
<<10+050000+000000+000000-190000+000000+000000+000000+000000+000000+000000210B2E7
>>SSTAT:00077EC1
<<000000EF5E
>>SSTAT:00077EC1
<<000000EF5E
>>GETINFO:Features.Volumes.Index.*F3AA
<<ERROR016BC2
Error 0x1 in command ndi.io.command.GetInfoCmd: Invalid command.
  COM9: command='GETINFO:Features.Volumes.Index.*F3AA
~~~~

#### By Adam Rankin on 2017-07-28 13:01
Ok, so this is the issue:

~~~~
Error 0x1 in command ndi.io.command.GetInfoCmd: Invalid command.
COM9: command='GETINFO:Config.*1110
'
~~~~

I'm not sure why, but your unit does not support the GetInfo command. Would you be willing to try to flash the newest firmware?
#### By Adam Rankin on 2017-07-28 13:11
That shouldn't be a problem though... are you specifying a MeasurementVolume?
#### By Adam Rankin on 2017-07-28 13:13
Ah, I see that. I'll see if I can workaround a missing GETINFO command.
#### By Adam Rankin on 2017-07-28 13:15
Also, is your unit a spectra, or vicra, or... ?
#### By Andras Lasso on 2017-07-28 13:53
Adam, we would need to make the NDI interface work with existing trackers, without messing with the firmware. Polaris interface has been working perfectly until recently and users don't have any reason to change their hardware or firmware to make Plus work with it (in many cases users cannot afford take the risk of changing firmware).
#### By Adam Rankin on 2017-07-28 13:57
Yes, I know, I am coding up the fallbacks
#### By Ppandey on 2017-07-28 14:14
Thanks for all the help so far! It's neither a spectra or a vicra, it's from before those models were available...
#### By Adam Rankin on 2017-07-28 14:16
Yes! I just reached out to NDI support to clarify what the different firmware revisions meant and they clarified for me that the "Polaris" device is a precursor to both the Polaris Spectra/Vicra.

So, that makes sense why the GETINFO command isn't available. I will commit the fallback code shortly.
#### By Ppandey on 2017-07-28 18:49
Going back to the question of ultrasound reconstruction - is there a way to pause and resume acquisition in plus or slicer so that any probe movements from one part of anatomy to another can be left out of the reconstruction?
#### By Andras Lasso on 2017-07-28 18:57
PlusServer supports suspend/resume of volume reconstruction but we did not add buttons for that because in practice we have never needed it. If you reconstruct disjoint regions then it's better to create two small separate volumes with relevant content than one big volume with large empty regions. If you are considering scanning the same region from multiple directions then often the reconstruction result is not as nice as from a single sweep (due to many reasons; I can explain it in more details if needed). If you give some more information about your workflow and clinical need then we can give more specific advice.
#### By Ppandey on 2017-07-28 19:04
Is there a way to merge two small separate reconstructed volumes while keeping their spatial relationship? We want to essentially acquire 3D scans from a few different anatomical locations which are not next to each other, and each of which is from a single sweep.
#### By Andras Lasso on 2017-07-29 21:35
Yes, all reconstructed volumes are recorded in their correct spatial location (in the specified reference coordinate system). You can easily merge them into a single volume but it is much more efficient to process them separately.
#### By Ppandey on 2017-07-29 21:56
I agree about the efficiency in processing separately, but what is the way to merge volumes in slicer/plus?
#### By Andras Lasso on 2017-07-29 22:09
You can very easily merge them into a single volume. Use vtkImageReslice to pad&resample both volumes on the same grid and then use vtkImageMathematics to combine them into one image.
#### By Ppandey on 2017-08-04 13:11
Any updates on the Polaris issue or the acquisition/processing server communication issue?
#### By Andras Lasso on 2017-08-04 13:13
Changes related to Polaris communication has been integrated recently, so please try today's development snapshot and let us know if it works.
#### By Ppandey on 2017-08-09 17:03
The polaris is still unable to communicate with PLUS. Here are the logs for two config files that I tried (one is the default Polaris config file).
080917_140028_PlusLog.txt	8.61 KB
080917_135856_PlusLog.txt	19.5 KB
#### By Adam Rankin on 2017-08-09 17:17
Are you able to build your own plus to help me debug? We do not have an original polaris to test with.
#### By Ppandey on 2017-08-09 17:27
I am willing to build it, but unfortunately I am not a developer so it may take some time for me to some concepts. I am also working on a windows ultrasonix machine, can I just follow the windows build instructions?
#### By Adam Rankin on 2017-08-09 17:51
Nevermind, read post above. If you install the x86 version of

https://www.microsoft.com/en-ca/download/details.aspx?id=48145

you will be able to run the packages I create. (it may already be installed)
#### By Ppandey on 2017-08-09 18:15
Okay, I will install Visual C++. Yes it's windows 7
#### By Ppandey on 2017-08-10 13:40
The machine has Visual C++ 2008 - will that be sufficient or should I install 2015?
#### By Adam Rankin on 2017-08-10 13:56
Are you referring to the development IDE or the redistributable?

I only need you to install the redistributable for 2015 (x86) from the link above
#### By Ppandey on 2017-08-10 15:24
Okay, I've installed the x86 2015 redistributable from the link above.
#### By Adam Rankin on 2017-08-10 16:01
Ok, I've added a bit more debug output. Can you try again with
http://perk-software.cs.queensu.ca/plus/packages/nightly/PlusApp-2.5.0.20170722-Ultrasonix-5.7-Win32.exe

and upload the log
#### By Ppandey on 2017-08-10 16:17
Sorry I should have mentioned that the machine is sdk 6.x and 64-bit. Does that make a difference?
#### By Adam Rankin on 2017-08-10 16:24
Oh cool, I didn't know the sdk 6.x supported 64.

Yeah install whichever one works for your setup
#### By Andras Lasso on 2017-08-10 17:40
We used Ultrasonix 6.x SDK on 64-bit systems but the SDK itself was 32-bit. Probably it's the case here, too. 32-bit Plus application running on a 64-bit OS.
#### By Adam Rankin on 2017-08-10 17:43
Ah right, that makes more sense. Yes, install the ultrasonix6-win32 version.
#### By Ppandey on 2017-08-14 14:18
When I tried the most recent nightly version, the polaris device seems to be working again when I use it with my own config file (see first log). It doesn't work with the "NDI Polaris with passive markers" config file provided with PLUS (see second log); it gives the warning that there is no data available to stream.
081417_110106_PlusLog.txt	5.11 MB
081417_110831_PlusLog.txt	3.6 MB
#### By Ppandey on 2017-08-14 14:36
Before I mentioned the Polaris issue, I had above mentioned an issue with the volume reconstructor. That issue still seems to be present (incorrect placing and scaling of the reconstructed value, which changes with the output spacing value I input).

Are you able to reproduce this issue?
#### By Adam Rankin on 2017-08-14 17:12
I improved the debug output for binary replies, which will let me know if your machine is giving proper replies but slowly, or if something else is messed up.

Note, the attached build is only for testing NDI devices.
PlusApp-2.5.0.20170807-Win32.exe	62.2 MB
#### By Adam Rankin on 2017-08-18 10:17
@ppandey Sorry I was just able to get around to this.

Confirmed the inability to send frames between plus IGT devices

https://app.assembla.com/spaces/plus/tickets/1224-vtkplusopenigtlinkvideosource-not-sending-embedded-image-transform-name-in-trackedfr/details
#### By Adam Rankin on 2017-08-18 10:43
See also https://app.assembla.com/spaces/plus/tickets/realtime_list?ticket=1225
#### By Ppandey on 2017-08-18 15:37
@rankin Okay, thanks! Looks like you've fixed the TRACKEDFRAME issue so I will test it on Monday with the nightly version. I will also do the Polaris debugging then.

With ticket #1225, are you doing the volume reconstruction with a separate 64-bit server? Have you tried the volume reconstruction with a single server?
#### By Adam Rankin on 2017-08-18 16:25
Just the 32->64 reconstruction
#### By Ppandey on 2017-08-21 11:48
When I attempt to run Plus Server or Plus Server Launcher from the nightly 32 or 64 bit releases, I get the error that the aruco2019.dll is missing and the application does not run.
#### By Andras Lasso on 2017-08-21 12:00
@rankin - I know that ArUco packaging solution was not nice (we optimized for minimizing ArUco library changes) and worked only on Windows, but now it seems to be broken on Windows. Could you please fix it or let us know if you don't have time for this right now and then we try to fix it? Thanks!
#### By Adam Rankin on 2017-08-21 12:04
I changed aruco two weeks ago, was it then? If so, simplest to revert plus build to 9c454016eb330d7be0ed8dd51d76040b05f1e447 for aruco
#### By Andras Lasso on 2017-08-21 12:09
I haven't tested packaging since two weeks ago and at that point you removed installation of ArUco dll from PlusApp, so most likely that was the issue. What would we lose by reverting your changes vs. fixing them (or just adding manual installation of missing .dlls)?
#### By Adam Rankin on 2017-08-21 12:11
Aaahhh yes shit.

Lose nothing. Revert them and we will make sure the new release of aruco works later.
#### By Ppandey on 2017-08-21 12:31
@rankin I can confirm the trackedframe issue has been resolved and I can send data between two servers with actual hardware acquisition (will later try 32->64 reconstruction when the aruco issue has been resolved). I can see for now that 32->32 volume reconstruction does not work as intended for both offline and live reconstruction.
#### By Andras Lasso on 2017-08-22 17:55
Tomorrow's Plus package should be functional. Thanks to @rankin for the fix.
#### By Ppandey on 2017-08-23 17:07
Looks like the nightly Win64 package was not built/uploaded today.

@rankin could you also rebuild me the NDI debug package (the one you linked above) with the aruco issue fixed?
#### By Adam Rankin on 2017-08-23 17:42
The nightly packages have the extra debugging output included in them. If you could run with the latest and upload the log.
#### By Andras Lasso on 2017-08-23 17:54
I had to make some space on the build computer. The 64-bit package should appear within a few hours or latest by tomorrow morning.
#### By Ppandey on 2017-08-23 19:23
I cannot run the nightly Plus Server;; I get the error that VCOM120.dll is missing. I searched for this file but couldn't find it on the system - any idea how to solve this?
#### By Adam Rankin on 2017-08-23 19:36
That DLL is from VS2013 redistributable. Could you try reinstalling it?

https://www.microsoft.com/en-us/download/details.aspx?id=40784
#### By Andras Lasso on 2017-08-23 23:18
I've tuned the package generation to include this missing vcomp120.dll, it should work in tomorrow's nightly build. Till then you can install the VS2013 redistributable package as Adam recommended above.
#### By Ppandey on 2017-08-24 12:25
Thanks! I tried out the nightly and the polaris is now working fine. Here is a log in case it is helpful.
082417_091802_PlusLog.txt	15.1 MB
#### By Andras Lasso on 2017-08-25 13:02
Great news! Thanks for letting us know.

## Broken link in manual
#### Posted by Dzenan Zukic on 2017-08-17 15:23

At the bottom of this page, a link to publications is broken.

#### 1 Comments
#### By Andras Lasso on 2017-08-17 17:04
Thanks for reporting - I've committed a fix. The correct link is: http://perk.cs.queensu.ca/contents/open-source-surface-mesh-based-ultrasound-guided-spinal-intervention-simulator

## MM7150 Interfacing with PLUS
#### Posted by sonja.pejcic on 2017-08-09 18:30

Hi,

We are looking to use the MM7150 for tracking, and are trying to figure out how best to interface it. Ideally we would like to use an Arduino microcontroller, but there does not seem to be any code development for this. Do you have any advice for how we should interface the MM7150 with plus? Thank you!!

#### 6 Comments
#### By Adam Rankin on 2017-08-09 18:38
Do you have the chip currently working with an Arduino? If so, you could forward the transforms out the serial port via TX0 and RX0 of the arduino to a connected computer. Then, you could use the generic serial device (or write your own that subclasses the generic serial device) to communicate with the arduino.
#### By Sonja.Pejcic on 2017-08-09 18:43
We don't have it working currently with Arduino - do you recommend we pursue working with Arduino or should we try a different microcontroller?
#### By Andras Lasso on 2017-08-09 19:07
I would recommend to hook it up with an Arduino. If it's a good and widely used component then you should be able to find a readily available solution to interface it with an Arduino.

Another option is to use one of the IMU or MARG sensors that Plus already has built-in support for (sensor fusion is provided for all of them):
Phidgets Spatial 3/3/3 magnetic, angular rate, and gravity (MARG) sensor
CHRobotics CHR-UM6 magnetic, angular rate, and gravity (MARG) sensor
Microchip MM7150 magnetic, angular rate, and gravity (MARG) sensor

(see more details at http://perk-software.cs.queensu.ca/plus/doc/nightly/user/Devices.html)
#### By Sonja.Pejcic on 2017-08-09 19:15
Okay thank you! To clarify, what would the hardware connection between the MM7150 and Plus be?
#### By Adam Rankin on 2017-08-09 19:19
Their example code is written in c for their own microcontroller. You could adapt their code to use common Arduino libraries.
#### By Adam Rankin on 2017-08-09 19:21
Mm7150->i2c pins->arduino->usb serial->plus

## 'Stylus calibration configuration missing' error
#### Posted by tejas.s.mathai on 2017-08-08 17:56

Hello,

We are trying to calibrate a DIASUS ultrasound probe using the Epiphan frame grabber and the Micron tracker. We successfully built the fCal application in PLUS in 64-bit Windows (with Micron tracker). We set up our instruments for calibration -- the N-wire phantom, stylus, ultrasound probe, markers, Micron tracker, and the Epiphan framegrabber -- and ran the fCal application. All the devices were able to connect, and the three status boxes for 'ProbeToTracker', 'ReferenceToTracker', and 'StylusToTracker' display 'OK' as the status.

However, when we move on to 'Stylus calibration' tab, we are unable to proceed because we get the following error -- "Stylus calibration configuration is missing'. We have set our calibration file with the stylus, but fCal does not seem to read/recognize it. The calibration file is attached, along with error screenshots. We are unsure how to proceed with fixing this error, and we would appreciate some help?

Thanks,
Tejas
fCaldevicesconnected.png	62.5 KB
PlusConfiguration_Epiphan_MicronTracker_VIALab.xml	7.17 KB
fCalstyluscalibrationmissing.png	56.8 KB

#### 1 Comments
#### By Tejas.S.Mathai on 2017-08-08 18:07
We realized that the error we were seeing was due to naming the pivot calibration algorithm in the xml with an older (deprecated?) name. Updating that name from 'vtkPivotCalibrationAlgo' to 'vtkPlusPivotCalibrationAlgo' solved the problem. I assume that we will have to do the same with other algorithm names as well.


## Phantom coordinate systems 2.0 vs. 2.1
#### Posted by gregorij on 2017-08-07 11:21

I was wondering if the coordinate system is different for phantom v. 2.1 than 2.0. I was looking at the example configurations given at the download links for the phantom:
https://app.assembla.com/spaces/plus/subversion/source/5112/trunk/PlusModelCatalog/fCalPhantom/fCal_2/PhantomDefinition_fCal_2.1_Wiring_2.0.xml
https://app.assembla.com/spaces/plus/subversion/source/5112/trunk/PlusModelCatalog/fCalPhantom/fCal_2/PhantomDefinition_fCal_2.0_Wiring_2.0.xml

From this it looks like the y & z coordinates are swapped for version 2.1 vs 2.0. The wiki mentions that the hole positions are the same between the two but there is no mention of the coordinate systems being changed. I just wanted to confirm this because I was getting incorrect detection when using 2.1 wiring configuration where the labeling seemed to have assumed that the image was rotated for 90 degrees. It's possible that I'm misinterpreting some of the parameters for segmentation. Is there an explanation what the parameters do?

#### 1 Comments
#### By Gregorij on 2017-08-08 17:51
I have determined the issue with the incorrect wire labeling. My raw ultrasound stream was generating images with different aspect ratio of the pixels (different scale in vertical vs horizontal directions). That was incorrectly interpreted by the segmentation algorithm as the image being rotated since the spacing between the vertical and horizontal wires looked as if it was flipped.

## Error in mha_write_volume.m
#### Posted by Colleen.Ogilvie on 2017-07-31 15:49

Hi Plus team!

I’m trying to use the function mha_write_volume.m to create a tracked sequence of 2D ultrasound images that I would like to then reconstruct with VolumeReconstructor.exe.

When I read ElbowUltrasoundSweep.mha using mha_read_volume, and then use mha_write_volume on the same data, I’m losing the transforms in my output .mha file. I have noticed that the code for the mha_write_volume.m file does not have cases in the switch loop for any of the transform fields. I’ve tried editing the code to write the transforms into the output mha file, but so far have been unsuccessful in getting the written file to run in VolumeReconstructor.exe.

The error I get in VolumeReconstructor.exe is “|ERROR|000.026000| No reader for file: july31.mha| in ..\..\...
Is it possible to write an .mha that maintains the transforms and could be used for volume reconstruction?

Thank you!
plusvolumereconstructionerror.png	37.5 KB

#### 7 Comments
#### By Andras Lasso on 2017-08-01 23:47
Check out nrrdread.m/nrrdwrite.m at https://subversion.assembla.com/svn/slicerrt/trunk/MatlabBridge/src/MatlabCommander/commandserver - they may do a better job in preserving metadata. Of course you need to save your data as nrrd or convert to need using seqfileeditor tool.
#### By Colleen.Ogilvie on 2017-08-03 16:05
Hi Andras,

Is this the tool you are referring to: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationEditSequenceFile.html ?
How do you convert from mha to nrrd?

Can VolumeReconstructor.exe read .nrrd files?

Thanks!
#### By Andras Lasso on 2017-08-03 16:07
> Is this the tool you are referring to: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationEditSequenceFile.html ?

yes

> How do you convert from mha to nrrd?

Enter .nrrd as extension for the output file.

> Can VolumeReconstructor.exe read .nrrd files?

yes
#### By Colleen.Ogilvie on 2017-08-04 13:23
Thanks Andras!

I tried converting the sample file to ElbowUltrasoundSweep.mha to ElbowUltrasoundSweep.nrrd in the sequence file editor tool, and then reconstructing it in volume reconstructor, and it works well. However, when I try to open ElbowUltrasoundSweep.nrrd in Matlab using nrrdread.m, I get the following error:

Error using reshape
To RESHAPE the number of elements must not change.

Error in nrrdread (line 104)
axes_directions=reshape(sscanf(img.metaData.space_directions,'(%f,%f,%f) (%f,%f,%f) (%f,%f,%f)'),3,3);

Error in nrrdsamplescript (line 6)
data = nrrdread('ElbowUltrasoundSweep.nrrd')

I've also attached a screenshot. Is there something I can do to fix this?

Thanks again!
nrrdreshapeerror.png	72.4 KB
#### By Andras Lasso on 2017-08-04 15:49
Could you please copy here the header of the nrrd file (first few ten lines of the file)?
#### By Colleen.Ogilvie on 2017-08-04 17:00
Also, as a follow up to the question about mha_read_volume.m, do you have any sample data for the functions mha_read_volume.m and mha_write_volume.m that I could use to test the functions on my computer?
#### By Colleen.Ogilvie on 2017-08-07 18:16
Hi Andras,

Here is the header of the file ElbowUltrasoundSweep.nrrd:

NRRD0004
Complete NRRD file format specification at:
http://teem.sourceforge.net/nrrd/format.html
File generated by PLUS version 2.4.0
dimension: 3
encoding: raw
endian: little
kinds: domain domain list
sizes: 820 616 40
space dimension: 2
space directions: (1,0) (0,1) none
space origin: (0,0)
type: uint8
ultrasound image orientation:=MFA
ultrasound image type:=BRIGHTNESS
ElbowUltrasoundSweep.nrrd	19.3 MB


## fCal - Segmentation Parameter Dialog crash
#### Posted by gregorij on 2017-08-03 16:57

Hello!

I'm trying to perform the calibration of the spatial calibration of the probe. All the previous steps have been done. When I try to run the spatial calibration, the ultrasound image appears in the window. However, when I try to open the dialog to edit the segmentation parameters, fcal crashes immediately. If I remove the Segmentation section all together from the xml file, then the dialog will appear, however it does not allow me to save the parameters (nothing happens when clicking save). I have tried running the example 'PlusDeviceSet_fCal_Sim_SpatialCalibration_2.0.xml' and there the dialog there appears and everything works fine. I'm using nightly build 'PlusApp-2.5.0.20170722-Win64'.
Attached is my XML configuration and the log file where fcal crashed when segmentation parameter dialog was opened.
ezono_phasespace_probe_registration.xml	9.12 KB
080317_135027_PlusLog.txt	328 KB

#### 14 Comments
#### By Adam Rankin on 2017-08-03 16:58
I will investigate
#### By Andras Lasso on 2017-08-03 17:22
Is it a crash or a hang? If there are many potential fiducial point candidates then the user interface may slow down or temporarily hang. Try to reduce dynamic range, decrease gain, increase threshold to reduce the number of point candidates.
#### By Gregorij on 2017-08-03 17:31
It is a crash. A dialog pops up that the application has crashed and Windows gives you option to debug or close. The debug points out to access violation reading memory location.
I have tried to reduce the ROI to just a dark region of the image, reduce gain to perhaps avoid an issue with large number of candidates etc. as one of the posts noted. It doesn't seem to make a difference.
As I mentioned if I remove the Segmentation tags all together, the dialog will open. If I write down the parameters that seem to work there and put them back into the Segmentation section of the XML, it still crashes on opening the window.
#### By Andras Lasso on 2017-08-03 18:11
Thank you, these are all useful information. Can you reproduce the crash with the spatial calibration sample configuration file that is included in the install package?
#### By Andras Lasso on 2017-08-03 18:16
Adam, have you been able to reproduce the issue?
#### By Gregorij on 2017-08-03 18:29
The crash doesn't happen with the sample file when opening the dialog. [Once the dialog is open, certain combo of parameters may cause the crash even there but that may be a different issues.] In my case, I was wondering if the reason could be in terms of the image size and initial ROI. My US image relatively small, about 240x360, while the example image has much higher resolution. If for some reason the parameters are initialized for a larger image until they get read in from the configuration, that could cause memory reading violation. I don't know if this is in any way related but the log has one error entry:
080317_135038.155|ERROR|010.707000| Render window unavailable when trying to render 2D image.| in D:\D\PTNP64b\PlusApp\fCal\vtkPlusImageVisualizer.cxx(319)
It seems something is getting rendered before things are ready. Unfortunately I don't have the code compiled yet to be able to further debug this.
#### By Adam Rankin on 2017-08-03 19:06
No, mine appears to work fine.

That error is because we re-purpose the vtk renderer from the main fCal window in the segmentation editing dialog.

I will try with a small image.
#### By Adam Rankin on 2017-08-03 19:37
I cropped our sample data file to those dimensions, and using the same parameters as you I experience no crash.
#### By Gregorij on 2017-08-04 12:38
Thanks for checking! I will record a sequence today and test if the loaded sequence from these devices also causes the crash. In the mean time, I'm compiling the code so hopefully I can debug the issue on my end as a fall back.
#### By Gregorij on 2017-08-04 13:47
It looks like the error happens in this line 1525 of QPlusSegmentationParameterDialog.cxx:
double spacing = (ui.doubleSpinBox_ReferenceWidth->text().toDouble() + ui.doubleSpinBox_ReferenceHeight->text().toDouble()) / m_SpacingModeHandler->GetLineLengthSumImagePixel();

m_SpacingModeHandler is NULL and it crashes the application.
#### By Gregorij on 2017-08-04 14:11
It appears that ComputeSpacingFromMeasuredLengthSum() is getting called on the initialization of the dialog (by one of the onchange dialog handlers), although spacing mode is not enabled and ROI mode is the default one. m_SpacingModeHandler. m_SpacingModeHandler gets created only on SwitchToSpacingMode(). For now, I have solved this by checking for m_SpacingModeHandler for NULL and defaulting to 0.0078 for spacing variable if NULL. I'm not sure why the issue appears only with my recording but not the example, perhaps some set of parameters triggers onchange callback. In any case, I'm attaching my recording data, if it's helpful to further debug things on your end (disregard the bad quality of the image stream).
ezono_sequence.mha	6.93 MB
ezono_sequence.mha_config.xml	9.15 KB
ezono_phasespace_probe_registration_from_file.xml	7.48 KB
#### By Adam Rankin on 2017-08-04 14:34
Thanks for debugging! I'll add you your null guards and make sure everything is initialized properly.
#### By Gregorij on 2017-08-04 18:08
Thanks for the support! By the way, the interface for the parameter editing seems to be a bit buggy as it doesn't always check if the parameters are within the valid ranges. For example, it is possible to set the origin of the ROI to 1,1 (manually with a mouse or in XML) and sometimes this will cause an error inside MorphologicalOperations() where the erode function will throw read access violation (I guess because of how image edges are handled with respect to the barSize). Similarly if one adjusts the bar size form the interface, too small or too big values will also cause a read violation.
#### By Adam Rankin on 2017-08-04 18:32
I was able to reproduce the crash. The <PhantomDefinition> configuration in the config file you gave me produces a maxZ - minZ that is not the same as the default value, thus triggering a OnReferenceHeight changed. When the value from the phantom configuration is the same as the default, OnReferenceHeight is not triggered because Qt detects that the value hasn't changed.

Sadly this is also a chicken and egg problem as the spacing mode handler needs the reference height and width values to properly initialize. So, disabling signals during read configuration!


## Publicly available ultrasound volumes
#### Posted by Dzenan Zukic on 2017-08-01 11:24

Are you aware of any public repositories of ultrasound volumes? I need one or more 3D ultrasounds of the abdomen. If there aren't any publicly available, maybe you have a few private ones willing to share? @lassoan @ungi @rankin @pinter

#### 6 Comments
#### By Adam Rankin on 2017-08-01 11:31
I wish, let me know if you find any.
#### By Andras Lasso on 2017-08-01 14:14
Volume reconstruction is rarely used for abdominal US. It is difficult to get meaningful volume as the field of view is typically not large enough to include everything in one sweep and there are many changes between sweeps (breathing motion, varying probe pressure, other internal patient motion, etc). We have some single-sweep breath-held liver scans but even in those you see that the reconstruction is quite noisy due to cardiac motion.
What organs you would be interested in? What would you like to measure/visualize?

If you can use non-abdominal images: Volume reconstruction is performed routinely in brain and brain ultrasound reconstruction databases are available (that also contains corresponding ground truth MRI segmentation).
#### By Dzenan Zukic on 2017-08-01 15:20
Our target organ is kidney, but we want to build a trainer for ultrasound procedure guidance so we need a large field of view in the abdomen. I guess we will have to make it ourselves :)

@lassoan thanks for the explanation. Can you share those single-sweep breath-held liver scans? Google Drive and Dropbox are my preferred ways.
#### By Andras Lasso on 2017-08-01 22:32
Actually, we have kidney images, too. See detailed analysis in this paper:
http://perk.cs.queensu.ca/contents/hole-filling-oriented-sticks-ultrasound-volume-reconstruction

For training, you may consider using simulated ultrasound. For teaching geometry (recognizing structures from shapes, etc), you can use the ultrasound simulator built into Plus (see a very simple example here: https://www.youtube.com/watch?v=2Oc_tCu_uzs - it uses surface meshes as inputs, for example created from segmented 3D MRI volumes). For reproducing more realistic textures and more sophisticated artifacts, reslicing reconstructed 3D volumes is certainly an option, but you then need smart motion compensation methods (we talked about this before in another thread).
#### By Dzenan Zukic on 2017-08-02 12:46
We are aiming for higher realism, hence we need to use real images instead of simulated ones.

Can you share those kidney images with me? I use my Kitware address for Google Drive and my GMail address for Dropbox. I can contact you privately if you need more info.
#### By Andras Lasso on 2017-08-03 10:30
I've sent a link to your Kitware email.

## Ultrasonix 612 and Visual Studio 2013
#### Posted by MattClarkson on 2017-07-21 16:45

HI there,

I've previously built code against ultrasonix sdk_612 using VS2012, without recompiling the SDK. I just used the SDK as I downloaded it.

Does the same SDK work with VS2013? Or would I have to recompile the SDK to suit?

Thanks

Matt

#### 3 Comments
#### By MattClarkson on 2017-07-21 17:00
Er... thats possibly a dumb question, as if you run CMake against the SDK, then all you are doing is compiling the demo programs against existing libs?
#### By Andras Lasso on 2017-07-21 18:58
Yes, the Ultrasonix SDK is pre-built (with C interface, so it works with any VisualStudio version). CMakeFiles are only there for rebuilding the demo apps.
#### By MattClarkson on 2017-07-22 01:21
Great. Thanks.

## Combined Tracker and Imaging Messages
#### Posted by MattClarkson on 2017-07-18 05:31

Hi All

(first - thanks for you continued works on PLUS, it's really growing quickly!)

This is a general question, and I apologise if its answered elsewhere, but I did try reading stuff first before posting :-)

If I use PLUS Server to connect to a tracker and an imaging device, what does PLUS server support on the output OpenIGTLink messages. Does it send tracking and imaging information on separate OpenIGTLink messages? Or can it send the tracking information in the matrix field of the OpenIGTLink Message format? If its separate messages, are the messages always paired, and synchronised, or is this all left up to the 3rd party application?

Thanks

Matt

#### 3 Comments
#### By Andras Lasso on 2017-07-18 08:10
> Does it send tracking and imaging information on separate OpenIGTLink messages?

Yes, it uses separate messages with exactly the same timestamp. Tracking data is interpolated exactly at the image data acquisition time (Plus waits for tracking information after the image is acquired so that it can interpolate; due to longer delay of image acquisition, the corresponding tracking information is received by the time the image arrives, so in practice Plus does not have to wait). For now, it is up to the receiver client to pair the messages, but usually you don't have to take any extra measures, as data corresponding to the same timestamp is sent at the same time.

We are developing the OpenIGTLinkIO library (https://github.com/IGSIO/OpenIGTLinkIO/), which is a Qt-based library, which implements an OpenIGTLink client that takes care of all the low-level communication with PlusServer and provides a convenient interface for receiving data as VTK objects, uses Qt signals to notify availability of data, allows executing commands (for example, changing ultrasound imaging parameters), etc. It is still relatively early phase, developed in collaboration with SINTEF Norway and Montreal MNI, contributions from others would be very welcome. If you use OpenIGTLink then probably you already had to develop such a component. If so, you could consider contributing part of it to this common library. The advantage would be that it would be developed and maintained as a shared effort, which is expected to lower the overall workload for everybody.
#### By MattClarkson on 2017-07-21 03:35
Hi there, thanks for this.

we previously developed: https://github.com/NifTK/NiftyLink
as in: https://link.springer.com/article/10.1007/s11548-014-1124-7

with slightly reduced scope to what you describe. Last time I saw you, i think you were working on this common library, but I think you were trying to avoid Qt, as I suggested NiftyLink at the time. But now you are using Qt!!

Either way, thanks for the clarification of separate images.

Matt
#### By Andras Lasso on 2017-07-21 15:03
OpenIGTLinkIO allows implementing clients using VTK only. Qt-based classes provide an optional top-level convenience layer for Qt-based applications.


## Offline 3D Reconstruction Configuration File Question
#### Posted by Colleen.Ogilvie on 2017-07-14 18:04

Hi Plus Team!

I’m also working on making an offline volume reconstruction of some tracked ultrasound data I took in PLUS, using the PLUS command prompt.
From the command prompt, it looks like it worked, and a new .mha file is created. However, when I open my new file in Slicer, it looks like only one slice made it into the final reconstruction. It should have about 358 frames. The input volume before running the volumereconstructor.exe is 380x400x358, and the output volume in the .mha file is 76 x 79 x 1. I can’t scroll through the images in Slicer or see a reconstructed volume, so it looks like only 1 slice made it through VolumeReconstructor.exe. Otherwise, the output file looks fine, and I can open it in both Matlab and Slicer. I think it is very possible there is a problem is in the config file I wrote, and I’ve attached the files I’ve used and a couple of screenshots.

Just wondering if this might be a common problem with an easy fix?

Thank you!
OfflineVolumeReconstructionScreenshots.docx	401 KB
Recordingcolleen1_config4.xml	1.16 KB
Recordingcolleen1.mha	52.3 MB

#### 4 Comments
#### By Andras Lasso on 2017-07-14 18:27
Could you please copy here the command-line and attach the debug-level output log of volume reconstructor?
#### By Colleen.Ogilvie on 2017-07-14 19:53
Hi Andras!

This is the line I used in the command-line:

VolumeReconstructor.exe --source-seq-file=Recordingcolleen1.mha --config-file=Recordingcolleen1_config4.html --output-volume-file=Recordingcolleen_volumetest.mha --image-to-reference-transform=ImageToReference

And I've attached a debug error log. Is this the right file?

Thanks!
debuglogcolleen.txt	42.9 KB
#### By Andras Lasso on 2017-07-15 00:15
In the attached Recordingcolleen1.mha file MotorToMotorRotatedTransform transforms are constant, you specified ReferenceToMotor transform to be identity, and you requested volume reconstruction in the Reference coordinate system. This means that you reconstructed all the frames in the same static position.

You can get a volume if you reconstruct the image in the Tracker coordinate system:

VolumeReconstructor.exe --source-seq-file=Recordingcolleen1.mha --config-file=Recordingcolleen1_config4.xml --output-volume-file=Recordingcolleen_volumetest.mha --image-to-reference-transform=ImageToTracker
#### By Colleen.Ogilvie on 2017-07-17 01:42
Ok great, that worked. Thank you! So if I have this right, the motor and transducer transforms aren’t actually relevant here, since I have the calibrated ImageToProbe transform defined in my volume reconstruction config file, and that should define the relationship between the image and the markers on the probe. In my .mha file, I need to have ProbeToTracker and ReferenceToTracker defined for each slice to get my reconstruction in the reference frame. Since ReferenceToTracker wasn’t defined in my .mha, changing the reference frame to the tracker frame, as you suggested, will get me a reconstruction in the tracker frame since I have the image to probe transform and the probe to tracker transform.

Thanks!


## IGTLink tracker
#### Posted by gregorij on 2017-07-11 18:06

Hello! I have built IGTLink compatible server that provides rigid body tracking data from a motion capture system (which is currently not supported by PLUS library). I have tested the server by directly connecting to Slicer and it seems my transforms are being sent properly. I'm sending data as TDATA messages. However, when I try to connect via the PLUS server, I'm getting errors that I have been unable to resolve. I assume that I'm setting something incorrectly in my configuration files. I have attached my current configuration. Thank you.
071117_150202_PlusLog.txt	194 KB
phasespace-config.xml	1.7 KB

#### 14 Comments
#### By Andras Lasso on 2017-07-11 18:14
It would be nice if you added this device directly into Plus. It's very easy to add a new device and we would be happy to help.

Till then, make sure you send proper timestamps and compute checksum correctly. Debug-level logs may give more information. If you are still not sure what's the problem, build Plus in debug mode and add breakpoints in the OpenIGTLink client device to see what goes wrong.
#### By Gregorij on 2017-07-12 13:04
Thanks for the quick response. I have only checked the content of the message via TrackingDataClient (part of OpenIGTLink examples) and it looks like the time stamps and matrices are being sent correctly. I have disabled crc check but it makes no difference. I have produced Trace level log file, if that helps (By the way, Plus Sever Launcher always crashes if log level is set to anything more than 'Info'. I was able to run it from command line though) . It seems it would be best, as you suggest, to compile Plus from source and check what the server actually receives. Once I get this working, I would be happy to work on getting the Phasespace system added to the Plus supported devices.
071217_095759_PlusLog.txt	91.5 KB
#### By Andras Lasso on 2017-07-12 13:15
Please try it with the latest development snapshot.

When you build Plus from source, use the latest master version, too.
#### By Gregorij on 2017-07-12 18:07
I have tried the nightly built of the plus server launcher and it does not crash, however the output is the same. I have been compiling the source code for the library etc from the repository. I've tried to follow Windows Build Instructions. However, I'm unsure where is the actual code for the plusserver.exe that I should be debugging. I think my computer is still in the process of building all the code at the moment but I was unable to find the particular project.
#### By Andras Lasso on 2017-07-12 22:44
Open the c:\D\PlusExp-bin\PlusLib-bin\PlusLib.sln solution file and run the PlusServer project.
#### By Gregorij on 2017-07-13 18:31
Thanks for the tip. I think I have figured out where the issue happens.

It seems that my message is received properly by the server with correct time stamp, size etc. However, looking at line #130 in vtkPlusOpenIGTLinkTracker.cxx, the statement if (typeid(bodyMsg) == typeid(igtl::TransformMessage)) is never true. I would expect that the type here should be comparing to 'TrackingDataMessage' (for TDATA type), however that doesn't return true either. If I set this statement to true manually, everything seems to work correctly and the message and the data of the transforms gets unpacked and sent to the client properly. So I must be setting something incorrectly in the XML or I'm not creating the message packet correctly. Here is the code that I use to create the message:


// initialization
trackingMsg = igtl::TrackingDataMessage::New();
	for (size_t i = 0; i < m_trackers.size(); i++)
	{
		igtl::TrackingDataElement::Pointer trackElement;
		trackElement = igtl::TrackingDataElement::New();
		trackElement->SetName(m_trackers[i].name.c_str());
		trackElement->SetType(igtl::TrackingDataElement::TYPE_TRACKER);

		trackingMsg->AddTrackingDataElement(trackElement);
	}
// --------------------

// in a thread loop
trackingMsg->SetDeviceName("PhasespaceTracker");

	for (size_t i = 0; i < m_trackers.size(); i++)
	{
		igtl::TrackingDataElement::Pointer ptr;
		trackingMsg->GetTrackingDataElement(i, ptr);
		ptr->SetMatrix(m_trackers[i].igtl_matrix);
		ptr->SetName(m_trackers[i].name.c_str());
	}
// setting time stamp
trackingMsg->SetTimeStamp(ts);

// pack & send 
trackingMsg->Pack();
status = socket->Send(trackingMsg->GetPackPointer(), trackingMsg->GetPackSize());
#### By Andras Lasso on 2017-07-13 21:29
Very nice work! You've discovered a regression that was introduced during recent code updates due to OpenIGTLink changes.

Try replacing:
(typeid(bodyMsg) == typeid(igtl::TransformMessage))
#### by this:
if (typeid(bodyMsg) == typeid(igtl::TrackingDataMessage))

If it fixes the problem then please send a pull request with the change. Thank you.
#### By Gregorij on 2017-07-14 11:13
bodyMsg seems to be a pointer so when I do the following it works:
if (typeid(*bodyMsg) == typeid(igtl::TrackingDataMessage))
I don't have too much experience with smart pointers so I'm not sure if that's a proper way for this case. Please, advice if there is a different way to dereference. In any case, this resolves my issue and I'm able to see the transforms being transmitted to Slicer. Thanks!
#### By Adam Rankin on 2017-07-14 11:33
Yes, I'm very sorry. This is my mistake. The syntax from vtkPlusOpenIGTLinkServer.cxx is the correct implementation (see line 662 for example).

It should definitely be (typeid(*bodyMsg) == typeid(igtl::TrackingDataMessage))

Thank you for catching this and for debugging it!
#### By Adam Rankin on 2017-07-14 11:36
Follow fix here https://app.assembla.com/spaces/plus/tickets/1212-tdata-handling-in-vtkplusopenigtlinktracker-is-not-working/details
#### By Gregorij on 2017-07-14 17:04
You're welcome. Thanks for the help!
#### By Ppandey on 2017-07-16 10:25
@lassoan @rankin could this issue be similar to the one described here https://app.assembla.com/spaces/plus/messages/5820763
#### By Adam Rankin on 2017-07-16 11:09
(Comment removed)
#### By Adam Rankin on 2017-07-16 11:12
Sorry, I didn't notice who wrote that message.

No, I have a colleague doing the same 32->64 reconstruction and his setup is working. I am running a conference this week, but I will try to make time to recreate a 32->64 reconstruction setup and see if it works.


## Webcam-based tracking is now available in Plus
#### Posted by Andras Lasso on 2017-06-23 16:26

While Plus toolkit have been supporting real-time tracking using high-end devices (optical trackers, electromagnetic trackers, surgical navigation system, etc), there has been no ultra-low-cost tracking solution available - until now.

See a short deme here: https://youtu.be/MOqh6wgOOYs

Plus has been now extended to support real-time marker tracking using ArUco & OpenCV libraries. It allows position tracking simple printed black-and-white patterns.

Many thanks to Mark Asselin at PerkLab for adding this feature!

While accuracy is already suitable for certain applications, development of further improvements are in progress.

How to use it:
- Install latest nightly version of Plus toolkit (www.plustoolkit.org)
- Install recent nightly version of 3D Slicer (www.slicer.org) and install SlicerIGT extension (from 3D Slicer extension manager)
- Print a sheet of paper with markers, cut them out, and attach to objects to be tracked. You may also create a camera calibration file for your camera for better tracking accuracy. See details here: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceOpticalMarkerTracker.html
- Launch PlusServer with "PlusServer: Optical marker tracker using MMF video" configuration file
- Launch 3D Slicer, in OpenIGTLinkIF module create a connection with default parameters for tracking data (port 18944 as client). For getting real-time video data, create a connection at port port 18945 as client.
- Use SlicerIGT modules to calibrate tools, set up display. See tutorials at www.slicerigt.org

Any
####  comments and feedbacks are welcome.

#### 7 Comments
#### By Gdardenne on 2017-07-03 11:37
Thanks to all the team !
I will try this new feature for the calibration of a TELEMED ultrasound probe with a black-and-white pattern.
Best
Guillaume
#### By Mark Asselin on 2017-07-03 13:29
Great to hear! Please let us know if you have any questions or
####  comments.
#### By Gdardenne on 2017-07-04 04:56
I have a problem.
When I set the CaptureDeviceId to 1 (front camera) and not 0, the tool state window is empty.
And it seems that the tracking of markers is not performed.
But when I use the camera with the Id 0, the tracking seems to be ok.
You will find my configuration in attached file.
Thanks
Guillaume
PlusDeviceSet_fCal_Telemed_ARUCO.xml	8.3 KB
#### By Andras Lasso on 2017-07-04 08:04
This topic is for announcing the new feature. Please create a new message for reporting your problem. Please attach the log file (not a screenshot of the log window, but the text file; acquired by setting the log level to Debug). Thank you.
#### By Gdardenne on 2017-07-05 05:51
Hi,

For information, I've tried the calibration of a TELEMED US probe with a black and white pattern (ARUCO) and fCal.
I obtained an accuracy of about 3.1 mm (much less accurate than NDI polaris I agree).

Thanks,
Guillaume
#### By Andras Lasso on 2017-07-06 10:45
Accuracy depends on camera resolution, distance of tracked objects, and motion direction (in-plane displacements can be measured much more accurately). In the coming few months we expect to reach 1mm accuracy in good conditions, using an Intel RealSense webcam (that contains an integrated surface scanner).
#### By Gdardenne on 2017-07-12 08:29
Thanks Andras for the message. I agree, by changing the configuration of my setup (motion direction) and by reducing the distance of tracked objects, I obtained an accuracy of about 2 mm.


## Slicer with PlusServer
#### Posted by amkostic on 2017-06-19 16:58

We are trying to duplicate the setup from this video: https://www.youtube.com/watch?v=lfZeXabDjMg&feature=youtu.be
Would you mind sending a sample configuration file?
PlusConfiguration_OpenIGT_test_20170619.xml	6.46 KB

#### 11 Comments
#### By Andras Lasso on 2017-06-19 18:32
A very similar config file was used while scanning a spine phantom (the difference is that this file is for an Ultrasonix scanner):
PlusServer: Ultrasonix US (C5-2/60 GPS probe) + Ascension3DG tracker (Probe, Reference, Stylus) - calibrated


First it is probably easier to get started with a replay of a recording. This one is scan of a fCal phantom wire pattern:
PlusServer: Replay fCal phantom scan with Ultrasonix US (L14-5 probe) + Ascension3DG tracker (Probe, Reference, Stylus)

All these config files are included in the Plus installation package.

There is nothing very special in the configuration file, you just have to make sure there is a VirtualVolumeReconstructor device that uses tracked image data as input.
#### By Amkostic on 2017-06-21 14:52
Using the first config file you mentioned, we edited for BK. When we launch PlusServer, it seems to recognize everything including BK oem, but it crashes:

|INFO|1422.284000|SERVER> Plus OpenIGTLink server listening on IPs: 192.168.0.7, 169.254.11.118, 172.17.222.27, 169.254.34.82, 127.0.0.1 -- port 18944
|ERROR|1422.407000| Server process error: Crashed| in D:\D\PTN-VS2013b\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(476)
|ERROR|1422.431000| Server stopped unexpectedly. Return code: -1073741819| in D:\D\PTN-VS2013b\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(489)
PlusConfiguration_OpenIGT_test_20170620_basedOnSample.xml	4.8 KB
#### By Amkostic on 2017-06-22 14:24
We decided to try to use an MMF, Manycam, to get the image data. This streams correctly to slicer when we input just image data.

Now, however, when we attempt to use the configuration file attached, plusserver complains about not being able to create an image message.

|WARNING|975.430000|SERVER> Skipped transformation matrix - Invalid transform in the transform repository (Image to Reference)| in :\D\PTN-VS2013b\PlusLib\src\PlusOpenIGTLink\vtkPlusIgtlMessageCommon.cxx(66)
|WARNING|975.432000|SERVER> Failed to create IMAGE message: cannot get image transform| in :\D\PTN-VS2013b\PlusLib\src\PlusOpenIGTLink\vtkPlusIgtlMessageFactory.cxx(174)
|WARNING|975.435000|SERVER> Failed to pack all IGT messages| in :\D\PTN-VS2013b\PlusLib\src\PlusServer\vtkPlusOpenIGTLinkServer.cxx(858)
PlusConfiguration_OpenIGT_test_20170620_basedOnSample_manycam.xml	4.68 KB
#### By Adam Rankin on 2017-06-22 14:31
Was the probe in view of the tracker?
#### By Amkostic on 2017-06-27 10:07
Now, when we are viewing in slicer, it seems that the tracking of the image is dependent on both the probe and the reference (when we move the reference but keep the ultrasound device/probe stationary, the position of the image in slicer changes).

How would we change the information we are sending to slicer in order to make the image's position dependent on only the probe?
Right now we are using the same configuration file linked to previously on 06/22.
#### By Amkostic on 2017-06-27 15:51
Also, if we try to do a scout scan or volume reconstruction with the reference present, plusserver gives error:

|ERROR|1459.513000|SERVER> Transform path not found from Image to Reference coordinate system. Available transforms in the repository (including the inverse of these transforms): ImageToProbe (valid, persistent), ImageToTransducerOriginPixel (valid, persistent), PhantomToReference (valid, persistent), StylusTipToStylus (valid, persistent), TransducerToProbe (valid, persistent), TransducerOriginPixelToTransducerOrigin (valid, persistent)| in :\D\PTN-VS2013b\PlusLib\src\PlusCommon\vtkPlusTransformRepository.cxx(542)

This page had some suggestions for this issue: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html
But it seems as if our configuration file has all the things specified (image to probe transform)
#### By Andras Lasso on 2017-06-27 17:12
> How would we change the information we are sending to slicer in order to make the image's position dependent on only the probe?

It's your decision what you choose as renderer world coordinate system (that is stationary in the renderer). For example, you can send the image and all transforms relative to the Tracker:


<TransformNames>
<Transform Name="ProbeToTracker"/>
<Transform Name="ReferenceToTracker"/>
</TransformNames>
<ImageNames>
<Image Name="Image" EmbeddedTransformToFrame="Tracker"/>
</ImageNames>
#### By Andras Lasso on 2017-06-27 17:15
> Transform path not found from Image to Reference coordinate system.

Please send a complete debug-level log of PlusServer. Probably there is some information there that gives a hint about the root cause of this error.
#### By Amkostic on 2017-06-28 11:22
The log attached is what happens when in volume reconstructor we put
ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Reference"

I tried ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Probe", with which I can reconstruct a volume, but it turns out with unexpected dimensions (see image attached, the yellow frame is very skinny).
062817_110633_PlusLog.txt	61.1 KB
PlusConfiguration_OpenIGT_test_20170620_basedOnSample_manycam_20170628.xml	4.64 KB
MasterSceneView.png	223 KB
#### By Amkostic on 2017-06-30 15:09
We are now trying to do a calibration of the probe, using the attached file. When we start, the spatial calibration, the green dots are correctly detected on the wires as they should be, but we get a flashing message "Cannot determine transform between probe and phantom, make sure all markers are in field of view" and the result has a very large error.
Also, if we click the second button for pattern recognition parameters (for segmentation parameter editing dialog), the application crashes.
PlusConfiguration_BKFlexFocus_8666_NDIAurora_fCal2.0-new_external_6.4cm_Epiphan_20170630.xml	9.47 KB
#### By Amkostic on 2017-07-05 16:47
Update on situation mentioned in previous message: the same thing is still occurring. Log file and calibration file being used are attached.
PlusConfiguration_BKFlexFocus_8666_NDIAurora_fCal2.0-new_external_6.4cm_Epiphan_20170630.xml	9.59 KB
070517_163729_PlusLog.txt	1.87 KB


## Calibration of an US probe with fCal and Webcam-based tracking (ARUCO)
#### Posted by gdardenne on 2017-07-05 02:44

HI,

Following this message "Webcam-based tracking is now available in Plus", I used fcla for calibrating a TELEMED ultrasound probe with a blach and white pattern tracked by the front webcam of my computer.
However, I have a problem.
When I set the CaptureDeviceId to 1 (front camera) and not 0, the tool state window is empty.
And it seems that the tracking of markers is not performed.
But when I use the camera with the Id 0, the tracking seems to be ok.
You will find my configuration and the log file in attached.
Thanks
Guillaume
070417_105235_PlusLog.txt	3.77 MB

#### 0 Comments


## Image processing of sequence file (.mha) acquired with fCal
#### Posted by Ai-Ray on 2017-06-13 09:25

Dear Plus Team,
I have acquired several sets of tracked image sequences using fCal and I need to segment some lesions in the images.
The data are acquired from a CIRS breast phantom with Claron MicronTracker and Ultrasonix MDP with L14 probe.

The original plan was to perform volume reconstruction and then segment lesions in the volume with standard image processing tools (3DSlicer or Mevislab).
Unfortunately, the interpolation algorithm reduces the image quality and resolution, making the segmentation of small lesions very difficult.

Since lesions are clearly visible in a subset of images contained in the recorded mha file, my idea is to segment lesions in these images and then reconstruct segmentation in 3D, thanks to the ImageToTracker or ImageToReference transformations. Is this procedure possible? Which is the best way of implementing it (Matlab, 3D slicer)?
I have already installed slicerIGT extensions, and I'm able to replay sequence mha files in 3Dslicer following the user tutorials provided on the slicerIGT site.

Any suggestions on how to perform lesions segmentation is really appreciate.

Thanks in advance for your support

#### 5 Comments
#### By Andras Lasso on 2017-06-13 09:35
In PlusRemote module in Slicer you can set a finer resolution output volume by setting a smaller Spacing value (next to Start live reconstruction button). Make sure the ROI is small enough so that the output volume fits in memory. You may need to move the probe very slowly to avoid holes (or enable hole filling).

For some projects (intraoperative breast cancer segmentation, bone osteophyte quantification) we use the Markups to model module (in SlicerIGT) for creating 3D segmentation from sparse tracked ultrasound slices. It works extremely well! You just drop markups on a couple of image slices at the boundary of the structure that you would like to segment and Markups to model creates a 3D structure in real-time. You can show surface boundaries in slice views. You can change the scale of markups in the Markups module to hide point markers and their labels.
#### By Ai-Ray on 2017-06-13 10:39
Thanks Andras for the suggestion,
I will try to improve the tuning of volume reconstruction parameters and also the acquisition protocol.

The idea of obtaining 3D segmentation from sparse tracked ultrasound slices is probably the best option, Is it possible to use "Markups to models" on a image sequences already acquired and imported in 3Dslicer? Or real time images are required?
#### By Andras Lasso on 2017-06-13 10:40
You can run it on sequences loaded into Slicer (using Sequences module).
#### By Ai-Ray on 2017-06-13 11:32
The "Markups to models" extension is working on the sequence data already acquired. Thanks for the great support (as usual)!

Unfortunately I found some problem in the tracking data, when I visualize the tracked images using ImageToReference transforms, the position of the images is shaky and less stable compared with the same sequence visualized with ImageToTracker.
I will do more experiments to better understand this behavior, Could it be due to transformations concatenation and inversion (in particular inversion of ReferenceToTracker and concatenation with ImageToTracker)?
#### By Andras Lasso on 2017-06-13 11:56
If you position the image relative to a reference marker/sensor it will be always more shaky than when you only use a single transform relative to the tracker. Typically reference sensors are large (so they can be accurately tracked) and they are close to the region of interest, so the additional error is acceptable. If you don't expect your patient to move that much during scanning (and between scans, if you need to use multiple co-registered scans) then you can work without a reference sensor.


## very slow stream of US images
#### Posted by sama.alimohamadi on 2017-05-28 05:28

Hi. I'm Samaneh Alimohamadi, a Ph.D. student in biomedical engineering. I'm interested in your very useful and efficient software. But I have a problem using it.
Actually, I have an NDI EM tracker and a TELEMED ultrasound machine and want to connect them to the plus server but the 3D slicer becomes very slow at the moment I connect the US machine and it seems not to take real-time streams of US images from the TELEMED.
my config file is attached.
whould you please help me to solve this problem.

Looking forward to hearing from you.

Regards,
Samaneh Alimohamadi
PlusDeviceSet_Server_TelemedandAuroraBothAquisition.xml	2.24 KB

#### 5 Comments
#### By Andras Lasso on 2017-05-28 08:26
Try to turn off auto brightness/contrast adjustment in Slicer: open Volumes module, in Display section change "Auto W/L" to "Manual W/L".

Does it work better if you send regular grayscale image from a webcam using MmfVideo (without any other device in the config file)? Adjust FrameSize to see how the performance changes with different frame size.

What version of Plus and Slicer do you use?
#### By Sama.Alimohamadi on 2017-05-30 04:14
Dear Andras, thanks for your reply.
unfortunately "Manual W/L" didn't work. I used 'MmfVideo' but we had the same problem and changing the Frame size didn't solve the problem. my real frame size was 640*480(from the camera capturing software) but setting the frame size to that didn't work too.
plus version:2.2.0
slicer version: 4.5.0-1

should both the windows and plus be 64 or 32 bit or it doesn't matter?

looking forward to hearing from you.

Regards,
Samaneh Alimohamadi
#### By Andras Lasso on 2017-05-30 06:46
Please try with latest nightly version of Plus and Slicer and let us know if it works better.
#### By Sama.Alimohamadi on 2017-06-06 09:13
Dear Andras,
as you said, I installed the latest nightly version of Plus and Slicer on 3 different systems, but the problem still exists. I've attached a few seconds of my screen if it can help you to see the problem.
I appreciate if you have time to connect to my system via team viewer to fix the problem or chat via a social network.
this is my phone number: +989127685214

Best Regards,
samaneh
bandicam2017-06-0615-52-21-403.avi	616 KB
#### By Sama.Alimohamadi on 2017-06-12 02:47
Dear Andras,
the nightly and also the latest stable version of plus and slicer installed on 3 different systems with three different specifications. it can be mentioned that all of them were slow but one of them seem to be a little bit better than others.
now I don't know what is really the source of this problem.
Looking forward to hearing from you.
best
samaneh


## Calibrating a 3D probe using fCal
#### Posted by ppandey on 2017-04-02 19:41

Hi all,

I am using an ultrasonix 4DL14-5/38 motorized transducer and NDI polaris and I would like to calibrate it to know the ImageToProbe transform. I have a fCal 2.1 phantom available, but I am not sure if it is wide enough to use with the 3D transducer - does anyone have any experience doing this?

Also if I run my fCal configuration file, the transducer sweeps along all the imaging planes - will this effect the accuracy of the calibration compared to having the imaging plane fixed to one angle?

Thank you

#### 12 Comments
#### By Andras Lasso on 2017-04-02 21:28
fCal is developed for calibrating 2D probes. Plus can automatically compute probe calibration for 4DL14-5/38 probe based on information that it gets through Ulterius interface. Use "PlusServer: Ultrasonix US (4DL14-5/38 motorized probe) - calibrated" configuration.

If you attach a position sensor (Probe coordinate system) and you want to compute where the image (defined in the Motor coordinate system) is relative to the Probe coordinate system then you have to simple calibration options:
Option A: Scan a 3D object (that has easily identifiable points) and perform landmark registration on the reconstructed volume. See U-34 tutorial for volume reconstruction, U-12 tutorial for landmark registration at http://www.slicerigt.org/wp/user-tutorial/.
Option B: Place a tracked stylus at various places in the field of view and reconstruct a volume at each position. Determine Probe to Motor coordinate system from correspondence between the needle tip point in the Motor and in the Probe coordinate system. See U-34 tutorial for volume reconstruction, U-31 tutorial for stylus-based calibration at http://www.slicerigt.org/wp/user-tutorial/.
#### By Ppandey on 2017-04-03 01:10
Thanks, I will try that out.

The link for tutorial U-03 seems to be broken by the way.
#### By Tamas Ungi on 2017-04-03 01:56
I fixed the link. You can also access the folder with all presentations at the "Tutorial presentations" link.
#### By Ppandey on 2017-04-20 21:19
Just wondering, would it not be possible for me to calibrate a single plane of the 3D probe using fCal, and then use that calibration data for all the elevation planes of the transducer?

Also, I don't quite understand what you mean by "Plus can automatically compute probe calibration for 4DL14-5/38 probe based on information that it gets through Ulterius interface" ? Don't I have to use some sort of image to probe calibration technique (like fcal)?
#### By Andras Lasso on 2017-04-20 22:26
> Just wondering, would it not be possible for me to calibrate a single plane of the 3D probe using fCal, and then use that calibration data for all the elevation planes of the transducer?

No need. fCal is needed only for 2D probe calibration. If you use Ultrasonix 4DL14-5/38 probe then Plus can already reconstruct a 3D volume without any calibration procedure (it retrieves all parameters from the ultrasound system itself, through Ulterius interface). You can scan any 3D object that has discernible features, for example corners and use landmark registration to determine the transformation between the "Motor" (coordinate system where the 3D volume is defined in) and the probe-attached tracking marker.

> Also, I don't quite understand what you mean by "Plus can automatically compute probe calibration for 4DL14-5/38 probe based on information that it gets through Ulterius interface" ? Don't I have to use some sort of image to probe calibration technique (like fcal)?

No calibration is necessary. fCal can compute all transforms from the information that it can get from the ultrasound system.
#### By Ppandey on 2017-04-30 18:22
Okay, I see. So in theory would it be possible to use image registration between the ultrasound image and a model of the object being scanned to find the necessary transformation to align the probe with the object's reference frame? This would forgo the process of manually selecting landmarks in the ultrasound volume.
#### By Andras Lasso on 2017-04-30 19:07
Marking landmarks in a 3D US volume is easy enough so it's difficult to beat it with an automatic method, but of course it should be doable.
#### By Ppandey on 2017-05-18 17:43
Where do I find the fCal 2.1 configuration files? Specifically how do I find the appropriate "ModelToObject" transformation, and information regarding References and Planes for the PhantomDefinition? I can only see configuration files for phantom 2.0 with 2.0 wiring, and I am looking for phantom 2.1 with 2.0 wiring.
#### By Ppandey on 2017-05-18 19:56
Also, every time I run the spatial calibration in fCal, fCal crashes. The info level log file says this, but I am not sure how to fix this:


051817_165317.776|WARNING|162.810000| Unable to read image orientation from configuration file (Rendering tag, DisplayedImageOrientation attribute). Defauting to MF.| in ..\..\PlusApp\PlusCommonWidgets\vtkPlusImageVisualizer.cxx(699)
051817_165317.785|ERROR|162.818000| Render window unavailable when trying to render 2D image.| in ..\..\PlusApp\PlusCommonWidgets\vtkPlusImageVisualizer.cxx(304)
051817_165317.798|WARNING|162.831000| Could not read UseOriginalImageIntensityForDotIntensityScore from configuration| in ..\..\PlusApp\PlusCommonWidgets\PlusSegmentationParameterDialog.cxx(1113)
051817_165317.901|WARNING|162.934000| The region of interest is too big, bar size is 26| in ..\..\..\PlusLib\src\PlusCalibration\PatternLocAlgo\PlusFidSegmentation.cxx(249)
051817_165414.160|INFO|219.193000| Filtered timestamp is probably invalid for video buffer item with item index=3002, time=219.193. The item may have been tagged with an inaccurate timestamp, therefore it will not be recorded.| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusBuffer.cxx(365)
051817_165414.188|INFO|219.222000| Filtered timestamp is probably invalid for tracker buffer item with item index=7956, time=219.222. The item may have been tagged with an inaccurate timestamp, therefore it will not be recorded.| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusBuffer.cxx(499)
051817_165414.194|INFO|219.228000| Filtered timestamp is probably invalid for tracker buffer item with item index=7956, time=219.222. The item may have been tagged with an inaccurate timestamp, therefore it will not be recorded.| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusBuffer.cxx(499)
#### By Ppandey on 2017-05-18 19:57
This is my configuration file.
PlusDeviceSet_fCal_Ultrasonix_4DL14-5_Polaris-Prash.xml	9.94 KB
#### By Ppandey on 2017-05-27 22:18
For future reference, I managed to stop fCal crashing by lowering the gain value from 50 to 20 in SonixPortaVideo. I was then able to perform the spatial calibration.
#### By Andras Lasso on 2017-05-27 23:07
Thanks for the feedback, it's very useful! What you experienced was just severe slowdown, not a crash: there were too many point candidates in the image and that's why processing of the image took too long time (if you waited some more then fCal would have resumed operation). I'll add a note to fCal instructions to make people aware that too high gain can make fCal slow/appear to hang.


## BK-Win32
#### Posted by xliu389709 on 2017-05-04 15:31

I see this package is available on request. Can you let me know how to get this package? We want to use the latest version of PLUS with BK flex Focus 700 through the ethernet interface. Thanks!

#### 8 Comments
#### By Andras Lasso on 2017-05-05 00:45
OK, we'll provide the package for you. What tracking system are you going to use?
#### By Xliu389709 on 2017-05-05 11:13
Thanks, Andras. We are using NDI Aurora EM tracking. Let me know if you need my email or something for sending the package.
#### By Andras Lasso on 2017-05-08 18:57
Please try this package:
http://perk-software.cs.queensu.ca/plus/packages/experimental/PlusApp-2.5.0.20170409-BK-Win32.exe
#### By Xliu389709 on 2017-05-09 13:51
Hi, I tried but the connection for fCal failed. I attached the log file and the config file I used.

For the BKOEM, we specified an INI file which was in the same folder with a CCF file. Not sure whether this is enough for connection with the BK machine. Any idea?

Thanks!
PlusConfiguration_BKFlexFocus_8666_NDIAurora_fCal2.0-new_external_6.4cm_20170313.xml	7.88 KB
050917_132637_PlusLog.txt	3.99 KB
#### By Andras Lasso on 2017-05-09 14:14
I don't see any errors related to image acquisition from BK, so it may work. You have other errors in your configuration file, as explained in the log.

In the ini file you have to set the IP address and port number of your ultrasound scanner in OemToolboxConnection section.

Have you used this BK scanner with Plus before?
#### By Xliu389709 on 2017-05-10 14:23
I think we have the correct IP address and port number in the ini file. We can connect this BK scanner to a computer with an older version of PLUS-2.1.1.3193. Now we want to connect the scanner to a new computer with the latest PLUS.

The error "Couldn't get tracked frame from video source, frames are not available yet" keep popping up. After I click Connect button in PLUS, the connection with the tracking device seems fine and there is the beeping sound from the NDI tracking device, then after a while, there is the connection successful message, but immediately after that, the software just crashed.

I don't think the other errors, except the above one, matter since we have the same error messages when we can connect to the old PLUS successfully.
#### By Andras Lasso on 2017-05-10 15:42
@jaspernijkamp Could you please write us what was the problem with number of bits per pixel that you need to change to make BK work for you? Maybe they have the same problem here.
#### By Xliu389709 on 2017-05-17 13:44
We keep getting the error "Couldn't get tracked frame from video source, frames are not available yet". We dig into the code and the error comes from vtkPlusChannel. It seems that the video source can be opened but get 0 number of item. Any suggestions?

PlusStatus vtkPlusChannel::GetTrackedFrame(double timestamp, PlusTrackedFrame& aTrackedFrame, bool enableImageData/*=true*/)
{
int numberOfErrors(0);
double synchronizedTimestamp(0);

// Get frame UID
if (this->HasVideoSource() && enableImageData)
{
if (this->VideoSource->GetNumberOfItems() < 1)
{
LOG_ERROR("Couldn't get tracked frame from video source, frames are not available yet");
return PLUS_FAIL;
}


## How to get frames out of vtkPlusDataSource
#### Posted by Dzenan Zukic on 2017-05-15 17:27

I am trying to add support for a new type of ultrasound machines, called WinProbe. My current progress is here and here. The config file which would go to PlusData is attached.

The problem I am running into is in vtkPlusWinProbeVideoSourceTest.cxx. Namely, how do I get frames out of WinProbeDevice? My current code does not produce files on disk. Just to make sure everything runs fine, I want to write them to disk in order to inspect them. Any help is appreciated.
PlusDeviceSet_WinProbeVideoSourceTest.xml	708 Bytes

#### 8 Comments
#### By Adam Rankin on 2017-05-15 19:12
Frames come from a channel. A channel needs at least: 0-1 video sources, 0-N tool sources. I think technically a channel can have 0 sources total, but not recommended.

See PlusDevice::ReadConfiguration
#### By Andras Lasso on 2017-05-15 19:32
The device makes available the first video output channel on the output of the device, so you can get it using GetOutput() or connect it to a filter pipeline:
https://github.com/dzenanz/PlusLib/blob/master/src/PlusDataCollection/Testing/vtkSonixVideoSourceTest1.cxx#L365

if you need to access more elements in the rotating buffer then get the output channel from the device, and get frame(s) using GetTrackedFrame or GetTrackedFrameList.
#### By Dzenan Zukic on 2017-05-16 09:12
I have such a setup, highlighted here.

In the frame callback, the number of items increases steadily meaning I add something. But my current code does not produce files on disk. If I try SetInputConnection instead of SetInputData, I get a crash.
#### By Andras Lasso on 2017-05-16 09:21
I would recommend to add real-time display in the test application the same way as it is done for all other ultrasound device tests.

For recording to file, I would use the vtkDataCollectorTest2.cxx test.
#### By Dzenan Zukic on 2017-05-16 09:33
@rankin If I try adding inherited ReadConfiguration, I get these errors:
|ERROR|000.068000| VideoDevice: Image with Id 'Video' is already in the image container!| in C:\Users\WinProbe\Documents\Plus64WPa\PlusLib\src\PlusDataCollection\vtkPlusDevice.cxx(2099)
|ERROR|000.072000| VideoDevice: Failed to add video source 'Video' to device.| in C:\Users\WinProbe\Documents\Plus64WPa\PlusLib\src\PlusDataCollection\vtkPlusDevice.cxx(1039)
|ERROR|000.084000| VideoDevice: Channel with duplicate channel Id 'VideoStream'. Skipping channel configuration.| in C:\Users\WinProbe\Documents\Plus64WPa\PlusLib\src\PlusDataCollection\vtkPlusDevice.cxx(1080)

Thanks Andras, I will try your suggestions.
#### By Dzenan Zukic on 2017-05-16 10:01
Interestingly enough, live view works. So the rest of my code was OK. Off to studying and using parts of vtkDataCollectorTest2.cxx.
#### By Adam Rankin on 2017-05-16 10:12
@dzenanz I didn't mean to say you had to call it, I just wanted to refer you to it to see how a channel/data source(s) are constructed.

Cheers,
Adam
#### By Dzenan Zukic on 2017-05-16 13:10
I got disk writing to work too. Thanks guys!


## Visual Studio 2017
#### Posted by Dzenan Zukic on 2017-03-09 14:18

Did anyone try compiling Plus with the newly released VS2017? What are the results?

ITK is compiling and all the tests are passing except for itkStatisticsAlgorithmTest. We are looking into that. A machine was set up to do nightly compilations for ITK dashboard using VS2017. First results are already available and a patch to address the warnings has been merged.

#### 11 Comments
#### By Andras Lasso on 2017-03-09 14:38
We test with VS2013 and VS2015. I haven't tried VS2017 yet. Usually it's more efficient for us to wait for others to iron out the problems with new compiler versions and switch when everything works as expected.
#### By Dzenan Zukic on 2017-03-09 14:52
Sure - as Plus has a few big dependencies, that is an OK strategy. However VS2017 is not much different from VS2015, so the transitions should be easy. I will try and report back.
#### By Dzenan Zukic on 2017-03-09 15:45
The compilation fails due to this kind of error which is repeated a few hundred times, each time caused by Qt:
C:\Libs\Qt\5.8\msvc2015_64\include\QtCore/qalgorithms.h(593): error C3615: constexpr function 'QAlgorithmsPrivate::qt_builtin_ctz' cannot result in a constant expression (compiling source file C:\Dev\PlusGit\b32-vs17\Deps\vtk\GUISupport\Qt\vtkEventQtSlotConnect.cxx) [C:\Dev\PlusGit\b32-vs17\Deps\vtk-bin\GUISupport\Qt\vtkGUISupportQt.vcxproj]
#### By Adam Rankin on 2017-05-14 14:12
I just started using VS2017. When there is a package (or possibly if you build Qt yourself), I suspect Plus will build just fine.
#### By Andras Lasso on 2017-05-14 14:41
Mark built latest Plus with VS2017 without problems. What error did you get?
#### By Adam Rankin on 2017-05-14 14:45
Which Qt did he use?

I don't see any packages for VS2017 at https://www.qt.io/download-open-source/#section-2
#### By Mark Asselin on 2017-05-14 15:44
@rankin I used Qt 5.7 obtained via the Qt open source downloader you linked above.
#### By Adam Rankin on 2017-05-14 15:50
@markasselin Which visual studio did you download for? 2015?
#### By Mark Asselin on 2017-05-14 16:03
@rankin I used msvc2015_64. I provided CMake the Qt5Config.cmake file located at %Qt_DIR%/5.7/msvc2015_64/lib/cmake/Qt5. I have also tried this successfully with the 32 bit version of Qt5.7.
#### By Adam Rankin on 2017-05-14 16:04
Ok, most likely something changed in 5.8 then, because I did the same thing (but with 5.8). Thanks!
#### By Andras Lasso on 2017-05-14 20:52
Could you please update the build instructions with these info? It's difficult to find earlier Visual Studio versions, so many people will try to build Plus with VS2017.


## Trying to use Polaris and Aurora trackers through Plus Server in Linux environment
#### Posted by rlopez456 on 2017-05-11 05:35

Hello,

I have installed Plus 2.4 (I couldn't Plus 2.5 since I am working with Fedora 24-Linux that supports cmake version 3.6 and not 3.8 as required to compile Plus 2.5). I connect Polaris Tracker, I launch the Plus Server Launcher and choose the config file I attach in the message. But the tracker is not connected. I launch the server in admin mode and it does not work neither. Do you know what might be happening? I paste here errors provided by Plus Server:

|ERROR|175.271307|SERVER> Device->host communication timeout| in home/albertalises/devel/PlusBuild-2.4-bin/PlusLib/src/PlusDataCollection/PolarisTracking/vtkPlusNDITracker.cxx(266)
|ERROR|175.274498|SERVER> TrackerDevice: Cannot connect to data source, ConnectInternal failed| in home/albertalises/devel/PlusBuild-2.4-bin/PlusLib/src/PlusDataCollection/vtkPlusDevice.cxx(1095)
|ERROR|175.274717|SERVER> Unable to connect device: TrackerDevice.| in home/albertalises/devel/PlusBuild-2.4-bin/PlusLib/src/PlusDataCollection/vtkPlusDataCollector.cxx(321)
|ERROR|175.275141|SERVER> Datacollector failed to connect to devices| in home/albertalises/devel/PlusBuild-2.4-bin/PlusLib/src/PlusServer/Tools/PlusServer.cxx(133)

Should I put the computer in the same local network as Polaris unit?
I would be grateful if you could help me to make it work.

Thank you very much in advance!

Regards,

Rocío López
POLARIS_ConfigFile.xml	1.95 KB

#### 12 Comments
#### By Adam Rankin on 2017-05-11 10:06
The NDI trackers need to be connected via USB (or serial to USB if you have an older revision). They are not network devices.

Device->host communication timeout

This message means it is not receiving a reply for the given COM port (or /dev/ttyUSB0 on Linux systems)
#### By Andras Lasso on 2017-05-11 10:34
> I couldn't Plus 2.5 since I am working with Fedora 24-Linux that supports cmake version 3.6
You can just download a more recent CMake version from www.cmake.org, copy it into any folder, and run it to configure Plus.
#### By Rlopez456 on 2017-05-11 10:37
Hi, thanks for your fast answer!

So, If my device is connected to port /dev/ttyUSB1, I should change de SerialPort parameter in the config file to "1" ? it gives me the same error... and if I change SerialPort to "/dev/ttyUSB1" he does not recognize the port..

It is just I am new to linux and I am doing my best to make Slicer IGT work in here!
#### By Andras Lasso on 2017-05-11 10:41
In ndicapi_serial.h:

#define NDI_DEVICE0 "/dev/ttyS0"
#define NDI_DEVICE1 "/dev/ttyS1"
#define NDI_DEVICE2 "/dev/ttyUSB0"
#define NDI_DEVICE3 "/dev/ttyUSB1"
#define NDI_DEVICE4 "/dev/ttyUSB2"
#define NDI_DEVICE5 "/dev/ttyUSB3"
#define NDI_DEVICE6 "/dev/ttyUSB4"
#define NDI_DEVICE7 "/dev/ttyUSB5"

For "/dev/ttyUSB1" you probably need to set "3". It is not intuitive at all, so probably we should improve our documentation.
#### By Rlopez456 on 2017-05-11 10:41
I just saw your answer Andras, I did what you say but then the terminal asked to run the Plus compilation in root mode and the root only watch cmake version 3.6 (supported by fedora 24), and my local user watch cmake version 3.8.1. So when building Plus in root mode he saw the lowest version...
#### By Andras Lasso on 2017-05-11 10:45
I don't think you need to build Plus as root. What is the exact error message that you get if you try to build as a regular user?
#### By Adam Rankin on 2017-05-11 10:45
One second. The Linux USB/COM ports don't line up the way we expect them to. Checking code...
#### By Adam Rankin on 2017-05-11 10:46
I can confirm you don't need root access to build and run Plus.
#### By Rlopez456 on 2017-05-11 10:58
Well, it seems it is building correctly from the local user... I'll let you know if it is successful. It is weird the message I got yesterday.
Regarding the Plus (2.4) connection with the device it does not work even with SerialPort set to "3"... And the Polaris tracker is well connected since I checked the connection with NDI Tool Box.
#### By Andras Lasso on 2017-05-11 14:30
Add some more logs to the code to see how far it gets. Also, try it with different numbers. Port="0" means auto-detect is attempted, you can try that, too. Try connecting as root user.
#### By Rlopez456 on 2017-05-12 05:31
Hi,

I had already tested connecting as a root user but I got exactly the same error. I think this will be something about permissions...

I was succesful installing Plus 2.5. However, when I try to run it in local user mode: "./PlusServerLauncher" I get the following error:

[albertalises@ws111041 bin]$ ./PlusServerLauncher
Software version: Plus-2.5.0.d1beb3b - Linux
System start timestamp: 1.49458e+09
Segmentation fault (core dumped)
[albertalises@ws111041 bin]$

If I run it in root mode: "sudo ./PlusServerLauncher" It runs and it prompt the window of Plus Server, however if I choose a config file located in PlusServer-bin/PlusLibData/ConfigFiles it crashes and stop working. I can choose config files located in another local folder but then when I run "Launch Server" it gives me the following errors:

|ERROR|042.472342| Server process error: FailedToStart| in /home/albertalises/devel/PlusBuild-2.5-bin/PlusApp/PlusServerLauncher/PlusServerLauncherMainWindow.cxx(476)
|ERROR|042.511280| Failed to start server process| in /home/albertalises/devel/PlusBuild-2.5-bin/PlusApp/PlusServerLauncher/PlusServerLauncherMainWindow.cxx(223)

I want to highlight that when building Plus 2.5 it didn't find the ndicapi library and I had to clone it and build it manually. Then building Plus again it gave me the following warnings:

/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:506:10: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
return "Unrecognized error code";
^~~~~~~~~~~~~~~~~~~~~~~~~
In file included from /home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.h:44:0,
from /home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:39:
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx: In function ‘char* ndiDeviceName(int)’:
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:83:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE0 "/dev/ttyS0"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:577:24: note: in expansion of macro ‘NDI_DEVICE0’
if (i == 0) { return NDI_DEVICE0; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:84:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE1 "/dev/ttyS1"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:580:24: note: in expansion of macro ‘NDI_DEVICE1’
if (i == 1) { return NDI_DEVICE1; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:85:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE2 "/dev/ttyUSB0"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:583:24: note: in expansion of macro ‘NDI_DEVICE2’
if (i == 2) { return NDI_DEVICE2; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:86:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE3 "/dev/ttyUSB1"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:586:24: note: in expansion of macro ‘NDI_DEVICE3’
if (i == 3) { return NDI_DEVICE3; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:87:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE4 "/dev/ttyUSB2"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:589:24: note: in expansion of macro ‘NDI_DEVICE4’
if (i == 4) { return NDI_DEVICE4; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:88:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE5 "/dev/ttyUSB3"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:592:24: note: in expansion of macro ‘NDI_DEVICE5’
if (i == 5) { return NDI_DEVICE5; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:89:25: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE6 "/dev/ttyUSB4"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:595:24: note: in expansion of macro ‘NDI_DEVICE6’
if (i == 6) { return NDI_DEVICE6; }
^~~~~~~~~~~
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi_serial.h:90:24: warning: ISO C++ forbids converting a string constant to ‘char*’ [-Wwrite-strings]
#define NDI_DEVICE7 "/dev/ttyUSB5"
^
/home/albertalises/devel/PlusBuild-2.5-bin/Deps/ndicapi/ndicapi.cxx:598:24: note: in expansion of macro ‘NDI_DEVICE7’
if (i == 7) { return NDI_DEVICE7; }


May it be something related with ndicapi that makes Plus not to work?

Thank you very much!!
#### By Adam Rankin on 2017-05-12 14:17
It may be plus trying to query the OS for the network topology.

We report the IPs and ports that the server is listening on.


## Ascension 3DG - Change hemisphere in config file?
#### Posted by Matthew Holden on 2017-05-08 09:59

I am using the Acension 3DG trakStar for several different projects, and for each setup I use a different hemisphere for the sensors in the Ascension tracker. In particular, for one application I use the FRONT hemisphere for all sensors, and for another application I use the TOP hemisphere for all sensors.

But I find that it is easy to forget to change the hemisphere through the Ascension trakStar utility.

Is there a way to set the hemisphere for the Ascension sensors through the PLUS config file?

#### 2 Comments
#### By Andras Lasso on 2017-05-08 10:53
It's easy to expose this parameter. Do you prefer to specify this for each sensor, or for all sensors at once?
#### By Andras Lasso on 2017-05-08 11:50
See follow-up in #1188


## Controlling 4DL14-5/28 motor through PLUS/Slicer
#### Posted by ppandey on 2017-05-04 18:55

Is there a way to control the motor sweep when using the above ultrasonix probe? Currently the motor is set to sweep continuously without live control.
I am using the default 4DL14-5 config file in my setup.

#### 2 Comments
#### By Andras Lasso on 2017-05-04 19:22
This is not implemented yet. You can implement a new OpenIGTLink command for this, see how command processing is implemented for vtkPlusVirtualVolumeReconstructor class.
#### By Ppandey on 2017-05-05 19:43
Thanks. I realised that setting MotorRotationRangeDeg = 0 fixes the transducer in the centre plane, essentially doing 2D imaging. This might be useful to anyone wanting to do image to probe calibration using n-wire phantoms or with a tracked stylus (I found this to be easier than using a reconstructed volume)


## OpenIGTLink changes
#### Posted by Adam Rankin on 2017-04-28 11:32

Hello Plus users/developers,

We have folded IGSIO/OpenIGTLink into the upstream OpenIGTLink/OpenIGTLink and ended development in the IGSIO fork. Please update your working copies accordingly.

Apologies for the very late announcement.

Plus Team

#### 0 Comments


## Avoid missing vtkzlib when using Slicer's VTK
#### Posted by Dzenan Zukic on 2017-04-21 14:44

I am trying to integrate Slicer, Plus and a couple other smaller libraries into my project. Of course, I want to have only one of each ITK, VTK etc. I think I have set up the build system using CMake superbuild, but I am running into:
LINK : fatal error LNK1181: cannot open input file 'vtkzlib.lib' [C:\_\APTxP\S-bld\PlusLib-build\src\PlusCommon\vtkPlusCommon.vcxproj] [C:\_\APTxP\S-bld\PlusLib.vcxproj]

In Slicer's External_VTKv7.cmake there is -DVTK_USE_SYSTEM_ZLIB:BOOL=ON and a reference to zlib which is part of its own superbuild, hence no vtkzlib is compiled. But as PlusBuild allows PLUSBUILD_USE_3DSlicer, I am wondering how this problem is avoided in that case, and more importantly how do I apply it in my project. Do you have any suggestions?

#### 10 Comments
#### By Andras Lasso on 2017-04-21 14:53
SlicerConfig.cmake contains ZLIB_INCLUDE_DIR, ZLIB_LIBRARY, etc. These should be passed to PlusLib and Plus should use them instead of vtkpluslib when Plus is configured with PLUSBUILD_USE_3DSlicer.
#### By Dzenan Zukic on 2017-04-21 17:20
I just tried modifying ExternalProject_Add in the following way and got the same error
message("ZLIB_INCLUDE_DIR: ${ZLIB_INCLUDE_DIR}")
message("ZLIB_LIBRARY: ${ZLIB_LIBRARY}")
message("ZLIB_ROOT: ${ZLIB_ROOT}")

ExternalProject_Add(PlusLib
...
CMAKE_CACHE_ARGS
    ...
    -DVTK_USE_SYSTEM_ZLIB:BOOL=ON
    -DUSE_SYSTEM_ZLIB:BOOL=ON
    -DZLIB_ROOT:PATH=${ZLIB_ROOT}
    -DZLIB_INCLUDE_DIR:PATH=${ZLIB_INCLUDE_DIR}
    -DZLIB_LIBRARY:FILEPATH=${ZLIB_LIBRARY}
    ...

Here is a snippet from the configure step:
2>  -- SuperBuild -     PlusLib => Requires VTKv7[INCLUDED], ITKv4[INCLUDED], OpenIGTLink[INCLUDED], OpenIGTLinkIO, IntersonArraySDKCxx[INCLUDED], 
2>  -- SuperBuild -       OpenIGTLinkIO => Requires OpenIGTLink[INCLUDED], 
2>  -- SuperBuild -       OpenIGTLinkIO[OK]
2>  -- SuperBuild -     PlusLib[OK]
2>  ZLIB_INCLUDE_DIR: C:/_/APTxP/S-bld/zlib-install/include
2>  ZLIB_LIBRARY: C:/_/APTxP/S-bld/zlib-install/lib/zlib.lib
2>  ZLIB_ROOT: C:/_/APTxP/S-bld/zlib-install
2>  -- SuperBuild -   APTx[OK]
2>  -- SuperBuild - Slicer[OK]
2>  -- Configuring done
2>  -- Generating done

I also took a look at PlusLib's cmake source files. String "zlib" was found only as part of vtkzlib and itkzlib (PlusCommon_LIBS) and part of IF(PLUS_USE_tesseract). How exactly is PlusLib supposed to pick up "system" zlib?
#### By Andras Lasso on 2017-04-21 17:32
You need to change in Plus to use whatever zlib is provided instead of hardcoding vtkzlib. Is itkzlib available? If Yes, then that may be used instead of vtkzlib.
#### By Dzenan Zukic on 2017-04-21 17:35
So we can kick out the hardcoded vtkzlib from Plus because itkzlib is mentioned there too? I will try that, and if it works make a pull request.
#### By Dzenan Zukic on 2017-04-21 17:38
Scratch that. In Slicer's superbuild ITK's internal zlib is turned off and Slicer-provided "system" zlib is used.

I will need to implement ITK/VTK like USE_SYSTEM_ZLIB mechanism.
#### By Andras Lasso on 2017-04-21 17:41
Exactly!
#### By Dzenan Zukic on 2017-04-24 11:26
I tried this, but I get this error:
PlusTrackedFrame.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) void __cdecl itk::MGHImageIOFactoryRegister__Private(void)" (__imp_?MGHImageIOFactoryRegister__Private@itk@@YAXXZ) referenced in function "void __cdecl itk::`anonymous namespace'::`dynamic initializer for 'ImageIOFactoryRegisterRegisterList''(void)" (??__EImageIOFactoryRegisterRegisterList@?A0xe64a45f0@itk@@YAXXZ) [C:\_\APTx3\S-bld\PlusLib-build\src\PlusCommon\vtkPlusCommon.vcxproj]

This error is repeated twice, and this one twice:
C:\_\APTx3\S-bld\PlusLib-build\bin\Release\vtkPlusCommon.dll : fatal error LNK1120: 1 unresolved externals [C:\_\APTx3\S-bld\PlusLib-build\src\PlusCommon\vtkPlusCommon.vcxproj]

Do you have any suggestions?
#### By Dzenan Zukic on 2017-04-25 16:34
The problem seems to be in MGHIO. When I disable this remote module in ITK, PlusLib builds without errors. But Slicer complains:
LINK : fatal error LNK1181: cannot open input file 'MGHIO.lib' [C:\_\APTx3\S-bld\Slicer-build\Libs\ITKFactoryRegistration\ITKFactoryRegistration.vcxproj]
I will keep investigating.
#### By Dzenan Zukic on 2017-04-26 09:34
I think I have a fix
#### By Andras Lasso on 2017-04-27 10:07
Thank you, your pull request has been merged.


## timestamp data for Ascension Tracker
#### Posted by david.kuegler833514 on 2017-04-25 09:30

Hi,

I realized, that you are using the System Time (i.e. the Time on the computer that is connected to the Ascension Tracker) instead of the time provided by the Ascension interface (specifically the "time" field in the Record).

This leads to inaccuracies in the order of the AquisitionRate.

Also some Parameters of the EMT System are not configurable, e.g. the Measurement Rate (always value stored on the board), Filter values (alphaMin, alphaMax, vm) (values hard coded).

Are these properties intentional?

Thanks.

David

#### 1 Comments
#### By Andras Lasso on 2017-04-25 09:50
Right, not all parameters of the Ascension 3DG API are exposed in Plus config files. If you need to configure more parameters then feel free to send a pull request with the proposed changes.

You can have a look at vtkPlusPhidgetSpatialTracker.cxx or vtkPlusMicronTracker.cxx to see how you can utilize a timestamp provided by the hardware device.


## OpenIGTLink with Arduino
#### Posted by Adam Rankin on 2017-04-03 15:23

Hello all,

I am trying to get Slicer to communicate with my Arduino. However, my PLUS server config file is not working. I am attempting to use this config file: https://app.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/ConfigFiles/PlusDeviceSet_Server_GenericSerial.xml.

When I run it, I get the following error: |ERROR|1044.934000|SERVER> Unable to start data sending. OutputChannelId not found: TrackerStream| in .\..\..\PlusLib\src\PlusServer\vtkPlusOpenIGTLinkServer.cxx(292).

I have compared this generic serial device config file to the config file I use with my Polaris Vicra, and the generic config file seems to be missing the line that defines the output channel. I am still learning how to create the server config files, and am not sure how to properly define the output channel. Do I need to define a DataSource within the output channel? What would this look like? All I want is to be able to send strings between my Slicer extension and Arduino. I would like to be able to trigger events in slicer using a button connected to my Arduino, and send intensity values to my Arduino from Slicer to control levels of haptic feedback driven by my Arduino.

Any assistance would be greatly appreciated.

Thanks and best regards,

Barrett

#### 24 Comments
#### By Adam Rankin on 2017-04-03 15:24
Hi Barrett,

I will revisit the serial device and address any issues.
#### By Banderies on 2017-04-03 15:36
Thank you! I assume that there is something that needs to be added (i.e. the file is only a framework), but I am not sure what. I have looked at the documentation but do not understand how to properly define the input and output channels (they appear to be specific to supported devices).

Thanks for the help!
#### By Adam Rankin on 2017-04-03 15:41
Sending strings from Slicer to Plus will be more complicated, as Plus has limited pre-programmed functionality for receiving commands.

You have may have to write your own vtkPlusCommand subclass for sending feedback levels back to Plus.
#### By Andras Lasso on 2017-04-03 15:43
Arduino communication worked well before. Probably the issue is that an output channel name is defined.
#### By Adam Rankin on 2017-04-03 15:49
@lassoan The generic serial device does not add an item to a data source anywhere, is this the device used for arduinos?
#### By Andras Lasso on 2017-04-03 15:50
Yes. It communicates using commands and responses. It does not need data sources.
#### By Adam Rankin on 2017-04-03 15:52
That doesn't really fit with the existing device model.

Also, does that mean that that configuration file should have a bogus channel? Do we need to support not having an active/valid channel?
#### By Andras Lasso on 2017-04-03 15:53
It should not be necessary to provide an output channel for PlusServer.
#### By Adam Rankin on 2017-04-03 15:55
Cool, did not know that!

@banderies Try removing the output channel attribute from the PlusServer tag and see if it works.
#### By Banderies on 2017-04-03 15:56
(Comment removed)
#### By Banderies on 2017-04-03 15:58
This is the PLUS config file I am using:

~~~~
<PlusConfiguration version="2.1">

<DataCollection StartupDelaySec="1.0">
<DeviceSet
Name="PlusServer: Generic serial device"
Description="Send text and receive response through OpenIGTLink"
/>
<Device
Id="SerialDevice"
Type="GenericSerialDevice"
SerialPort="3"
BaudRate="9600"
LineEnding="0d"
>
</Device>
</DataCollection>

<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="1"
MaxTimeSpentWithProcessingMs="50"
ListeningPort="18944"
OutputChannelId="TrackerStream"
/>

</PlusConfiguration>
~~~~

Is the problem the OutputChannelID? When I try to launch the server I get the "OutputChannelID not found" error in the log. The server still starts, and I am able to connect to it in slicer, but it throws another error in the the server log when I try to send it commands from slicer (using slicer.modules.openigtlinkremote.logic().SendCommand(self.arduinoCmd, self.connectorNode.GetID())).
#### By Adam Rankin on 2017-04-03 16:05
Yes, try removing that.
#### By Banderies on 2017-04-03 16:08
When I remove it I get "Unable to find required OutputChannelId attribute in PlusOpenIGTLinkServer element in device set configuration" error in the log. And the server does not start. Does the "OutputChannelID not found" even matter if the server starts? The only reason I ended up asking about this is because when I try to use OpenIGTLink from within slicer I start getting the previously mentioned error in the server log.
#### By Adam Rankin on 2017-04-03 16:14
What the... you're right. I ran it not two minutes ago without that attribute...
#### By Adam Rankin on 2017-04-03 16:16
As a workaround, grab the latest PlusLib and PlusLibData, I've updated the config file to use a data source and channel (which are optional, but they will avoid the "no OutputChannelId" error)
#### By Banderies on 2017-04-03 16:25
Thank you! I am not sure what you mean by PlusLib and PlusLibData. Do you mean that I will need to build PLUS Server using new source code? I see that the config file has been update. It launches, but is now continuously generating a "No data is broadcasted, as no data is available yet" warnings. Is that expected?

Thanks
#### By Andras Lasso on 2017-04-03 16:47
You can ignore "No data is broadcasted, as no data is available yet" warning - we'll fix that (see https://app.assembla.com/spaces/plus/tickets/1179).

I've tried and the config file with Adam's modifications works well. If I copy-paste the code into Slicer's Python console then I can send a command and receive response from a connected Arduino:

connectorNode = slicer.vtkMRMLIGTLConnectorNode()
connectorNode.SetTypeClient('127.0.0.1', 18944)
slicer.mrmlScene.AddNode(connectorNode)
connectorNode.Start()

arduinoCmd = slicer.vtkSlicerOpenIGTLinkCommand()
arduinoCmd.SetCommandName('SendText')
arduinoCmd.SetCommandAttribute('DeviceId','SerialDevice')
arduinoCmd.SetCommandTimeoutSec(1.0)

arduinoCmd.SetCommandAttribute('Text', "123456")
slicer.modules.openigtlinkremote.logic().SendCommand(arduinoCmd, connectorNode.GetID())

def onArduinoCmdCompleted(observer, eventid):
  print("Command completed with status: " + arduinoCmd.StatusToString(arduinoCmd.GetStatus()))
  print("Response message: " + arduinoCmd.GetResponseMessage())
  print("Full response: " + arduinoCmd.GetResponseText())

arduinoCmd.AddObserver(arduinoCmd.CommandCompletedEvent, onArduinoCmdCompleted)
#### By Banderies on 2017-04-03 17:12
Perfect, thanks so much! I really appreciate your help. This appears to be working (I can see the RX LED light up on my board). However, it is throwing an error on the second line of onArduinoCmdCompleted: "cannot concatenate 'str' and 'NoneType' objects." I assume this is because my Arduino is not responding, so GetResponseMessage() is empty. My Arduino code is written to echo anything it receives, but it is not responding for some reason (TX LED does not light up). I tried adding "\n" to "123456" of the command attribute (since my Arduino code waits for a newline before responding), but this did not change anything. Would you mind sending me the code your are running in your Arduino? I have not been able to figure out what my Arduino is sending/receiving since I can't access the COM port while PLUS is using it. Again, I really appreciate the help!
#### By Andras Lasso on 2017-04-03 18:12
Make sure you use the line ending character (0d or 0a) that matches the character that your Arduino code is expecting. In the Plus config file:
LineEnding="0d"
#### By Banderies on 2017-04-03 18:33
LineEnding ="0a" fixed it, thanks!
#### By Banderies on 2017-04-03 19:46
Now that I can send strings to the Arduino, how do I receive information from the Arduino in Slicer? The response message is working, but it requires Slicer to initiation communication with the Arduino. Is there a way to have Slicer execute a function to parse input whenever new data arrives from the Arduino? Would I add an observer to the connector node? If so, how? Thanks!
#### By Andras Lasso on 2017-04-03 21:09
Yes, Slicer always sends a query and the Arduino responds. This is useful because Arduino does not flood Slicer with messages that it cannot process (e.g., if it performs some lengthy computation). You can set up a repeating timer (qt.QTimer) to do this in the background, with any frequency you need.

My example included the observer - see arduinoCmd.AddObserver(...). Your method will be called whenever you receive a response from the Arduino.

In the future we may implement sending of all unexpected Arduino outputs (that are not responses to commands) to Slicer as a STRING message (see #1179).
#### By Banderies on 2017-04-03 23:37
I see, that makes sense. I managed to get the timer to work, so now I just need to work out the best protocol to pass data back and forth. Thank you!
#### By Banderies on 2017-04-06 02:32
I am now able to send and receive data from the Arduino. However, there is a delay of about 300ms between the command being sent from Slicer and the response from the Arduino. This is not due to my Arduino code, which I have tested separately from Slicer. The Arduino's response is nearly instantaneous as little processing occurs. Will any of the changes discussed in ticket #1179 allow the system to respond faster? I read the conversation on the ticket, but I did not understand what was changed. I see that PlusDeviceSet_Server_GenericSerial.xml has been updated. Will I need to install an updated version of PLUS to use this new config file? Thanks.


## Saving Video and Tracking data within .mha
#### Posted by jpunnoo1 on 2017-03-16 11:21

Hello,

I was wondering if anyone had any guidance on how to create a mha file that contains both video and tracking data. Currently what I am doing is converting the ts video file outputted from my SonoSite 180 plus to a sequence of png images and importing the png images to Slicer to save as a mha file. I then planned on using the sequence metafile editor provided with the plus library. However, as I know realize that I need to include tracking data in my mha file, I realize that this process might not work. I am now thinking instead of using OpenIGTLink to transfer both the tracking and the imaging data to slicer so that I can possibly save it as an mha file from there.

Does anyone have any
####  comments on if this is a smart way to save tracking and imaging data to mha? If not, do you recommend any other methods / can point me towards sources where I can read how to do this?

Thanks in advance!

#### 1 Comments
#### By Adam Rankin on 2017-03-16 11:29
You can use a virtual mixer device to a virtual capture device. There are many examples in the sample configuration files.


## Outdated svn data links on volume recon page
#### Posted by pieper on 2017-03-10 13:08

Hi -

This page:

http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationVolumeReconstructor.html

Has links like this:

https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/data/TestImages/SpinePhantomFreehand.mha

But it looks like the svn is reorganized and the correct link is now:

https://app.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/TestImages/SpinePhantom2Freehand.mha

it looks like the other links have similar issues.

Thanks,
Steve

#### 1 Comments
#### By Andras Lasso on 2017-03-10 23:24
Thank you, I've fixed these issues (will be available tomorrow morning).


## NDI polaris and Plus
#### Posted by akash.gajjar2239237279 on 2017-03-01 16:10

No message content.


#### 2 Comments
#### By Akash.Gajjar2239237279 on 2017-03-01 16:15
I am having trouble connecting to the plus server I have written the xml file like the user guide said, but when I select connect it gives me an error that connection failed. Any reason why?
#### By Andras Lasso on 2017-03-01 16:30
You have to set the correct COM port number in the config file in SerialPort attribute.
If the problem persists then send debug-level log file.


## creating an interface for the vtkPlusLogger to custom applications
#### Posted by david.kuegler833514 on 2017-02-20 14:42

Hi,

I do have a request, that I would like to bring up for consideration.

Since I am the person interested, I should would be happy to provide a patch, once you can confirm, that this patch would be of interest to pluslib:

I would like to "catch" or "listen to" log messages sent to the Pluslogger. Currently this is not possible, but I could envision multiple ways to make this happen:

a) Deriving a subclass off vtkPlusLogger and just "filling" the instance pointer with my own implementation "in advance", i.e. before plus creates its own Logger.

This would require the instance pointer and the creation critical section to be "protected" and some methods to be virtual.

a.1) introduce an abstract class instead of vtkPlusLogger and move the actual implementation into vtkPlusLoggerImpl (or something similar) where the vtkPlusLoggerImpl is the standard class generated in vtkPlusLogger::Instance()

b) Adding the possibility to register a callback, which is called every time a Message is logged.

This would require the Logger to have a std::vector and the corresponding hooks integrated.

I would actually prefer the a) or a.1) in order to restrict the necessity of considering double logging.

As I said, if you would share your opinion, I would be happy to provide a corresponding implementation.

Thanks!

David

#### 2 Comments
#### By Andras Lasso on 2017-02-20 14:47
You should be able to capture all log messages already. See https://github.com/PlusToolkit/PlusLib/blob/master/src/PlusWidgets/QPlusStatusIcon.cxx for an example.
#### By David.Kuegler833514 on 2017-02-21 06:50
Ah, thank you :)


## PlaneParametersEstimator and SphereParametersEstimator
#### Posted by david.kuegler833514 on 2017-02-16 11:49

Hi,

why are PlaneParametersEstimator and SphereParametersEstimator in the Utilities Path? It seems they are used by vtkLineSegmentationAlgo and others, but this way, these classes are not available to "outside" projects.

It seems you are using a third party implementation for the RANSAC Algorithm, but since the ParametersEstimator base class MUST be available to deriving Projects, why not make all classes available. Moreover, you do not provide information as to the "original" RANSAC implementation, so I must assume, this is the "original" implementation.

Cheers
David

#### 2 Comments
#### By Andras Lasso on 2017-02-16 12:16
Utilities folder contain third-party libraries that don't follow Plus coding rules so that they can be updated more easily when the libraries are changed by their original developers. They are not part of the Plus API.
#### By David.Kuegler833514 on 2017-02-20 11:53
I guess for consistency sake, you should either not require those 3rd party libraries to be installed at all, or install them all.
Additionally, a link to the original source would be nice ;)


## using PlusLib as a submodule in git yields "error"
#### Posted by david.kuegler833514 on 2017-02-20 10:56

Hi,

I think updating plus to git has helped my workflow a lot and will help others to contribute as well, i hope ;).

I want to inform you of a small error I get, when building, that might be easily fixed.
I am using plus in a git submodule and configuring in cmake yields the following messages:

Configuring PLUS toolkit version 2.5.0.
Detected platform: Win32.
Current git hash is 6b3071f36f2ba09d75f7e93030d78069d1919adc
cp
: failed to access '.git/hooks': Not a directory

Configuring done
Generating done

This is due to ... for "my case" the correct path being: ../../.git/modules/lib/plus/hooks instead of .git/hooks
I think the easiest way to fix this would be to get the path to .git/hooks by using
git rev-parse --git-dir
This should return the "base path", i.e. ../../.git/modules/lib/plus in my case.

I will try to create a patch :)

Cheers

#### 1 Comments
#### By Adam Rankin on 2017-02-20 11:01
Oh sorry! This was my first foray into establishing hooks.

I will fix this asap.

https://app.assembla.com/spaces/plus/tickets/1170-git-hooks-are-not-properly-established/details


## Building Error
#### Posted by abdou9989 on 2017-02-15 21:15

Hey,

I am trying to build Plus under MinGW64. I am using VTK 6.3 and I have an error while compiling:


[ 28%] Linking CXX shared library ..\..\bin\libvtkPlusRendering.dll
CMakeFiles\vtkPlusRendering.dir/objects.a(PlusPlotter.cxx.obj):PlusPlotter.cxx:(.text+0x1): undefined reference to `vtkRenderingVolumeOpenGL_AutoInit_Destruct()'
CMakeFiles\vtkPlusRendering.dir/objects.a(PlusPlotter.cxx.obj):PlusPlotter.cxx:(.text.startup+0x7b): undefined reference to `vtkRenderingVolumeOpenGL_AutoInit_Construct()'
collect2.exe: error: ld returned 1 exit status
gnumake[2]: *** [src\PlusRendering\CMakeFiles\vtkPlusRendering.dir\build.make:192: bin/libvtkPlusRendering.dll] Error 1
gnumake[1]: *** [CMakeFiles\Makefile2:413: src/PlusRendering/CMakeFiles/vtkPlusRendering.dir/all] Error 2
gnumake: *** [Makefile:127: all] Error 2

can anyone syggest solution for that?

#### 1 Comments
#### By Adam Rankin on 2017-02-15 21:17
Are you limited to VTK 6.3? We do not officially support MinGW, but if that's the issue then we may be able to help.


## PLUS repositories are moving to GitHub
#### Posted by Adam Rankin on 2017-01-24 20:18

Hello everyone,

The PLUS team has decided to move our repositories to git, and to GitHub specifically. This will enable a branch-based fork/pull request development model which has proven benefits.

The repositories will be found under https://github.com/PLUSToolkit. The transition is in progress, and we appreciate your understanding as we make the switch.

#### 8 Comments
#### By Tamas Ungi on 2017-01-24 20:39
Are we keeping this Assembla space for Wiki and Messages?
#### By Adam Rankin on 2017-01-24 20:39
Yes, the only thing that's changing is the code repository configuration.
#### By Adam Rankin on 2017-01-24 20:55
Authors that could not be identified are:
alexis.boucharin
Simrin
hussam.ashab
saman
EricMoult
bartha
vikasrs
RyanWalsh
anderson_perk
ckrahmet
mmscr
msoehl
matt.mccormick
MattLougheed
#### By Tamas Ungi on 2017-01-24 21:45
I know them all, except mmscr. Let me know if you need more info.
#### By Adam Rankin on 2017-01-24 23:30
It's more for author attribution. If they have GitHub accounts then I can link them so commits show up with their account linked.
#### By Adam Rankin on 2017-01-30 09:30
The GitHub repositories appear to be stable. Developers can now switch to GitHub development. Please run Utilties/SetupForDevelopment.sh in whichever repo you have fixes to commit (PlusBuild, PlusLib, or PlusApp)
#### By Dzenan Zukic on 2017-02-01 18:30
Are you using this feature?

This is Matt McCormick's profile: https://github.com/thewtex
#### By Adam Rankin on 2017-02-01 19:43
@dzenanz Yup, I'm having trouble using it to add organization repos as a linked GitHub repo, but I am investigating.


## User docs not found
#### Posted by Dzenan Zukic on 2017-01-27 10:50

http://perk-software.cs.queensu.ca/plus/doc/nightly/user/index.html

This page is currently not found. You are probably aware of it, but in case you are not I wanted to let you know.

#### 1 Comments
#### By Andras Lasso on 2017-01-27 10:53
Thank you, we are aware (due to migration of PlusLib/App/Build code github). Until we restore online doc, you can use offline documentation packaged with each plus package. Packaged documentation is faster and matches exactly your plus application version anyway.


## Usage of OpenIGTLinkIO
#### Posted by david.kuegler833514 on 2017-01-25 16:25

Hi,

OpenIGTLinkIO is used in PlusLib for the OpenIGTLinkServer Project (PlusServer/vtkPlusOpenIGTLinkServer.cxx seems to be the only mention in code), but the included file is actually a original OpenIGTLink file.

Additionally, it looks like the OpenIGTLinkIO is only used in Cmake, but not actually linked to any targets.

So my question is: what is OpenIGTLinkIO used for in PlusLib?

Thanks
David

#### 1 Comments
#### By Dzenan Zukic on 2017-01-27 10:48
Some converter in OpenIGTLinkIO is used somewhere. I remember error messages about it not being found a week or two ago.


## switch (compoundingMode) - code duplication
#### Posted by Dzenan Zukic on 2017-01-24 17:38

Long portions of code are duplicated within the compounding mode switches in volume reconstructor. Is this intentional (maybe to allow easier auto-vectorization)?

If not, we could reduce code duplication by taking those portions outside of switch. Also, the accumulation overflow case is not properly handled. Maybe both problems could be solved in one stroke.

#### 6 Comments
#### By Andras Lasso on 2017-01-24 17:46
Yes, "duplication" is intentional. Volume reconstructor code is highly optimized (and therefore very difficult to read and maintain).

What do you mean by "accumulation overflow case is not properly handled" - can you point to the location in the source code that doesn't seem right?
#### By Dzenan Zukic on 2017-01-25 12:30
C:\Dev\plus\bin64-2015\PlusLib\src\PlusVolumeReconstruction\vtkPlusPasteSliceIntoVolumeHelperOptimized.h, line 576. Besides the already noted problem of not going through all the scalars, the weights for inPtr and outPtr1 seem to be reversed. And this pattern occurs for other cases as well.
#### By Thomas Vaughan on 2017-01-25 16:00
@lassoan I looked at the code, and I agree that it looks like the variables had been flipped
#### By Andras Lasso on 2017-01-25 16:38
OK, so that flipping should be fixed. Thanks for testing and finding this bug.

What about the accumulation overflow? @dzenanz Do you have a better suggestion for handling overflow? Overflow should only happen when the volume's resolution is magnitudes lower than the image resolution, so we don't need a perfect solution, just a simple solution that is fast and works reasonably well.
#### By Thomas Vaughan on 2017-01-25 16:48
I think the accumulation overflow was going to be fixed by flipping the variables, but maybe @dzenanz can correct me if I'm wrong or if I misunderstood.
#### By Dzenan Zukic on 2017-01-25 18:03
The additional bug in accumulation overflow is that it updates only the first scalar (not all of them), so it only works properly for grayscale images. I don't have non-grayscale images to test with.


## Smooth transition in the blending region for volume reconstruction
#### Posted by Dzenan Zukic on 2017-01-06 11:46

Hi guys,

with other things solved (thanks @lassoan and @rankin ) my focus turns towards better blending of partly overlapping frames. Currently, if mean blending is chosen there are very visible artifacts at edges of overlapped region. The CompoundingMode idea I want to add to volume reconstructor is distance field weighted blending.

A distance field is calculated for each of the overlapping regions, and pixel's contribution is proportional to its distance to the edge of the frame. This results in pixels which are close to the edge contribute less (almost nothing) to the blended result, making a smooth transition in the overlap region.

What do you think of this plan?
Screenshot2017-01-0611.23.19.png	391 KB

#### 5 Comments
#### By Adam Rankin on 2017-01-06 11:55
Neat idea, the screenshot provided, is that mean blending?
#### By Andras Lasso on 2017-01-06 11:57
Distance weighting may or may not be a good idea. It depends on why the same region appears brighter/darker in different sweeps.

For example, if a region is dark because of acoustic shadowing then a better approach would be to use maximum operator for compounding.

Is there an intensity difference in the images that depict the same region? Do you know why there is a difference? Can you eliminate that difference?
If there is no intensity difference in the input images but the dark artifact still appears in the overlapping area then it may be possible that there is some error in the averaging operation in the volume reconstructor. Try with Optimization="NONE".
#### By Tamas Ungi on 2017-01-06 12:07
The edges of your images may be darker because of the angle between the sound and the surface in your phantom model. In the middle of the image, the sound and the surface are perpendicular, so all sound bounces back to the transducer. Near the edges, there is an angle between the surface and the sound propagation direction, so some sound bounces away from the transducer, never coming back as echo. But this is because of your special phantom with horizontal layers. If you scan a random shape, like an anatomical region, you may not get this effect.
Another explanation could be that the surface of your phantom model is plane. When you push a curved transducer against a plane surface, the sides of the transducer may not have as good acoustic coupling with the phantom. Often the edges of curved transducer images are darker, even in human ultrasound. For similar reasons.

Blending the images more smoothly will certainly improve the visual, but it may hide some information that would lead us to debug something else. So I'm not sure what to think.
#### By Dzenan Zukic on 2017-01-24 16:34
I have started implementing a variant of this idea, and I am running into overflows in fixed-point arithmetic. Not enough bits are given to integer part. If I reduce point from 14 to 12 bits, it works OK with my small test case. If I use 13, there are visible overflows. With 14 (currently in code) result is unrecognizable.

Are there assumptions in the rest of the code about minimum precision of fixed type? Would reducing this to e.g. 8 adversely affect rest of Plus?
point12.png	305 KB
point14.png	408 KB
point13.png	319 KB
#### By Dzenan Zukic on 2017-01-25 14:33
OK I created a ticket which I will use for commit.

I changed the formula for compounding, now it works with unmodified (point=14) fixed type. I have a bit more debugging to do before I commit.


## DeviceFactory
#### Posted by david.kuegler833514 on 2017-01-24 09:16

Hi,

I am developing a "new" (fake) Device for my specific testing needs.

Unluckily it is rather hard to register this device into the vtkDeviceFactory without actually changing the plustoolkit code. This in turn is not intended, as to reduce merging efforts.

This is due to the fact, that the DeviceFactory class initializes in its the classname - creationfunction correlation in its constructor.

From where I am standing, there are 2 solutions to this issue I am having and I want to propose the solution 1 to be integrated into Plus.

Solution 1: have static variables to "keep a registry of devices"
Solution 2: have datacollector use a "exchangeable factory instance"

I have a barebones implementation of solution 1 and will attach the corresponding patch.

Cheers
David
devicefactory_using_staticregistry.patch	3.76 KB

#### 8 Comments
#### By Andras Lasso on 2017-01-24 09:28
Good point. I think what we miss is a public vtkPlusDeviceFactory::RegisterDeviceClass(const std::string& deviceName, PointerToDevice deviceNewMethod) method. If you implement this method and send a patch then we would be glad to review and integrate it.
#### By Adam Rankin on 2017-01-24 09:59
I was just writing up the same thing! Agreed.

The signature should be
vtkPlusDeviceFactory::RegisterDeviceClass(const std::string& deviceName, const std::string& className, PointerToDevice deviceNewMethod)

Our device name is not the same as the class name.
#### By David.Kuegler833514 on 2017-01-24 14:13
May I point your attention to the attached patch :)
#### By Andras Lasso on 2017-01-24 14:38
Why do you need the static registry? Why don't you just save in the existing structures in the factory?
#### By Adam Rankin on 2017-01-24 14:42
It was an option, I implemented option 2 as I prefer the owned instance approach. See #1147
#### By Andras Lasso on 2017-01-24 14:45
@rankin Are you integrating the patch/implementing a solution for this?
#### By Adam Rankin on 2017-01-24 14:45
https://app.assembla.com/spaces/plus/subversion/commits/5044
#### By Andras Lasso on 2017-01-24 14:50
@rankin, I see your commit now, it looks good! Thank you.

@david.kuegler833514 If you have any issues with this then continue the discussion in the ticket
####  comments #1147.


## Spatial calibration issues: Phantom registration is not available
#### Posted by vipulraikar288768 on 2017-01-22 13:02

Greetings Everyone,

First of all, thank you very much for this wonderful research toolkit. I am having a little trouble performing spatial calibration and am seeing the following info message with the start button grayed out.

[INFO] Phantom registration is not available: transform between Probe and Reference coordinate frames is missing. Either phantom registration has not performed yet or the ProbeCoordinateFrame, ReferenceCoordinateFrame, or PhantomCoordinateFrame attributes in the device set configuration file are not set correctly.

I have performed all the pre-requisite steps up to this point and the config file shows the Phantom to Reference transform. I am unsure why I am not able to perform spatial calibration. I have attached my config file and will be happy to furnish you with more specific details.

Thank you,

Best regards,

Vipul
4CM_1.xml	7.69 KB
fcalissues.png	295 KB

#### 13 Comments
#### By Andras Lasso on 2017-01-22 15:33
Thank you for your feedback. You have to call your probe's coordinate system "Probe" (now it's called "Tool"). See fCal configuration files as examples.
#### By Vipulraikar288768 on 2017-01-22 15:42
I completely missed it. That fixed the problem. I will get back to you if I have any more questions.

Thank you very much for your prompt response!
#### By Vipulraikar288768 on 2017-01-22 16:58
So having tried to perform spatial calibration step, I am again running into a problem where I am able to get the dots segmented in the segmentation tool box, but not when the calibration is running. These are the things I have tried:

1.) Adjust ROI
2.) Suggest pixel spacing
3.) Adjust morphology parameters
4.) Probe notch is pointing in the correct direction (Probe oriented to face M)
5.)Adjust gain on US system

I am not sure if I should start another question, or just post in this thread.

Thank you again!

Edit: I am seeing these errors in log level debug

|ERROR|1808.220000| Failed to get video buffer item by timestamp 1807.25| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusChannel.cxx(776)
|ERROR|1808.247000| Failed to get tracked frame list from data collector (last recorded timestamp: 1807.249058| in ..\..\PlusApp\fCal\Toolboxes\SpatialCalibrationToolbox.cxx(768)
|DEBUG|1808.338000| TrackerDevice-ProbeToTrackerDevice: vtkPlusBuffer: Cannot do data interpolation. The closest item to the requested time (time: 1807.431000, uid: 62245) is invalid.| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusBuffer.cxx(1026)
|DEBUG|1808.382000| TrackerDevice-StylusToTrackerDevice: vtkPlusBuffer: Cannot do data interpolation. The closest item to the requested time (time: 1807.692058, uid: 62253) is invalid.| in ..\..\..\PlusLib\src\PlusDataCollection\vtkPlusBuffer.cxx(1026)
|ERROR|1808.417000| Transform path not found from Probe to Tracker coordinate system. Available transforms in the repository (including the inverse of these transforms): ProbeToTrackerDevice (invalid, non-persistent), ReferenceToTrackerDevice (valid, non-persistent), StylusToTrackerDevice (invalid, non-persistent)| in ..\..\..\PlusLib\src\PlusCommon\vtkPlusTransformRepository.cxx(535)
|ERROR|1808.476000| Unable to retrieve transform 'ProbeToTracker'.| in ..\..\..\PlusLib\src\PlusCommon\vtkPlusTrackedFrameList.cxx(345)
SegIssues.png	267 KB
4CM_1_seg.xml	8.18 KB
#### By Andras Lasso on 2017-01-22 17:26
Unable to retrieve transform 'ProbeToTracker'

=> For calibration you need the transform between Probe and Tracker coordinate system, but Plus cannot get this.

Transform path not found from Probe to Tracker coordinate system. Available transforms in the repository (including the inverse of these transforms): ProbeToTrackerDevice (invalid, non-persistent), ReferenceToTrackerDevice (valid, non-persistent), StylusToTrackerDevice (invalid, non-persistent)

=> "ProbeToTrackerDevice (invalid, non-persistent)" indicates that your Probe marker was not visible.

Solution: Make sure the probe and reference markers are visible during spatial calibration data collection. To show tool visibility status, go to Configuration tab and click on the "pop out" icon in the top-right corner of the tool state display section.
#### By Vipulraikar288768 on 2017-01-22 17:47
I am certain they were visible but, I tried again. I have attached screenshots for the same.

I apologize if I am missing something trivial.
calibration_img.png	449 KB
segtoolbox_img.png	343 KB
#### By Andras Lasso on 2017-01-22 17:52
Can you attach the log?
You may try to set LocalTimeOffset to 0 and see if it helps.
#### By Vipulraikar288768 on 2017-01-22 18:14
Okay tried that with the same conditions. Log1 is before making the change to the LocalTimeOffsetSec value.
Log1.txt	8.32 MB
Log2.txt	551 KB
#### By Andras Lasso on 2017-01-22 18:50
Could you try changing your tracker configuration to one of these?

<Device
Id="TrackerDevice"
...
ToolReferenceFrame="TrackerDevice" >

or to:

<Device
Id="Tracker"
...
ToolReferenceFrame="Tracker" >
#### By Vipulraikar288768 on 2017-01-22 20:33
The second one works and now I can perform the calibration. However, the error is very high in all the trials I have conducted so far. The video stream seems to be quite jittery and slow.
#### By Andras Lasso on 2017-01-22 20:39
Set logging to INFO level and attach the log of a complete spatial calibration. Move the probe very slowly, just translate it forward and backwards.
#### By Andras Lasso on 2017-01-22 20:48
See also "I get large (>2-3mm) probe spatial calibration error - what's wrong?" section on this page:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html
#### By Vipulraikar288768 on 2017-01-22 21:41
I got it at a mean of 1.2mm. It was the wrong image orientation. Thank you very much for your help and prompt responses! Also restarting fCal stopped the jittery video.
#### By Andras Lasso on 2017-01-23 09:20
Thanks for letting us know, I'm happy that it all worked out. FYI, we've fixed the issue that required setting ToolReferenceFrame="Tracker" (it was due to unnecessarily strict data validity check).


## Unable to record data with the Plus Remote module
#### Posted by lars.eirik.bo558524 on 2017-01-16 08:43

Hi,

I am trying to do a tracked ultrasound recording with a SonixMDP scanner, NDI Aurora and the Plus Remote module in Slicer. Streaming images and tracking data from the scanner to Slicer was straight forward, but when I open the Plus Remote module and select the OpenIGTLinkConnector, the Capture Device ID and Reconstructor Device ID both remain blank (the drop-down lists are empty). Subsequently, I'm able to start a recording, but when I try to stop it, I get the error message "VirtualStreamCapture has not been found (auto-detect), StopRecording failed". I am guessing that there's something wrong with my Device Set configuration file, which I have attached. Can anyone see what is wrong?
PlusDeviceSet_Server_SonixTouch_C5-2_pointer_Aurora.xml	4.85 KB

#### 2 Comments
#### By Andras Lasso on 2017-01-16 08:48
There is no capture device (device that writes a channel to file) in your configuration file. Add a VirtualDiscCapture device attached to the mixer device output and it should work. See VirtualDiscCapture documentation and examples at:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceVirtualDiscCapture.html
#### By Lars.Eirik.Bo558524 on 2017-01-23 05:45
Great! That solved it. Thank you for the swift and helpful reply.


## config file for Polaris Vicra for use with SlicerIGT
#### Posted by banderies on 2017-01-22 20:23

Hello all,

I am an undergraduate student in biomedical engineering currently working on my senior capstone project. I am hoping to use an NDI Polaris Vicra in conjunction with 3D Slicer via SlicerIGT in my project. I am new to 3D Slicer, SlicerIGT, and PLUS, so please forgive me if my questions are naive or the information is available elsewhere.

I am trying to understand what needs to be in the config file for the PlusServer in order for it to work with SlicerIGT. I have looked at the SlicerIGT tutorial powerpoints, the "PlusDeviceSet_Server_Ascension_NDIPolaris.xml" file, and tried to find information on the PLUS website, but have not had any luck. Does anyone have any experience using a Vicra with 3D Slicer? Is there somewhere I can learn the basics of how the config file works? The "PlusDeviceSet_Server_Ascension_NDIPolaris.xml" file is for both an optical and EM tracker. I have not been able to figure out how to remove all of the EM tracker parts of the file, nor do I understand what is needed (i.e. what data do I need to feed to SlicerIGT).

I would appreciate any information!

Thanks and best regards,

Barrett

#### 6 Comments
#### By Tamas Ungi on 2017-01-22 21:00
Hi,

Have you tried to start from a config file that only uses an NDI optical tracker, like PlusDeviceSet_Server_NDIPolaris.xml?
I haven't used Vicra, but I think it is the little brother of Polaris, so the Polaris config files might work as is. The com port needs to be adjusted and the rom files for your specific markers for sure.

Tamas
#### By Andras Lasso on 2017-01-22 21:29
Polaris and Vicra has the same software interface, so any Polaris example will work.

What tools you would like to track? Do you use any real-time imaging?
#### By Banderies on 2017-01-22 21:59
Hi Tamas and Andras,

Thank you for the responses! I do not see a file called "PlusDeviceSet_Server_NDIPolaris.xml." I only have what is in the SlicerIGT-Tutorial folder from the SlicerIGT website. Where can I get the previously mentioned file?

As I understand it, the Polaris Vicra and Polaris Spectra are the same apart from refresh rate and trackable volume, therefore I think that their config files would be nearly identical.

I will need to track at least one rigid body and several tools. I will not be using real time imaging. The first step is to recreate a simple image-guided system that just allows visualizations of scans (and 3D reconstructions of scans) based on the position of a pointer (i.e. the most basic features of a stealth station or brain lab system). Then I am hoping to be able to place 3D objects into the scenes (both in the 2D and 3D visualizations) using the pointer (say, create a solid sphere of radius r and color c at the tip of the wand). Does this sound possible? I was planning to attempt this using a Slicer extension written in python, but I am just beginning and am not exactly sure how extensions work. I only discovered this approach several days ago.

I would greatly appreciate it if you could help me locate the file mentioned, and any suggestions you might have.

Thanks!

Barrett
#### By Tamas Ungi on 2017-01-22 22:09
You will find all the PLUS config file examples under the SVN tab of this space. More specifically, this is the config file we were referring to: https://app.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/ConfigFiles/PlusDeviceSet_Server_NDIPolaris.xml
Note the .rom file references for each tool. Do you have rom files for your markers?
#### By Banderies on 2017-01-22 22:32
Perfect, thanks!

I do not have .rom files for my markers yet because the tools and rigid bodies we are using are those that come with BrainSight, not the stock NDI ones. I am hoping to locate the .roms on the BrainSight workstation, but if I can't, I have the NDI 6D Architect software and will create my own .rom files.

Thanks for the help. I really appreciate it!
#### By Andras Lasso on 2017-01-23 01:26
If you only need tool tracking then you can use the NDI Polaris configuration as is. The config file is included in your Plus applications install package and show up in PlusServerLauncher as "PlusServer: NDI Aurora and Polaris tracker".

For most navigation scenario you don't need any programming, just follow tutorials at www.slicerigt.org to learn how to set up navigation scenes.


## Inverted fan clipping region parameters
#### Posted by Dzenan Zukic on 2016-12-26 19:11

What would be appropriate parameters for fan clipping of the attached slice? Frame size is 700x640. The rectangular clipping as specified below works well.

When I try adding Fan clip region, I get empty volume as a result. Besides parameters below, I also tried FanAnglesDeg="-30 30" and FanAnglesDeg="150 210" with same result (all black volume). Removing FanAnglesDeg and adding EnableFanAnglesAutoDetect="true" detects that all frames are empty (again all black result).

~~~~
  <VolumeReconstruction
    OutputSpacing="0.03 0.03 0.2"
    PixelRejectionThreshold="3"
    FanOriginPixel="350 1940"
    FanRadiusStartPixel="1440"
    FanRadiusStopPixel="1940"
    FanAnglesDeg="-60 -120"    
    ClipRectangleOrigin="15 0"
    ClipRectangleSize="670 550"
    Interpolation="LINEAR"
    Optimization="FULL"
    CompoundingMode="Mean"
    FillHoles="OFF">
  </VolumeReconstruction>
~~~~

#### By the way, docs are not in sync with the code (EnableFanAngleAutoDetect vs EnableFanAnglesAutoDetect, singular vs plural).
FanParams.png	278 KB

#### 3 Comments
#### By Andras Lasso on 2016-12-26 21:36
From the image it seems that your fan origin is outside the image, so Y coordinate should be negative (see axis direction in the documentation page).

The fan always opens towards the "far" direction, so if you need to invert the fan it indicates that probably your image orientation is defined incorrectly (xF <-> xN).

Automatic fan angle detection only reduces the fan angle range, never makes it larger than the complete fan.

Doc typo fixed in rev 4999. Thanks!
#### By Dzenan Zukic on 2016-12-27 11:58
Thanks for the help Andras!

To change the image orientation from UN to UF or MF, some other pieces of the system would probably need to be modified. I will have to check with collaborators whether this is worth it after the holidays.

The temporary solution is to comment out the check if (fanLinePixelRatioLeft > fanLinePixelRatioRight) in PlusLib\src\PlusVolumeReconstruction\vtkPlusPasteSliceIntoVolumeHelperOptimized.h line 939. This allows the fan to point in the other direction if angles are reversed. The accompanying configuration section:

~~~~
  <VolumeReconstruction
    OutputSpacing="0.03 0.03 0.2"
    PixelRejectionThreshold="3"
    EnableFanAnglesAutoDetect="false"
    FanOriginPixel="350 1300"
    FanRadiusStartPixel="800"
    FanRadiusStopPixel="1300"
    FanAnglesDeg="15 -15"
    ClipRectangleOrigin="15 0"
    ClipRectangleSize="670 530"
    Interpolation="LINEAR"
    Optimization="FULL"
    CompoundingMode="Mean"
    FillHoles="OFF">
  </VolumeReconstruction>
~~~~
  
#### By Andras Lasso on 2016-12-27 12:46
Using correct image orientation is not optional. If you leave an error like this in the pipeline then it forces you to make several additional errors at random locations to compensate for that. Such mistakes also make debugging/troubleshooting a trial-and-error based process (as there is always some inconsistency in your data).


## IANA_TYPE_US_ASCII undeclared
#### Posted by Dzenan Zukic on 2016-12-22 11:36

With current SVN version I get this build error:

C:\Dev\plus\bin64-2015\PlusLib\src\PlusServer\vtkPlusOpenIGTLinkServer.cxx(1174): error C2065: 'IANA_TYPE_US_ASCII': undeclared identifier

Google search does not yield any results for this name. Revision 4975 changed 3 into IANA_TYPE_US_ASCII.

The reason I updated was trying to see if a crash of EditSequenceFile in C:\Dev\plus\bin64-2015\PlusLib\src\PlusCommon\vtkPlusRecursiveCriticalSection.cxx was resolved. Namely, just EditSequenceFile.exe --help causes a crash during cleanup after main exits, both with current revision and at least since revision 4945. I am using VS2015 x64.

#### 5 Comments
#### By Adam Rankin on 2016-12-22 11:57
Pull latest OpenIGTLink depedency
#### By Dzenan Zukic on 2016-12-22 12:59
Thanks Adam, that solved it. A clean build does, too.

However, even with a clean build in Release mode, I am still experiencing this crash with --help argument. It happens with many (all?) command line tools: VolumeReconstructor, PlusServer, EditSequenceFile, PlusServerRemoteControl.
#### By Dzenan Zukic on 2016-12-23 09:21
With shorter build path the crash with --help argument disappears, too.
#### By Dzenan Zukic on 2016-12-23 09:23
I jumped the gun. This was built with shared libraries. Doing another clean build with static libraries in short path.
#### By Dzenan Zukic on 2016-12-23 10:28
It crashes with static libraries even in short build path. I will submit an issue.


## VolumeReconstructor with non 1.0 pixel spacing?
#### Posted by Dzenan Zukic on 2016-12-22 16:31

Invoking VolumeReconstructor with --source-seq-file=Pruned.mhd --output-volume-file=PrunedRec.mha --config-file=Config.xml --image-to-reference-transform=USImageToReference yields a reconstructed volume with approximate size 800mm x 700mm x 60mm. Given the ElementSpacing = 0.0303 0.0283 10.0 I would have expected approximate size 20mm x 20mm x 60mm. By looking at the volume rendering (screenshot), it is clear that Z coordinate was ignored too, as slices look too thin to be 10 mm thick.

How to get pixel spacing different from 1.0?
Config.xml	4.13 KB
Pruned.zraw	1.11 MB
Pruned.mhd	2.07 KB
Screenshot2016-12-2216.27.44.png	276 KB

#### 9 Comments
#### By Andras Lasso on 2016-12-22 16:34
ElementSpacing in sequence metafiles are ignored. Image position, orientation, and spacing are defined by transforms.
#### By Dzenan Zukic on 2016-12-22 16:36
OK, I will give it a try.
#### By Andras Lasso on 2016-12-22 16:48
Also note that the volume reconstructor considers the US slices to be inifinitely thin. You can prevent gaps in the reconstructed volume by dense enough sampling (have at least one US slice intersect each voxel) or enable hole filling.
#### By Dzenan Zukic on 2016-12-22 16:56
OK, putting scales in the transform matrix solves the X and Y size.

The Z size seems to be ignored and what is used is the target spacing instead. Also, the last slice is not in the reconstructed volume, probably because size was rounded down. Both of these are noticeable in this minimal artificial example.
Pruned.mhd	1.84 KB
#### By Dzenan Zukic on 2016-12-22 17:06
OK, I found a fix for rounding. I will create an issue and close it via a commit.
#### By Andras Lasso on 2016-12-22 17:08
Automatic extent computation (enabled by default, if you don't specify output extent) might be too conservative - feel free to adjust it by adding some epsilon or round it up.

Output spacing specifies the output volume's spacing. Input slice spacing has no effect on output spacing.
#### By Dzenan Zukic on 2016-12-22 17:09
The ticket number was #1132
#### By Dzenan Zukic on 2016-12-22 17:15
Thanks for your help Andras!

Does current version of PlusOpenIGTLinkServer put image spacing in transform?
#### By Andras Lasso on 2016-12-22 17:27
Thank you. Yes, slice position, orientation, and spacing are always specified using transforms. Image coordinate system unit is pixel. Usually ImageToProbe transforms from pixel to physical space.


## Multiple inputs for VolumeReconstructor
#### Posted by Dzenan Zukic on 2016-12-20 17:49

For a project there is a need to fuse multiple sweeps with ultrasound into a single 3D volume. The ultrasound frames have proper tracking information (so consecutive sweeps are next to each other with partial overlap). My plan is to modify VolumeReconstructor to accomplish this. What is the best way for you to test my modifications before I commit them to subversion?

As doing sweeps takes time, I thought it would be good to have a partially reconstructed volume with all sweeps so far, and then extend it by adding the newest sweep to it once it is available. This would parallelize frame acquisition and volume reconstruction. Also, the process priority of the volume reconstructor would be lowered to not interfere with the ongoing acquisition. This would require adding optional --initial-volume parameter to VolumeReconstructor.

Do you have any suggestions or
####  comments about this plan? @lassoan @rankin @ungi

#### 8 Comments
#### By Andras Lasso on 2016-12-20 19:08
You can already fuse as many sweeps as you need. Of course the main issue is how to handle overlapping regions, as there are always differences between sweeps (due to varying probe pressure, patient motion, cardiac, respiratory, and other internal organ motion, difference in reflectance depending on scan direction, speckle pattern, ...). Plus supports different compounding modes(latest, min, max, averaging) and hole filling modes (mean, gaussian, sticks) to reduce seams at overlapping regions but you still need to pay attention to reduce displacements if you want artifact-free volumes.

You can also add frames continuously and retrieve snapshot of the currently reconstructed volume anytime you need (it's called the Live reconstruction mode, available in PlusRemote module in Slicer, see https://www.youtube.com/watch?v=lfZeXabDjMg).

Do you plan to improve compounding modes in Plus? There are a couple of groups that have been working on this (for example http://link.springer.com/chapter/10.1007/978-3-319-46630-9_8). Note that it's very easy to reconstruct nice images from static phantoms - there you only have a few error sources out of the many that you have when scanning patients.
#### By Tamas Ungi on 2016-12-20 19:45
Now that I'm trying to imagine your use case, it seems there could be room for an additional feature over what we have now. You probably want to "fuse" multiple sweeps because you need to change transducer position, but don't want to include the images scanned during probe translation. This would be something like a pause button for the live volume reconstruction we have now (as seen in the video Andras sent).
You could still simulate this workflow by using live volume reconstruction and record sequences at the same time. Then concatenate the sequences offline using EditSequenceFile, and run an offline reconstruction on the concatenated sequence. Then, if it proves to be useful, you could implement that "pause" feature for the live reconstruction device.
#### By Andras Lasso on 2016-12-20 20:56
We already have API for pause/resume volume reconstruction - there is just no button for that on the GUI. It could be added easily.
There is also a feature in Plus that blanks the image automatically if there is no image content (it is mainly used for ignoring part of the image if there is no skin contact somewhere - mostly an issue for curvilinear probes; if you remove the probe from the skin completely then it ignores the entire frame). See demo here: https://www.youtube.com/watch?v=ss7ZTRTNWio
#### By Tamas Ungi on 2016-12-20 23:01
I cannot even keep track of what features we have in PLUS and SlicerIGT...
#### By Adam Rankin on 2016-12-21 13:00
Would the pause button fit your use case?
#### By Dzenan Zukic on 2016-12-21 13:09
Thanks for suggestions! I was unaware of EditSequenceFile tool, this obviates the need for multiple inputs to VolumeReconstructor.

The reason to have partial volume fusion is to reduce time waiting for volume reconstruction, not because those partial volumes are needed - they aren't.

The problems at the seams should be minimal, as "patients" are lab mice. There was also a separate effort to detect respiration and mark those frames with a DO_NOT_USE flag. And the probe motion is motor-actuated and encoder tracked. So this is a near ideal case scenario.

I guess I will try to make it with the existing tools, and gauge importance of potential additions ( --initial-volume or improved compounding).
#### By Andras Lasso on 2016-12-21 13:29
> The reason to have partial volume fusion is to reduce time waiting for volume reconstruction
Volume reconstruction should be doable in real-time, so you can access the reconstructed volume as images are acquired. Hole filling may take a few seconds, but if probe motion is linear and speed is controlled then hole filling is probably not needed. If you run PlusServer in a separate process then you can use the same method as PlusRemote in Slicer to get snapshots at every few seconds.
#### By Dzenan Zukic on 2016-12-21 14:58
Thanks for the suggestion. I will check how long does volume reconstruction take with the test sequences, and possibly have just a single reconstruction at the end.


## std::string to std::wstring
#### Posted by Dzenan Zukic on 2016-12-12 17:38

With revision 4970 I get the following error twice:

C:\Dev\plus\bin64-2015\PlusLib\src\PlusDataCollection\Testing\vtkMmfVideoSourceTest.cxx(103): error C2664: 'void vtkPlusMmfVideoSource::SetRequestedVideoFormat(const std::wstring &)': cannot convert argument 1 from 'std::string' to 'const std::wstring &' [C:\Dev\plus\bin64-2015\PlusLib-bin\src\PlusDataCollection\Testing\vtkMmfVideoSourceTest.vcxproj]

#### 2 Comments
#### By Adam Rankin on 2016-12-12 18:38
4971... oops
#### By Dzenan Zukic on 2016-12-12 20:39
That fixed it, thanks.


## LINK : fatal error LNK1181: cannot open input file 'vtkRenderingGL2PS.lib'
#### Posted by Dzenan Zukic on 2016-12-12 13:03

I set PLUSBUILD_VTK_RENDERING_BACKEND to OpenGL2, and everything builds except fCal and PlusServerLauncher which get the above link error. I guess the recent changes to ${VTK_LIBRARIES} forgot to enumerate all of the libraries needed for those projects.

#### 4 Comments
#### By Dzenan Zukic on 2016-12-12 13:03
Oh, this is VS2015 @Win7 x64.
#### By Adam Rankin on 2016-12-12 13:10
Hmm, checking. I had written a bit of CMake logic to detect if the target vtkRenderingGL2PS${VTK_RENDERING_BACKEND} existed, and if so, included that.

Investigating.
#### By Adam Rankin on 2016-12-12 13:12
Could you throw a message("1234")/("5678") in ...\PlusApp\PlusServerLauncher\CMakeLists.txt line 41 and 45 and see which one fires?

Adam
#### By Dzenan Zukic on 2016-12-12 17:37
Revision 4970 resolves this error.


## Error in Volume Reconstruction inside fcal
#### Posted by goby.dll173884 on 2016-10-07 09:36

Dear All,
when I try to reconstruct a volume from a recorded tracker image sequence with more than 200 images I have the following error (and consequent fcal crash):

~~~~
|ERROR|121.885000| VTK log: ERROR: In d:\d\psnpimt37b\deps\vtk\common\core\vtkDataArrayTemplate.txx, line 142|vtkUnsignedCharArray (1EDEF250): Unable to allocate 131019744 elements of size 1 bytes. ||| in ..\..\..\PlusLib\src\PlusCommon\vtkPlusLogger.cxx(75)
|ERROR|121.897000| Last error: 0| in ..\..\..\PlusLib\src\PlusCommon\vtkPlusLogger.cxx(79)
Qt has caught an exception thrown from an event handler. Throwing exceptions from an event handler is not supported in Qt. You mustreimplement QApplication::notify() and catch all exceptions there.
~~~~

I think the error is related to memory limitation connected to the use of 32bit version of Plus. is it right?

#### 1 Comments
#### By Andras Lasso on 2016-12-04 20:50
Yes it is due to limited memory space. If you want to reconstruct a large high-resolution volume then you have two options:

A. Use real-time volume reconstruction. This way you don't need to allocate memory for the input frames, only for the reconstructed volume, so the volume can be larger.

B Reconstruct the volume in a 64-bit PlusServer. If your devices only have 32-bit drivers then you can run a 32-bit PlusServer to connect to devices and send tracked frames to the 64-bit server.

Example config files:
32-bit PlusServer acquiring data from hardware:
https://app.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/ConfigFiles/PlusDeviceSet_Server_Sim_NwirePhantomTrackedFrameAcquisition.xml
64-bit PlusServer reconstructing volume:
https://app.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/ConfigFiles/PlusDeviceSet_Server_Sim_NwirePhantomTrackedFrameProcessing.xml


## PlusServerRemoteControl
#### Posted by david.kuegler833514 on 2016-11-30 17:26

Hi

There seems to be an issue with the plusserverremotecontrol.exe tool.

So regarding PlusLib/src/PlusServer/Tools/PlusServerRemoteControl.cpp:

It seems the std::string command line 697 in HEAD is never actually set.

I.e. the parameter --command is missing in the list (lines 724 to 747).

David

#### 1 Comments
#### By Andras Lasso on 2016-12-04 20:38
Good catch, thank you. The line has been accidentally removed during a recent merge. I've restored it now.


## Image + position with SonixTab and MicronTracker
#### Posted by Loïc_Tetrel on 2016-09-30 18:01

Hi everyone,

I want to collect images and positions from a SonixTab echograph and MicronTracker 3. I installed plus (version Plus-2.3.0.4888 - Win32) into a PC which is connected to the echograph via local network.
When I stream images alone there is no problem, but when I add microntracker device, there is an error. I use a custom marker called "plastic" that I placed into the right folder into plus.
The positions works well with the C# demo of MicronTracker.

I attached my configuration file and log file,

Somebody here to help me please ?
092716_171735_PlusLog.txt	1.92 KB
SonixTabletMicronTracker.xml	2.88 KB

#### 14 Comments
#### By Andras Lasso on 2016-09-30 18:40
Connection to MicronTracker fails. Probably due to mismatch of the MicronTracker SDK that is on your computer vs. the one that is built into Plus. Which MicronTracker SDK version do you use? 32/64 bit? Does MicronTrackerCppDemo works on your computer?
#### By Loïc_Tetrel on 2016-10-03 11:07
MicronTrackerCppDemo doesn't work on my computer, just C# demo, vb.net demo and R fine.
I will try to fix this.
#### By Loïc_Tetrel on 2016-10-03 11:43
MicronTrackerCppDemo is working, I have 3.8.0.8 build in 32 bit.

If we look at the first error :
data at: C:\Program Files\ClaroNav\MicronTracker/CalibrationFiles

It should be "\" instead of "/" : C:\Program Files\ClaroNav\MicronTracker\CalibrationFiles

Maybe that is why he couldn't find calibration files ?

Because PLUS uses 3.6.5.4 build, do you think the 3.8.xx is not compatible ?
#### By Andras Lasso on 2016-10-03 12:11
I think the issue is that Plus packages are built with MicronTracker 3.6 or 3.7 but not with 3.8. From the Start menu run Plus applications ... / Plus command prompt and run PlusVersion.exe. It'll print the MicronTracker version that your Plus is built with. If there is a mismatch then you either have to install that MicronTracker SDK version on your computer or build Plus with MicronTracker 3.8. If none of them is feasible then let me know and we may be able to create a Plus build with MicronTracker 3.8
#### By Loïc_Tetrel on 2016-10-03 13:39
Hi Andras and thank you for your fast awnser !

It said that PLUS is built with 3.6.5.4 Micron Tracker sdk.
Because this computer is not really fast and don't have lot of hard space, is it possible to build a version of plus win32 with MicronTracker 3.8.0.10 ?

Thank you,
#### By Loïc_Tetrel on 2016-10-03 15:21
To be more precise, the 32bit version of the newest MicronTracker sdk (3.8.0.10) is located under Program Files and not Program Files (x86). In this subfolder there are folders called 32bits release, maybe this is the problem ?

I am in contact with MicronTracker to see if it is possible to have the 32 bits version.
#### By Andras Lasso on 2016-10-03 15:23
Usually MicronTracker SDKs that differ in minor version (for example 3.7 vs. 3.8) are not compatible with each other. Also, 32/64 bitness should match.
#### By Tamas Ungi on 2016-10-03 21:27
I remember having many random issues with MicronTracker before I got it working. Like e.g. the cable has to be connected to the computer before the computer is powered on. If the cable is disconnected and reconnected, the computer needs to be restarted.
But I also clearly remember using the 64-bit MicronTracker software with 32-bit PLUS.
Are you using an Ultrasonix ultrasound machine? I was reading about PLUS packages, and both installers for Sonix says that "MicronTracker ... devices are not supported". Just a thought.
#### By Loïc_Tetrel on 2016-10-04 10:40
I am using a normal PC (where I have MicronTracker) which is connected to the SonixTab via local network. If you use 64 bit version of PLUS, MicronTracker is not supported. But it should be supported for PLUS 32bit if you have 3.6.5.4 sdk.
I will now try to build PLUS on my computer and let you know.
#### By Loïc_Tetrel on 2016-10-13 15:43
I built PLUS and it works. The problem is that the company change name, so in the new sdk (5.8) the folder change from \Claron to \ClaroNav. I updated the Cmake.
Don't forget that it requires path to lib: ..\ClaroNav\MicronTracker\Dist\MTC.lib
And just folder for inc and bin : ..\ClaroNav\MicronTracker\Dist\
(\Dist64 if you want to try 64bit).
Moreover, don't forget to look at the Marker folder in Plus if PLUS can't detect position while running.

If you have an sonixTab, then the version is 6.0.7 but this sdk doesn't work with PLUS. Instead download 6.1.2 and it should work (don't forget to change sdk version variables in Cmake from 5.7.4 to 6.1.2). I would advice you to set PLUS_TEST_ULTRASONIX on for a ping test between the echograph and your PC (don't forget to change IP in CmakeLists.txt or Cmake).

I still have problem to detect EM position using 3Dascension (it's wired because all test passed http://crunch.cs.queensu.ca/CDash/buildSummary.php?buildid=58554). It works if I have PLUS installed on the echograph, I attached the log.

Does someone had this error : "No BIRDs found" ?
FindMicronTracker.cmake	4.4 KB
101316_112720_PlusLog.txt	19.7 KB
#### By Andras Lasso on 2016-10-22 23:13
Does it work for you now?

Plus has to run on the computer that the Ascension tracker is connected to. We usually run fCal on the Ultrasonix computer. If you want to run fCal on a different computer then run PlusServer on the Ultrasonix computer to make tracking data available to other computers using OpenIGTLink.
#### By Loïc_Tetrel on 2016-11-04 15:49
Ok, I wasn't sure it was possible to have multiple instance of PlusServer.

Thank you !
#### By Loïc_Tetrel on 2016-12-01 17:08
So I'm trying to create an .mha file with electromagnetic (EM), optical (OP) tracker and US images.
I have a plus Server running on the echograph for image + EM.
I have a plus Server running on my computer for OP.

I want to record a single sequence in slicer with EM + OP + images. How can I do that ?

For now I have under OpenIGTLinkIF module :
IGTLConnector for EM + image
IGTLConnector_1 for OP

When I use PlusRemote module I can save a .mha file but just with one IGTLConnector (I can't combine IGTLConnector and IGTLConnector_1).
#### By Adam Rankin on 2016-12-02 11:57
Hi Loïc,

Sorry for the delayed response. In order to record everything into a single file, they will have to be output by a single channel in a single device. If you are unable to plug the OP into the same computer as the image + EM, you will have to do the following:
diagram.png	10.4 KB


## Building fCal fails due to link errors in QSpatialCalibrationToolbox
#### Posted by Dzenan Zukic on 2016-11-23 09:54

A clean build produces these errors. CMakeCache.txt is attached.
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: static class vtkPlusProbeCalibrationAlgo * __cdecl vtkPlusProbeCalibrationAlgo::New(void)" (__imp_?New@vtkPlusProbeCalibrationAlgo@@SAPAV1@XZ) referenced in function "public: __thiscall QSpatialCalibrationToolbox::QSpatialCalibrationToolbox(class fCalMainWindow *,class QFlags<enum Qt::WindowType>)" (??0QSpatialCalibrationToolbox@@QAE@PAVfCalMainWindow@@V?$QFlags@W4WindowType@Qt@@@@@Z)
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: enum PlusStatus __thiscall vtkPlusProbeCalibrationAlgo::ReadConfiguration(class vtkXMLDataElement *)" (__imp_?ReadConfiguration@vtkPlusProbeCalibrationAlgo@@QAE?AW4PlusStatus@@PAVvtkXMLDataElement@@@Z) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::OnActivated(void)" (?OnActivated@QSpatialCalibrationToolbox@@UAEXXZ)
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: enum PlusStatus __thiscall vtkPlusProbeCalibrationAlgo::Calibrate(class vtkPlusTrackedFrameList *,class vtkPlusTrackedFrameList *,class vtkPlusTransformRepository *,class std::vector<class PlusNWire,class std::allocator<class PlusNWire> > const &)" (__imp_?Calibrate@vtkPlusProbeCalibrationAlgo@@QAE?AW4PlusStatus@@PAVvtkPlusTrackedFrameList@@0PAVvtkPlusTransformRepository@@ABV?$vector@VPlusNWire@@V?$allocator@VPlusNWire@@@std@@@std@@@Z) referenced in function "protected: void __thiscall QSpatialCalibrationToolbox::DoCalibration(void)" (?DoCalibration@QSpatialCalibrationToolbox@@IAEXXZ)
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall vtkPlusProbeCalibrationAlgo::GetImageToProbeTransformMatrix(class vtkMatrix4x4 *)" (__imp_?GetImageToProbeTransformMatrix@vtkPlusProbeCalibrationAlgo@@QAEXPAVvtkMatrix4x4@@@Z) referenced in function "protected: enum PlusStatus __thiscall QSpatialCalibrationToolbox::SetAndSaveResults(void)" (?SetAndSaveResults@QSpatialCalibrationToolbox@@IAE?AW4PlusStatus@@XZ)
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: double __thiscall vtkPlusProbeCalibrationAlgo::GetCalibrationReprojectionError3DMean(void)" (__imp_?GetCalibrationReprojectionError3DMean@vtkPlusProbeCalibrationAlgo@@QAENXZ) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::SetDisplayAccordingToState(void)" (?SetDisplayAccordingToState@QSpatialCalibrationToolbox@@UAEXXZ)
30>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __thiscall vtkPlusProbeCalibrationAlgo::GetResultString(int)" (__imp_?GetResultString@vtkPlusProbeCalibrationAlgo@@QAE?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::SetDisplayAccordingToState(void)" (?SetDisplayAccordingToState@QSpatialCalibrationToolbox@@UAEXXZ)
CMakeCache.txt	27.2 KB

#### 13 Comments
#### By Adam Rankin on 2016-11-23 10:17
Doing a clean build now, will let you know what I discover.
#### By Adam Rankin on 2016-11-23 10:29
Also, I don't have access to the Capistrano Labs SDK, so I cannot enable that device. I will continue with it disabled.

Perhaps you could negotiate with them to open up their SDK.
#### By Adam Rankin on 2016-11-23 10:32
Same issue with the IntersonCXX option.
#### By Dzenan Zukic on 2016-11-23 11:17
I have disabled those two options and doing an incremental build.
#### By Adam Rankin on 2016-11-23 11:26
My clean build succeded (vs2015). Testing vs2013 now.

Those two options still disabled.
#### By Dzenan Zukic on 2016-11-23 11:44
I still have the errors:

11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: static class vtkPlusProbeCalibrationAlgo * __cdecl vtkPlusProbeCalibrationAlgo::New(void)" (__imp_?New@vtkPlusProbeCalibrationAlgo@@SAPAV1@XZ) referenced in function "public: __thiscall QSpatialCalibrationToolbox::QSpatialCalibrationToolbox(class fCalMainWindow *,class QFlags<enum Qt::WindowType>)" (??0QSpatialCalibrationToolbox@@QAE@PAVfCalMainWindow@@V?$QFlags@W4WindowType@Qt@@@@@Z) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: enum PlusStatus __thiscall vtkPlusProbeCalibrationAlgo::ReadConfiguration(class vtkXMLDataElement *)" (__imp_?ReadConfiguration@vtkPlusProbeCalibrationAlgo@@QAE?AW4PlusStatus@@PAVvtkXMLDataElement@@@Z) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::OnActivated(void)" (?OnActivated@QSpatialCalibrationToolbox@@UAEXXZ) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: enum PlusStatus __thiscall vtkPlusProbeCalibrationAlgo::Calibrate(class vtkPlusTrackedFrameList *,class vtkPlusTrackedFrameList *,class vtkPlusTransformRepository *,class std::vector<class PlusNWire,class std::allocator<class PlusNWire> > const &)" (__imp_?Calibrate@vtkPlusProbeCalibrationAlgo@@QAE?AW4PlusStatus@@PAVvtkPlusTrackedFrameList@@0PAVvtkPlusTransformRepository@@ABV?$vector@VPlusNWire@@V?$allocator@VPlusNWire@@@std@@@std@@@Z) referenced in function "protected: void __thiscall QSpatialCalibrationToolbox::DoCalibration(void)" (?DoCalibration@QSpatialCalibrationToolbox@@IAEXXZ) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall vtkPlusProbeCalibrationAlgo::GetImageToProbeTransformMatrix(class vtkMatrix4x4 *)" (__imp_?GetImageToProbeTransformMatrix@vtkPlusProbeCalibrationAlgo@@QAEXPAVvtkMatrix4x4@@@Z) referenced in function "protected: enum PlusStatus __thiscall QSpatialCalibrationToolbox::SetAndSaveResults(void)" (?SetAndSaveResults@QSpatialCalibrationToolbox@@IAE?AW4PlusStatus@@XZ) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: double __thiscall vtkPlusProbeCalibrationAlgo::GetCalibrationReprojectionError3DMean(void)" (__imp_?GetCalibrationReprojectionError3DMean@vtkPlusProbeCalibrationAlgo@@QAENXZ) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::SetDisplayAccordingToState(void)" (?SetDisplayAccordingToState@QSpatialCalibrationToolbox@@UAEXXZ) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>QSpatialCalibrationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __thiscall vtkPlusProbeCalibrationAlgo::GetResultString(int)" (__imp_?GetResultString@vtkPlusProbeCalibrationAlgo@@QAE?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) referenced in function "public: virtual void __thiscall QSpatialCalibrationToolbox::SetDisplayAccordingToState(void)" (?SetDisplayAccordingToState@QSpatialCalibrationToolbox@@UAEXXZ) [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
11>C:\Dev\plus\bin32-2013\bin\Debug\fCal.exe : fatal error LNK1120: 6 unresolved externals [C:\Dev\plus\bin32-2013\PlusApp-bin\fCal\fCal.vcxproj]
#### By Andras Lasso on 2016-11-23 12:13
Can you find New@vtkPlusProbeCalibrationAlgo@@SAPAV1@XZ text in vtkPlusCalibration.lib? Can you find vtkPlusCalibration.lib in linker inputs of fCal application (in VIsual Studio project settings)?
#### By Dzenan Zukic on 2016-11-23 14:25
The first offending symbol __imp_?New@vtkPlusProbeCalibrationAlgo@@SAPAV1@XZ does not exist, but ?New@vtkPlusProbeCalibrationAlgo@@SAPAV1@XZ does exist (the difference being __imp_ prefix)
#### By Dzenan Zukic on 2016-11-23 14:26
vtkPlusCalibration.lib is among the linker inputs of fCal
#### By Adam Rankin on 2016-11-23 17:20
Confirmed problem occurs when building static libs. Investigating.
#### By Adam Rankin on 2016-11-23 17:45
Problem identified. PlusLib_STATIC is not correctly defined in the context of QSpatialCalibrationToolbox.cxx. Thus functions are linked to as _declspec dllimport even though they were built statically. I'd like to move the static definition into CMake target defines instead of PlusConfigure.h, but will consult with Andras first.
#### By Adam Rankin on 2016-11-24 12:25
Ok, static build is resolved.
#### By Dzenan Zukic on 2016-11-25 10:16
Confirmed, builds without errors now, both with and without Interson and Capistrano enabled.


## volume reconstruction problem, scaling not applied to images?
#### Posted by Elvis Chen on 2016-11-15 17:10

Greetings,

I am trying to use fCal to acquire a set of tracked 2D US images and use VolumeReconstroctor.exe to reconstruct them into a 3D volume. While this pipeline works, the output volume is NOT what I expect, I seek your help.

First, I am using Ultrasonix SonixTouch with a L14-5 linear probe (6cm imaging depth). The configuration file (.xml) is attached. In short, in the configuration file I specified the probe calibration using the following transform:

~~~~
<CoordinateDefinitions>
<Transform From="Image" To="Probe"
Matrix="0.000641493683585 -0.102010981266328 -0.005996727197143 -39.769054339584912
-0.102108458621093 -0.001469475655336 0.014408706768261 33.703798883286794
-0.014537197022929 0.005820000504602 -0.101470572292781 -3.718941855551710
0 0 0 1"
Error="2.61713" Date="110415_125215" />
</CoordinateDefinitions>
~~~~

Note the first 3x3 contained the scaling information. Using this configuration file, I was able to run fCal (on the ultrasonix embedded 32bit XP), and save the tracked sequence to a file. In the process of doing so, it saves a ".xml" file as well as a ".mha" file.

I was NOT able to reconstruct the 3D volume, in real time, on the SonixTouch due to the limitation of the memory/32bit OS. Therefore, I took the 2 files (.mha/.xml) to another computer running 64bits Windows 10, which has PlusApp-2.4.0.4932-Win64.exe installed. From there, I used the volume reconstructor to perform 3D volume reconstruction:

VolumeReconstructor.exe --config-file=TrackedImageSequence_20161115_163736_config.xml --source-seq-file=TrackedImageSequence_20161115_163736.mha --output-volume-file=test.mha --image-to-reference-transform=ProbeToTracker

and it was successful, it generated a volume called test.mha. However, when I visualized the volume inside, say, paraview, the volume looked squeezed in z-dimension, please refer to the attached screen capture. As a reference, the image depth should be roughly 6cm, but the linear translation (across the narrow part) should be 18cm or so.

It would appear to me that the scaling information is not respected, or perhaps there is something wrong with my configuration file. If anyone can help me debugging this, it is very much appreciated,
TrackedImageSequence_20161115_163736_config.xml	9.37 KB
visualize.png	914 KB

#### 7 Comments
#### By Andras Lasso on 2016-11-15 17:20
image-to-reference-transform is the transform between the image coordinate system and reference coordinate system. If you don't have a reference sensor and just want to reconstruct the volume in the tracker coordinate system then use:
--image-to-reference-transform=ImageToTracker
#### By Andras Lasso on 2016-11-15 17:22
Note that ParaView discards image axis orientation information, so images in general appear at a wrong place. Use Slicer or similar applications to view volumes.
#### By Elvis Chen on 2016-11-15 17:31
Thanks Andras. I did what you suggested, but it still looks "flat":

C:\Users\chene\PlusApp-2.4.0.4932-Win64\bin>VolumeReconstructor.exe --config-file=c:\Users\chene\Documents\temp\TrackedImageSequence_20161115_163736_config.xml --source-seq-file=c:\Users\chene\Documents\temp\TrackedImageSequence_20161115_163736.mha --output-volume-file=c:\Users\chene\Documents\temp\test.mha --image-to-reference-transform=ImageToTracker
System start timestamp: 856538
Software version: Plus-2.4.0.4932 - Win64
Reading configuration file:c:\Users\chene\Documents\temp\TrackedImageSequence_20161115_163736_config.xml
Reading image sequence c:\Users\chene\Documents\temp\TrackedImageSequence_20161115_163736.mha
Set volume output extent...
Reconstruct volume...
[==================================================] 100%

Number of frames added to the volume: 192 out of 233
Saving volume to file...

please refer to the attachment for the visualization inside Slicer.

Any help is very much appreciated,
visualize.png	541 KB
#### By Andras Lasso on 2016-11-15 17:38
(Comment removed)
#### By Andras Lasso on 2016-11-15 17:44
In the attached file the image to probe transform is:
<Transform Date="110415_125215" Error="2.61713" Matrix=" 0.0292 0.9993 0.0221 11.1796 0.9992 -0.0285 -0.0275 -58.2856 -0.0269 0.0228 -0.9994 -3.4084 0 0 0 1" To="Probe" From="Image"/>
This is approximately [1,1,1] spacing.
#### By Andras Lasso on 2016-11-15 17:48
#### By the way, real-time-reconstruction require much less memory than off-line reconstruction (it only needs memory for storing the reconstructed volume; frames are not stored). If even the reconstructed volume does not fit into memory then you can launch a PlusServer on a 64-bit machine that receives all tracked frames through OpenIGTLink from the 32-bit PlusServer and reconstructs the volume (and sends it to the application).
#### By Elvis Chen on 2016-11-16 09:54
Andras,

you are absolutely right. Looks like I was working on one XML file (on one machine) but was using the other on a different machine. The problem is now solved.

Thank you for the keen eye, my mistake.


## install target
#### Posted by david.kuegler833514 on 2016-11-01 07:02

Hi,

I want to use PlusToolkit (PlusLib) and be able to redistribute the compiled binaries/libraries for the development of students.
So I created "proper" install files, that is I updated PlusLibConfig.cmake.in, etc. to include no absolute paths (for as much as I could figure out).

It has not undergone rigorous testing yet, which will be limited anyhow, since I only have access to one Tracker (Ascension 3DG).

This should only change the installation target.

I have attached the patch file.

I also added quotation marks so spaces in paths do not break things.
You might want to look through some
####  comments I added.

This post is here to document my changes and to give the opportunity to eventually incorporate them in Plus.

Cheers
David
install_logic_uses_relative_paths_portability.patch	89 KB

#### 1 Comments
#### By Adam Rankin on 2016-11-01 10:26
Hi David,

Thanks for the patch, I learned quite a bit from your cmake changes!

We haven't encountered this use case, as we have our students build PLUS. This is a great feature to have. I have added a ticket and reviewed the changes, and I have a few questions. I will write them up here as I come across them.

Cheers,
Adam


## NDI Polaris Spectra and 3D slicer
#### Posted by akash.gajjar2239237279 on 2016-10-28 02:04

No message content.


#### 1 Comments
#### By Andras Lasso on 2016-10-28 08:11
See www.slicerigt.org


## Saving fCal Temporal Calibration Plots
#### Posted by umutjan on 2016-10-25 05:37

Hello All,
Is there a way to save temporal calibration plots and intermediate data using fCal.exe? I couldn't find generated plots in the data folder.
Should we use TemporalCalibration.exe instead of fCal.exe for this purpose?

Thank you,
Umut

#### 6 Comments
#### By Adam Rankin on 2016-10-27 09:49
Hi @umutjan,

No, there is currently no way to save the plots. I am working on implementing that now. See https://app.assembla.com/spaces/plus/tickets/1118-add-the-option-to-save-plots-from-temporal-calibration-in-fcal/details
#### By Andras Lasso on 2016-10-27 10:40
Temporal calibration command-line tool can save the plots.
#### By Adam Rankin on 2016-10-27 11:15
The latest build of fCal now has a button in the show plots window that allows you to save them to .png
#### By Umutjan on 2016-10-27 11:25
Thank you both. I could also generate plots if I had the moving signal data and line segmentation data in the log files. This is also not possible as I see.
#### By Andras Lasso on 2016-10-27 13:44
You can of course do temporal calibration on recorded data. Option 1: use the command-line temporal calibration tool (the temporal calibration dashboard test uses this method). Option 2. create a configuration file that replays the recorded data using saved data source (there is an example configuration file for this).
#### By Umutjan on 2016-10-28 02:50
Thank you both.


## Can't access the user manual
#### Posted by lars.eirik.bo558524 on 2016-08-18 04:07

Hi,

I'm trying to access the Plus applications user manual, but I get a 404 error message ("The requested URL /plus/doc/nightly/user/index.html was not found on this server."). Anyone who knows anything about this?

Lars Eirik

#### 2 Comments
#### By Umutjan on 2016-10-26 02:26
Have you tried this link: WikiPage User Guide ?

Or, what link are you using?
#### By Adam Rankin on 2016-10-26 07:18
Hi Lars,

It's possible that the build for that night was down, and the documentation wasn't built. The build should be stable now.

Regards,
Adam


## igtlPlusClientInfoMessage.cxx
#### Posted by david.kuegler833514 on 2016-10-24 11:15

Hello everybody,

I am currently trying to use the Plustoolkit with OpenIGTLink.

I came across some issues with building plus with openIGTLink from a "installed" source.

1) #include "igtlutil/igtl_header.h" ( and igtl_util.h ) does not work, since OpenIGTLink installs the util-files into the same include folder.

Solution add igtlutil as an include directory, drop folder specifier (I will probably provide a patch, maybe it could be included in the codebase ;) )

2) several attributes and methods of igtl::PlusClientInfoMessage (or igtl::PlusTrackedFrameMessage or ) are not found by my compiler here are some:
m_SendMessageType
m_MessageSize
GetHeaderVersion()
AllocateBuffer()
InitBuffer()
AllocateBuffer()
GetBufferBodyPointer()
GetBufferBofySize()

They all seem to be missing from MessageBase (part of OpenIGTLink) but I cannot find them in the standard OpenIGTLink distribuition. Do you use a custom distribution?

Thanks for the advise
David

#### 8 Comments
#### By David.Kuegler833514 on 2016-10-24 11:18
(Comment removed)
#### By Adam Rankin on 2016-10-24 11:20
Yes, PLUS uses an OpenIGTLink v3 implementation available at https://github.com/IGSIO/OpenIGTLink. I believe the master branch of https://github.com/openigtlink/OpenIGTLink also has the v3 implementation integrated into it.
#### By David.Kuegler833514 on 2016-10-24 11:25
Well, the openigtlink implementation does not include these.
So I am wondering, what the differences are...

But the official implementation "says" it is v3 compatible so I guess the versions of openigtlink and IGSIO are not compatible, which obviously are very confusing and I cannot use my existing OpenIGTLink Build...
#### By Adam Rankin on 2016-10-24 11:33
What version of the implementation are you working with? Installed from repo? Built from source then installed?

The OpenIGTLink implementation is pulled from the IGSIO implementation. Perhaps it is a CMake issue? I can make the PLUS detection smarter to handle any missing includes in the source repo FIND_PACKAGE configuration file.
#### By Adam Rankin on 2016-10-24 11:35
I think I understand.

You can follow progress here:
https://app.assembla.com/spaces/plus/tickets/1117-plus-does-not-build-against-reference-openigtlink-build/details
#### By David.Kuegler833514 on 2016-10-24 11:46
I guess this is what I am confronted with ... "Plus does not build against reference build".

I had to change the branch of the reference implementation to Version3, since it does not have a Protocoll Version 3 implementation in its main branch ... as far as I know...

Which would be fine, but since IGSIO and openigtlink "both call themselves" "openigtlink" this is a bit confusing. Maybe mention the compatibility in your documentation?


I do not know how well the IGSIO implementation is maintained, but It seems a bit redundant to me.

Thanks for the quick response.
#### By Adam Rankin on 2016-10-24 11:55
OpenIGTLink is just a protocol. Many implementation exist which support different feature sets.

PLUS requires a v3 implementation, which is provided by IGSIO and OpenIGTLink. We are waiting for the OpenIGTLink developers to merge v3 features into the main branch before removing the IGSIO repository.

I will add a check in the CMake to check for v3 functionality.
#### By David.Kuegler833514 on 2016-10-24 11:56
cool ;)


## fCal Temporal Calibration
#### Posted by umutjan on 2016-10-24 09:37

Dear All,
I have questions about the minimum requirements just for doing temporal calibration with VfW Video and NDI Aurora. I have read the documentation but still have questions. Could you please help me with following questions:

- Is it enough to use VfW Video and a single NDI Tracker attached to the probe (a probe without built-in tracker)?
- Do you have a temporal calibration config file for VfW + NDI Tracker setup?
- Do I need to run any pre-calibration process before running temporal calibration (of course, except having a connection)? I see no pre-requisite in the documentation. I assume I can connect and run temporal calibration immediately.
- Do I need to set CoordinateDefinitions? Or temporal calibration is only calculated using periodic data analysis which does not require coordinate transformations?


Thank you for your help.

Umut

#### 2 Comments
#### By Adam Rankin on 2016-10-24 10:36
1) Yes that is sufficient, although beware bumping or moving the Aurora field generator, it will produce a false calibration. If possible, have a fixed reference sensor somewhere within the magnetic field.

2) Not for that combination exactly, but if you substitute a VfW device (or MMF if your capture device supports it) for the Epiphan device in data...\ConfigFiles\PlusDeviceSet_fCal_Epiphan_NDIPolaris.xml that should be close.

3) No, temporal calibration requires no other calibration step.

4) The aformentioned config file will work for temporal calibration. Simply choose the video device, and the transformation that represents your probe movement (most likely ProbeToTracker)
#### By Umutjan on 2016-10-24 11:17
Thank you for quick reply. These will be the first things to do tomorrow morning.

Best,
Umut


## Adjusting US-Image rotation
#### Posted by david.c on 2016-10-13 09:47

Hello everybody,

I'm using an Epiphan VGA2USB FrameGrabber to import the Image of a BK Ultrasound into fCal. The image I get is rotated by 90 degrees (the transducer is on the right), which happens with other software as well (Epiphan, Matlab). I think this is a result of the vertical display-orientation of the BK.
'PortUsImageOrientation' only flips the image. Is there any way of rotating the image to get the right orientation, or am I missing something else?

Regards

#### 13 Comments
#### By Tamas Ungi on 2016-10-13 10:55
Hi David,

In the config file you use, there should be a line that tells PLUS what orientation to expect the images in. Something like
PortUsImageOrientation="MF"
It is important to set this line up correctly, by giving the right two letters. You can use vertical images (although I'm not sure anybody tried that option yet).
Please read this to understand the two-letter orientation code: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/UltrasoundImageOrientation.html

Tamas
#### By Adam Rankin on 2016-10-13 10:57
No, he's correct. There is only flip option.

Would you be able to provide a screenshot David? Does the Epiphan software have an option to rotate the image?

If not, we can add a feature request to add rotation as an image operation option.
#### By Tamas Ungi on 2016-10-13 10:59
I see, you cannot specify a value like "FM". It would be best (simplest for us) if Epiphan could rotate internally.
#### By Adam Rankin on 2016-10-13 11:02
It's not a huge deal really, the infrastructure already exists in VTK.

@david.c, let us know if Epiphan cannot rotate the images.
#### By Andras Lasso on 2016-10-13 11:20
Yes, there is image rotation in Epiphan API (search for "rotation" in the API documentation). It should be very easy to add a new attribute to the Epiphan video source that changes the rotation settings.

Rotation (image transpose) could be done in Plus, too (e.g., allow defining FM for B-mode images).
Pro: It could be usable in all video sources. Note that Epiphan is moving away from offering its own SDK, and instead relies on standard video acquisition APIs (Microsoft Media Foundation, etc) in their newer affordable framegrabbers - so for these devices only Plus-based image transpose will be an option.
Con: Performing combined cropping and flipping for all imaging modes and pixel types in an efficient manner is already quite complex. Adding transpose to the mix (cropping+transposing+flipping) would be feasible but significant work. Also, most probably it would be slower than using Epiphan's built-in (potentially hardware-accelerated) processing.

For now, I would recommend to add support for Epiphan SDK's rotate option in Plus.
#### By David.C on 2016-10-13 11:23
Thanks for your answers!

@Ungi: Yes, "NM" ist exactly what I tried, but changing the axis-definitions like that does not work.

@:Rankin: The Epiphan capture tool can rotate the display-presentation, but this has no effect on the video-stream, and does not change the orientation in other software. Driver-wise there is no option to rotate the incoming video-signal.

EDIT: @Andras: Just read your answer, thank you, I will look it up!
USImageQuer.png	180 KB
#### By Adam Rankin on 2016-10-13 11:30
You can follow development at this ticket

https://app.assembla.com/spaces/plus/tickets/1116-enable-rotation-of-epiphan-stream/details
#### By Adam Rankin on 2016-10-15 19:32
@david.c could you test with the latest revision? You can define a rotation with the RotationMode tag in the Epiphan device.

~~~~
    <Device
      Id="VideoDevice" 
      RotationMode="Right90"
      Type="Epiphan" >
      <DataSources>
        <DataSource Type="Video" Id="Video" PortUsImageOrientation="MF"  />
      </DataSources>      
      <OutputChannels>
      ...
~~~~


Options for RotationMode are "Right90", "Left90", and "180".
#### By David.C on 2016-10-17 06:18
@rankin The RotationMode Tag works well with 180 degrees, but I only get an empty window with Left90 or Right90. Maybe a problem with the image height being bigger than the display window? I added some screenshots in the attachements.

Thanks for your fast help!
Capt_Left90.png	55.9 KB
180.png	414 KB
Segm_Left90.png	41.9 KB
#### By David.C on 2016-10-17 06:45
@lassoan and if somebody else has the same issues: I looked into the epiphan documentation, but it seems like the only adjustable attributes, which affect the video stream itself, are Resolution, Scaling, Vertical Flip and Frame Rate. I contacted Epiphan and they also claimed, that the Video Stream can't be adjusted that way. I am not really experienced with APIs, so if I misunderstood or overlooked something, please let me know.
#### By Andras Lasso on 2016-10-17 08:47
Thank you. In this case, the simplest solution is to implement transpose operation in the Epiphan video source as a pre-processing step, when rotation is specified. It's simple, the drawback is that it's an extra step, so it is slightly slower than combining with flipping&clipping.
#### By David.C on 2016-10-18 06:10
@lassoan Could you please go just a little bit into detail on how you could implement such operations in a Video Source? The BK-Ultrasound doesn't provide image rotation adjustments itself and the US-OS is a closed system. I am not using any interface here, so I have no idea how I would go about implementing such transformations as a pre-processing step with the SDK. Thanks again!
#### By Adam Rankin on 2016-10-18 10:46
@david.c I will implement it. I have a first pass, but am getting image errors in rotation. Will debug throughout the week.


## StealthLink - Win32
#### Posted by MattClarkson on 2016-10-17 05:52

Hi there,

we have a StealthLink, and I was interested in using PLUS to grab tracking data. I see from the download that I need to request it. Also, I presume there is some Medtronic licensing thing I need to sort out. Please can someone walk me through the process?

Thanks

Matt

#### 1 Comments
#### By Andras Lasso on 2016-10-17 07:41
Yes, Plus supports getting tracking, registration, and image data through StealthLink and you need to have a research agreement with Medtronic.


## 4x4 matrix through OpenIGTLink
#### Posted by Dzenan Zukic on 2016-10-11 13:08

Hi guys,

I am trying to send a 4x4 transform matrix along with a video stream.

Setting the transform in Slicer using transforms module produces the desired effect (rectangular video is transformed into a trapezium). Setting the same matrix in Plus config file produces just shearing (rhomboid instead of trapezium), as if the 4th row of the matrix has been replaced by 0 0 0 1. Side note: same effect is produced is that transform is saved to a file and then loaded (the last row is 0 0 0 1).

JC mentioned a tool to inspect the messages PlusServer sends, but I could not find it (the idea was to check whether Plus already strips that information away).

Can someone shed some light on it?

Here is the matrix from config.xml:

~~~~
    <Transform From="WebCamStream" To="Reference"
      Matrix="
        -0.483962826241  -0.0409672998239  0.0  144.87
        0.00243082619702  0.324552465703  0.0  -62.0
        0.0  0.0  1.0  0.0
        -1.42348556889e-05  0.00139655675222  0.0  1.0
        " />
~~~~

Regards,
Dženan

#### 4 Comments
#### By Adam Rankin on 2016-10-11 13:14
Could you attach the complete config file?
#### By Andras Lasso on 2016-10-11 13:39
OpenIGTLink transfers a linear transform as orientation and translation (as a 3-component vector). The 4th line of the transformation matrix is not transferred. See details in http://openigtlink.org/protocols/v2_transform.html.

Slicer does not work correctly with linear transforms that don't have [0,0,0,1] in the last line, because at many places it is assumed that it is a homogeneous transformation matrix. It is not actively prevented or checked, but it should be (http://www.na-mic.org/Bug/view.php?id=1915).
#### By Dzenan Zukic on 2016-10-11 13:43
Thank you Andras!

For posterity, \OpenIGTLink\Examples\Receiver\ReceiveClient.cxx can be used to inspect the incoming messages.

I guess we will have to use a transform which is applied in Slicer instead of the config file.
#### By Andras Lasso on 2016-10-11 14:02
Slicer also assumes at many places that linear transforms are orthogonal (no shearing).

Slicer assumes that all transforms that are derived from vtkLinearTransform only contain translation, rotation, and scaling and - not very accurately - it uses the term "linear" for it. To support generic affine transforms, probably the easiest way would be to add a custom transform class that is derived from vtkWarpTransform. It could be possible to rework Slicer to manage not just 2 main types ("linear" and warping), but 3 main types (homogeneous, rigid&scaling, and warping), but I'm not sure if the effort would pay off.


## Support for new Interson .NET SDK (IntersonSDKCxx)
#### Posted by goby.dll173884 on 2016-10-04 06:39

Dear Plus Staff,
from what I have understand the PlusApp-2.5.0.4889-Interson-* releases only support old Interson SDK. Is it correct?

Is there any possibility for supporting the new Interson SDK (ideally in the package "PlusApp-2.5.0.4889-Interson-MTC-3.7-Win32.exe" )?

I've tried to compile Plus from sources on a Windows 7 32 bit, VS2015 Community edition, Qt5.7 both stable and nightly repositories following the "Windows build instructions" in the wiki.
Unfortunately, I have MSB6006 ("cmd.exe" exited with error code 1) compilation errors for "vtk", "PlusApp" and "PlusLib".
Any idea on how to solve this problem?

Thanks in advance for your support.

Diego

#### 6 Comments
#### By Andras Lasso on 2016-10-04 08:35
As you can see on the dashboard, Plus trunk version can be built without problems using VS2015 (http://crunch.cs.queensu.ca/CDash/index.php?project=PLUS). Most probably your build error is caused by too long source/bin directory. For example, use C:\D\PlusBuild and C:\D\PlusB-bin - as suggested in the build instructions.

FYI, we switched to using Telemed micrUS ultrasound systems, as they offer magnitudes better image quality than Interson, for about the same price - you might check those out, too, before investing too much of your time to Interson.
#### By Goby.Dll173884 on 2016-10-04 09:09
Thanks Andras,
I've strictly followed the Windows build instructions, the directory name is already the short one suggested in the build instructions.
The MSB6006 errors information is not very helpful for solving the problem (they point to a Microsoft.CppCommon.targets file). Any other suggestion of possible causes of the error?

Thanks for your support
Diego

PS: I heard of the Telemed micrUS, unfortunately we have already purchased a new Interson probe, and I need to work with it :-(
#### By Goby.Dll173884 on 2016-10-06 09:21
I solved the compilation error (that was related to a ploblem with Qt and Vtk library) but now I need to setup the scan conversion for my probe (VC 7.5).

Where could I find the RadiusStartMm and RadiusStopMm?

From the SDK documentation I was able to extract all the other parameters. I saw that you put in the example configuration file the parameters for the the GP3.5.

Thanks in advance
Diego
#### By Andras Lasso on 2016-10-06 09:46
If you don't have the specification of the transducer then you have to determine these experimentally, for example compare scan-converted output to B-mode images displayed by Interson's image viewer. RadiusStopMm-RadiusStartMm is approximately the imaging depth.
#### By Goby.Dll173884 on 2016-10-07 08:51
Thanks! I will do some experiment and I will share the parameters with the other plus users.

Just a last questions: Why Plus is not using the scan conversion functions provided in the Interson SDK for the generation of B-mode images?
#### By Andras Lasso on 2016-10-07 15:46
@matt.mccormick - Do you remember why in IntersonSDKCxx you decided to not use Interson's scan converter?


## AUTOGEN error (Project: PlusApp)
#### Posted by joaolgfonseca on 2016-09-23 14:15

Hello,

I am new here!

I am trying to build the Plus from your repositories, but I am facing some problems.

When I tried to build the app, I got an "AUTOGEN error".

Like this:
"...
Generating moc_PlusCaptureControlWidget.cpp
No command
1>AUTOGEN : error : process for C:/Users/User-User/devel/PlusExp-bin/PlusApp-bin/PlusCommonWidgets/moc_PlusCaptureControlWidget.cpp failed: [C:\Users\User-User\devel\PlusExp-bin\PlusApp-bin\PlusCommonWidgets\PlusCommonWidgets_automoc.vcxproj]

Generating moc_PlusConfigFileSaverDialog.cpp
No command
1>AUTOGEN : error : process for C:/Users/User-User/devel/PlusExp-bin/PlusApp-bin/PlusCommonWidgets/moc_PlusConfigFileSaverDialog.cpp failed: [C:\Users\User-User\devel\PlusExp-bin\PlusApp-bin\PlusCommonWidgets\PlusCommonWidgets_automoc.vcxproj]
...."

Do you know how to fix it?

I am using win10, qt.5.5, vtk7, vs2013 community (x64).

Thanks in advance.

Best regards,
jfonseca

#### 6 Comments
#### By Adam Rankin on 2016-09-23 15:56
I'm not sure. It appears that Qt has failed to run. Is this an installed Qt or built?
#### By Joaolgfonseca on 2016-09-23 16:12
Hello Rankin,

This is an installed Qt using a web installer. Do you need more information?
#### By Adam Rankin on 2016-09-23 16:40
Honestly I'm kind of stumped. I've never seen this error.

@lassoan is this familiar to you?
#### By Andras Lasso on 2016-09-23 17:20
Try the build in a very short directory, such as c:\d.
What is your CMake version?
#### By Joaolgfonseca on 2016-09-24 16:00
It works with the short directory!

Thanks!
#### By Andras Lasso on 2016-09-25 14:01
Great! Thanks for letting us know.


## XY stage or 6DoF arm?
#### Posted by Dzenan Zukic on 2016-08-19 15:24

Does PLUS have support for any XY motion stage (to move the ultrasound transducer)? How about a 6 degree of freedom robotic arms? Have you ever looked into using/supporting one, and what are the impressions?

#### 4 Comments
#### By Adam Rankin on 2016-08-19 15:27
Do you mean a tracker that reports an XY offset? We have support for some motorized steppers, but they are mostly for brachytherapy applications.

Re: robotic arms, there is basic support for reading daVinci arm poses. Adding other robotic manufacturers is as easy/powerful as the supplied manufacturer API.
#### By Andras Lasso on 2016-08-19 18:31
We used Velmex translational/rotational stages for high-accuracy positioning. They are accessible through serial (RS-232) interface, so you can use the Generic serial device in Plus to control it.

Plus also supports USDigital position encoders.

6-DOF arms are usually relatively inaccurate, so most groups use optical tracker to get accurate end-effector pose.
#### By Andras Lasso on 2016-08-19 18:34
Plus supports Phidgets Spatial sensor. The device class could be extended (or cloned and modified) to support additional Phidgets devices (stepper motors, linear positioning stages, etc).
#### By Dzenan Zukic on 2016-08-22 14:53
We might be involved in integration of an ultrasound therapy system, so I was interested in how easy/hard would it be to support those two cases. From your answers, it seems to be on the easy side :)

Thanks guys!


## Building Plus with PLUSBUILD_USE_3DSlicer enabled
#### Posted by AlexanderSeitel on 2015-09-16 16:58

When build the current source of Plus using the 3DSlicer configuration as built in the Slicer version 4.4.0, Plus CMake configuration throws an error during PlusApp configuration:

CMake Error at CMakeLists.txt:326 (MESSAGE):
You have to build VTK with VTK_USE_QT flag ON if you need to use
PLUSBUILD_BUILD_PLUSAPP.

VTK_USE_QT is ON for the VTK built during the Slicer superbuild. There seems to be no CMake flag VTK_USE_QT available in the Plus CMake configuration.

Any idea what could cause this problem?

Thanks in advance,
Alex

#### 19 Comments
#### By Adam Rankin on 2015-09-16 17:01
I will look into this, but first I had a question.

Typically PLUS is built in 32 bit to support 32 bit drivers, and Slicer is built in 64bit to support larger memory pools. Is this not the case for you? If so, what is your situation where you are using 64 bit PLUS or 32bit Slicer?

Cheers,
Adam
#### By Adam Rankin on 2015-09-16 17:10
@lassoan Would vtkGUISupportQt_LOADED=1 be a better variable to check?
#### By Andras Lasso on 2015-09-16 17:33
Yes, it should work but I think (TARGET vtkGUISupportQt) is somewhat nicer
#### By Andras Lasso on 2015-09-16 17:34
It's also not checked at the best location, as it's only tested if using Slicer's VTK, while it should check any external VTK. I'll commit a fix, it would be great if you could have a look.
#### By Andras Lasso on 2015-09-16 17:39
Committed a fix (https://www.assembla.com/code/plus/subversion/compare/4356...4358)
#### By Andras Lasso on 2015-09-16 20:29
@rankin: Unfortunately, there is a build error:

4>1>c:\users\lasso\devel\plusexp-bins\pluslib\src\pluscommon\vtkNrrdSequenceIO.h(17) : fatal error C1083: Cannot open include file: 'itkzlib/zutil.h': No such file or directory
4>1>vtkToolAxesActor.cxx
4>1>vtkRecursiveCriticalSection.cxx
4>1>vtkSequenceIO.cxx
4>1>c:\users\lasso\devel\plusexp-bins\pluslib\src\pluscommon\vtkNrrdSequenceIO.h(17) : fatal error C1083: Cannot open include file: 'itkzlib/zutil.h': No such file or directory
4>1>vtkSequenceIOBase.cxx
4>1>vtkMetaImageSequenceIO.cxx
4>1>TrackedFrame.cxx
4>1>vtkTrackedFrameList.cxx
4>1>c:\users\lasso\devel\plusexp-bins\pluslib\src\pluscommon\vtkNrrdSequenceIO.h(17) : fatal error C1083: Cannot open include file: 'itkzlib/zutil.h': No such file or directory
4>1>PlusVideoFrame.cxx

Could you check this? Disabling compressed NRRD writing when itkzlib is not available or using vtkzlib or adding a pluszlib are all acceptable solutions.
#### By Adam Rankin on 2015-09-16 22:04
Will do.
#### By Louis10th on 2016-08-19 15:10
Hi.
Was this issue fixed?
I am getting the same error and don't see that option in the slicer build.
I am trying to build on a 64bit windows machine. Slicer is built on the same PC.

Thanks!
#### By Adam Rankin on 2016-08-19 15:19
I will test it out and fix any issues. The trunk has changed to use much newer requirements, so I will see if using Slicer builds is still possible. Note you will have to use a build of Slicer that uses VTK7.
#### By Louis10th on 2016-08-19 17:47
My current Slicer uses VTK6.
Will build a recent nightly and test it out.

Thanks.
#### By Adam Rankin on 2016-08-20 10:11
Hi Dan,

I am sorting out issues after building Slicer last night. There are a few fixes to make it work but it will work. Note you will need a Qt5 setup as Slicer does not use Qt5 but PLUS trunk does.
#### By Adam Rankin on 2016-08-20 10:22
Hah... well...

VTK is built with Qt, but in Slicer, that Qt is 4.xyz. OpenIGTLink is an outdated version without v3 support, and Qt is 4.xyz... So that leaves the only component from Slicer that is prebuilt is ITK.

So, basically, for now (until Slicer updates Qt and OpenIGTLink), you get ITK for free.

Will commit fix shortly after I confirm build works with Slicer's ITK.
#### By Andras Lasso on 2016-08-20 10:26
You need to use Plus-2.4 branch if you want to build a Slicer extension that uses Plus.
#### By Adam Rankin on 2016-08-20 10:28
Oh... for the extension... crap. I thought it was to save on build time.
#### By Andras Lasso on 2016-08-20 10:29
PlusLib doesn't use Qt, so if we upgrade OpenIGTLink in Slicer then the Plus trunk can be built with Slicer, too.

Adam, can we just upgrade OpenIGTLink git hash in Slicer and it'll work? Or there are some non-backward compatible API changes?
#### By Adam Rankin on 2016-08-20 10:32
No, but PlusApp does, and using the Slicer VTK means that PlusApp doesn't compile.

OpenIGTLink is backwards compatible, it is up to Junichi to integrate all of IGSIO into OpenIGTLink/master.
#### By Andras Lasso on 2016-08-20 10:36
PlusApp is not likely to be used by Slicer extensions (they have their own GUI), so Qt should not be an issue.
#### By Adam Rankin on 2016-08-20 10:39
So, building against Slicer is to build it as an extension? Oohhh... is this to ensure PLUS is built against all the same DLLs/versions of Slicer?

In the trunk, I should disable this feature completely until Slicer is updated to versions that match. With it's dependency of Webkit, that may be a while.
#### By Adam Rankin on 2016-08-20 10:39
We could restrict our Qt version to be a max of 5.5 to keep webkit in?


## PlusServer: Help writing Config file for .jpg Images
#### Posted by nathanvw on 2016-07-29 17:25

Hello,

I am trying to write a config file to send some simple image data over PlusServer. I am working with 2D Ultrasound images, so I do not require any tracking or transform information, just the image data.
The images were originally in .jpg format, so I have been using the <vtkJPEGReader> class to read in a .jpg image, and then the <MetaImageWriter> class to write it to an .mhd + .raw (similar to http://www.vtk.org/Wiki/VTK/Examples/Cxx/IO/MetaImageWriter)
The .mhd+.raw files appear to have been generated correctly as I can load and view them in the Slicer viewer.

I am however having trouble sending the data over PlusServer: I adapted the config file from PlusDeviceSet_DataCollectionOnly_SavedDataset.xml, but when I run the plusServer with my Config file I get the following errors:

|ERROR|000.003000| Failed to connect to saved dataset - there is no frame in the sequence metafile!| in C:\dev\PlusExp-bin-2.2\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(393)
|ERROR|000.003000| VideoDevice: Cannot connect to data source, ConnectInternal failed| in C:\dev\PlusExp-bin-2.2\PlusLib\src\DataCollection\vtkPlusDevice.cxx(960)
|ERROR|000.003000| Unable to connect device: VideoDevice.| in C:\dev\PlusExp-bin-2.2\PlusLib\src\DataCollection\vtkDataCollector.cxx(299)
|ERROR|000.018000| Data sets in saved data source devices do not have a common time range. Synchronization of loop times is not possible.| in C:\dev\PlusExp-bin-2.2\PlusLib\src\DataCollection\vtkDataCollector.cxx(626)
|WARNING|000.019000| Failed to set loop times!| in C:\dev\PlusExp-bin-2.2\PlusLib\src\DataCollection\vtkDataCollector.cxx(312)
|ERROR|000.019000| Datacollector failed to connect to devices| in C:\dev\PlusExp-bin-2.2\PlusLib\src\PlusServer\Testing\PlusServer.cxx(132)

I'm not sure if the errors are coming from the config file or the mhd file (or both).
I have attached the relevant files...Any ideas as to what i'm doing wrong?

Thank you,
Nathan
output1.mhd	327 Bytes
PlusServerConfig.xml	1.57 KB
output1.raw	44.9 KB

#### 22 Comments
#### By Adam Rankin on 2016-07-29 17:30
The meta files read by PLUS are expected to have header data indicating the status of the image and a timestamp associated with each frame. There are also a number of PLUS specific tags.

As an example:

ObjectType = Image
NDims = 3
AnatomicalOrientation = RAI
BinaryData = True
BinaryDataByteOrderMSB = False
CenterOfRotation = 0 0 0
CompressedData = False
DimSize = 820 616 188              
Kinds = domain domain list
ElementSpacing = 1 1 1
ElementType = MET_UCHAR
Offset = 0 0 0
TransformMatrix = 1 0 0 0 1 0 0 0 1
UltrasoundImageOrientation = MFA
Seq_Frame0000_Timestamp = 425.398686
Seq_Frame0000_ImageStatus = OK
Seq_Frame0001_Timestamp = 425.477657
Seq_Frame0001_ImageStatus = OK
Seq_Frame0002_Timestamp = 425.555686
Seq_Frame0002_ImageStatus = OK


For each frame in your image series, you will need to assign it a timestamp.
#### By Samira Sojoudi on 2016-08-03 13:45
Hello,

Following Nathan's question, is there any way we could send multiple images over PlusServer? or is there any way we can create a mha/mhd+raw file out of some jpeg images?

Thanks,
Samira
#### By Adam Rankin on 2016-08-03 14:51
I've had success using ImageJ with the meta image plugin to convert jpg series to a single mha/mhd sequence.

ImageJ
Meta plugin

Then, you have to hand create your own header as described above.
#### By Samira Sojoudi on 2016-08-03 17:13
Thanks Adam.
#### By Nathanvw on 2016-08-15 16:58
Hello again,

Thank you for previous responses. They worked great.


I have a new question pertaining to this issue:

I want to send some simple metadata (just an int) attached to each frame I send over PlusServer.
Ideally, I would be able to edit my mhd file like so:

Seq_Frame0000_Timestamp = 1
Seq_Frame0000_ImageStatus = OK
Seq_Frame0000_MetaData = 0
Seq_Frame0001_Timestamp = 1.2
Seq_Frame0001_ImageStatus = OK
Seq_Frame0001_MetaData = 4
Seq_Frame0002_Timestamp = 1.4
Seq_Frame0002_ImageStatus = OK
Seq_Frame0002_MetaData = 3
Seq_Frame0003_Timestamp = 1.6
Seq_Frame0003_ImageStatus = OK
Seq_Frame0003_MetaData = 5


Also, I would need a way to retrieve the metadata in my module's C++ code. Currently, my code has access to the vtkMRMLNode* but i'm unsure how to store any useful data in it (other than the imageData itself).

Do you have any ideas?

Thanks,
Nathan
#### By Adam Rankin on 2016-08-16 13:31
You want to send arbitrary information for each frame? Let me look into it. I'm not sure if that's supported.
#### By Adam Rankin on 2016-08-16 13:36
It is supported, you will have to add the following to your PlusServer tag in your config file.

~~~~
<PlusOpenIGTLinkServer 
  ...
  <DefaultClientInfo>
    <MessageTypes>
      <Message Type="STRING" />
      ...
    </MessageTypes>
    <StringNames>
      <String Name="MetaData" /> <!-- must match characters after Seq_Frame000X_ -->
    </StringNames>
    ...
~~~~

Then, you will have to receive it somehow in Slicer. I believe they are stored in Text nodes.
#### By Adam Rankin on 2016-08-16 13:38
PlusServer will send separate IGTL StringMessages with the data for each frame. I am not sure how to correlate the frame numbers from a string message to an image message.

It's possible you could send everything in a tracked frame, but Slicer/OpenIGTLinkIF doesn't know what a tracked frame is.
#### By Andras Lasso on 2016-08-16 14:59
How accurate temporal matching between image and string metadata do you need?
#### By Nathanvw on 2016-08-16 15:40
Within 5 frames preferably.

We could also use the frame timestamps as a work around. We are currently looking for a way to access the timestamps using a vtkMRMLIGTLConnectorNode.
#### By Andras Lasso on 2016-08-16 16:18
OK, 5 frames should achievable just by reading images and metadata from nodes at the same time.
OpenIGTLink timestamps are added to some MRML nodes (for example transform nodes) as custom node 'Timestamp' node attribute (you can use the Data module's node inspector to see it). If you need high-accuracy synchronization then OpenIGTLinkIF can be easily extended to add this attribute to every MRML node it receives.
#### By Nathanvw on 2016-08-18 14:01
I've extracted the Timestamps, but they don't hold the values specified in the .mhd file, leading to synchronization problems...
Instead they have large integer values for seconds and nanoseconds, which don't help me identify the exact frames they correspond to.

So i'm back to looking at adding the MetaData tag, but having trouble locating where my STRING message is held.
Adam mentioned that STRING's should be stored in a Text node, but adding the metadata tag to my .mhd and .xml files did not create any new nodes in my MRML scene.
As far as I can tell, I only have access to the following nodes:
vtkMRMLIGTLConnectorNode
vtkMRMLScalarVolumeNode
vtkMRMLScalarVolumeDisplayNode

Could any of them contain my new MetaData information?
#### By Adam Rankin on 2016-08-18 14:07
Did you update your config file to send the string message?
#### By Nathanvw on 2016-08-18 14:23
Yes i did.

Attached are the config and mhd files i'm running
PlusServerConfigAllGS.xml	1.69 KB
alloutGS.mhd	289 KB
#### By Adam Rankin on 2016-08-18 14:54
Config and data look good, are you working with a build of Slicer or an install?
#### By Nathanvw on 2016-08-18 14:57
a build. (Specifically r24735)
#### By Adam Rankin on 2016-08-18 16:00
Are you looking at the data module for your nodes? If so, have you enabled "show hidden nodes" or similar?
#### By Andras Lasso on 2016-08-18 16:21
The timestamp is in the format specified by OpenIGTLink (http://openigtlink.org/protocols/v2_timestamp.html). I agree that it's not very simple to use and I think the timestamp is not added to images. So, I would suggest to change OpenIGTLinkIF to add timestamp to image nodes as well and maybe change the timestamp field to something that it's easier to parse.
#### By Nathanvw on 2016-08-18 16:55
I have looked in the data module (with hidden nodes enabled), and the only nodes of relevance are:
IGTLConnector
Image_Reference
VolumeDisplay
OpenIGTLink


Also, I have printed all the node classes in my scene (using GetMRMLScene()->GetNodeClassesList()):
vtkMRMLCameraNode
vtkMRMLClipModelsNode
vtkMRMLColorTableNode
vtkMRMLColorTableStorageNode
vtkMRMLCrosshairNode
vtkMRMLFreeSurferProceduralColorNode
vtkMRMLIGTLConnectorNode
vtkMRMLIGTLStatusNode
vtkMRMLInteractionNode
vtkMRMLLayoutNode
vtkMRMLLinearTransformNode
vtkMRMLModelDisplayNode
vtkMRMLModelNode
vtkMRMLPETProceduralColorNode
vtkMRMLProceduralColorNode
vtkMRMLScalarVolumeDisplayNode
vtkMRMLScalarVolumeNode
vtkMRMLScriptedModuleNode
vtkMRMLSelectionNode
vtkMRMLSliceCompositeNode
vtkMRMLSliceNode
vtkMRMLUnitNode
vtkMRMLViewNode
vtkMRMLdGEMRICProceduralColorNode

As for changing OpenIGTLinkIF: Our program will need to be built on different machines, and it would be preferable if we didn't need to modify the Slicer builds that they already have installed...
#### By Andras Lasso on 2016-08-18 18:01
Slicer is constantly improved, so it's strongly recommended to keep updating it time to time. If you send a pull request, I review and integrate it, and the next day you get a new package built on all platforms.
#### By Andras Lasso on 2016-08-18 18:03
String messages were not sent because if only IMAGE data is selected as UseData then all metadata is ignored. Change the config file to UseData="IMAGE_AND_TRANSFORM". I'll update the saved data source documentation with this info. A complete working example is attached.
20160818-StringMessage.zip	899 KB
#### By Nathanvw on 2016-08-18 18:37
Ahhhh i see. The GoldStandard node now shows up in my scene.
Thank you for your help Andras!


## NDI Certus - How to define markers?
#### Posted by Amir Abdi on 2016-07-15 22:04

Hi,

I'm trying to connect to NDI Optotrak Certus using Plus server. I have created the xml config file for Plus and the data from the stylus tool is successfully received by Plus server and sent to 3DSlicer. The Plus config file is attached.

Then I try to add a tracking marker to the Optotrak Certus; therefore I edit the config file to capture the marker data (the edited Plus config file is also attached). However, the server gives the following warning/error:

|INFO|490.442000| Connect using configuration file: C:\Users\Admin\PlusApp-2.2.0.4177-Win32\config\NDICertus_1.0_stylus+marker.xml| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(215)
|INFO|490.442000| Server process command line: "C:/Users/Admin/PlusApp-2.2.0.4177-Win32/bin/PlusServer.exe" --config-file="C:\Users\Admin\PlusApp-2.2.0.4177-Win32\config\NDICertus_1.0_stylus+marker.xml" --verbose=3| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(135)
|INFO|491.101000| Server process started successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(142)
|INFO|491.108000|SERVER> Software version: Plus-2.2.0.4177 - Win32 | in PlusServerLauncher(0)
|INFO|491.109000|SERVER> Logging at level 3 (INFO) to file: C:/Users/Admin/PlusApp-2.2.0.4177-Win32/data/071516_190121_PlusLog.txt | in PlusServerLauncher(0)
|INFO|491.110000|SERVER> TrackerDevice: Local time offset: 0ms | in PlusServerLauncher(0)
|INFO|516.039000|SERVER> Found tool port 0 for device NDI_8700311_20120106-01 | in PlusServerLauncher(0)
|INFO|517.679000|SERVER> Plus OpenIGTLink server started on port: 18944 | in PlusServerLauncher(0)
|INFO|517.679000|SERVER> Press Ctrl-C to quit. | in PlusServerLauncher(0)
|WARNING|517.679000|SERVER> Buffer item is not in the buffer (Uid: 0)!; in ..\..\..\PlusLib\src\DataCollection\vtkTimestampedCircularBuffer.cxx(183) | in PlusServerLauncher(0)
|WARNING|517.680000|SERVER> Unable to get timestamp from Marker1ToTracker tool tracker buffer for time: 0; in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(993) | in PlusServerLauncher(0)
|ERROR|517.680000|SERVER> Failed to get tracker buffer item UID from time: 26.731539; in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(1025) | in PlusServerLauncher(0)

It still detects the stylus, but cannot detect the marker. I tried different port numbers in my config file and nothing worked.

Here is how I defined my data source (copied from the config from which is attached):
<DataSources>
<DataSource Type="Tool" Id="Stylus" PortName="0" />
<DataSource Type="Tool" Id="Marker1" PortName="4" />
</DataSources>
<OutputChannels>
<OutputChannel Id="TrackerStream" >
<DataSource Id="Stylus"/>
<DataSource Id="Marker1"/>
</OutputChannel>
</OutputChannels>

I could not find any documentation to resolve this issue.
NDICertus_1.0_stylus.xml	1.08 KB
NDICertus_1.0_stylusmarker.xml	1.22 KB

#### 15 Comments
#### By Andras Lasso on 2016-07-16 07:07
Do you use active (wired) tools? Are they tracked correctly by NDI's own software applications (NDI Architect etc)?
#### By Amir Abdi on 2016-07-16 21:21
Yes, I'm using active tools and they are correctly tracked by the NDI First Principle software.
And as mentioned, the Stylus also works fine both with the NDI First Principle and the Plus server and 3D Slicer.
#### By Andras Lasso on 2016-07-17 08:18
Wired port numbers should be in the range of 0 to 3 (unless you use 5-DOF tools and splitters). Does tracking work if you unplug the stylus and plug in the marker in the same slot and use the same configuration file? What is the difference between the stylus and marker tools? Did you make the marker tool? Does it have a built-in ROM?
#### By Amir Abdi on 2016-07-17 15:35
The stylus is the only TOOL I have which is manufactured and calibrated by NDI, and therefore it holds a .rom file in its definition.
The markers I'm using other than the stylus, are single active wired markers. They don't have any .rom files assigned to them. However, I also created a .rig file (for rigid bodies) for these markers using the NDI 6D Architect software, and copied it anywhere I thought was appropriate; but it did not help.

Based on your suggestion, I tried detaching the stylus and only use markers, but did not work.
#### By Amir Abdi on 2016-07-17 15:42
In the attachment you can find my NDI Certus Setup.
The big box in the top is the SCU. The stylus is connected to the first port dedicated to tools, numbered 1 (the blue socket).
Individual wired markers are connected through RJ11 jacks to a strober (each RJ11 jack connects two markers). The strober is then connected to socket numbered 2 (the left black socket).
You can see one of the markers on the bottom left of the image.
IMG_7818.JPG	1.11 MB
#### By Andras Lasso on 2016-07-19 21:11
Plus supports custom ROMs for Polaris and Aurora active tools.

For Certus I'm not sure how custom ROMs can be uploaded to the tracker. You might be able to upload it using some NDI utilities (check manuals) or modify vtkPlusNDICertusTracker::EnableToolPorts method to read it from a file and upload it to the tracker when establishing connection (similarly to how it is done for Polaris/Aurora trackers in vtkPlusNDITracker).
#### By Amir Abdi on 2016-07-21 21:30
Based on the NDI Certus manuals, what I understood is that custom ROMs cannot be defined for a rigid body. Even if there was a way to do that, there was no SROM attached to my markers on which I save the ROM file to be retrieved later.
The only thing that can be defined for a rigid body is a .rig file, which hold the X,Y,Z positions of all the markers on that rigid body, plus some parameters (e.g. MaxSensorError, MarkerAngle, ...).

Do you think there exists a way to use this .rig file to define a rigid body for the plus server and in turn for the 3D slicer?

You can find a sample .rig file in the attachment.
mandible.rig	893 Bytes
#### By Andras Lasso on 2016-07-21 21:37
Currently you cannot specify a .rig file in Plus. You have two options:
A. upload the rig file to the tracker using NDI utilities (I don't know if there is persistent storage in the tracker that can store this information)
B. extend Plus so that you can upload information in the .rig file from Plus to the tracker
#### By Amir Abdi on 2016-08-07 17:12
I am currently following two paths:
- Writing my own CertusServer which receives data from the tracker and sends them on the OpenIGTLink. So far I have been able to get individual marker data and read rig files. I have difficulty working with the stylus (digitizing probe) and still working on it; this is something already integrated into PLUS.
- Extending PLUS to get an extra functionality of receiving individual marker data or read local rig files. Do I need the PLTools for this as I already have the OAPI of Certus from NDI?

(I'm at UBC, working with Dr. Abolmaesumi.)
#### By Adam Rankin on 2016-08-08 11:31
Hi Amir,

We would greatly appreciate improvements to the NDI Certus interface. If you have the OAPI you do not need PLTools. You will simply have to provide the location of the OAPI using the NDIOAPI_ROOT_HINT field. Set it to the folder above your NDI OAPI folder.

This is available in Plus revision 4793 and later.
#### By Amir Abdi on 2016-08-09 17:48
Hi Rankin,

The path for OAPI of NDI is set and working fine; however, I have a build issue with vtkCaptionActor2D and vtkalglib.lib:

fatal error C1083: Cannot open include file: 'vtkCaptionActor2D.h': No such file or directory [D:\svnRepositories\PlusBuild\build\PlusLib-bin\src\PlusCommon\vtkPlusCommon.vcxproj]
cannot open file 'vtkalglib.lib' [D:\svnRepositories\PlusBuild\build\PlusLib-bin\src\PlusDataCollection\Haptics\vtkPlusHaptics.vcxproj]

I tried both USE_VTK6 and USE_VTK7 flags.
#### By Amir Abdi on 2016-08-11 21:46
Hi,

For now, I'm studying the code to understand its dynamic and so far I am pretty confident that I can extend the vtkPlusNDICertusTracker and add the "reading .rig files from local drive" with no problem.

However, one thing is ambiguous: "how is the position of stylus tip calculated?"
I see that the vtkPlusNDICertusTracker::InternalUpdate method receives the stylus rotation and translation in a quaternion. The translation vector corresponds to a point somewhere in the middle of the tool, but not its tip. However the exact position of its tip can be calculated based on its orientation.
I couldn't find anything that calculated the position of the stylus tip from the transformation parameters of the stylus.
The Stylus_Example.stl file is loaded as a DisplayableObject in the config file (PlusDeviceSet_fCal_SonixTouch_L14-5_NDICertus_1.0.xml). But this is just for representation and I don't assume the stylus tip is calculated based on this mesh.

My linking error is still in place. The following projects are building successfully: OpenIGTLink, itk, vtk, PlusLib.
The PlusApp project then fails. I have attached the build output of this project in case you had feedback.
plusApp_failed.txt	243 KB
#### By Andras Lasso on 2016-08-11 22:54
Don't worry about the StylusTipToStylus transform. It's trivial to compute by pivot calibration. Pivot calibration is available in Plus (for example in fCal), Slicer (in SlicerIGT extension), and also in the NDI tool characterization utility.

Update to latest Plus trunk version and make sure there are no locally modified files. Plus builds without problems on the test machines using VTK6. If you changed the VTK version then you may need to rebuild Plus (including VTK, ITK, ...) from scratch.
#### By Amir Abdi on 2016-08-12 23:23
The PlusApp-2.2.0.4177-Win32 stable release gives the following error when connecting to Certus:

|ERROR|18523.927000|SERVER> Call to Certus TransputerInitializeSystem() failed; in ..\..\..\PlusLib\src\DataCollection\NDICertusTracking\vtkNDICertusTracker.cxx(145) | in PlusServerLauncher(0)
|ERROR|18523.928000|SERVER> |ERROR|021.869000| Optotrak: Invalid node version detected. (Node 0. Version 3.12.00) | in PlusServerLauncher(0)
|ERROR|18523.929000|SERVER> (Oapi Version 3.01.03)| in ..\..\..\PlusLib\src\DataCollection\NDICertusTracking\vtkNDICertusTracker.cxx(146) | in PlusServerLauncher(0)

It seems like I need to update the OAPI version which doesn't seem feasible unless I build Plus with another OAPI. Am I right, or is there any other way?
#### By Adam Rankin on 2016-08-13 09:39
Since you already have a build, update to latest, enable PLUS_USE_NDI_CERTUS in the PlusBuild CMake. It should work then.


## Epiphan frame grabber/ device not found
#### Posted by Samira Sojoudi on 2016-08-08 19:42

Hello guys,

We are going to use Epiphan frame grabber to capture images from the ultrasound machine the model we are using is AV.io HD (https://www.epiphan.com/products/avio-hd/).
When we are trying to run the plus server using PlusDeviceSet_Server_EpiphanVideoCapture.xml config file, it says Epiphan device not found.
However we could capture data using VLC and it means that the device is working.
any advice?

Thanks,
Samira

#### 8 Comments
#### By Andras Lasso on 2016-08-08 20:19
Could you please attach the log file?
#### By Andras Lasso on 2016-08-08 20:27
I've checked the product page and it seems that AV.io does not use Epiphan drivers. It means that it should be accessible using generic framegrabber interfaces, such as "MmfVideo" (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceMicrosoftMediaFoundation.html).
#### By Samira Sojoudi on 2016-08-09 12:59
Hi Andras,

I tried PlusDeviceSet_Server_MmfColorVideoCapture.xml and renamed the device type to epiphan and again it says Epiphan device not found when I changed the device type to GenericSerialDevice it says unable to find required SerialPort attribute. log files are attached.
080916_095349_PlusLog.txt	1.1 KB
080916_095428_PlusLog.txt	1.02 KB
#### By Andras Lasso on 2016-08-09 13:24
Use PlusDeviceSet_Server_MmfColorVideoCapture.xml as is, without any changes.

Serial device is unrelated.
#### By Samira Sojoudi on 2016-08-09 13:29
I tried it first, it says unknown device type
080916_095150_PlusLog.txt	1.37 KB
#### By Andras Lasso on 2016-08-09 13:36
Which Plus edition do you use (installation package name)?
Use the generic Windows 32 or 64 bit package.
#### By Samira Sojoudi on 2016-08-09 13:46
I have built the stable version. Ok will try the package.
Is this good PlusApp-2.2.0.4177-Win64.exe?
Thanks Andras
#### By Samira Sojoudi on 2016-08-09 13:54
Thanks Andras. It worked with that package and this PlusDeviceSet_Server_MmfVideoCapture.xml and PlusDeviceSet_Server_MmfColorVideoCapture.xml config files both.


## PlusServer: sending video stream from two cameras
#### Posted by sordas on 2015-10-30 23:05

Dear Plus experts,
I am trying to broadcast over OpenIGTLink the video stream from two MMF-compatible USB cameras. I do receive in Slicer (OpenIGTLinkIF/View Controllers) the video stream of the first output channel (i.e. VideoStream1) repeated in both transformations (Image1_reference and Image2_reference)

Could you please have a look to my configuration file and tell me what is the obvious thing that I am missing?
Both cameras are working fine: if I change the order of <OutputChannelId="VideoStream1" > and <OutputChannelId="VideoStream2" >
I get the video stream of the other camera

thank you!
sebastian

~~~~
<PlusConfiguration version="2.0">

<DataCollection StartupDelaySec="1.0" >
<DeviceSet
Name="PlusServer: Mmf color video capture device x2"
Description="Broadcasting over OpenIGTLink the video from two USB cameras. The two
cameras belong to flexible endoscopes and are Microsoft Media Foundation compatible." />

<Device
Id="VideoDevice1"
Type="MmfVideo"
FrameSize="640 480"
VideoFormat="YUY2"
CaptureDeviceId="0" >
<DataSources>
<DataSource Type="Video" Id="Video1" PortUsImageOrientation="MF"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="VideoStream1" VideoDataSourceId="Video1" />
</OutputChannels>
</Device>

<Device
Id="VideoDevice2"
Type="MmfVideo"
FrameSize="640 480"
VideoFormat="YUY2"
CaptureDeviceId="1" >
<DataSources>
<DataSource Type="Video" Id="Video2" PortUsImageOrientation="MF" />
</DataSources>
<OutputChannels>
<OutputChannel Id="VideoStream2" VideoDataSourceId="Video2" />
</OutputChannels>
</Device>

</DataCollection>

<CoordinateDefinitions>
<Transform From="Image1" To="Reference"
Matrix="
0.2 0.0 0.0 0.0
0.0 0.2 0.0 0.0
0.0 0.0 0.2 0.0
0 0 0 1" />

<Transform From="Image2" To="Reference"
Matrix="
0.2 0.0 0.0 0.0
0.0 0.2 0.0 0.0
0.0 0.0 0.2 0.0
0 0 0 1" />

</CoordinateDefinitions>


<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="1"
MaxTimeSpentWithProcessingMs="50"
ListeningPort="18944"
SendValidTransformsOnly="true"
OutputChannelId="VideoStream1" >
OutputChannelId="VideoStream2" >
<DefaultClientInfo>
<MessageTypes>
<Message Type="IMAGE" />
</MessageTypes>
<ImageNames>
<Image Name="Image1" EmbeddedTransformToFrame="Reference" />
<Image Name="Image2" EmbeddedTransformToFrame="Reference" />
</ImageNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>

</PlusConfiguration>
~~~~


#### 4 Comments
#### By Andras Lasso on 2015-10-30 23:30
One PlusOpenIGTLinkServer only broadcasts one channel (specifying different values for the same OutputChannelId attribute is not valid in XML, unfortunately it seems the VTK XML parser does not detect this).

Add two PlusOpenIGTLinkServer elements, one with OutputChannelId="VideoStream1", the other with OutputChannelId="VideoStream2", with different ListeningPort values.
#### By Sordas on 2015-10-30 23:33
ah I see. now it works!
#### By Sordas on 2015-10-30 23:35
thank you! now it works
#### By Dzenan Zukic on 2016-08-04 12:50
I needed a similar thing: ultrasound+webcam over OpenIGTLink, and this thread answered my questions. Thanks Sebastian for asking and Andras for answering!


## Simplifying Capistrano SDK usage
#### Posted by Dzenan Zukic on 2016-07-18 17:15

Is it problematic for anyone if I apply these two patches to PlusBuild\Modules\FindCapistrano.cmake and PlusLib\src\PlusDataCollection\CMakeLists.txt ? With current source code it does not work out of the box for a 64 bit build.
FindCapistrano.cmake.patch	2.74 KB
CMakeLists.txt.patch	2.29 KB

#### 2 Comments
#### By Adam Rankin on 2016-07-18 17:21
Looks good to me. @lassoan?
#### By Andras Lasso on 2016-07-18 17:24
I cannot test it but it looks OK.


## Using Polhemus FASTRAK with PLUS
#### Posted by akostenko on 2016-06-24 11:01

Dear folks,

I would like to use PLUS to connect Polhemus FASTRAK motion tracking device with Slicer3D. I can't find it in the list of supported devices though. Could you give me some recommendations on whether I can do it and if yes, then how? Perhaps it's possible to connect via VRPN server?

Cheers!
Alex Kostenko

#### 5 Comments
#### By Andras Lasso on 2016-06-24 11:14
Plus doesn't support Polhemus trackers. Dzenan Zukic (http://www.kitware.com/company/team/zukic.html) worked on adding support for VRPN - you can contact him directly to get more information about its status.
#### By Adam Rankin on 2016-06-25 04:49
Is there a device SDK for the Polhemus devices?
#### By Adam Rankin on 2016-06-25 04:52
Found it, I will request permission from them to create an interface from PLUS.
#### By Akostenko on 2016-07-05 11:42
Great! @lassoan, thanks a lot! I will write to Dzenan Zukic about support for VRPN
#### By Akostenko on 2016-07-05 11:43
@rankin, thanks, let me know if there will be an interface in PLUS.


## volume reconstruction - tracker data not considered
#### Posted by reiker on 2016-06-06 05:51

Hi!

I had severe problems reconstructing a phantom volume, because in several tries, the reconstructed volume was in differend position in the image coordinate system. So I gave it a trie and scanned the phantom in a sine wave like manner. what i got was very interesting and puzzeling. See the attached screenshot. It looks like that the reconstruction algorithm does not consider the position of the transducer during scan but only at the beginning and the end of the scan. This is my assumtion, becaus the dimension of the scanned volume is independent from the amount of images, so the distance scanned seems to fit in the reconstructed volume.

Is there anything I have missed in the configuration?

Thanks in advance,
Reinhard
PlusDeviceSet_Server_IGTLink.xml	4.46 KB
Screenshot.png	190 KB

#### 20 Comments
#### By Andras Lasso on 2016-06-06 07:55
If you do batch-mode volume reconstruction (first record a complete sequence and then reconstruct a volume from that) then the image extents are determined automatically. The image will always be in the same position in the ReferenceCoordinateFrame, which you define to be the Tracker coordinate system.

If you do a scout scan to determine image position and extents (or manually define or adjust image position and extents) and then perform live volume reconstruction then image extents and position will always be what you predefine.
#### By Reiker on 2016-06-06 16:43
Hi Andras!

No, the problem is, that the position of the volume is dependent on the position of the phantom in the image frame of the scanned image.
which means, that the phantom in the image frame changes its position in the scanned image, when sweeping the transducer in a sine wave manner, which can be seen in the attached screenshot.
#### By Andras Lasso on 2016-06-06 16:52
The attached image does not show the phantom, only shows the transducer surface (which is most of the time bright due to imperfect acoustic coupling). That of course moves as you move the transducer. I would recommend to set clipping parameters (ClipRectangleOrigin, ClipRectangleSize, FanOriginPixel, etc) so that you exclude the transducer surface from volume reconstruction.

The volume contents is rendered as transparent. Change volume rendering parameters if you want to actually see the reconstructed volume.

You can verify that the phantom appears correctly in 3D by dropping markups at the phantom boundaries while keeping the transducer at a certain position then move the transducer and see if the markups and the object boundaries are aligned in other transducer positions.
#### By Reiker on 2016-06-07 03:57
The attached image does show the phantom, but as the scan was in a sine wave manner, the reconstructed phantom is distorted. This is exactly the problem. I have attached two new images, the first where the figures in the distorted phantom are labeled. The second image shows the phantom reconstructet when scanned straight. But it also can be seen in this image, that the phantom is not fully straigt. You can see movements, as the phantom was scanned freehand. In the third image I have drawn the movement how the distorted phantom was scanned (sine wave manner). And this is exactly how it was reconstructed. But this should not be like this. The transform from the transducer to the image is know. So when moving the transducer, in wich manner soever, movements in X and Y direction are not considered, only movements in Z are considered.

In the first message I also have attached the used config, where can be seen, that I have used clipping.
Phantomincorrectreconstructed.jpg	61.5 KB
reconstructedPhantom.jpg	35.8 KB
sinewavescan.jpg	51.3 KB
#### By Reiker on 2016-06-08 17:56
Dear Andras,

is there any possibility of misconfiguration that causes the sine wave distorted reconstruction of the phantom. There is to mention, that every reconstruction I have tried is underlied with handmovement. The position is dependent on the position in the ultrasound image. Clipping was used, to minimize reflections. Maybe it is a misstake I have made, a missleading configuration or any other fault by me, but maybe there is a problem with the reconstruction algorithm? If not, is there any other reasonable explanation for this behavior?

Thanks in advance for any help.
#### By Andras Lasso on 2016-06-08 19:13
How did you create the volume that you show in Phantomincorrectreconstructed.jpg?

Can you send the input image sequence, configuration file that contains probe calibration and volume reconstruction parameters, and command-line parameters that you specified for the volume reconstructor?
#### By Andras Lasso on 2016-06-08 19:15
Also, can you send a screenshot (or even better, a screen capture video) that shows the live ultrasound image as you move the probe?
#### By Andras Lasso on 2016-06-08 19:56
A vertical image flip may cause the pattern that you see. You should be able to see what's the error if you observe the contents of the live ultrasound image as you move the probe (e.g., if you move the probe down then objects in the image should move up).
#### By Reiker on 2016-06-09 04:35
I've used two Computers.
The first is the acquisition machine (Win XP x86 with VfV Framegrabber, NDI Polaris), which sends tracker- and imagedata through OpenIGTLink to the second machine (Win 7 x64), which is responsible for reconstruction. On the second machine I use 3D Slicer for operation of Plus Server on PC2. Therefor PC2 is responsible for reconstruction.

PC1: Plus Server
PC2: Plus Server + 3D Slicer

But I do have the same Problem when scanning and reconstructing the volume using fCal on PC1.

The Config attached in the first post shows all relevant information. Probe Calibration as well as volume reconstruction parameters

I'm afraid, I can't send you a screen capture video. But I'll trie. If so, it will be a video on the processing machine where 3D slicer runs.

I have to mention, that I am using a vertical image flip. This is because of image clipping, as the starting point for clipping is at the bottom left.
But I also have to mention, that I assume that the sine wave volume may not result from image flip but from the sine wave movement of the probe during scan. But from my understanding the reconstruction algorithm should take care of this by considering the position of the probe during reconstruction. But maybe I am wrong with my assumption?
#### By Andras Lasso on 2016-06-09 07:38
This is most likely not a reconstruction problem. You should see the inconsistency of directions when you observe how objects move in the image when you move the probe. A vertical image flip causes the sine wave motion pattern of the probe appear with double amplitude in the images instead of being suppressed.
#### By Reiker on 2016-06-09 10:34
Hi Adam!

Well, the image is fliped, but maybe we ran in a misunterstanding. The images is upside down, which is necessary to perform fan shaped clippinng. As the probe is moved along the same hight, the amplitude in y and z direction stays the same, doesn't it? only if the sine wave is in Y direction, the amplitude would change, or am I getting something wrong?

the requested files you may find here:
https://onedrive.live.com/redir?resid=4648F4C014726CE6!310&authkey=!AMW7GJmZvv2ukfU&ithint=folder%2c

Ok, I've deactivated the upside down image flip and performed a new scan and reconstruction. Again, no success. The sine wave scan can be seen in the reconstructed volume.
#### By Reiker on 2016-06-16 11:14
Hi Adam!

Do you have any news concerning the incorrect reconstruction?
#### By Adam Rankin on 2016-06-16 11:26
Sorry, do you mean Andras @lassoan or me @rankin?
#### By Reiker on 2016-06-16 12:08
oh, sorry. I ment andras.
But maybe you also have some information that would help me?
#### By Adam Rankin on 2016-06-16 12:18
I will run a couple of tests here. Give me an hour or so.
#### By Reiker on 2016-06-20 22:32
Hi Adam!
Revealed the tests any news?
#### By Adam Rankin on 2016-06-21 03:38
In my local setup I was unable to even reconstruct a basic volume. Unfortunately I am now in Heidelberg for NAMIC week and do not have any hardware to test with.

I may have access to some hardware during the week but I am not sure.
#### By Reiker on 2016-07-01 07:08
Hi Adam, hi Andras!

Do you have any news concerning the reconstruction?
Revealed the tests any outcome?
#### By Adam Rankin on 2016-07-01 09:46
Ticket created at https://app.assembla.com/spaces/plus/tickets/1088-reports-of-volume-reconstruction-not-behaving-properly/details
#### By Reiker on 2016-07-02 03:28
Thanks for the info. I hope that the error/bug can be found quickly.


## Problem when building the trunk in ubuntu linux 14.04 - can't find IGTL_HEADER_VERSION_1
#### Posted by albertogomezherrero6904 on 2016-05-09 11:44

Hi,

I am trying to build Plus with the default settings in the cmake. There seems to be a problem when building OpenIGTLink, particularly with vtkPlusOpenIGTLink.

I get the following compiler error:

[ 16%] Built target vtkTransformRepositoryTest
[ 17%] Built target ModelRenderer
[ 18%] Built target PlusMathTest
[ 19%] Building CXX object src/PlusOpenIGTLink/CMakeFiles/vtkPlusOpenIGTLink.dir/igtlPlusTrackedFrameMessage.cxx.o
In file included from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusOpenIGTLink/igtlPlusTrackedFrameMessage.cxx:9:0:
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusOpenIGTLink/igtlPlusTrackedFrameMessage.h: In constructor 'igtl::PlusTrackedFrameMessage::MessageHeader::MessageHeader()':
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusOpenIGTLink/igtlPlusTrackedFrameMessage.h:57:19: error: 'IGTL_HEADER_VERSION_3' was not declared in this scope
: m_Version(IGTL_HEADER_VERSION_3)
^
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusOpenIGTLink/igtlPlusTrackedFrameMessage.cxx: In member function 'PlusStatus igtl::PlusTrackedFrameMessage::SetTrackedFrame(const PlusTrackedFrame&)':
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusOpenIGTLink/igtlPlusTrackedFrameMessage.cxx:42:39: error: 'IGTL_HEADER_VERSION_1' was not declared in this scope
this->m_MessageHeader.m_Version = IGTL_HEADER_VERSION_1;
^
make[5]: *** [src/PlusOpenIGTLink/CMakeFiles/vtkPlusOpenIGTLink.dir/igtlPlusTrackedFrameMessage.cxx.o] Error 1
make[4]: *** [src/PlusOpenIGTLink/CMakeFiles/vtkPlusOpenIGTLink.dir/all] Error 2
make[3]: *** [all] Error 2
make[2]: *** [PlusLib-prefix/src/PlusLib-stamp/PlusLib-build] Error 2
make[1]: *** [CMakeFiles/PlusLib.dir/all] Error 2
make: *** [all] Error 2
16:41:36: The process "/usr/bin/make" exited with code 2.
Error while building/deploying project PlusBuild (kit: Desktop Qt 5.6.0 GCC 64bit2)
When executing step "Make"
16:41:36: Elapsed time: 00:30.


Where is IGTL_HEADER_VERSION_1 and IGTL_HEADER_VERSION_3 suposed to be degfined? Anyone can help with this issue?

Thanks!

Alberto

#### 11 Comments
#### By Adam Rankin on 2016-05-09 11:51
Hello!

Could you try pulling the OpenIGTLink subfolder to the latest, rebuild it, and then try the build again?
#### By Albertogomezherrero6904 on 2016-05-13 05:01
HI! Thanks for your answer.

I did that and rebuilt, but now I get a different error. Any clues?

Thanks:

[ 85%] Performing update step (SVN update) for 'PlusApp'
Updating '.':
At revision 4627.
[ 87%] Performing configure step for 'PlusApp'
-- PlusApp version: 2.3.0
-- Current revision is 4627
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp-bin
[ 89%] Performing build step for 'PlusApp'
[ 1%] Automatic moc, uic and rcc for target CommonWidgets
[ 1%] Built target CommonWidgets_automoc
[ 3%] Building CXX object CommonWidgets/CMakeFiles/CommonWidgets.dir/DeviceSetSelectorWidget.cxx.o
In file included from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_compiler.h:243:0,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_limits.h:5,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkNumericTraits.h:45,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkPoint.h:22,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkContinuousIndex.h:21,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkImageRegion.h:34,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkImageIORegion.h:24,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/IO/ImageBase/include/itkImageIOBase.h:26,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusCommon/PlusCommon.h:12,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib-bin/src/PlusConfigure.h:126,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/CommonWidgets/DeviceSetSelectorWidget.h:12,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/CommonWidgets/DeviceSetSelectorWidget.cxx:7:
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:387:60: error: ‘constexpr’ needed for in-class initialization of static data member ‘const float vnl_numeric_traits<float>::zero’ of non-integral type [-fpermissive]
static const float zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:389:59: error: ‘constexpr’ needed for in-class initialization of static data member ‘const float vnl_numeric_traits<float>::one’ of non-integral type [-fpermissive]
static const float one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:391:62: error: ‘constexpr’ needed for in-class initialization of static data member ‘const float vnl_numeric_traits<float>::maxval’ of non-integral type [-fpermissive]
static const float maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(3.40282346638528860e+38F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:410:61: error: ‘constexpr’ needed for in-class initialization of static data member ‘const double vnl_numeric_traits<double>::zero’ of non-integral type [-fpermissive]
static const double zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:412:60: error: ‘constexpr’ needed for in-class initialization of static data member ‘const double vnl_numeric_traits<double>::one’ of non-integral type [-fpermissive]
static const double one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:414:63: error: ‘constexpr’ needed for in-class initialization of static data member ‘const double vnl_numeric_traits<double>::maxval’ of non-integral type [-fpermissive]
static const double maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(1.7976931348623157E+308);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:433:66: error: ‘constexpr’ needed for in-class initialization of static data member ‘const long double vnl_numeric_traits<long double>::zero’ of non-integral type [-fpermissive]
static const long double zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:435:65: error: ‘constexpr’ needed for in-class initialization of static data member ‘const long double vnl_numeric_traits<long double>::one’ of non-integral type [-fpermissive]
static const long double one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:437:68: error: ‘constexpr’ needed for in-class initialization of static data member ‘const long double vnl_numeric_traits<long double>::maxval’ of non-integral type [-fpermissive]
static const long double maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(1.7976931348623157E+308);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk-bin/Modules/ThirdParty/VNL/src/vxl/vcl/vcl_config_compiler.h:152:48: note: in definition of macro ‘VCL_STATIC_CONST_INIT_FLOAT_DECL’
define VCL_STATIC_CONST_INIT_FLOAT_DECL(x) = x
^
make[5]: *** [CommonWidgets/CMakeFiles/CommonWidgets.dir/DeviceSetSelectorWidget.cxx.o] Error 1
make[4]: *** [CommonWidgets/CMakeFiles/CommonWidgets.dir/all] Error 2
make[3]: *** [all] Error 2
make[2]: *** [PlusApp-prefix/src/PlusApp-stamp/PlusApp-build] Error 2
make[1]: *** [CMakeFiles/PlusApp.dir/all] Error 2
make: *** [all] Error 2
#### By Adam Rankin on 2016-05-13 09:30
Switch your ITK to the 4.9 release and rebuild it. Then rebuild PLUS.
#### By Albertogomezherrero6904 on 2016-05-19 11:53
Thanks Rankin,

I now switched to itk v4.9.1 by going to the PlusBuild build directory, subfolder itk and doing 'git checkout v4.9.1'

When I rebuild the whole thing I still get errors:

Scanning dependencies of target CommonWidgets
[ 3%] Building CXX object CommonWidgets/CMakeFiles/CommonWidgets.dir/DeviceSetSelectorWidget.cxx.o
In file included from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_c_vector.h:26:0,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_vector.h:22,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_vector_ref.h:20,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkVector.h:23,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkPoint.h:23,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkContinuousIndex.h:21,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkImageRegion.h:34,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/Core/Common/include/itkImageIORegion.h:24,
from /home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/IO/ImageBase/include/itkImageIOBase.h:26,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusCommon/PlusCommon.h:12,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib-bin/src/PlusConfigure.h:126,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/CommonWidgets/DeviceSetSelectorWidget.h:12,
from /home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/CommonWidgets/DeviceSetSelectorWidget.cxx:7:
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:388:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR float zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:390:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR float one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:392:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR float maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(3.40282346638528860e+38F);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:411:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR double zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:413:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR double one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:415:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR double maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(1.7976931348623157E+308);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:434:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR long double zero VCL_STATIC_CONST_INIT_FLOAT_DECL(0.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:436:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR long double one VCL_STATIC_CONST_INIT_FLOAT_DECL(1.0);
^
/home/ag09_local/workspace/PlusBuildTrunk/release/itk/Modules/ThirdParty/VNL/src/vxl/core/vnl/vnl_numeric_traits.h:438:21: error: ‘VCL_CONSTEXPR’ does not name a type
static VNL_EXPORT VCL_CONSTEXPR long double maxval VCL_STATIC_CONST_INIT_FLOAT_DECL(1.7976931348623157E+308);
^
make[5]: *** [CommonWidgets/CMakeFiles/CommonWidgets.dir/DeviceSetSelectorWidget.cxx.o] Error 1
make[4]: *** [CommonWidgets/CMakeFiles/CommonWidgets.dir/all] Error 2
make[3]: *** [all] Error 2
make[2]: *** [PlusApp-prefix/src/PlusApp-stamp/PlusApp-build] Error 2
make[1]: *** [CMakeFiles/PlusApp.dir/all] Error 2
make: *** [all] Error 2

Any clue?

thanks!
#### By Adam Rankin on 2016-05-19 11:56
Did you rebuilt the ITK solution on its own first? If you do it from the superbuild it doesn't register all the dependency versions
#### By Albertogomezherrero6904 on 2016-05-19 12:00
Hi @rankin, I missed the 'build itk then rebuild Plus' bit. I have done it this way and it now seems to compile. Thanks a lot for your help! I got past that bit but I still get an error:

Scanning dependencies of target DiagPlusDataCollection
[ 68%] Building CXX object DiagnosticTools/CMakeFiles/DiagPlusDataCollection.dir/DiagDataCollection.cxx.o
[ 70%] Building CXX object DiagnosticTools/CMakeFiles/DiagPlusDataCollection.dir/DiagPlusDataCollection_automoc.cpp.o
[ 71%] Linking CXX executable /home/ag09_local/workspace/PlusBuildTrunk/release/bin/DiagPlusDataCollection
[ 71%] Built target DiagPlusDataCollection
[ 73%] Automatic moc, uic and rcc for target TrackingDataServer
[ 73%] Built target TrackingDataServer_automoc
Scanning dependencies of target TrackingDataServer
[ 75%] Building CXX object DiagnosticTools/CMakeFiles/TrackingDataServer.dir/TrackingDataServer.cxx.o
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/DiagnosticTools/TrackingDataServer.cxx: In function ‘int main(int, char**)’:
/home/ag09_local/workspace/PlusBuildTrunk/release/PlusApp/DiagnosticTools/TrackingDataServer.cxx:169:53: error: ‘igtl::SmartPointer<igtl::MessageBase>::ObjectType’ has no member named ‘GetMessageType’
std::cerr << "Receiving : " << headerMsg->GetMessageType() << std::endl;
^
make[5]: *** [DiagnosticTools/CMakeFiles/TrackingDataServer.dir/TrackingDataServer.cxx.o] Error 1
make[4]: *** [DiagnosticTools/CMakeFiles/TrackingDataServer.dir/all] Error 2
make[3]: *** [all] Error 2
make[2]: *** [PlusApp-prefix/src/PlusApp-stamp/PlusApp-build] Error 2
make[1]: *** [CMakeFiles/PlusApp.dir/all] Error 2
make: *** [all] Error 2


Any idea with this one?
#### By Adam Rankin on 2016-05-19 12:05
Could you perform the exact same steps but for the OpenIGTLink dependency? Check out master
#### By Nathanvw on 2016-06-23 19:28
Hello,

I am encountering a similar issue while trying to build Plus. While building PlusApp, I get the following errors:

error C2039: 'GetMessageType' : is not a member of 'igtl::MessageBase' [C:\dev\PlusExp-bin\PlusApp-bin\DiagnosticTools\TrackingDataServer.vcxproj] C:\dev\PlusExp-bin\PlusApp\DiagnosticTools\TrackingDataServer.cxx
error C2065: 'IGTL_HEADER_VERSION_1' : undeclared identifier [C:\dev\PlusExp-bin\PlusApp-bin\DiagnosticTools\TrackingDataServer.vcxproj] C:\dev\PlusExp\bin\PlusLib\src\PlusOpenIGTLink\vtkPlusIgtlMessageFactory.h

I am using an up-to-date clone of Plus, therefore the OpenIGTLink subfolder should be the latest one.

Any ideas of what could be causing this?

Thanks,
Nathan
#### By Adam Rankin on 2016-06-24 03:36
Hi,

My apologies. Right now PLUS trunk is unstable. May I recommend reverting to 4675 until next week.
#### By Andras Lasso on 2016-06-24 04:30
Several Plus/SlicerIGT developers are the NAMIC project week now, working on adding nice new PlusServer capabilities (we'll be able to query and control ultrasound device remotely; start PlusServer with custom configuration files on a remote computer, etc). We'll try to make things work again as soon as possible.
#### By Adam Rankin on 2016-06-24 06:13
The latest PLUS commit should make things stable. Just waiting for the build machines to report back.


## Building Plus in Ubuntu 16.04 -problem with qt webkit
#### Posted by albertogomezherrero6904 on 2016-06-03 05:52

Dear all,

I am trying to build plus in ubuntu 16.04 following the instruction here, unfortunately I get an error in the vtk build step (see below). I have previously built qt by doing:

./configure -debug-and-release -nomake demos -nomake examples < -prefix /some/qt-install-dir >

Any clues why this is happening?

Thanks!

Alberto

...
...
vtkRenderingVolumeOpenGL
vtkUtilitiesEncodeString
vtkUtilitiesHashSource
-- * vtktiff, needed by vtkIOImage.
-- * vtkverdict, needed by vtkFiltersVerdict.
-- * vtkzlib, needed by 10 modules:
vtkIOCore
vtkIOGeometry
vtkIOImage
vtkMetaIO
vtkfreetype
vtkgl2ps
vtkhdf5
vtklibxml2
vtkpng
vtktiff
CMake Error at /usr/share/cmake-3.5/Modules/FindPackageHandleStandardArgs.cmake:148 (message):
Could NOT find Qt4 (missing: QT_QTWEBKIT_INCLUDE_DIR QT_QTWEBKIT_LIBRARY)
(found version "4.8.5")
Call Stack (most recent call first):
/usr/share/cmake-3.5/Modules/FindPackageHandleStandardArgs.cmake:388 (_FPHSA_FAILURE_MESSAGE)
/usr/share/cmake-3.5/Modules/FindQt4.cmake:1333 (FIND_PACKAGE_HANDLE_STANDARD_ARGS)
GUISupport/QtWebkit/CMakeLists.txt:22 (find_package)


-- Configuring incomplete, errors occurred!
See also "/home/ag09/workspace/plus/plus2.2/release/vtk-bin/CMakeFiles/CMakeOutput.log".
See also "/home/ag09/workspace/plus/plus2.2/release/vtk-bin/CMakeFiles/CMakeError.log".
CMakeFiles/vtk.dir/build.make:105: recipe for target 'vtk-prefix/src/vtk-stamp/vtk-configure' failed
make[2]: *** [vtk-prefix/src/vtk-stamp/vtk-configure] Error 1
CMakeFiles/Makefile2:67: recipe for target 'CMakeFiles/vtk.dir/all' failed
make[1]: *** [CMakeFiles/vtk.dir/all] Error 2
Makefile:83: recipe for target 'all' failed
make: *** [all] Error 2

#### 5 Comments
#### By Adam Rankin on 2016-06-03 09:15
Hi Alberto,

I just got my 16.04 setup up and running, I'll have PLUS built in about 30-60 minutes. I will get back to you if I encounter the same issue.

The instructions are a bit out of date, I will update them shortly.
#### By Andras Lasso on 2016-06-03 09:51
I think VTK requires QtWebKit, so you need to enable QtWebKit for your Qt installation.
#### By Adam Rankin on 2016-06-03 10:27
I recommend using the qt from apt.

I would remove your custom build and perform the following:
sudo apt install libqt4-dev libqtwebkit-dev
#### By Adam Rankin on 2016-06-03 11:09
I am fixing build errors. It should be resolved shortly.
#### By Adam Rankin on 2016-06-03 14:49
Confirmed successful build on Ubuntu 16.04LTS. New build instructions have been updated.


## Problem with SendValidTransformsOnly
#### Posted by ifinddev498773 on 2016-05-27 06:54

Dear all,

I just updated the PluServer to the laatest version in the svn, and now it seems I am not getting the expected functionning.

Essentially I want to capture data from two EM position sensors (using NDI Aurora tracker), and I want that when the sensors are out of range zero position is sent. I achieved this in the past with the config file below.

Now I have two problems:
1 - When the sensor is out of range the Server does not sends anything, blocking my receivng
2 - For some reason, I can only see the first sensor, not the second.

The log is giving me the following message when the first sensor is within the field of view:

/home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageCommon.cxx(60)
052716_110557.638|ERROR|039.550092| Invalid transform requested from repository: Transducer1ToEmTracker| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageFactory.cxx(206)
052716_110557.638|WARNING|039.550140| Failed to pack all IGT messages| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(646)
052716_110557.639|WARNING|039.550759| Unknown OpenIGTLink message is received from client 1. Device type: STP_TDATA. Device name: TDataClient.| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(599)
052716_110557.664|WARNING|039.576171| Skipped transformation matrix - Invalid transform in the transform repository (Transducer1 to EmTracker)| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageCommon.cxx(60)
052716_110557.664|ERROR|039.576286| Invalid transform requested from repository: Transducer1ToEmTracker| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageFactory.cxx(206)
052716_110557.664|WARNING|039.576365| Failed to pack all IGT messages| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(646)
052716_110557.714|WARNING|039.625700| Skipped transformation matrix - Invalid transform in the transform repository (Transducer1 to EmTracker)| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageCommon.cxx(60)
052716_110557.714|ERROR|039.625830| Invalid transform requested from repository: Transducer1ToEmTracker| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageFactory.cxx(206)
052716_110557.714|WARNING|039.625882| Failed to pack all IGT messages| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(646)
052716_110557.915|INFO|039.826854| Client disconnected (127.0.0.1:62345). Number of connected clients: 0| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(767)
052716_111057.710|INFO|339.621974| Stop requested...| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/Testing/PlusServer.cxx(364)
052716_111057.910|INFO|339.822221| Plus OpenIGTLink server stopped.| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/vtkPlusOpenIGTLinkServer.cxx(161)
052716_111057.910|INFO|339.822297| Shutdown successful.| in /home/ifind/workspace/plustrunk/release/PlusLib/src/PlusServer/Testing/PlusServer.cxx(269)

Everything was working perfectly with the previous version (I think is the version from around January this year).

Any clue?


------------------ configFile.xml -------------
~~~~
<PlusConfiguration version="2.3">
<DataCollection StartupDelaySec="1.0">
<DeviceSet Name="PlusServer: NDI Aurora tracker"
Description="Broadcasting tool tracking data through OpenIGTLink
Tracking a Pointer in port 0 and an EM sensor in port 1." />
<Device
Id="EmTracker"
Type="AuroraTracker"
SerialPort="3"
BaudRate="115200"
AcquisitionRate="40"
LocalTimeOffsetSec="0.0"
ToolReferenceFrame="EmTracker" >
<DataSources>
<DataSource Type="Tool"
Id="Transducer0"
PortName="0"
BufferSize="150"
AveragedItemsForFiltering="20"/>
<DataSource Type="Tool"
Id="Transducer1"
PortName="1"
BufferSize="150"
AveragedItemsForFiltering="20"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="EmTrackerStream">
<DataSource Id="Transducer0" />
<DataSource Id="Transducer1" />
</OutputChannel>
</OutputChannels>
</Device>
</DataCollection>
<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="2"
MaxTimeSpentWithProcessingMs="50"
ListeningPort="62345"
SendValidTransformsOnly="FALSE"
OutputChannelId="EmTrackerStream" >
<DefaultClientInfo>
<MessageTypes>
<Message Type="TRANSFORM" />
</MessageTypes>
<TransformNames>
<Transform Name="Transducer0ToEmTracker" />
<Transform Name="Transducer1ToEmTracker" />
</TransformNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>
</PlusConfiguration>
~~~~


#### 5 Comments
#### By Adam Rankin on 2016-05-27 10:59
@lassoan Could this be an IGTv3 issue? I don't think I touched any code relating to this...
#### By Andras Lasso on 2016-05-27 11:03
It's very likely related to that, as there haven't been any other Plus modification.
#### By Adam Rankin on 2016-05-27 14:21
You can follow along with my fixes at ExampleName
#### By Ifinddev498773 on 2016-06-03 04:00
Dear @rankin and @lassoan, thanks a lot. It all works all as expected now.

Thanks!
#### By Adam Rankin on 2016-06-03 09:20
No problem, sorry about that.


## Put pixel spacing values of US B-Mode image to OpenIGTLink ImageMessage
#### Posted by Hyun Jae Kang on 2016-06-01 11:46

Dear all,

I am updating the vtkPlusCapistranoVideoSource [1] to put the pixel spacing values to OpenIGTLink ImageMessage.
Right now, the source device can send US B-Mode image to Slicer program through PlusOpenIGTLinkServer in real-time.
(Please check the attached configuration file.)

But, I cannot put the pixel spacing values of an acquired B-Mode image into OpenIGTLink ImageMessage.
Could you help me to solve this problem?

[1] https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLib/src/PlusDataCollection/Capistrano/vtkPlusCapistranoVideoSource.cxx
PlusDeviceSet_CapistranoVideoSourceOverall_Test.xml	5.11 KB

#### 6 Comments
#### By Adam Rankin on 2016-06-01 11:48
Hello!

You can add them as a custom field to the tracked frames that you acquire.

Then, in the PlusIGTLServer configuration tag, you can send STRING message types, and put the name of the custom field. I will grab an example in two seconds.
#### By Adam Rankin on 2016-06-01 11:49
Code example here:
https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLib/src/PlusDataCollection/VirtualDevices/vtkPlusVirtualTextRecognizer.cxx#ln126

Config file example here:
https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLibData/ConfigFiles/PlusDeviceSet_Server_VirtualTextRecognizer.xml
#### By Andras Lasso on 2016-06-01 13:48
Sending the pixel spacing as a STRING message would work, but I would recommend to use a transform message to specify the image geometry. The advantage is that with a transformation matrix you can fully specify the image geometry, including spacing, origin, and axis directions in a clear and consistent manner.
#### By Hyun Jae Kang on 2016-06-02 15:42
Thanks Adam and Andras for your reply.

@Andras : Could you share an example code to send pixel spacing values with a transformation matrix?
#### By Andras Lasso on 2016-06-02 17:17
Actually, this is already implemented in the ultrasound imaging device base class. So, if you set this->CurrentPixelSpacingMm and this->CurrentTransducerOriginPixels and in the configuration file specify ImageToTransducerTransformName="ImageToTransducer" then it should be enough. See for example how it is done in vtkPlusSonixVideoSource.
#### By Hyun Jae Kang on 2016-06-03 06:59
Thank you for your reply. I will check and try it.


## Added support for Phidget accelerometer-gyroscope-magnetometer tracker device
#### Posted by Andras Lasso on 2012-05-23 18:31

A new class has been added (vtkPhidgetSpatialTracker) for interfacing with the Phidget Spatial 3/3/3 IMU device. This is a very small, low-cost (about $150) device that includes an accelerometer, gyroscope, and magnetometer sensor and it may be an alternative to electromagnetic and optical trackers in certain applications.

The device is readily usable as a tilt sensor in Plus. Full pose tracking is planned to be implemented in the future (see #503).

See this video for an illustration of using the device for tracking C-arm pose: http://www.youtube.com/watch?v=RXHmL58AeK4

Andras

#### 4 Comments
#### By Mangotee on 2016-04-01 18:31
Hi Andras,
I realize this is an older post, but I was wondering to what degree IMUs are now supported in PLUS. If I have a different IMU than the Phidget device (e.g. one that can transmit data wireless in real-time), but with an API (C++), how difficult is it to integrate it as a new device in PLUS? In the documentation for developers, I could not see instructions on how to integrate new devices into PLUS in general. Is there documentation available?
From a more general perspective - to what degree do you think is PLUS suitable as a general sensor acquisition and OpenIGTLink-based streaming framework? I am asking not only for tracking and image data, but also for other (more "exotic") data available through C++ APIs , e.g. data from high-frequency EEG, treadmill and pressure sensors...
I know this is a little bit off topic from tracked ultrasound, but I have made very good experiences with PLUS for 3D ultrasound, and now I am just wondering to what degree the acquisition platform can be extended by integrating "arbitrary" devices. Also, I understand that sending data over the network (e.g. through PLUSServer) happens through OpenIGTLink. What kind of limitations are there as to what kind of data OpenIGTLink can process?
Many thanks in advance!
Ahmad
#### By Andras Lasso on 2016-04-04 00:35
Adding an IMU should be easy (it took me a day to add support for Microchip IMUs). Should not take more than a couple of days work. We can help if you stuck at any point. Would you like to add support for x-IMU?

OpenIGTLink is already quite generic and is capable of transferring signals in standard message types. So far we have been able to transfer all types of signals (multiple "quality value" scalars, time-varying 1D light spectrum, etc) in image, transform, and string messages, but we would like to extend Plus to be able to stream arbitrary signals in more suitable message type (probably as n-dimensional array) and also add an optimized rotating buffer for signal data.

Could you write about what data would you record? How many channels you acquire from simultaneously, what is the data rate, how timestamps are obtained, is acquisition of data from multiple channels are synchronized, do you need synchronization/temporal resampling of signals, ...?
#### By Adam Rankin on 2016-04-04 09:57
how difficult is it to integrate it as a new device in PLUS? In the documentation for developers, I could not see instructions on how to integrate new devices into PLUS in general. Is there documentation available?


Sadly there is no documentation, but I can give you a quick summary here:

The major work for adding a device is the addition of a class that subclasses vtkPlusDevice. It's role is to make device API calls, receive data from the API (via callback or via polling) and then package that data into a vtkPlusDataSource.

The functions in vtkPlusDataSource that are relevent:
PlusStatus AddVideoItemToVideoSources(...); // Add an image item to a video data source
PlusStatus ToolTimeStampedUpdate(...); // Add a transform to a tracking data source
PlusStatus ToolTimeStampedUpdateWithoutFiltering(...); // Add a transform to a tracking data source

There are a number of housekeeping tasks that the class also performs, and to determine those I encourage you to look at other device classes as examples.
#### By Adam Rankin on 2016-04-04 09:57
There will also be a bit of CMake coding to integrate the API and make it available to your class.


## PlusServer.exe not longer generated
#### Posted by sordas on 2016-04-03 18:12

Hello,
PlusServer.exe is not being generated on the latest trunk. Sorry if I miss something obvious but PlusServerLauncher is still calling it right?

many thanks
sebastian

#### 2 Comments
#### By Andras Lasso on 2016-04-03 22:54
Currently, you shouldn't disable testing if you want to build any application in PlusLib or PlusApp. In the near future we plan to distinguish certain applications and allow to build them even with testing disabled (#1011).
#### By Sordas on 2016-04-04 07:39
ah, that´s it! thank you!


## Right way to avoid SVN download of PlusLib when building the SuperBuild solution
#### Posted by sordas on 2016-04-01 14:25

Dear experts,

I always wanted to avoid re-downloading the latest commit of the Plus toolkit every time the SuperBuild solution is built.
What is the right way of doing this in CMake?

I would also like to understand why that is the default behavior and why it is there a second source folder in the binary build? I use SmartGit and I would like to see my modifications on the source code. That is not possible this way.
Most toolkits build their binaries on a separate folder and whatever you modify on the code it is directly reflected in GIT.

I´m sure you will have an interesting explanation for this

As a collateral issue, the latest commit is not building in Visual Studio 2012:

1) #include "metaArray.h" is not found
2) many of these: Error 398 error C2086: 'int vnl_numeric_traits<double>::VCL_CONSTEXPR' : redefinition [D:\binX64\Plus\PlusLib-bin\src\DataCollection\Haptics\PlusHaptics.vcxproj] D:\binX64\Plus\itk\Modules\ThirdParty\VNL\src\vxl\core\vnl\vnl_numeric_traits.h 413

many thanks,
sebastian

PS: great to see the merged branch regarding latest OpenIGTLink version!

#### 4 Comments
#### By Adam Rankin on 2016-04-01 14:40
To change this locally, you can remove the BUILD_ALWAYS flag from the External_PlusLib.cmake file in PlusBuild.

However, changes in PlusLib won't be built by the superbuild, as it does not correctly detect changes in subprojects.

It is advisable to point your svn or git client to PlusBuild-bin/PlusLib, as that is the svn checkout of PlusLib.
#### By Andras Lasso on 2016-04-01 14:41
You can specify PLUS_SVN_REVISION in CMake to use a specific version of Plus.

Plus uses "superbuild" method to build all dependencies and itself. This is a very commonly used method in CMake-based projects with several dependencies.

If you want to use PlusLib in your own application then you don't have to use PlusBuild, just include PlusLib among the libraries that your project uses. You can use PlusBuild build scripts as an example for building applications (PlusApp) that use PlusLib, Qt, VTK, ITK, etc.

> Most toolkits build their binaries on a separate folder and whatever you modify on the code it is directly reflected in GIT.
Of course we separate source and binary directories: PlusLib (src), PlusLib-bin (bin), etc.

> As a collateral issue, the latest commit is not building in Visual Studio 2012:
As you can see on the dashboard, there are no build problems on VS2012: http://crunch.cs.queensu.ca/CDash/index.php?project=PLUS
The problem is that there some recent changes in ITK require a clean build of ITK (you need to delete ITK-bin directory and rebuild all).
#### By Sordas on 2016-04-01 14:50
great! thank you!
#### By Sordas on 2016-04-01 19:45
hi, everything builds fine now, except that PlusServer.exe is not generated. I might be missing something very stupid here but I cannot find it ...


## VTK5 support?
#### Posted by Andras Lasso on 2016-04-01 12:46

Hi all,

Does anyone still uses VTK5? We are considering dropping VTK5 support from Plus to simplify things, but we can hold it off for a while if there is a strong need to keep supporting VTK5.

Andras

#### 0 Comments


## CustomProperties has been rewritten
#### Posted by Jason... on 2016-03-13 09:12

Hi, I find that CustomProperties has been rewritten many times in configuration file , and the PartNumber in CustomProperties seems not right for probe and reference(the tool's PartNumber should be 610060,not 610029 ).

i have tested in the latest stable release version with the same problem.

Any idea about this ?
config_versio_20160313.xml	34.4 KB

#### 2 Comments
#### By Andras Lasso on 2016-03-17 08:37
These attributes are not used by Plus, they are just retrieved from the tracker and saved into the configuration file. I'm not aware that any information would be wrong (I've checked the code that queries that information and it looks correct). We plan to remove these attributes from the configuration file anyway, as they are not used (they can still be accessible for any application that uses the Plus library, just it will not be saved into configuration file).
#### By Andras Lasso on 2016-03-17 08:40
Plus reads and reports whatever is written to the tool's SROM. You can change the SROM contents, so if the model number is not what you expect then maybe you or someone else has changed the SROM.


## ToolFlags variable (PLUS) in Slicer
#### Posted by vgarciavazquez on 2015-12-04 10:50

Hello,

I am using an optical tracking system, PLUS and Slicer. I can see the transformation that comes from the optical tracking system in Slicer by using Plus and OpenIGTKLinkIF module.
Some parameters of ToolTimeStampedUpdate function (PLUS) are the transformation (position and orientation of the tool) and toolFlags. Do you know if there is a way to see this last variable (toolFlags) in Slicer?

Thanks a lot!

Verónica

#### 13 Comments
#### By Andras Lasso on 2015-12-04 10:57
OpenIGTLink cannot send tool status information in TRANSFORM messages. If you want to know if a tool is out of view then do the following:
Make sure in Plus configuration file SendValidTransformsOnly="TRUE" (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationPlusServer.html#ApplicationPlusServerConfigSettings)
In Slicer: Use the ToolWatchdog module (in SlicerIGT extension, IGT category) to watch a transform and display a warning if no up-to-date transform is received.
#### By Vgarciavazquez on 2015-12-04 11:20
Thanks a lot Andras! I will try if this way works in my case since I receive data from two different devices (one is the optical tracking system) and both devices are synchronised by using LocalTimeOffsetSec (PLUS configuration file). Maybe I could lose this synchronisation if I set SendValidTransformsOnly parameter to TRUE.
#### By Andras Lasso on 2015-12-04 11:24
Setting SendValidTransformsOnly="TRUE" should not cause any problem in combining the two data streams.
#### By Vgarciavazquez on 2015-12-04 11:27
I will check it! Thanks a lot!
#### By Vgarciavazquez on 2015-12-15 09:18
Andras, I have added checking if the tool is out of view using ToolWatchdog module. This module works great but there is a delay between the tool is out of view and when you see the message on the 3D view or you see the change in the Status flag. Do you know the status refresh rate? We have downloaded the last version of SlicerIGT but in a previous version of SlicerIGT, this module had advanced options and you could set up the status refresh rate (by default 200 ms). We would need to work with a status refresh rate of less than 20 ms as our complete system works at 50 Hz.

Thank you!
#### By Andras Lasso on 2015-12-15 10:35
We haven't added an option to change this on the GUI because we considered this an advanced parameter that users would not change. However, you can modify the timeout value (and the value is saved with the scene) by copy-pasting the following two lines in the Python console (assuming your watchdog node name is 'Watchdog'):
w=getNode('Watchdog')
for i in range(w.GetNumberOfWatchedNodes()): w.SetWatchedNodeUpdateTimeToleranceSec(i, 0.2)
#### By Vgarciavazquez on 2015-12-15 11:00
Thanks a lot Andras!
#### By Vgarciavazquez on 2015-12-18 06:04
Andras, we did some tests with the lines you suggested. Thanks a lot!

Now, we can filter more wrong data coming from the optical tracking system than before by using Watchdog tool but we have a strange behaviour. Do you know what is the minimum status refresh rate we can set up? For example, we tried two status refresh rates (0.2 and 0.02 s) and we can filter more wrong data with a refresh rate of 0.02 (great!). However, without touching the tool that is tracked (always in the field of view of our optical tracking system and no occlusions), we see sometimes the warning message of watchdog tool on the 3D view (more times if we decrease the refresh rate to 0.02 s). Do you know why? We saved the information coming from PLUS (file .mha) and, in both cases (0.2 and 0.02 s), TransformStatus is always set to OK (not INVALID) in all frames. What do you check to show that warning message?

Thanks again!
#### By Andras Lasso on 2015-12-18 14:40
There are slight delays caused by data processing/visualization (and network transfer, if data acquisition runs on a different computer). If the status display is only for human operator then a 0.5-second delay should be fast enough (you don't move tools quickly during surgeries anyway).

If you want to do some automatic processing then I would recommend to do it on the server side, where you have access to all low-level data.

As a workaround, you may choose to send all transforms (not just valid transforms) and then you'll receive an identity transform if a transform is invalid. You can detect this strict equality and act accordingly.

We are working on improving tool status information transfer (tool marker damaged, tool out of optimal tracking volume, etc) and then we'll certainly be able to give detailed status information. We are just working on the specification now, so probably detailed status information will be available in Plus/SlicerIGT in a few months.
#### By Vgarciavazquez on 2015-12-23 02:37
Thank you so much Andras. I will try your suggestions. The status display is not just for human operator, it´s for filtering the incoming data. Anyway, It´s a bit strange that when we reduce the status refresh rate and the optical tool is in the same position (inside the field of view of the cameras, the transforms are valid all the time), we have a lot of warning messages from the Watchdog Tool.
#### By Andras Lasso on 2015-12-23 08:18
If the transform is not updated for any reason within the specified tolerance (data is not acquired that frequently, delayed during transfer, delayed due to precessing) then you'll get a warning from the watchdog.

What kind of filtering you would like to do? The PlusServer can already do the most common processing operations and it's easy to extend to do more.
#### By Andras Lasso on 2015-12-23 08:26
You may find the Timestamp attribute of the transform useful. It's a high-precision timestamp determined in PlusServer. As this value is not impacted by network transfer and processing time it is a much more robust indicator of acquisition time of the frame. The timestamp encoding is specific in OpenIGTLink documentation: http://wiki.na-mic.org/Wiki/index.php/OpenIGTLink/Timestamp
#### By Vgarciavazquez on 2016-03-12 13:49
Thank you so much Andras. Sorry for the delay in replying you.


## Ultrasound Volume reconstruction in Slicer3D with PLUS + epiphan framegrabber
#### Posted by Mupamuc on 2016-02-26 05:12

Hello!
We have Imagic Agile Ultrasound device with Epiphan DVI2USB3.0 framegrabber.
Following this quide (U34) https://onedrive.live.com/view.aspx?cid=7230D4DEC6058018&resid=7230D4DEC6058018%213992&app=PowerPoint&authkey=%21AGQkSCZOwjVYXw8 received an 2d image from an ultrasound machine, rotated it on 180 degrees so its ok.
1) But it is looks impossible to build 3d volume reconstruction from ultrasound images without tracking system. Is it true? If yes is it possible to simulate something? even simple example from 2d ultrasound images to 3d. (I'm a student and looking for university further support - so needed to show them something, even a simple simulation example to say "we would do it with tracking system too")
2) What we can do else with this frame grabber (for example streaming via internet or/and recording data / measuring or planning in slicer (looks kind of useless because of existing ultrasound functionality/ what else?)
3) Do you know something about kinect implementation as a tracking system for slicer?
4) Can you suggest any free/trial/open source tracking systems for slicer3d by using simple cams? for edu/dev needs.

Thank you very much for any answers!

#### 8 Comments
#### By Andras Lasso on 2016-02-26 12:44
1. You are right, it's not possible to insert image slices into a volume if you don't know the position of the slices.

Without any additional hardware: Try to translate the probe with a constant speed. Load the recorded sequence file as a regular volume into Slicer - it will stack slices next to each other. You can adjust the spacing in the Volumes module to match the actual speed of motion.

A very simple and inexpensive option is to buy a PhidgetSpatial IMU sensor (http://www.phidgets.com/products.php?product_id=1044), you can generate volumes by rotating the probe. Costs $140, no programming is needed, you get the sensor, tape it on your probe, and you are ready to go.

3. We don't have a Kinect interface for Slicer.

4. We use Slicer with high-quality trackers that are suitable for guiding interventions on patients. However, I agree that it would be nice to have some simple, inexpensive solutions for demos and initial evaluation. There are several low-accuracy webcam-based tracking solutions, see for example http://www.uco.es/investiga/grupos/ava/node/26. Intel RealSense cameras are very cheap, too, and through stereo optics it may provide much better accuracy than basic webcams. Kinect could be used for tracking, too. If you decide to try to implement an interface in Plus for any of these devices/libraries then we would be happy to assist you.
#### By Mupamuc on 2016-02-26 15:33
Thank you for fast response!
We will try to create tracking system with Kinect (probably would based on IGSTK and openkinect) with PLUS framework.
About education materials - Ziv Yaniv have done a really good work for us http://yanivresearch.info/educationalMaterial.html
#### By Fuzeshan2014442609 on 2016-02-29 00:54
@Mupamuc: Hi, could you pls send me some grabbed images, I want to check whether those grabbed images could be used in our algorithm. Thank you (fuzeshan2014@gmail.com)
#### By Mupamuc on 2016-02-29 06:29
@fuzeshan2014442609 Do you need grabbed images from ultrasound device or any other image (from my laptop's desktop ?)
#### By Andras Lasso on 2016-02-29 15:00
With a good-quality framegrabber (such as this Epiphan framegrabber: http://www.epiphan.com/products/dvi2usb-3-0/) you get the same image quality as you see on the ultrasound console screen. The main advantage of OEM interface is not image quality but the access to image without annotations (various lines and text overlaid on the image) and ability to get metadata (what probe is used, depth changed, etc).
#### By Fuzeshan2014442609 on 2016-03-01 04:22
@lassoan thx so much for your help
#### By Fuzeshan2014442609 on 2016-03-01 04:45
@Mupamuc: I'm wondering that will the labels on the grabbed ultrasound images weaken the 3d reconstruction or result of the algorithm, as you know the ultrasound image itself is not very clear. Pls send me some grabbed ultrasound image to check this.
#### By Mupamuc on 2016-03-01 07:30
@fuzeshan2014442609 Ok, I'll do it ASAP (hope on this week, because I'm not a medic)


## connection between Plus and Ultrasound device
#### Posted by fuzeshan2014442609 on 2016-01-09 04:17

Hi,
Our team is preparing to develop real-time ultrasound to MRI registration system based on the Plus. And I have tested the connection between NDI trackers and the Plus-server,and it works fine. Recently , I'm trying to export real-time ultrasound data from [BK pro focus 2202] device to the Plus on my PC (windows 7). My question is: What kind of hardware connection is used to export the real-time data from device to the Plus. Does USB or RS232 works with it? I really appreciate your help.

thank you !
fedral

#### 17 Comments
#### By Adam Rankin on 2016-01-09 16:14
Hi Fedral!

With the BK you have a couple of options. If you are using a screen grabber, PLUS supports the Epiphan through their API and other screen grabbers through windows drivers.

Alternatively, there is a research interface for the BK probes that is also supported by PLUS.

What hardware are you using to acquire images from the BK machine?
#### By Andras Lasso on 2016-01-09 18:58
Do you have license access to the OEM interface on the BK machine? (that's a TCP/IP-based interface for transferring control and live images)
#### By Fuzeshan2014442609 on 2016-01-10 21:10
@Andras Lasso : No, we just started the corporation with the local hospital to get ultrasound data, and this week I am going to meet the urologist and check the ultrasound device. How can I get a BK license? Do you have any suggestions? Thank you!
#### By Fuzeshan2014442609 on 2016-01-10 21:58
@ Rankin : Thanks for your reply. We just started the project and the hospital only provide us the ultrasound imaging device, so image acquiring hardware is not decided yet. We hope to get the pure ultrasound image data without labels, so the screen grabber may not be our choice. Is it possible to export the internal data from the machine just the way as USB communication? Thank you!
#### By Adam Rankin on 2016-01-10 23:35
Andras will be able to provide more information, but BK offers a research interface (for a cost, perhaps a research agreement I am not sure) that offers b-mode and rf data.

As per the BK device documentation:
Image acquisition is available through both the OEM interface (TCP/IP) and CameraLink interface (high-speed interface for RF data acquisition).
#### By Fuzeshan2014442609 on 2016-01-11 01:14
@ Rankin: thank you !
#### By Andras Lasso on 2016-01-11 08:18
Contact BK Sales to get a quote on OEM interface license. Let them know that you need live image streaming (GRAB ON/OFF command).
#### By Fuzeshan2014442609 on 2016-01-12 02:01
Hi, Andras! I have contacted the local BK sales at Shanghai, VGA and S-video protocols are supported to directly transmit ultrasound image. Could those two data formats be supported by the PLUS?
#### By Fuzeshan2014442609 on 2016-01-12 02:12
During cmake when PLUS_USE_BKPROFOCUS_VIDEO is on, error is reported that PLUS_GRABBIELIB_SOURCE_DIR is not defined. Where could I get GRABBIE library? Thanks
#### By Andras Lasso on 2016-01-12 10:38
There is VGA and S-video output and you can connect a framegrabber to grab the screen content, but that's very limited. Let BK sales know that you are interested in the OEM interface that allows you to acquire images through TCP/IP. If they cannot help then contact BK through another channel (maybe through this form: http://www.bkultrasound.com/contact) and describe what you would need.
#### By Andras Lasso on 2016-01-12 10:39
You'll get the Grabbie library from BK along with the OEM interface.
#### By Andras Lasso on 2016-01-12 10:50
If you decide to grab the screen then you can use any compatible framegrabber listed on the http://perk-software.cs.queensu.ca/plus/doc/nightly/user/Devices.html page, "Framegrabbers and cameras" section. For VGA capture I would suggest Epiphan DVI2USB 3.0 (about $700). If lower quality is acceptable then you can use S-video and ImagingControls DFG/USB2pro (about $300).
#### By Fuzeshan2014442609 on 2016-02-21 21:31
Hi, Andras. I have asked BK staff at Shanghai to contact the BK R&D in US and reported my request to them, but there is still no reply after a long wait. Could you tell me more details about where do you get the OEM so that I could contact them directly. I really need the data for my research as fast as possible. Thanks~
#### By Andras Lasso on 2016-02-22 08:50
I've sent an email to a BK contact, I'll let you know if I hear from them.
#### By Fuzeshan2014442609 on 2016-02-22 20:41
Thanks so much, and my email is fuzeshan2014@gmail.com
#### By Mupamuc on 2016-02-26 05:14
I have an Epiphan DVI2USB 3.0 and its works perfectly!
#### By Fuzeshan2014442609 on 2016-02-28 21:01
@Mupamuc : yeah, I should try it, thank you~


## Skip recording invalid frames by Virtual Disc Capture
#### Posted by Bartłomiej Pyciński on 2016-02-18 17:07

Hello,

I would like to record an entire navigated US biopsy procedure. Right now the data can be saved by Virtual Disc Capture device. Unfortunately the mha file size spreads rapidly if the procedure lasts long. Obviously the recording could be significantly limited if the image data were appended only if the probe's position was visible. I haven't find this possibility in Virtual Disc Capture or Data Collection classes.

What is the easiest way to achieve this solution? I would imagine the proper working, that after the probe disappears (i.e. the transform becomes invalid) some delay is applied and the capturing is paused. If the probe comes back, the capturing returns. The delay is necessary to deal with transitory occlusions.

Best regards,

Bartłomiej

#### 5 Comments
#### By Andras Lasso on 2016-02-18 17:28
We usually add two capture devices for recording tracked ultrasound procedures. One only records the tracking data and it is enabled by default and records all tracking data during the entire procedure. We have a button for start/stop tracked ultrasound recording and we can also change the filename prefix (a timestamp is appended to the filename prefix to produce the complete filename) to indicate what is the content of the recording (without that it would be too difficult to figure out just form the image contents what was being done).

I agree that it could be nice to allow automatic pause/resume of image recording. Start/stop based on transform status would not work in general (EM trackers keep giving you position information even if you put down the probe) so doing it based on image contents would be nicer (e.g., by checking image intensity and variance at a number of predefined positions).
#### By Andras Lasso on 2016-02-18 17:35
We have higher priority tasks, so we don't plan to work on this in the near future, but I've added a ticket to remember this (https://www.assembla.com/spaces/plus/tickets/1069) and we would be happy to help you if you plan to implement this feature.
#### By Tamas Ungi on 2016-02-18 17:42
This is a feature that could be implemented on the application level. E.g. if you use 3D Slicer for controlling PLUS, then you could write a relatively simple script for Slicer that starts and stops the PLUS capture device based on the status or contents of the tracking/imaging data received.
#### By Andras Lasso on 2016-02-18 17:48
Yes, that's a good point. Implementing this mechanism at application level would also make manual override of start/stop recording, definition of a region of interest (outside of which recording would be stopped), and changing of filename prefixes easier.

3D visualization of tracked images and tools, volume reconstruction, registration, start/stop recording, etc. are all already freely available in SlicerIGT. Automatic start/stop feature could be implemented by adding 10-20 lines of Python code in PlusRemote module. It would not be even necessary to rebuild Slicer or any of the SlicerIGT modules.
#### By Bartłomiej Pyciński on 2016-02-19 05:15
That's right, I didn't think that this could be done from the other side. I'll look into PlusRemote module and try to customize it properly.
Thank you for immediate help!


## Extract MPR slices from reconstructed volume
#### Posted by mangotee on 2016-02-02 06:26

Dear all,
I use PLUS to calibrate and acquire tracked 2D US images and I use the VolumeReconstructor to reconstruct them, all beautifully.
After reconstruction, I would like to extract MPR (multi-planar reformatted) slices from the reconstruction US volume again, in the exact 3D poses of the 2D images from which I reconstructed the 3D volume, either for all 2D images from the input stack, or for a sub-selection of those. An application would be e.g. "n-fold cross-validation" of reconstruction quality by comparison of MPR slices to 2D images that were left out during reconstruction. In other words, the extracted MPR slices need to exactly correspond to the pixel grid of the 2D tracked input slices.
Is there a function/method to do this in PLUS? Or in Slicer/SlicerIGT?
Many thanks in advance!
Cheers, Ahmad

#### 4 Comments
#### By Andras Lasso on 2016-02-02 08:55
I would recommend all visualization and analysis in 3D Slicer. For example, you can select the reconstructed volume as background and the live image slice as foreground, use the Volume Reslice Driver module to set a reslicing transform and use the following few lines of script to extract the image slices from the red slice viewer:

sliceNode = slicer.mrmlScene.GetNodeByID('vtkMRMLSliceNodeRed')
sliceLogic = slicer.app.applicationLogic().GetSliceLogic(sliceNode)

backgroundWriter=vtk.vtkMetaImageWriter()
backgroundWriter.SetInputConnection(sliceLogic.GetBackgroundLayer().GetReslice().GetOutputPort())
backgroundWriter.SetFileName('c:/tmp/background.mha')
backgroundWriter.Update()
backgroundWriter.Write()

foregroundWriter=vtk.vtkMetaImageWriter()
foregroundWriter.SetInputConnection(sliceLogic.GetForegroundLayer().GetReslice().GetOutputPort())
foregroundWriter.SetFileName('c:/tmp/foreground.mha')
foregroundWriter.Update()
foregroundWriter.Write()


In the example above the slices are written to file but you can use them as inputs to any filter. In Slicer you have access to all VTK filters, SimpleITK, and numpy - so you can do all kinds of analyses very easily, with just a few lines of code.
#### By Mangotee on 2016-02-12 05:29
Hi Andras,
thanks for the fast answer! I read your message just now that I logged in again - I didn't realize that email notifications have to be switched on manually after creating an account.
The solution seems straightforward, I will try this out! Thanks again!!
Just one more question - the solution seems like it needs to be performed on live streaming data. I wonder what would be the best way to use an offline sequence as the foreground "live image slice", e.g. the sequence with which the volume was reconstructed originally?
I see two ways: Say, I have a imgSeqUS.mha file with image-trackingdata pairs, from which I reconstruct a volUS.mha. One possibility would be to stream the imgSeqUS.mha through a PLUSServer as a "TrackedVideoDevice" of type "SavedDataSource" and use the live image solution as you wrote. The other way is to look at the code of "MultiVolumeExplorer" (is that a Python or C++ module?) and implement that during replay, every frame is resliced in the way you suggested and stored out with the vtkImageWriter.
Or is there a simpler way that I am not seeing?
#### By Andras Lasso on 2016-02-13 10:46
You can replay recorded sequences from Plus and reconstruct using PlusRemote module in Slicer. Or, use the http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationVolumeReconstructor.html tool to reconstruct a volume from a sequence file.
#### By Andras Lasso on 2016-02-13 10:49
You can use Sequences extension in Slicer to replay a sequence file (play/pause, browse or step frame by frame).

https://www.slicer.org/slicerWiki/index.php/Documentation/Nightly/Extensions/Sequences


## NDI Optotrak support in Linux
#### Posted by lzhang89 on 2016-02-01 11:17

Hello, I plan to use PLUS for a project and would like to know whether the Optotrak Certus system is supported by PLUS in Linux.
As refer in the user manual, in order to use the Optotrak Certus in Linux, the Optotrak API is needed.
However I can hardly find the OAPI online (only one which has only been tested in outdated Ubuntu 12).
I wonder if you have the OAPI and its wrapper included in PLUS or not.

Thanks very much!

#### 3 Comments
#### By Andras Lasso on 2016-02-01 12:04
Plus supports Optotrak Certus on all operating systems, you "just" need to have the OAPI interface.

As Optotrak Certus is a really old system it may not be supported anymore, so it may be difficult to obtain software for it. The newer-generation 3D Investigator (http://www.ndigital.com/msci/products/3d-investigator/) might share the same interface, so there is a chance that you can still get some software support. As far as I know, OAPI is not freely available, so if you don't have it then I would suggest to contact NDI sales.
#### By Lzhang89 on 2016-02-02 10:45
Thanks very much for replying.
I found the oapi here:
https://github.com/CarloNicolini/cncsvision/tree/master/deps/drivers/NDIoapi/

But I am not sure if it's compatible with current Linux distribution, will try it.
I will also contact NDI and see if the cost is reasonable.

Thanks very much again!
#### By Andras Lasso on 2016-02-02 11:19
Thanks, good to know that OAPI is publicly available. It may be possible that the OAPI client libraries and header files are freely redistributable and you only have to pay for the software/firmware running on the tracker itself.


## problem with probe calibration using fCal
#### Posted by bflach on 2016-01-14 06:12

Hi,

we have a problem calibrating our probe with fCal. We attached two tracking markers to our Ultrasonix probe (4DEC9-5/10 Endovaginal Microvonvex 4D). Then we calibrated both sensors separately by fCal to get the "probe to image" transformation according to the attached configuration files with identical image settings. And in the end we acquired several pairs of tracking positions for the two sensors.

We would now assume that the coordinates of the origin of the image (voxel (0,0,0)) are equal in the coordinate system of the tracking basis no matter which of the two tracking informations we use. But unfortunately they are not. There is a deviation of about 80 mm between the image origins.

We computed the coordinates by T_probe2track*T_img2probe*[0;0;0;1] where T_probe2track is the transformation from the probe to the tracking basis coming from the tracking marker and T_img2probe is the transformation from the image to the probe as calibrated by fCal. The transformation matrices for one exemplary measurement in our case are the following:
- for first marker:

~~~~
T_probe2track = [-0.5862948, -0.1737263, -0.7912499, 232.507;
0.7608475, 0.2172800, -0.6114736, -55.4757;
0.2781517, -0.9605248, 0.0047896, 34.7142;
0, 0, 0, 1];
T_img2probe = [0.00634536, 0.104189, -0.0121171, 174.247;
-0.101832, -0.00157682, -0.0429132, 59.4132;
-0.0436709, 0.0121541, 0.0983041, 61.3263;
0, 0, 0, 1];
- for second marker:
T_probe2track = [-0.5552303, 0.4262148, 0.7141849, 259.296;
0.7800746, -0.030942, 0.6249208, -39.4022;
0.2884488, 0.9040933, -0.3152993, 59.1592;
0, 0, 0, 1];
T_img2probe = [0.00571667, 0.103333, -0.0106283, 181.114;
0.11028, -0.00346323, 0.0105264, -38.6065;
0.0103412, -0.0106668, -0.106379, -13.6855;
0, 0, 0, 1];
~~~~

The problem seems to be the "probe to image" transformation from fCal since we already checked the tracking markers. The distance between the two markers as well as the orientation of the tracking positions are correct. Regarding the "probe to image" transformation the orientation of the image seems to be OK, it is almost identical. Looks more like a translation.

What could be the problem? Do we apply the transformation in a wrong way? Or is there something wrong with our configuration file?

I am looking forward to your reply!

Kind regards,
Barbara Flach
firstMarker.xml	9.47 KB
secondMarker.xml	9.47 KB

#### 10 Comments
#### By Adam Rankin on 2016-01-14 11:23
Hi Barbara,

I'll take a peek and see if I can figure out what's happening.

Adam
#### By Adam Rankin on 2016-01-14 12:38
Some basic questions first just to confirm my understanding.

Are the two sensors approximately 1.2cm apart?
You connected to the first config file, performed a calibration, disconnected, switched sensors, then calibrated again?
Was the reference sensor bumped at any time during the calibrations?
#### By Andras Lasso on 2016-01-14 13:40
Check "I get large (>2-3mm) probe spatial calibration error - what's wrong?" section on page http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html

One possible cause is that you rotate the probe between the two calibrations, while the marked side of the probe must always be on one specific side of the phantom. See the description on documentation page:
Probe orientation: make sure that the probe orientation is correct (for fCal_2.x_Wiring_1.x the marked side of the probe shall be close to the A1 point). The wire numbers are shown in fCal during spatial calibration and in the segmentation parameter setting dialog box, which can help in verification of the correct orientation. To verify the probe orientation: touch a w1 wire with your finger => your finger should appear near w1 wire on the US image. If your finger appears at a different wire (and you are sure that the image orientation is set correctly) then you do not keep the marked side of the probe on the w1 wire's side - in this case simply rotate the probe by 180 deg (and keep it in this orientation while collecting the calibration data). #435 will enable automatic detection of the probe orientation.


If you need to have the probe in a different orientation then you have to change the configuration file. For example, change from

~~~~

      <Pattern Type="NWire">
        <Wire Name="7:G1_g1" EndPointFront="30.0 0.0 20.0" EndPointBack="30.0 40.0 20.0" />
        <Wire Name="8:L1_h1" EndPointFront="55.0 0.0 20.0" EndPointBack="35.0 40.0 20.0" />
        <Wire Name="9:M1_m1" EndPointFront="60.0 0.0 20.0" EndPointBack="60.0 40.0 20.0" />
      </Pattern>
      
~~~~

to this:

~~~~

      <Pattern Type="NWire">
        <Wire Name="9:M1_m1" EndPointFront="60.0 0.0 20.0" EndPointBack="60.0 40.0 20.0" />
        <Wire Name="8:L1_h1" EndPointFront="55.0 0.0 20.0" EndPointBack="35.0 40.0 20.0" />
        <Wire Name="7:G1_g1" EndPointFront="30.0 0.0 20.0" EndPointBack="30.0 40.0 20.0" />
      </Pattern>
      
~~~~

#### By Bflach on 2016-01-15 05:59
Hi Adam,

thanks for having a look at it.
The two sensors are approximately 43 mm apart. From tracking without the probe we get exactly that distance. With the probe - like in the example I gave here - we get a distance of 40 mm. This results from subtracting the forth column of the two T_probe2track transformations and calculating the norm of this distance vector. How do you get 1.2 cm?
This means the probe has an influence on the accuracy of our magnetic tracking. But not in a range to result in 80 mm deviation of the image points.
Yes, we connected to the first config file, performed a calibration, disconnected, switched sensors, then calibrated again. For switching sensors we only connected the other sensor. Both sensor were attached fix to the probe for the whole procedure (calibration as well as measurement) without moving them. Also the reference sensor was fixed for the whole calibrations.
#### By Bflach on 2016-01-15 06:06
Hi Andras,

thanks for your help. But the calibration error is not the problem. It is below 1 mm. And we also verified to hold the probe for both calibrations correctly.
#### By Adam Rankin on 2016-01-15 11:01
I performed the multiplications you listed, imported them into Slicer, attached them to two models representing the transformation space, and measured the distance between the origins.

It is definitely possible that I screwed up the multiplications though.

Edit: I am not a smart man. I accidentally used the same probe2track for both sensors. Disregard my results.
#### By Adam Rankin on 2016-01-15 11:34
I admit I am not sure what's happened. I ran the calculation through python and here are my results. Perhaps you could verify? I get a distance of 91mm

~~~~

>>> a_probe2track = numpy.array([-0.5862948,-0.1737263,-0.7912499,232.507,0.7608475,0.2172800,-0.6114736,-55.4757,0.2781517,-0.9605248,0.0047896,34.7142,0,0,0,1])
>>> a_probe2track = numpy.asmatrix(a_probe2track)
>>> a_probe2track = a_probe2track.reshape(4,4)
>>> a_probe2track
matrix([[ -5.86294800e-01,  -1.73726300e-01,  -7.91249900e-01,
           2.32507000e+02],
        [  7.60847500e-01,   2.17280000e-01,  -6.11473600e-01,
          -5.54757000e+01],
        [  2.78151700e-01,  -9.60524800e-01,   4.78960000e-03,
           3.47142000e+01],
        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
           1.00000000e+00]])
>>> a_image2probe = numpy.asmatrix([[0.00634536, 0.104189, -0.0121171, 174.247],[-0.101832, -0.00157682, -0.0429132, 59.4132],[-0.0436709, 0.0121541, 0.0983041, 61.3263],[0, 0, 0, 1]])
>>> a_image2probe
matrix([[  6.34536000e-03,   1.04189000e-01,  -1.21171000e-02,
           1.74247000e+02],
        [ -1.01832000e-01,  -1.57682000e-03,  -4.29132000e-02,
           5.94132000e+01],
        [ -4.36709000e-02,   1.21541000e-02,   9.83041000e-02,
           6.13263000e+01],
        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
           1.00000000e+00]])
>>> origin = numpy.asmatrix([[0],[0],[0],[1]])
>>> origin
matrix([[0],
        [0],
        [0],
        [1]])
>>> point1 = a_probe2track * a_image2probe * origin
>>> point1
matrix([[ 71.50082583],
        [ 52.50958099],
        [ 26.40717567],
        [  1.        ]])
>>> b_probe2track = numpy.asmatrix([[-0.5552303, 0.4262148, 0.7141849, 259.296],[0.7800746, -0.030942, 0.6249208, -39.4022],[0.2884488, 0.9040933, -0.3152993, 59.1592],[0, 0, 0, 1]])
>>> b_probe2track
matrix([[ -5.55230300e-01,   4.26214800e-01,   7.14184900e-01,
           2.59296000e+02],
        [  7.80074600e-01,  -3.09420000e-02,   6.24920800e-01,
          -3.94022000e+01],
        [  2.88448800e-01,   9.04093300e-01,  -3.15299300e-01,
           5.91592000e+01],
        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
           1.00000000e+00]])
>>> b_image2probe = numpy.asmatrix([[0.00571667, 0.103333, -0.0106283, 181.114],[0.11028, -0.00346323, 0.0105264, -38.6065],[0.0103412, -0.0106668, -0.106379, -13.6855],[0, 0, 0, 1]])
>>> b_image2probe
matrix([[  5.71667000e-03,   1.03333000e-01,  -1.06283000e-02,
           1.81114000e+02],
        [  1.10280000e-01,  -3.46323000e-03,   1.05264000e-02,
          -3.86065000e+01],
        [  1.03412000e-02,  -1.06668000e-02,  -1.06379000e-01,
          -1.36855000e+01],
        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,
           1.00000000e+00]])
>>> point2 = b_probe2track * b_image2probe * origin
>>> point2
matrix([[ 132.50738032],
        [  94.52243982],
        [  80.81246655],
        [   1.        ]])
>>> point1-point2
matrix([[-61.00655449],
        [-42.01285883],
        [-54.40529088],
        [  0.        ]])
>>> numpy.linalg.norm(point1-point2)
91.906559463847316

~~~~

#### By Andras Lasso on 2016-01-15 17:33
The two ImageToProbe matrices seems to be consistent, as they show that the two Probe markers are at 47mm distance:

ImageToProbe1=[0.00634536 0.104189 -0.0121171 174.247; -0.101832 -0.00157682 -0.0429132 59.4132; -0.0436709 0.0121541 0.0983041 61.3263; 0 0 0 1];
ImageToProbe2=[0.00571667 0.103333 -0.0106283 181.114; 0.11028 -0.00346323 0.0105264 -38.6065; 0.0103412 -0.0106668 -0.106379 -13.6855; 0 0 0 1];
Probe1ToProbe2 = ImageToProbe2 * inv(ImageToProbe1);
norm(Probe1ToProbe2(1:3,4))
ans =
   46.3637


However, the Image origin was indeed at a different position:

Probe1ToTracker = [-0.5862948, -0.1737263, -0.7912499, 232.507; 0.7608475, 0.2172800, -0.6114736, -55.4757; 0.2781517, -0.9605248, 0.0047896, 34.7142; 0, 0, 0, 1];
Probe2ToTracker = [-0.5552303, 0.4262148, 0.7141849, 259.296; 0.7800746, -0.030942, 0.6249208, -39.4022; 0.2884488, 0.9040933, -0.3152993, 59.1592; 0, 0, 0, 1];

ImageToTracker_1 = Probe1ToTracker * ImageToProbe1
ImageToTracker_2 = Probe2ToTracker * ImageToProbe2

ImageToTracker_1 =

    0.0485   -0.0704   -0.0632   71.5008
    0.0094    0.0715   -0.0787   52.5096
    0.0994    0.0306    0.0383   26.4072
         0         0         0    1.0000

ImageToTracker_2 =

    0.0512   -0.0665   -0.0656  132.5074
    0.0075    0.0740   -0.0751   94.5224
    0.0981    0.0300    0.0400   80.8125
         0         0         0    1.0000


Just to confirm: the probe did not move when you switched to the other probe marker, did it? What tracker do you use?

Anyway, the easiest way to check the ImageToProbe calibration is to acquire images of a tracked stylus. Where the stylus intersects the US image you should see a bright reflection. You should be able to see the tracked stylus and your US image in fCal (switch to 3D view using buttons at the top), or, you can set up any tool visualization easily in 3D Slicer as explained in the tutorials at http://www.slicerigt.org/wp/user-tutorial/.
#### By Bflach on 2016-01-22 06:12
Thanks for all your help! We finally solved the problem. It was a problem how we interpreted the tracking data. Sorry for wasting your time!
#### By Adam Rankin on 2016-01-22 10:21
Not at all, I'm glad you were able to figure it out.


## Buying a used SonixDAQ
#### Posted by orajput on 2016-01-21 14:57

Hello all,

(This might be completely off-topic as far as PLUS toolkit is concerned. However, considering a high activity on this forum I thought of posting it here. @admins feel free to remove this post if it violates any community guidelines.)
Due to some limitations of our budget, we were interested to find out if there is a way to purchase a used SonixDAQ. I would like post this here to see if there is a research group out there wanting to sell their SonixDAQ, then we would be really interested to get that.

Thanks!

Regards,
Omer

#### 2 Comments
#### By Adam Rankin on 2016-01-21 19:57
No problem, happy to leave it up.

Robarts doesn't have any for sale at the moment, sorry!
#### By Orajput on 2016-01-22 05:12
Thanks Rankin. Much appreciated.


## 64 bit Ascension and Errors in PlusBuild/External_PlusLib.cmake
#### Posted by david.kuegler833514 on 2016-01-18 16:00

Hi everybody,

2 suggestions:
1) 64-bit support for Ascension Tracker;
It seems the 64-bit version of Plus does not support the Ascension 3D Guidance tracker.
Since Ascension Tech provides a 64 bit library, that is compiled to the same header file as the 32-bit variant, it seems easy to include 64 bit support.
I do not think I am allowed to share the library though, but I guess a short mail to Ascension (or NDI) should solve enable you to include the 64-bit dll…

2) Bug in CMake files;
The PlusLib and PlusApp subprojects do not get generated by cmake with the following error:
--
CMake Warning (dev) at C:/Program Files (x86)/CMake/share/cmake-3.4/Modules/ExternalProject.cmake:449 (message):
value '' with no previous keyword in ExternalProject_Add
Call Stack (most recent call first):
C:/Program Files (x86)/CMake/share/cmake-3.4/Modules/ExternalProject.cmake:2381 (_ep_parse_arguments)
External_PlusLib.cmake:204 (ExternalProject_Add)
CMakeLists.txt:483 (INCLUDE)
--
This warning is for project developers. Use -Wno-dev to suppress it.
It seems the cause of this is, that in my specific case this is due to "${PLUSBUILD_EXTERNAL_PROJECT_CUSTOM_COMMANDS}" beeing an empty string. If I comment out that specifig line (for PlusLib line 205 in PlusBuild/External_PlusLib.cmake) it works fine.

Cheers
David

#### 8 Comments
#### By Andras Lasso on 2016-01-18 17:24
Thanks for your notes.

1) We are only aware of Ascension drivers for 32-bit and 64-bit operating system that can be used in 32-bit applications. Do you mean you have Ascension lib and dll that can be used in a 64-bit application? Have you actually tried to build a 64-bit application with it? (you can try it using Plus, just replace the DLLs and try to build a 64-bit application) The latest Ascension SDK that we have is trakSTAR_Rev-D. Do you have a more recent version?

2) We knew about the warnings but we couldn't find an easy solution earlier to fix it and it caused no harm, so that's why it was not resolved. Now I've spent some more time with it and the warning is fixed now (see #1011). If you experience any further problem related to this then let me know.
#### By Adam Rankin on 2016-01-18 18:07
I will reach out to NDI and find out.
#### By David.Kuegler833514 on 2016-01-19 05:24
regarding 1)
I have "3D Guidance driveBAY (Rev D1)" and it provides separate dlls for standard and 64-bit operation.
ATC3DG.dll/lib and ATC3DG64.dll/lib

The linking seems to work as well.

regarding 2)
Why not just remove the quotation marks around ${PLUSBUILD_EXTERNAL_PROJECT_CUSTOM_COMMANDS} in the ExternalProject_Add() call.
that way the passed arguments would be parsed and all should be fine.

The warning is fixed in the current SVN, but I have a different issue still remaining:
Nothing really is downloaded to or created in the SOURCE directory. CMAKE_BINARY_DIR/PlusApp and CMAKE_BINARY_DIR/PlusLib remain empty folders.
#### By David.Kuegler833514 on 2016-01-19 05:31
This would all make sense, if you expect CMAKE_SOURCE_DIR to be CMAKE_BINARY_DIR/PlusBuild

In this case all works out nicely, but this should not always be the case.

Two questions:
1) why do you not default PLUS_PLUSLIB_DIR to CMAKE_SOURCE_DIR/../PlusLib
2) why keep the variable (PLUS_PLUSLIB_DIR) internal? why not export it to the CMAKE gui?

David
#### By David.Kuegler833514 on 2016-01-19 06:48
I made the changes I questioned above to the ExternalProjects of PlusLib and PlusApp (c.f. the attached patch).
Also I made PLUSLIB_DIR (which ist the binary dir) a actually configurable option. Up to this point the folder was hardcoded and then exported to cmake gui ... which seemed beyond the point.

I would rather change the variable names alltogether, to make PLUS_PLUSLIB_DIR and PLUSLIB_DIR more distinguishable (say: PLUS_PLUSLIB_SOURCE_DIR and PLUS_PLUSLIB_BINARY_DIR)... For the PlusApp project, this seems easily possible, but the PLUSLIB_DIR variable is used in several places across the projects.
Plus-PlusBuild-export-Source-Dirs_relative-to-PlusBuild-Source-Directory.patch	2.41 KB
#### By David.Kuegler833514 on 2016-01-19 08:09
update: remove FORCE from PLUSLIB_DIR and PLUSAPP_DIR
Plus-PlusBuild-export-Source-Dirs_relative-to-PlusBuild-Source-Directory.patch	2.4 KB
#### By Adam Rankin on 2016-01-19 14:00
Hi David,

I have retrieved the latest revision from NDI and integrated it into PLUS. You should now be able to use the Ascension in 64 bit builds.

See details here https://www.assembla.com/spaces/plus/tickets/1065-upgrade-ascension-driver-support-to-include-64-bit-driver-package/details
#### By David.Kuegler833514 on 2016-01-19 14:23
Nice
I do not know why, but it seems, I am not able to build PlusApp
The PlusApp-Binary folder ist just an empty folder; no files at all

The CMakeLists.txt in the source folder is never actually executed (at least the message command I put in there is never evaluated)
The ExternalProject_Add(PlusApp ) - call on the other hand is fine.
Paths seem to be correct, but as written above there are might be some confusion on how to set those folders up....

PlusLib on the other hand seems to work fine... (although it being the same concept)


## Plus on SonixTouch Q+ Windows 7 64 bit
#### Posted by ersmistad377977 on 2016-01-18 09:55

Hi

I am wondering whether Plus is known to work on the Ultrasonix SonixTouch Q+ (with Sonix GPS) Windows 7 64 bit embedded system?
And if so, which Plus software edition should one use?

Thanks.
- Erik Smistad

#### 3 Comments
#### By Andras Lasso on 2016-01-18 10:14
We have a couple of those systems here and Plus works well with them (the only difference is that we use 32-bit XPe operating system, but that shouldn't be an issue). Use the PlusApp-...-Ultrasonix-6.1-Win32 package for Exam software 6.1.1 or later; PlusApp-...-Ultrasonix-5.7-Win32 for Exam software 6.0.2 or earlier.
#### By Ersmistad377977 on 2016-01-18 10:31
So these PlusApp-...-Ultrasonix software editions should work for both XP and windows 7?
#### By Andras Lasso on 2016-01-18 10:35
PlusApp-...-Ultrasonix-...-Win32 packages work on all NT-based Windows operating systems (XP, XPe, 7, 8, 10; both 32-bit and 64-bit).


## Pivot calibration of Stylus with OpenIGTLinkTracker
#### Posted by Medimax1 on 2016-01-10 09:16

Hello assembla community!

How is it possible to obtain the transformation matrix or the translation from the needle coordinate system to the needle tip by doing a pivot calibration with fCal?

My plan is to change the PlusDeviceSet_fCal_Sim_PivotCalibration.xml config file and replace the Fake Device with an OpenIGTLinkTracker Device. Therefore, I just use the first Device Tag from http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceOpenIGTLinkTracker.html instead of the Fake Device. The Tracker, which sends the data, should be the standard TrackerServer from OpenIGTLink. Although I was able to connect the TrackerServer to fCal the stylus calibration is not working.

Am I right that "Stylus tip translation 210.003 x 0.035 x 0.066" means the translation from the needle coordinate system to the needle tip in X x Y x Z? This is the result if I start the Fake Stylus calibration.

I am grateful for each hint or config file!
PlusDeviceSet_fCal_Sim_PivotCalibration.xml	1.86 KB

#### 3 Comments
#### By Andras Lasso on 2016-01-12 16:49
How to get stylus calibration result: Perform stylus calibration in fCal and save the configuration. The StylusTipToStylus transform is available in the CoordinateDefinitions section, in an element like this:
~~~~
    <Transform From="StylusTip" To="Stylus"
      Matrix="
        0.999594	0	-0.0284841	-0.305774
        -0.0042307	0.988908	-0.148468	-1.59379
        0.0281681	0.148529	0.988507	10.6115
        0	0	0	1"
       Error="0.287287" Date="082315_112217" />
~~~~
#### By Andras Lasso on 2016-01-12 16:53
See this config file for a sample of using an OpenIGTLink tracker:
https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_BkProFocus_OpenIGTLinkTracker.xml

For a Stylus tool it would be something like this:
~~~~
    <Device
      Id="TrackerDevice"
      Type="OpenIGTLinkTracker"
      MessageType="TRANSFORM"
      ServerAddress="127.0.0.1"
      ServerPort="18944"
      IgtlMessageCrcCheckEnabled="true"
      AcquisitionRate="30"
      LocalTimeOffset="0.0"
      ToolReferenceFrame="Tracker" >
      <DataSources>
        <DataSource Type="Tool" Id="Stylus" />
        <DataSource Type="Tool" Id="Reference" />
      </DataSources>
      <OutputChannels>
        <OutputChannel Id="TrackerStream">
          <DataSource Id="Stylus" />
          <DataSource Id="Reference" />
        </OutputChannel>
      </OutputChannels>
    </Device>
~~~~
#### By Andras Lasso on 2016-01-12 16:56
You can also download 3D Slicer and its SlicerIGT extension for live visualization of tools and performing stylus calibration (good for quick visual verification of the tracking and the calibration result). See more details at http://slicerigt.org/ and more specifically, in the U11 - Pivot calibration tutorial at http://www.slicerigt.org/wp/user-tutorial/ .


## StealthLink Win 32 availability
#### Posted by andrea-GE on 2015-12-18 05:45

Hello,

I read in the download page that a build with StealthLink support could be provided on request,
I would be interested in testing it, what are the requirements needed to make the request?

Thank you in advance for your kind attention and support,

Andrea

#### 1 Comments
#### By Andras Lasso on 2015-12-18 14:47
You need to have a StealthLink license. We can discuss the details in email (lasso@queensu.ca).


## PlusServer: how to send TDATA instead of TRANSFORM message types
#### Posted by sordas on 2015-11-06 16:57

Hello,

My application can receive tracking streams of type TDATA from TrackingDataServer.exe, using STT_TDATA and STP_TDATA for stopping and resuming the transfer. Now I would like to do the same from PlusServer. How can I setup a configuration file for streaming TDATA messages instead of TRANSFORM?

Since I don´t have a tracking system at the moment, I've been using in PlusServer a device of type "FakeTracker" (vtkFakeTracker). I was able to send and receive such data (tracking messages of type TRANSFORM) from PlusServer to Slicer-IGT but now I would like to get them into my aforementioned application.

I thought of using an "OpenIGTLinkTracker" device (vtkOpenIGTLinkTracker) which looks like it is using TDATA.

I could only find PlusLib configuration files examples using "OpenIGTLinkTracker" as a client for receiving data from servers (e.g. BrainLab simulator)

but not for sending data as server ... For instance, is this correct?

~~~~
<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="1"
MaxTimeSpentWithProcessingMs="10"
ListeningPort="18944"
OutputChannelId="TrackingStream" >
<DefaultClientInfo>
<MessageTypes>
<Message Type="TDATA" />
...
~~~~

I know I might be missing something very important here. So any clarification or link for further studying will help a lot

thank you,
sebastian

#### 7 Comments
#### By Andras Lasso on 2015-11-06 22:36
PlusServer currently does not support sending transforms as TDATA. It would not be too much work to add it (probably only vtkPlusIgtlMessageCommon and vtkPlusIgtlMessageFactory classes have to be modified) but currently we don't plan to work on it. However, if you are willing to spend some time with implementing this, we would be happy to help.
#### By Sordas on 2015-11-07 21:03
I would be glad. I will send the first modifications asap for your review
#### By Sordas on 2015-11-08 20:41
Andras, these would be the first changes. We have to think if we want to respond to STT_ and STP_ and how to pack/unpack all tools.
0001-ENH-add-TDATA-message-type.patch	8.72 KB
#### By Andras Lasso on 2015-11-09 15:29
Thank you. It's a good start! A few things to sort out before integrating:

1. Pack all tools into one message - similarly how it is done in vtkPlusIgtlMessageCommon::PackTrackedFrameMessage.

2. When a STT or STP request is received store the information in the PlusIgtlClientInfo& clientInfo:
Store OpenIGTLink device name: it'll be used as device name in the TDATA messages
Store coordinate system name value: it'll be used when constructing the TDATA messages (as "To" transform)
Store a boolean flag for TDATA transmission is started: set it to true on STT, set it to false on STP. If the transmission started flag is false then don't send TDATA to the client.
Store resolution. We'll also store timestamp of the last send TDATA message. When new tracking data is available we compare that time elapsed since the latest sent TDATA and we only send a new TDATA if the time elapsed is at least the resolution value (otherwise we don't send this tracking data to the client).
#### By Sordas on 2015-11-16 08:08
Andras, I found the time to advance a little bit. Please have a look. It´s already working for me (I can receive the TDATA stream in my application). Now we should add the timestamp comparison, decide on the units for the Resolution parameter, complete the unpacking, etc.
As for "storing the coordinate system value" I need to study Plus more.
0001-ENH-can-send-TDATA.patch	11.6 KB
#### By Andras Lasso on 2015-12-01 14:00
Created #1050 to track this. Could you please upload the latest cumulative patch (that contains all the changes needed for the Plus trunk) as an attachment to the ticket?
#### By Sordas on 2015-12-02 13:35
thank you! I was not able to generate a cumulative patch with SmartGit but you should be able to apply the two attached patches one after the other. Please let me know how it goes. I can put time to continue working on this thread on the next 3 days


##  How to do the stylus calibration for puncturing needle
#### Posted by Jason... on 2015-11-30 03:15

Hi,
I have some problems with the stylus calibration for a puncturing needle :

1) how to fix the sensor to the needle ? We need to align the sensor and needle's tip, right? it that means i have to get a custom-make puncturing needle ?
2) the size of the needle is 18G x 350mm. It's very easy to bend while doing the calibration. what should i do with that ?

Any help would be great !
Thanks,
Jason

#### 3 Comments
#### By Andras Lasso on 2015-11-30 10:03
You can find 3D-printable needle clips in the model catalog (http://perk-software.cs.queensu.ca/plus/doc/nightly/modelcatalog/).

Calibration of long needles is not a big issue, as you can be careful enough to not bend the needle during calibration. However, during insertion into tissue long needles may bend so much that tracking at the base will be probably too inaccurate. One solution is to insert a sensor in the needle and track the needle tip (sterile/sterilizable needle kits are available for Ascension - http://www.ultrasonix.com/node/968, and NDI http://www.ndigital.com/medical/products/tools-and-sensors/). If you cannot implement this then you may experiment with fixing the sensor closer to the needle tip, tracking a needle guide, etc.
#### By Jason... on 2015-12-02 09:18
thanks, Andras
another question: what is the right way to fix the sensor to the needle ? It is right that i do as the picture showed in the attachment ? The result i have got is weird.
needle.jpg	1.44 MB
#### By Andras Lasso on 2015-12-02 10:24
You have to attach the sensor to the tracked tool rigidly. Tape will not do.

For example, glue the sensor tip into a small plastic box (the same size as the MarkerHolder_120mm-even_long in the model catalog) and then you can use it with any needle clips (e.g., NeedleClip-Assembly_16-20G, NeedleGrabberFlappy-Assembly_1.0).


## Log limit
#### Posted by ersmistad377977 on 2015-11-23 05:15

Hi

Is it possible to set a limit to how much log data can be stored on disk by Plus?
We are currently having the problem that Plus fills up the entire hard drive on our ultrasound system with log data and thereby slowing the entire system.

Thanks
- Erik Smistad

#### 7 Comments
#### By Adam Rankin on 2015-11-23 09:06
Hi Erik,

Unfortunately there is no mechanism presently for limiting the file log size. If you do not need all of the INFO level information, you could reduce the warning level to 'Warning' or 'Error'.

If this is not an acceptable solution for you, let me know and we can discuss.
#### By Andras Lasso on 2015-11-23 10:22
If the log level is set to DEBUG or TRACE then log file sizes can be large and logging might also have performance impact, so these levels should only be used for debugging. If your files are large because of this then set the log level to INFO.

If the log level is set to INFO then the log file size should be small. If you still get large log files then there might be a problem that triggers warning or error messages. In this case, check the log file content and let us know what messages are in the file so that we can find out why they are logged and how to prevent it.

The number of log files always increase, but normally it's not an issue, because if the files are small (and the available storage space on the device is reasonable) then it is enough to delete the log files once in every few years. Based on our experience, recording of images on the ultrasound system takes magnitudes of more storage space, so instead of spending time with implementing log rotation, I would rather work on a solution for archiving and cleaning up unneeded image recordings. However, standard solutions already exist for cleaning up/archiving both log and image files, such as periodically executing a batch file that deletes all log files; network sharing or ftp for transferring/deleting log and image files, etc., so I'm not sure if a solution inside Plus is necessary.
#### By Ersmistad377977 on 2015-11-25 05:23
Log level is set to INFO.

I tried to investigate what fills up the log, and noticed that if I press the freeze button on our system, the following line is generated several times per second:
112515_111145.960|ERROR|566.351000|SERVER> Failed to get video buffer item UID from time: 543.063186; in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(927) | in PlusServerLauncher(0)

If I press freeze again to unfreeze, the error messages stops after several other errors message such as:
112515_111235.660|ERROR|616.051000|SERVER> Failed to get oldest timestamp: no overlap between tracking and video data; in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(937) | in PlusServerLauncher(0)

and

112515_111235.668|ERROR|616.060000|SERVER> Failed to get tracked frame list from data collector (last recorded timestamp: 608.783971; in ..\..\..\PlusLib\src\PlusServer\vtkPlusOpenIGTLinkServer.cxx(392) | in PlusServerLauncher(0)

If these error messages are generated several times per second I'm sure you can understand that it won't be long before our harddrive is filled up.

Hope we can find a solution to this problem. Is it possible to turn logging off completely?

Btw, we are using Plus 2.1.2.4115 Ultrasonix 6.1
#### By Andras Lasso on 2015-11-25 08:27
We usually freeze in the application, not on the ultrasound machine (the surgeons don't even see the Ultrasonix screen, as it's all draped), but I understand that you use the system differently then (maybe radiologist use the system, who got used to tinkering with the ultrasound system instead of using custom intra-operative interfaces). Anyway, as a short-term workaround, you can disable logging by setting log level to 0. I'm not sure if it can be set on the GUI, but you can set it in the --verbose argument if you start PlusServer from the command line. For a long-term solution, we can add an option to not log errors if images are not acquired because of freeze activated.
#### By Ersmistad377977 on 2015-11-25 09:40
The system will also auto-freeze after a certain amount of time to avoid damage to the probe. Thus, if we leave the system untouched for a while and let the plus server running, the system will go into freeze mode and the rush of error messages start. We will try the short-term workaround for now, but I think this will be problem for other users as well.

Once again, thanks for you help
#### By Andras Lasso on 2015-11-25 09:52
We disable auto-freeze on systems that are in clinical use (these systems are only used for surgeries and after operations they are shut down, so there is no risk of excessive use).
#### By Andras Lasso on 2015-11-25 10:12
Added ticket #1048 to track error logging customization for freeze.


## Calculating Resolution/Distances
#### Posted by jnc74 on 2015-11-23 11:11

Hi,

I am trying to calculate distances between two points in image space on a spine phantom that we have scanned. We need to know the resolution of the images in order to obtain this quantitative information. Where would I be able to obtain this information? We obtain scans in the fCal software and then volume render in 3DSlicer.

Thanks,
Jackie

#### 2 Comments
#### By Andras Lasso on 2015-11-23 11:34
This is a question about using 3D Slicer, so it should be asked on the 3D Slicer users mailing list. Anyway, the volume position, direction, and spacing information is stored in the IJK to RAS matrix. Also, you can measure distances interactively using the ruler tool (http://www.slicer.org/slicerWiki/index.php/Documentation/4.5/Modules/Annotations).
#### By Jnc74 on 2015-11-23 11:42
Alright, thank you for your help.


## Problem in 3D Slicer
#### Posted by jnc74 on 2015-11-05 12:46

Hello,

We are currently running into problems when trying to reconstruct our volumes in 3D slicer. We have the volumes, which can be successfully reconstructed in fCal, but when opened in 3D slicer the scans appear to be blank. I have attached a couple of screenshots showing errors in fCal and what we get in 3D slicer. Hopefully you can help us figure out why we can no longer reconstruct with this program.

Thanks,
Jackie
error1152.png	240 KB
error1153.png	191 KB
error11515.png	224 KB

#### 8 Comments
#### By Andras Lasso on 2015-11-05 13:06
Please attach a sample volume file that does not appear in Slicer as you expect.
#### By Jnc74 on 2015-11-05 13:32
I attached the mha and configuration file. Thanks.
TrackedImageSequence_20151105_121732nov1.mha	260 MB
TrackedImageSequence_20151105_121732nov1_config.xml	10 KB
#### By Jnc74 on 2015-11-10 15:26
If we changed the Ultrasonix depth settings after temporal/spatial calibration but before recording 2D images, will that have an impact on our reconstruction in 3D slicer? Does the calibration have to be performed again if depth is changed?
#### By Andras Lasso on 2015-11-10 15:29
If you use a probe with a built-in GPS then you can change the spatial calibration on the fly (those config files that use ImageToTransducerTransformName, see for example https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_Ultrasonix_L14-5_Ascension3DG_calibrated.xml).

Otherwise you need to use a different calibration after each depth change.
#### By Jnc74 on 2015-11-12 15:59
Hi Andras,

So we went ahead and re-did our temporal and spatial calibrations after changing our depth, focus, and gain settings, just to be safe. We achieved a relatively small error (1.2 mm), and all errors for the remaining calibrations are under 1 mm as well. However, when collecting the scans and reconstructing the volumes in both fCal and 3Dslicer we are encountering a couple problems.

1. When viewing the scans in 3D slicer, we find that some of the scan images are flipped and skewed (see the 'error3' attached). We do not know what would cause these transformations since all our calibrations are within good error values. This corrupted images are definitely affecting our reconstruction.

2. We also are finding that after scanning, the size of our files are getting smaller, and not all scans are being retrieved. Our original scans taken a couple of weeks ao that were effectivew were of size MB-600,000 KB. Now we are down to files of 2,000 KB which does not make sense. I attached error messages found in the fcal program which could explain why this is happening. It is saying "Unable to write entire frame to file".

Additionally, I attached another image of the results we are achieving in volume reconstruction of fCal. We are scanning a 3D spine model, and as seen in the screen-grab, it does not resemble it whatsoever.

Hopefully you can help us fix these problems we are running into. Any help/advice would be great.

Thanks,
Jackie
11_12_error3.png	70.9 KB
11_12_error1.png	115 KB
11_12_error2.png	103 KB
#### By Andras Lasso on 2015-11-12 19:02
(Comment removed)
#### By Andras Lasso on 2015-11-12 23:12
I've checked where the "Unable to write entire frame to file" error is logged and added a mechanism to try to recover from writing error (#1047). Please try the latest trunk version of Plus and see if you still get "Unable to write entire frame to file" errors.

We haven't experienced this "Unable to write entire frame to file" error. Do you have enough disk space on all drives? What operating system do you use?
#### By Jnc74 on 2015-11-23 11:08
Thank you for your help! We ended up deleting files from the drives and it worked.


## Live streaming with Ultrasonix Porta and PLUS
#### Posted by HGueziri on 2015-11-06 09:22

Hi,

We are currently trying get a live stream using PLUS and SonixTouch via Porta.

- SonixTouch with Windows 7 64-bits and Porta 6.1.2 SDK (we also tried 6.0.7)
- We use a C5/2 probe plugged on controller 0
- PLUS 2.2.0 (we also tried 2.3.0) with Ultrasonix 6.1
- USM and PCI verified
- Porta paths verified (work well with our other application)
- Exam is not running

When using PLUS 2.2.0, it seems that PLUS is unable to initialize porta. We get the following messages:

|ERROR|020.111000|SERVER> Initialize: Porta could not be initialized: (unknown); in ..\\..\\..\\PlusLib\\src\\DataCollection\\SonixVideo\\vtkSonixPortaVideoSource.cxx(440) | in PlusServerLauncher(0)
|ERROR|020.112000|SERVER> VideoDevice: Cannot connect to data source, ConnectInternal failed; in ..\\..\\..\\PlusLib\\src\\DataCollection\\vtkPlusDevice.cxx(960) | in PlusServerLauncher(0)
|ERROR|020.113000|SERVER> Unable to connect device: VideoDevice.; in ..\\..\\..\\PlusLib\\src\\DataCollection\\vtkDataCollector.cxx(299) | in PlusServerLauncher(0)
|ERROR|020.114000|SERVER> Datacollector failed to connect to devices; in ..\\..\\..\\..\\PlusLib\\src\\PlusServer\\Testing\\PlusServer.cxx(132) | in PlusServerLauncher(0)
|ERROR|020.136000| Server stopped unexpectedly. Return code: 0| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(333)


When using PLUS 2.3.0, the application crashes with the following log messages:

|INFO|000.028000| Logging at level 3 to file: C:/Users/research/PlusApp-2.3.0.4394-Ultrasonix-6.1-Win32/data/110515_163748_PlusLog.txt| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(84)\par
|INFO|000.035000| Supported devices: - 3dConnexion (ver: Plus-2.3.0) - Ascension3DG (ver: Plus-2.3.0) - AuroraTracker (ver: NDICAPI-3.1) - BrachyTracker (ver: Plus-2.3.0) - CertusTracker (ver: Optotrak API (Win32 DLL Version) Version 3.01.03) - ChRobotics (ver: Plus-2.3.0) - Epiphan (ver: Plus-2.3.0) - FakeTracker (ver: Plus-2.3.0) - GenericSerialDevice (ver: Plus-2.3.0) - ICCapturing (ver: The Imaging Source UDSHL-3.2) - ImageProcessor (ver: Plus-2.3.0) - Microchip (ver: Plus-2.3.0) - NoiseVideo (ver: Plus-2.3.0) - OpenIGTLinkTracker (ver: OpenIGTLink v1.10.10) - OpenIGTLinkVideo (ver: OpenIGTLink v1.10.10) - PhidgetSpatial (ver: Plus-2.3.0) - PolarisTracker (ver: NDICAPI-3.1) - SavedDataSource (ver: Plus-2.3.0) - SonixPortaVideo (ver: UltrasonixSDK-6.1.1) - SonixVideo (ver: UltrasonixSDK-6.1.1) - UsSimulator (ver: Plus-2.3.0) - VFWVideo (ver: Plus-2.3.0) - VirtualBufferedDiscCapture (ver: Plus-2.3.0) - VirtualDiscCapture (ver: Plus-2.3.0) - VirtualMixer (ver: Plus-2.3.0) - VirtualSwitcher (ver: Plus-2.3.0) - VirtualVolumeReconstructor (ver: Plus-2.3.0) | in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(88)\par
|INFO|010.010000| Connect using configuration file: C:\\Users\\research\\PlusApp-2.3.0.4394-Ultrasonix-6.1-Win32\\config\\customImage.xml| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(306)\par
|INFO|010.011000| Server process command line: "C:/Users/research/PlusApp-2.3.0.4394-Ultrasonix-6.1-Win32/bin/PlusServer.exe" --config-file="C:\\Users\\research\\PlusApp-2.3.0.4394-Ultrasonix-6.1-Win32\\config\\customImage.xml" --verbose=4| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(168)\par
|INFO|010.670000| Server process started successfully| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(175)\par
|INFO|016.347000|SERVER> Software version: Plus-2.3.0.4394 - Win32| in tkPlusLogger(188)\par
|INFO|016.347000|SERVER> Logging at level 4 (DEBUG) to file: C:/Users/research/PlusApp-2.3.0.4394-Ultrasonix-6.1-Win32/data/110515_163804_PlusLog.txt| in .\\..\\..\\..\\PlusLib\\src\\PlusServer\\Testing\\PlusServer.cxx(85)\par
|INFO|016.350000|SERVER> Server status: Reading configuration.| in .\\..\\..\\..\\PlusLib\\src\\PlusServer\\Testing\\PlusServer.cxx(113)\par
|INFO|016.351000|SERVER> Selected US image orientation: MF| in .\\..\\..\\PlusLib\\src\\DataCollection\\vtkPlusDataSource.cxx(264)\par
|INFO|016.352000|SERVER> VideoDevice: Local time offset: 0ms| in .\\..\\..\\PlusLib\\src\\DataCollection\\vtkPlusDevice.cxx(868)\par
|INFO|016.354000|SERVER> Server status: Connecting to devices.| in .\\..\\..\\..\\PlusLib\\src\\PlusServer\\Testing\\PlusServer.cxx(130)\par
|WARNING|016.355000|SERVER> SonixPortaVideo Channels attribute is ignored (number of channels is now automatically determined from USM (ultrasound module version) attribute.| in .\\..\\..\\PlusLib\\src\\DataCollection\\SonixVideo\\vtkSonixPortaVideoSource.cxx(714)\par
|ERROR|040.041000| Server process error: Crashed| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(424)\par
|ERROR|040.042000| Server stopped unexpectedly. Return code: -1073741676| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(437)\par
|INFO|040.043000| Disconnect request successful| in ..\\..\\PlusApp\\PlusServerLauncher\\PlusServerLauncherMainWindow.cxx(299)\par


We suspect the CineBufferSize to cause an overflow (??) line 131 in vtkSonixPortaVideoSource.cxx. However, this parameter cannot be changed from the PLUS config file

this->PortaCineSize = 256 * 1024 * 1024; // defaults to 256MB of Cine


Here is our PLUS config file
~~~~
<PlusConfiguration version="2.1">

   <DataCollection StartupDelaySec="1.0" >
      <DeviceSet
	Name="Custom Image"
	Description="Acquires images without positions" />
     
      <Device
	Id="VideoDevice"
	Type="SonixPortaVideo"
	AcquisitionRate="30"
	LocalTimeOffsetSec="0"
	PortaBModeWidth="640"
	PortaBModeHeight="480"
	Depth="120"
	Gain="50"
	Frequency="5000000"
	PortaFirmwarePath="C:/Users/research/Downloads/UltrasonixSDK_6.0.7/porta/fw/"
	PortaSettingPath="C:/Users/research/Downloads/UltrasonixSDK_6.0.7/porta/dat/"
	PortaLicensePath="C:/Users/research/Downloads/UltrasonixSDK_6.0.7/porta/"
	PortaLUTPath="C:/Users/research/Downloads/UltrasonixSDK_6.0.7/porta/dat/map/"
	Channels="64"
	Usm="4"
	Pci="3" >
         <DataSources>
            <DataSource Type="Video" Id="Video" PortName="B" PortUsImageOrientation="MF" BufferSize="64" />
         </DataSources>
         <OutputChannels>
            <OutputChannel Id="VideoStream" VideoDataSourceId="Video"/>
         </OutputChannels>
      </Device>
      
   </DataCollection>


   <PlusOpenIGTLinkServer
	MaxNumberOfIgtlMessagesToSend="1"
	MaxTimeSpentWithProcessingMs="50"
	ListeningPort="18944"
	SendValidTransformsOnly="true"
	OutputChannelId="VideoStream" >
      <DefaultClientInfo>
         <MessageTypes>
            <Message Type="IMAGE" />
         </MessageTypes>
         <ImageNames>
	    <Image Name="Image"/>
	 </ImageNames>
      </DefaultClientInfo>
   </PlusOpenIGTLinkServer>

</PlusConfiguration>
~~~~

Is there any thing we missed ?
Your help will be greatly appreciated.

Thanks in advance

#### 2 Comments
#### By Andras Lasso on 2015-11-06 10:10
Plus nightly version requires at least Porta-6.1.1. In the attached config file the Porta*Path was set to old directories (6.0.7).
Fix these path values and test.
#### By HGueziri on 2015-11-06 11:15
Hi Andras,

Thank you for the quick answer.
It works perfectly with PLUS 2.3.0 and Sonix SDK 6.1.2.


## Using PlusServer to read from an NDI Aurora under Ubuntu linux
#### Posted by albertogomezherrero6904 on 2015-10-19 13:22

Dear all,

I have build the Plus library under ubuntu linux, with the following options enabled in the CMake:

PLUSBUILD_USE_GIT_PROTOCOL
PLUSBUILD_USE_OpenIGTLink
PLUSBUILD_USE_POLARIS

That compiles fine. Now I am trying to use a very simple setup: just one sensor plugged to the first port of the Aurora box. My configuration file is posted below, at the end of the message.

When I run the PlusServer app, it does not seem to work: I get the following output:

./PlusServer --config-file=PlusDeviceSet_Server_NDIAurora.xml --verbose=5
|INFO|000.000548| Software version: Plus-2.1.0.4376
|TRACE|000.000827| vtkDataCollector::ReadConfiguration()|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(61)
|DEBUG|000.000886| StartupDelaySec: 1.000000|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(82)
|TRACE|000.001498| vtkPlusDevice::ReadConfiguration|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(680)
|TRACE|000.031994| vtkPlusDataSource::ReadConfiguration|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDataSource.cxx(264)
|TRACE|000.053701| vtkPlusDevice::SetAcquisitionRate(20)|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(392)
|INFO|000.054123| Device local time offset for EmTracker: 0ms|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(803)
|TRACE|000.054195| vtkDataCollector::GetDevice( aDevice, EmTracker)|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(343)
|DEBUG|000.054246| Couldn't read transform from CoordinateDefinitions - CoordinateDefinitions element not found|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/PlusCommon/vtkTransformRepository.cxx(536)
|DEBUG|000.054276| Initializing data collector... |in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/PlusServer/Testing/PlusServer.cxx(99)
|TRACE|000.054296| vtkDataCollector::Connect()|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(269)
|TRACE|000.054312| vtkPlusDevice::Connect|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(883)
|TRACE|000.054326| vtkDataCollector::SetLoopTimes|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(571)
|DEBUG|000.054342| No saved data source devices were found that use original timestamps, so synchronization of loop times is not performed|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(606)
|TRACE|000.054359| vtkDataCollector::Start()|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(228)
|TRACE|000.054375| vtkPlusDevice::StartRecording|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(929)
|ERROR|010.307652| Measurement System failed to reset on break|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(368)
|ERROR|010.307906| Cannot start recording, internal StartRecording failed|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(948)
|ERROR|010.307964| Failed to start data acquisition for device EmTracker.|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(240)
|DEBUG|010.308031| vtkDataCollector::Start -- wait 1.000000 sec for buffer init...|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(246)
|ERROR|011.308344| Datacollector failed to start!|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/PlusServer/Testing/PlusServer.cxx(108)

It seems that the problem is at |DEBUG|000.054246| Couldn't read transform from CoordinateDefinitions - CoordinateDefinitions element not found|
Can anyone give me some advice on how to troubleshoot this?

Thanks!

Alberto

/---------------------------------------- Below the config file -----------------------------------------------------------
~~~~
<PlusConfiguration version="2.3">
<DataCollection StartupDelaySec="1.0">
<DeviceSet Name="PlusServer: NDI Aurora tracker"
Description="Broadcasting tool tracking data through OpenIGTLink
Tracking a single EM sensor." />
<Device
Id="EmTracker"
Type="AuroraTracker"
SerialPort="1"
BaudRate="115200"
AcquisitionRate="20"
LocalTimeOffsetSec="0.0"
ToolReferenceFrame="EmTracker" >
<DataSources>
<DataSource Type="Tool" Id="Transducer" PortName="0" BufferSize="150" AveragedItemsForFiltering="0"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="EmTrackerStream">
<DataSource Id="Transducer" />
</OutputChannel>
</OutputChannels>
</Device>
</DataCollection>

<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="1"
MaxTimeSpentWithProcessingMs="50"
ListeningPort="62345"
SendValidTransformsOnly="true"
OutputChannelId="EmTrackerStream" >
<DefaultClientInfo>
<MessageTypes>
<Message Type="TRANSFORM" />
</MessageTypes>
<TransformNames>
<Transform Name="SensorToEmTracker" />
</TransformNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>
</PlusConfiguration>
~~~~

#### 9 Comments
#### By Andras Lasso on 2015-10-19 13:27
In general, don't worry about DEBUG messages. The issue is this ERROR message:

|ERROR|010.307652| Measurement System failed to reset on break|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(368)

Most probably the serial port number or baud rate setting is incorrect.
#### By Albertogomezherrero6904 on 2015-10-19 13:50
Thanks for the quick answer!

You where right, switching to SerialPort 3 seems to work better. Now I can launch it but I get the following:

./PlusServer --config-file=/home/ag09_local/Copy/work/iFIND/tracking/Plus/PlusDeviceSet_Server_NDIAurora.xml
|ERROR|003.544063| Unable to initialize Tool-in-Port|in /home/ag09_local/workspace/PlusBuild/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(806)
Press Ctrl-C to quit:


I have launched also the TrackingTest app, with similar results, and in the viewport a message in red saying "TransducerToEmTracker: missing or out of view".

My amended config file is at the bottom.

Many thanks!
~~~~
<PlusConfiguration version="2.1">
<DataCollection StartupDelaySec="1.0">
<DeviceSet Name="PlusServer: NDI Aurora tracker"
Description="Broadcasting tool tracking data through OpenIGTLink
Tracking a single EM sensor." />
<Device
Id="EmTracker"
Type="AuroraTracker"
SerialPort="3"
BaudRate="115200"
AcquisitionRate="20"
LocalTimeOffsetSec="0.0"
ToolReferenceFrame="EmTracker" >
<DataSources>
<DataSource Type="Tool"
Id="Transducer"
PortName="0"
BufferSize="150"
AveragedItemsForFiltering="20"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="EmTrackerStream">
<DataSource Id="Transducer" />
</OutputChannel>
</OutputChannels>
</Device>
</DataCollection>

<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="2"
MaxTimeSpentWithProcessingMs="50"
ListeningPort="62345"
SendValidTransformsOnly="true"
OutputChannelId="EmTrackerStream" >
<DefaultClientInfo>
<MessageTypes>
<Message Type="TRANSFORM" />
</MessageTypes>
<TransformNames>
<Transform Name="TransducerToEmTracker" />
</TransformNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>
</PlusConfiguration>
~~~~
#### By Andras Lasso on 2015-10-19 14:01
Could you please test with the latest trunk version of Plus?
Does the sensor work with any other test or example applications (e.g., those provided by NDI)? Does the sensor work if you plug the tracker into a Windows computer and use it with a pre-compiled Plus release?
#### By Albertogomezherrero6904 on 2015-10-19 14:37
Hi,

Thanks for your help .


I have tried with the trunk version, and it still fails. This time I get:

./PlusServer --config-file=/home/ag09_local/Copy/work/iFIND/tracking/Plus/PlusDeviceSet_Server_NDIAurora.xml
Software version: Plus-2.3.0.4376 - Linux
Logging at level 3 (INFO) to file: /home/ag09_local/workspace/PlusBuildTrunk/release/bin/Output/101915_193403_PlusLog.txt
EmTracker: Local time offset: 0ms
|ERROR|009.716414| Unable to initialize Tool-in-Port| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(583)
|ERROR|009.751418| Failed to enable NDI tool TransducerToEmTracker| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(692)
|ERROR|009.751452| Failed to enable tool ports| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/DataCollection/PolarisTracking/vtkNDITracker.cxx(309)
|ERROR|009.751469| EmTracker: Cannot connect to data source, ConnectInternal failed| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/DataCollection/vtkPlusDevice.cxx(959)
|ERROR|009.751484| Unable to connect device: EmTracker.| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/DataCollection/vtkDataCollector.cxx(306)
|ERROR|009.751512| Datacollector failed to connect to devices| in /home/ag09_local/workspace/PlusBuildTrunk/release/PlusLib/src/PlusServer/Testing/PlusServer.cxx(132)

The sensors work with NDI software in the example applications. I will try to get hands on a windows computer, but for us the point of using Plus is that NDI does not provide linux software, which is what we would like to use.

Thanks!
#### By Andras Lasso on 2015-10-19 14:50
The problem is the same as before (unable to initialize port), which seems to be a tracker/sensor issue. Maybe you could try to turn off/on the system control unit, try with another sensor, different sockets, plugging in sensors into all sockets, use different port number, etc.
#### By Albertogomezherrero6904 on 2015-10-21 05:33
Hi Andreas,

I think I solved it. As a matter of fact, we were using a custom rom for our sensor, so using the code provided in this other thread (https://www.assembla.com/spaces/plus/messages/5255553#comment_5259023) made it work. Do you know if that fix will make it to the next release, or if there is currently a better way to use custom ROM files?

Thanks!
#### By Andras Lasso on 2015-10-21 12:38
The fix is already included in the nightly version of Plus (with some minor changes that should not affect functionality - but of course errors might have happened). Could you please test if a recent nightly snapshot works as expected (http://perk-software.cs.queensu.ca/plus/packages/nightly/)?
#### By Albertogomezherrero6904 on 2015-10-29 12:02
Hi Andreas,

sorry that snapshot seems to take me to just the executables for Windows. Is the fix included in the nightly sources (which I believe are in https://www.assembla.com/spaces/plus/subversion/source/HEAD/trunk)
#### By Andras Lasso on 2015-10-29 12:20
Yes, fixed in the trunk (that's what the nightly versions are built from).


## SonixPorta and 4DC7 Probe Acquisition Problem
#### Posted by andrea-GE on 2015-10-29 05:46

Hello, I'm currently working on a SonixTouch with a 4DC7 probe, under UltraSonix 6.1.1 SDK.

I am building a custom version of PLUS, with some changes on the SonixPorta data collection, in order to manually control the motor when needed for my application using PLUS Server and some custom vtkCommand.

I started from the version in the PLUS 2.2 release, modifying it for my needs, and I just recently looked at the trunk updated version. While I already incroporated most of the changes related to geometry of the image acquired, I still rely on internal counters to manage cw/ccw sweep movement and motor step.
One of the most interesting changes, that I'd like to integrate in my version, is the one related to the usage of the header of the PORTA_IMG_CALLBACK.

It appears that using my version of porta (6.1.1) the int header returned by this function is always set to 0, breaking the automatic computation of motor step and direction of sweep movement. Looking at propello and porta api, it seems that the header of the display callback is never used there, (while they use the one coming from the RAW data), so I couldn't get help from their approach.

Do you have any suggestion in fixing this issue? Is 6-1-1 the correct version to test it?

Thank you in advance,

Andrea

#### 3 Comments
#### By Andras Lasso on 2015-10-29 10:28
After I implemented the new angle computation method it turned out that some probes. Such as the 4DC7 does not have some sensors and so the header is empty. Using the header is much better for probes such as the 4DL, but we would need to add a method that works for 4DC and similar ones. We don't have a 4DC probe at the moment, so we cannot work on adding back support for that, but if you can implement it then we would be happy to test that there is no regression and integrate ot into Plus.
#### By Andrea-GE on 2015-10-29 10:54
Ok I see, thank you very much for you help.
I'll work on that, I'm experiencing misalignment between cw and ccw volume acquisition right now, and I am trying to find a fix on that (Did you experience something similar with the past version of the code?). As soon as I get good results I'll share my version

Andrea
#### By Andras Lasso on 2015-10-29 11:57
Yes, I've experienced some fixed offset or drift with the old method, too. Maybe due to using a different SDK version or probe type (the code was developed for an older SDK version and 4DC probe) or the method was just not robust enough.


## Building Plus on Ubuntu 14.04 LTS
#### Posted by Siavash Khallaghi on 2015-10-20 11:32

Hello,

I am trying to build Plus on Ubuntu. I have looked at the build instructions and I am having problems with building Qt.

I don't quite understand this line: ./configure -debug-and-release -nomake demos -nomake examples < -prefix /some/qt-install-dir >

what does < -prefix /some/qt-install-dir > mean? I have tried running:

./configure -debug-and-release -nomake demos -nomake examples /opt/Qt5.5/

and

./configure -debug-and-release -nomake demos -nomake examples opt/Qt5.5/

But I get the following error: Unknown part demos passed to -nomake.

Best,

Siavash

#### 2 Comments
#### By Andras Lasso on 2015-10-20 15:45
It's a standard qt build option. https://forum.qt.io/topic/12887/qt4-8-prefix-and-relocatable-build/3
#### By Siavash Khallaghi on 2015-10-26 20:59
5.5.x (5.5.0 and 5.5.1 in my case) is really difficult to build on Ubuntu. The common configurations do not support a static build since the make process terminates with errors. As a result, Qt5core static libraries are not generated.

In a twist of fate, I am no longer involved in that project, but should I find a solution, I will let you know.


## Scripts for real-time receiving of tracked 2D images in Matlab through OpenIGTLink
#### Posted by goby.dll173884 on 2015-10-26 06:27

Dear All,
is it possible to receive in Matlab IMAGE messages from PLUS server on-line during the acquisition?

As far as I understand, I think it would be possible to start from igtlReceiveTransform.m script and modify it to receive openIGTlink IMAGE messages, is it right?

Thanks for your support

Diego

#### 1 Comments
#### By Andras Lasso on 2015-10-26 16:33
This is correct. See more information at https://www.assembla.com/spaces/plus/messages/5310933#comment_5339853


## Problem with Interson USB probe image acquisition (model AB 3.5)
#### Posted by goby.dll173884 on 2015-05-14 07:12

Dear Plus staff,
I'm starting working with an Interson USB AB3.5 probe (light blue and white abdominal model) on Windows 7 32bit, and I've tried to use the following nightly build packages:
- PlusApp-2.1.2.4134-Interson-Win32.exe
- PlusApp-2.1.2.4136-Interson-Win32.exe
In both cases, I think the probe is correctly detected (with name OB 3.5 MHz?) but I have the following errors (see also the attached log file) when I try to run the standard "PlusDeviceSet_Server_IntersonVideoCapture.xml" from fCal.exe:
|WARNING|015.814000| VideoDevice-Video: Frame format and buffer frame format does not match (expected frame size: 800x512x1  received: 800x512x-2)!| in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(189)
|ERROR|015.831000| vtkPlusBuffer: Unable to add frame to video buffer - frame format doesn't match!| in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(288)
|ERROR|015.839000| Error adding item to video source Video| in ..\..\..\PlusLib\src\DataCollection\Interson\vtkIntersonVideoSource.cxx(589)
|ERROR|015.955000| VideoDevice-Video: Invalid frame size requested: 800, 512, -2| in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(575)
Frame size: 800x512, pixel type: unsigned char, probe sample frequency (Hz): 10, probe name: OB 3.5 MHz, display zoom: 1, probe depth scale (mm/sample):0.308, buffer image orientation: MFA


I have updated the Seemore software from version 1.0.6 to 2.0.3, but the problem still remain. I've also tried to use the configuration file with acquisition parameters obtained from here without any changes.

I've checked in the SVN repository the file /trunk/PlusLib/src/DataCollection/Interson/vtkIntersonVideoSource.cxx
and it looks to me that there is a problem in the method vtkIntersonVideoSource::InternalUpdate(), where the variable int frameSizeInPx[2] (line 552) should have dimension 3. I think this is the cause of other error s repoterted in the log file (starting from the vtkIntersonVideoSource.cxx(589)). is it right?

Could you help me with this problem? Thanks in advance for your support!

Diego

#### 25 Comments
#### By Andras Lasso on 2015-05-14 10:59
Nice catch! I've committed a fix (rev 4137). You can update your working copy and rebuild or wait for tomorrow's snapshot.
Thanks for reporting the error.
#### By Goby.Dll173884 on 2015-05-22 09:41
Thanks a lot!
Now the probe is correctly detected and I'm able to acquire image inside fCal.

Unfortunately, I have some problems in finding the correct setting for acquisition parameters, Do you have any suggestion?

I'm attaching two images if a water bath obtained with the probe kept in fixed position.
I tryed different parameter settings in the Plus configuration file, but I'm not able to obtain the same image appearance as in Interson SeeMore software.
plus.png	218 KB
interson.png	368 KB
#### By Andras Lasso on 2015-05-22 11:00
I think the image in Plus looks much nicer. In the Interson screenshot the image is too bright and lots of details are lost because the saturation.

Anyway, if you prefer a brighter image then change GainPercent , Intensity, and Contrast parameters as described here http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceInterson.html
#### By Goby.Dll173884 on 2015-05-25 10:39
Thanks a lot! I spent some time in tuning the acquisition parameters and now the image quality is very good (probably better than in original Interson software)!

Now I have a problem in configuring the Claron Micron Tracker (model H60) together with Interson Probe.

When I try to connect to the tracker (for example by loading PlusDeviceSet_Server_MicronTracker.xml inside fCal) I receive these error messages
|ERROR|007.115000| MicronTracker:  Failed to attach cameras using calibration data at: C:\Program Files\Claron Technology\MicronTracker/CalibrationFiles in ..\..\..\..\PlusLib\src\Utilities\MicronTrackerInterface\Cameras.cpp(191)| in ..\..\..\PlusLib\src\DataCollection\MicronTracking\vtkMicronTracker.cxx(451)
|ERROR|007.132000| MicronTracker:  MicronTracker error: -1 (generic) in ..\..\..\..\PlusLib\src\Utilities\MicronTrackerInterface\MicronTrackerInterface.cpp(1319)| in ..\..\..\PlusLib\src\DataCollection\MicronTracking\vtkMicronTracker.cxx(451)
|ERROR|007.146000| Error in initializing Micron Tracker: setup cameras failed. Check the camera connections and INI and Markers file locations.| in ..\..\..\PlusLib\src\DataCollection\MicronTracking\vtkMicronTracker.cxx(386)
|ERROR|007.158000| TrackerDevice: Cannot connect to data source, ConnectInternal failed| in ..\..\..\PlusLib\src\DataCollection\vtkPlusDevice.cxx(960)
|ERROR|007.166000| Unable to connect device: TrackerDevice.| in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(299)
|ERROR|007.173000| Unable to start collecting data!| in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(194)

I have this problem in Interson releases 4151 and 4136.
The same hardware setup is working perfectly when used in the standard releases PlusApp-2.1.2.4151-Win32 and older PlusApp-2.1.2.3381-Win32.

Any idea on how to solve this issue?
#### By Andras Lasso on 2015-05-25 11:04
Please run PlusVersion and check the reported Microntracker SDK version for both packages.
#### By Goby.Dll173884 on 2015-05-25 17:10
Working releases:
PlusApp-2.1.2.3381-Win32 --> MTC-3.6.5.4
PlusApp-2.1.2.4151-Win32 --> MTC-3.6.5.4

Not working releases:
PlusApp-2.1.2.4151-Interson-Win32 --> MTC-3.7.6.8
PlusApp-2.1.2.4143-Interson-Win32 --> MTC-3.7.6.8

Probably you found the problem... is there any way to downgrade the MTC library version in the interson package?
#### By Andras Lasso on 2015-05-25 17:12
Would you be able to upgrade your system to 3.7?
#### By Goby.Dll173884 on 2015-05-26 09:29
I'm not sure... :-|

I've installed the last MTC release (MTC-3.7.6.8) and my H60 model is not recognized from any Claron demos.

I wrote to Claron support to ask if the last release interrupted the support for older model, since the release documentation is not clear about that.

In the worst case that my H60 is not supported from MTC-3.7.6.8, is there any (simple) solution to this problem?

Diego
#### By Andras Lasso on 2015-05-26 09:37
You have to install new drivers as well. Ask Claron support if your hardware is compatible with 3.7. We'll decide on the best way to solve this once we know the answer.
#### By Goby.Dll173884 on 2015-05-26 17:35
I received the response from Claron technical support, and unfortunately my H60 model is not supported in release 3.7.

MTC-3.7.6.8 release only supports Hx40, Hx60, Sx60 and H3-60 models

The last release that supports my tracking system is MTC-3.6.5.4 (only under 32bit OS).
No future releases of the MTC sdk will support older models.

I think this information could be useful to all members of the plus community working with Claron tracking systems.
#### By Andras Lasso on 2015-05-26 18:05
OK, then I'll create a MTC-3.6 release with Interson support
#### By Andras Lasso on 2015-05-26 21:20
A release with Interson and MTC-3.6 should appear by tomorrow morning in the nightly download section. Let me know if it works.
#### By Goby.Dll173884 on 2015-05-31 11:42
Dear Andras,
I can not find the compiled release with MTC 3.6 support...
I have downloaded the PlusApp-2.1.2.4166-Interson-Win32.exe but it is compiled with MTC 3.7 support...

Could you give me a link?
Thanks
Diego
#### By Andras Lasso on 2015-06-01 08:22
Sorry, there was a build configuration error. Now the release is available on the download page (http://perk-software.cs.queensu.ca/plus/packages/nightly/PlusApp-2.1.2.4166-Interson-MTC-3.6-Win32.exe).
#### By Goby.Dll173884 on 2015-06-08 10:42
Thanks a lot Andras,
devices are working correctly now!

Today I was able to perform a geometrical calibration with Interson Probe and Claron H60 tracker.
Diego
#### By Andras Lasso on 2015-06-08 17:34
Great! Thanks for the update.
#### By Goby.Dll173884 on 2015-06-10 09:06
I have a problem when streaming the data with Plus Server, after few seconds the server stop working with the following message:
|INFO|037.415000|SERVER> OpenIGTLink broadcasting started. No data was available between 0-17.8843sec, therefore no data were broadcasted during this time period. | in PlusServerLauncher(0)
|WARNING|037.416000|SERVER> Skipped transformation matrix - Invalid transform in the transform repository (Image to Tracker); in ..\..\..\PlusLib\src\PlusOpenIGTLink\vtkPlusIgtlMessageCommon.cxx(60) | in PlusServerLauncher(0)

I'm attaching the Log File of the Plus Server Launcher.
logFile.txt	236 KB
#### By Andras Lasso on 2015-06-10 09:12
Probably the marker is out of view. Please attach the config file.
#### By Goby.Dll173884 on 2015-06-10 09:24
Attached the configuration file.

Probably you are right about the marker visibility, but I need to keep the connection active even in this case.
Should I need to change the connection timeout in the client? Is there any parameter setting that I could change in the Plus server config?
PlusDeviceSet_Server_IntersonVideoCapture_ClaronTracking_FCAL_20150610_115747.xml	10.2 KB
#### By Andras Lasso on 2015-06-10 09:34
Set SendValidTransformsOnly="FALSE" (see details in http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationPlusServer.html) to get transforms even if the transforms are invalid.
#### By Andras Lasso on 2015-06-10 09:40
Probably SendValidTransformsOnly only applies to TRANSFORM messages. If you want to send image regardless of the image position is known or not, send the Image in the Image coordinate system (<Image Name="Image" EmbeddedTransformToFrame="Image"/>) and send the ImageToTracker or ImageToReference transform in separate TRANSFORM message.
#### By Goby.Dll173884 on 2015-06-10 10:20
As usual you are right! :-)

The solution of sending separate image and transform is working correctly, but the ImateToTracker Transform looks like have a scaling coefficient embedde thath changes the dimension of the associated 3D object. In fact the corresponding 3D object looks really small [see attached snapshot2], compared to the original solution (<Image Name="Image" EmbeddedTransformToFrame="Tracker"/>) [see snapshot1].
snapsho2t.png	33 KB
snapshot1.png	40.3 KB
#### By Andras Lasso on 2015-06-10 10:37
The unit of Image coordinate system is pixels (see http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CommonCoordinateSystems.html).
If you send the image in the Probe coordinate system then you'll have the units in mm.
#### By Goby.Dll173884 on 2015-10-26 06:52
Dear PLUS team,
unfortunately our Claron MicronTracker Model H60 stopped working and it is not repairable.

Since probably we are the only ones that use the build PlusApp-2.3.0.4377-Interson-MTC-3.6-Win32.exe
I think you could stop supporting this build and probably MTC 3.6 in general.

Thanks for the fantastic support!
#### By Andras Lasso on 2015-10-26 16:31
Thank you for the information!


## Problem with connecting to OpenIGTLink
#### Posted by maxmahh on 2015-10-19 12:33

Hello all,

I'm trying to calibrate a bunch of devices using some old/non-standard tracking and frame-grabbing hardware, and Plus framework seemed to be perfect for this, however I'm having troubles configuring it.

I've written a wrapper for our old Atracsys EasyTrack 500 tracking device to produce OpenIGTLink-based servers. The wrapper generates a separate server/port for each marker, and I am able to connect to both of my markers (on different ports) with 3D slicer without problems.

Ultimately I want to calibrate an ultrasound probe, but I am already stuck at the stylus calibration stage. fCal seems to have issues connecting to my servers (or rather I have troubles writing a correct config. I took the PlusDeviceSet_fCal_Sim_PivotCalibration.xml as an example and modified it).

I'm attaching the logs and screenshots. Any help is appreciated!

Thanks and regards,
Maxim
101915_175206_PlusLog.txt	182 KB
101915_173957_PlusLog.txt	412 KB
3D_Slicer_window.png	81.7 KB
fCal_window.png	27.6 KB

#### 6 Comments
#### By Andras Lasso on 2015-10-19 12:56
From the log it seems that the sender does not set correctly the timestamp of the OpenIGTLink message. Either fix the timestamping issue in your server (and synchronize the clock, if it runs on a different computer) or set UseReceivedTimestamps="FALSE" for the OpenIGTLinkTracker devices in the config file (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceOpenIGTLinkTracker.html).
#### By Maxmahh on 2015-10-20 04:45
Hi Andreas, thank you for your reply. I was a bit puzzled with the time stamp error, actually. OpenIGTLink allows to set time in a format "SetTime(igtlUint32 second, igtlUint32 nanosecond)", but what are those seconds should correspond to, from the PLUS point of view? My time stamp is a time elapsed since my OpenIGTLink server started, and all time stamps of my OpenIGTLink proxies are synchronized, but this is apparently not what PLUS expects. Should it be time of the day, unix time or something else?
#### By Maxmahh on 2015-10-20 05:59
ps: I've tried the UseReceivedTimestamps="false" option, and eventually it worked (I had another issue with how the name of the tool was given: there was an extra end of the line character in the name that I set in OpenIGTLink, which confused PLUS).

I would, however, still very much like to know how to set time stamp in OpenIGTLink correctly, as the correct time stamp will be more important when I'll add a frame grabber to the setup.
#### By Andras Lasso on 2015-10-20 16:45
If you use the received timestamps then the timestamping should be mostly OK (it uses the time of receiving the package and not the time of acquiring the data; the only issue if there is variable time delay). If you use the OpenIGTLink SDK then the timestamp should be generated correctly automatically. If you reimplemented the OpenIGTLink message sending then have a look at the implementation (https://github.com/openigtlink/OpenIGTLink/blob/master/Source/igtlTimeStamp.cxx) or the specification (http://openigtlink.org/protocols/v2_timestamp.html).
#### By Maxmahh on 2015-10-21 04:30
According to the links you provided, I should have used unix time instead of the program run time. I've fixed my timings accordingly, and now PLUS doesn't spill the errors. I was able to calibrate my stylus and the fCal 2.0 phantom. Temporal and probe calibrations are on the way.

Thanks a lot Andreas!
#### By Andras Lasso on 2015-10-21 12:35
Great, thanks for the update!


## 2D Curvilinear Probe
#### Posted by jnc74 on 2015-10-16 12:38

Hi Andras,

I am looking to use a different probe, a 2D curvilinear probe, to obtain calibration results. What needs to change for the fCal software in order to go about using this different probe?

Thanks,
Jackie

#### 3 Comments
#### By Andras Lasso on 2015-10-16 13:03
There is no difference between linear and curvilinear probe calibration.
#### By Jnc74 on 2015-10-16 13:38
Great. If I already have spatial calibrations results saved with a different probe, can I still use these? Or must the new probe I am using have its own temporal and spatial calibration, in order to obtain correct volume reconstruction results?
#### By Andras Lasso on 2015-10-16 13:51
You have to re-do the calibration for the new probe. For volume reconstruction you can also define a clipping fan (in addition to a clipping rectangle).


## Plus Build error with Qt 5.5.0, Windows Server ESERV0, Visual Studio 2013 64-bit Ultimate
#### Posted by Siavash Khallaghi on 2015-10-15 17:59

Hello,

I am trying to build Plus with Qt 5.5.0, Windows Server ESERV0, Visual Studio 2013 64-bit Ultimate, with the OpenIGTLinkFlag disabled. However, we get the errors related to including OpenIGTLink headers even though OpenIGTLink is disabled. Please see the dashboard:

http://crunch.cs.queensu.ca/CDash/viewBuildError.php?buildid=41198

I have attached the CMakeCache as well, in case it helps.

Thank you,

Siavash
CMakeCache.txt	22.5 KB

#### 2 Comments
#### By Siavash Khallaghi on 2015-10-15 20:05
I can reproduce the same problem on a different PC as well. Please see the dashboard:

http://crunch.cs.queensu.ca/CDash/viewBuildError.php?buildid=41199
CMakeCache.txt	25.1 KB
#### By Andras Lasso on 2015-10-15 20:11
Thanks for reporting this. PlusServerLauncher and TrackingDataServer applications require OpenIGTLink. I'll change the makefiles to not build these applications if OpenIGTLink is disabled. You can track progress in #1027.


## Getting images from Ultrasonix motorized probes
#### Posted by Andras Lasso on 2015-09-04 11:21

What information can be extracted from the "header" of data?
Post by benxkang » Wed Aug 26, 2015 11:21 am

As shown in Propello demo, the last argument returned to a user-defined PORTA_DATA_CALLBACK function is named "header". Also shown in the Propello is how to get from the header some extra information for a 3D/4D probe.

My question is that, what information could be obtained from the "header" (whose data type is int)? Is there a complete list (e.g., defined in a .h file or .xml) that defines all the information contained in the "header"?

Thanks!
Ben

#### 52 Comments
#### By Andras Lasso on 2015-09-04 11:21
Re: What information can be extracted from the "header" of d
Post by lasso » Tue Sep 01, 2015 4:12 pm

The Propello example is not fully correct (no bitshift is applied to the motor step count), but you can find image header parsing here:
https://www.assembla.com/spaces/plus/su ... .cxx#ln268

and motor angle computation here:
https://www.assembla.com/spaces/plus/su ... .cxx#ln331

The Plus toolkit (www.plustoolkit.org) has a Porta interface that supports real-time volume reconstruction and streaming through OpenIGTLink. If you have an OpenIGTLink interface in your application then everything is ready, no programming is needed. No calibration is needed either, as Plus constructs all the necessary transformation matrices from the probe descriptor, image header, and scan converter parameters. See a short demo video here: https://youtu.be/KTz0nwAmeMo

You can use Plus as is (recommended), or just copy-paste what you need into your own applicaiton. We don't require anything in return but of course citations, contributing back fixes, etc. are very appreciated.

Andras
#### By Andras Lasso on 2015-09-04 11:22
Re: What information can be extracted from the "header" of d
Post by benxkang » Wed Sep 02, 2015 1:12 pm

Hi Andras,

Thanks a lot for your valuable reply! Could you kindly tell me step-by-step how to set up Plus and 3D Slicer as demonstrated in the Youtube video? Or is there an online document or tutorial I can follow? I would like to try Plus as you recommended.

I could definitely contribute back citations, bug reports, and if possible fixes.

Best,
Ben


Re: What information can be extracted from the "header" of d
Post by lasso » Wed Sep 02, 2015 1:21 pm

Here are the step-by-step instructions:
Download Porta sample config file from here: https://www.assembla.com/spaces/plus/su ... brated.xml
Update ...Path attributes in the XML config file
Download and install the latest Plus development snapshot from https://www.assembla.com/spaces/plus/wiki/Downloads corresponding to your Ultrasonix SDK version
Run PlusServer with the config file that you edited and configure 3D Slicer as described here: http://perk-software.cs.queensu.ca/plus ... licer.html (Show live images in 3D Slicer)
To get the volumes, install SlicerIGT extension in Slicer from the extension manager, run the PlusRemote module, acquire a scout scan of a complete sweep, click 'Start live reconstruction' to start receiving the volumes

Let me know if anything is not clear.
#### By Andras Lasso on 2015-09-04 11:22
Re: What information can be extracted from the "header" of d
Post by benxkang » Fri Sep 04, 2015 10:16 am

Hi Lesso,

Thanks a lot for the instruction. However, meet some difficulties when following it.
I do not know to do "Update ...Path attributes in the XML config file". Could you give me an example?
After launched PlusServer, I did not see an item corresponding to "Ultrasonix_4DL14-5_Porta_calibrated" in the list of "Device Sets". Could be this due to not modifying the XML config file?
I had a difficulty in find out "Image_Reference" in 3D Slicer (nightly build version 4.4.0-20150-09-02).

Looking forwards to your kind reply!

Best,
Ben
#### By Andras Lasso on 2015-09-04 11:30
I've added the 3D probe config file to the package now, which makes things simpler.

Download and install the latest Plus package (PlusApp-2.3.0.4338-...) and run PlusServer.
Select the "PlusServer: Ultrasonix US (4DL14-5/38)..." configuration
Click on the pencil icon on the left side of the configuration selector
Change these paths to the correct values on your system:

PortaFirmwarePath="D:/devel/PLTools/Ultrasonix/sdk-6.1.1/porta/fw/"
PortaSettingPath="D:/devel/PLTools/Ultrasonix/sdk-6.1.1/porta/dat/"
PortaLicensePath="D:/Ultrasonix Settings/"
PortaLUTPath="D:/Ultrasonix Settings/LUTS/"


Typically the first two are in the Ultrasonix SDK directory that you installed on your system.
The second two are your settings directory on your system. Probably D:/Ultrasonix Settings/ or C:/Ultrasonix Settings/ (whichever directory exists on your system).

If you successfully start PlusServer and establish OpenIGTLink connection with Slicer then the ultrasound image (in our case Image_Ras instead of Image_Reference, as we don't use a reference sensor) will appear in Slicer
#### By Ben.Xkang on 2015-09-04 12:11
Hi Andrass,

I did not see an item like "PlusServer: Ultrasonix US (4DL14-5/38)..." in the device set list, although "PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml" is in the config folder. The item I found most relevant is "PlusDeviceSet_Server_Ultrasonix_L14-5_Ascension3DG_calibrated.xml", which I doubt it is correct.

Best,
Ben
DeviceSetDidNotShowUp.png	80.4 KB
#### By Andras Lasso on 2015-09-04 12:15
Download and install the latest Plus package (PlusApp-2.3.0.4338-...) and follow the other instructions that I described above
#### By Ben.Xkang on 2015-09-04 13:59
Error in Plus Server Launcher. Any suggestions? Thanks!

|INFO|000.022000| Software version: Plus-2.3.0.4338 - Win32| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(57)
|INFO|000.022000| Logging at level 3 to file: D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/data/090415_135904_PlusLog.txt| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(58)
|INFO|000.028000| Supported devices: - 3dConnexion (ver: Plus-2.3.0) - Ascension3DG (ver: Plus-2.3.0) - AuroraTracker (ver: NDICAPI-3.1) - BrachyTracker (ver: Plus-2.3.0) - CertusTracker (ver: Optotrak API (Win32 DLL Version) Version 3.01.03) - ChRobotics (ver: Plus-2.3.0) - Epiphan (ver: Plus-2.3.0) - FakeTracker (ver: Plus-2.3.0) - GenericSerialDevice (ver: Plus-2.3.0) - ICCapturing (ver: The Imaging Source UDSHL-3.2) - ImageProcessor (ver: Plus-2.3.0) - Microchip (ver: Plus-2.3.0) - NoiseVideo (ver: Plus-2.3.0) - OpenIGTLinkTracker (ver: OpenIGTLink v1.10.10) - OpenIGTLinkVideo (ver: OpenIGTLink v1.10.10) - PhidgetSpatial (ver: Plus-2.3.0) - PolarisTracker (ver: NDICAPI-3.1) - SavedDataSource (ver: Plus-2.3.0) - SonixPortaVideo (ver: UltrasonixSDK-6.1.0) - SonixVideo (ver: UltrasonixSDK-6.1.0) - UsSimulator (ver: Plus-2.3.0) - VFWVideo (ver: Plus-2.3.0) - VirtualBufferedDiscCapture (ver: Plus-2.3.0) - VirtualDiscCapture (ver: Plus-2.3.0) - VirtualMixer (ver: Plus-2.3.0) - VirtualSwitcher (ver: Plus-2.3.0) - VirtualVolumeReconstructor (ver: Plus-2.3.0) | in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(62)
|INFO|000.036000| Server host name: PC-ae9a22| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(82)
|INFO|000.046000| Server IP addresses: 199.59.210.103, 127.0.0.1| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(103)
|INFO|004.204000| Connect using configuration file: D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(215)
|INFO|004.205000| Server process command line: "D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/bin/PlusServer.exe" --config-file="D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml" --verbose=3| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(135)
|INFO|004.864000| Server process started successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(142)
|INFO|010.216000|SERVER> Software version: Plus-2.3.0.4338 - Win32 | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> Logging at level 3 (INFO) to file: D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/data/090415_135915_PlusLog.txt | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> Selected US image orientation: UF | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> VideoDevice: Local time offset: 0ms | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> Initialize: Porta could not be initialized: (unknown) PortaFirmwarePath=D:/sdk/sdk611/porta/fw/ PortaSettingPath=D:/sdk/sdk611/porta/dat/ PortaLicensePath=D:/Ultrasonix Settings/ PortaLUTPath=D:/Ultrasonix Settings/LUTS/ Usm=4 Pci=3 channels=64; in ..\..\..\PlusLib\src\DataCollection\SonixVideo\vtkSonixPortaVideoSource.cxx(501) | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> VideoDevice: Cannot connect to data source, ConnectInternal failed; in ..\..\..\PlusLib\src\DataCollection\vtkPlusDevice.cxx(959) | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> Unable to connect device: VideoDevice.; in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(306) | in PlusServerLauncher(0)
|ERROR|011.203000|SERVER> Datacollector failed to connect to devices; in ..\..\..\..\PlusLib\src\PlusServer\Testing\PlusServer.cxx(132) | in PlusServerLauncher(0)
|ERROR|011.289000| Server stopped unexpectedly. Return code: 0| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(333)
|INFO|011.290000| Disconnect request successful| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(209)
#### By Ben.Xkang on 2015-09-04 14:04
Changed Pci="3" to Pci="4". Connection successfully, but get PlusServer crashed...

|INFO|000.022000| Software version: Plus-2.3.0.4338 - Win32| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(57)
|INFO|000.022000| Logging at level 3 to file: D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/data/090415_135904_PlusLog.txt| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(58)
|INFO|000.028000| Supported devices: - 3dConnexion (ver: Plus-2.3.0) - Ascension3DG (ver: Plus-2.3.0) - AuroraTracker (ver: NDICAPI-3.1) - BrachyTracker (ver: Plus-2.3.0) - CertusTracker (ver: Optotrak API (Win32 DLL Version) Version 3.01.03) - ChRobotics (ver: Plus-2.3.0) - Epiphan (ver: Plus-2.3.0) - FakeTracker (ver: Plus-2.3.0) - GenericSerialDevice (ver: Plus-2.3.0) - ICCapturing (ver: The Imaging Source UDSHL-3.2) - ImageProcessor (ver: Plus-2.3.0) - Microchip (ver: Plus-2.3.0) - NoiseVideo (ver: Plus-2.3.0) - OpenIGTLinkTracker (ver: OpenIGTLink v1.10.10) - OpenIGTLinkVideo (ver: OpenIGTLink v1.10.10) - PhidgetSpatial (ver: Plus-2.3.0) - PolarisTracker (ver: NDICAPI-3.1) - SavedDataSource (ver: Plus-2.3.0) - SonixPortaVideo (ver: UltrasonixSDK-6.1.0) - SonixVideo (ver: UltrasonixSDK-6.1.0) - UsSimulator (ver: Plus-2.3.0) - VFWVideo (ver: Plus-2.3.0) - VirtualBufferedDiscCapture (ver: Plus-2.3.0) - VirtualDiscCapture (ver: Plus-2.3.0) - VirtualMixer (ver: Plus-2.3.0) - VirtualSwitcher (ver: Plus-2.3.0) - VirtualVolumeReconstructor (ver: Plus-2.3.0) | in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(62)
|INFO|000.036000| Server host name: PC-ae9a22| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(82)
|INFO|000.046000| Server IP addresses: 199.59.210.103, 127.0.0.1| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(103)
|INFO|004.204000| Connect using configuration file: D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(215)
|INFO|004.205000| Server process command line: "D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/bin/PlusServer.exe" --config-file="D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml" --verbose=3| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(135)
|INFO|004.864000| Server process started successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(142)
|INFO|010.216000|SERVER> Software version: Plus-2.3.0.4338 - Win32 | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> Logging at level 3 (INFO) to file: D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/data/090415_135915_PlusLog.txt | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> Selected US image orientation: UF | in PlusServerLauncher(0)
|INFO|010.216000|SERVER> VideoDevice: Local time offset: 0ms | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> Initialize: Porta could not be initialized: (unknown) PortaFirmwarePath=D:/sdk/sdk611/porta/fw/ PortaSettingPath=D:/sdk/sdk611/porta/dat/ PortaLicensePath=D:/Ultrasonix Settings/ PortaLUTPath=D:/Ultrasonix Settings/LUTS/ Usm=4 Pci=3 channels=64; in ..\..\..\PlusLib\src\DataCollection\SonixVideo\vtkSonixPortaVideoSource.cxx(501) | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> VideoDevice: Cannot connect to data source, ConnectInternal failed; in ..\..\..\PlusLib\src\DataCollection\vtkPlusDevice.cxx(959) | in PlusServerLauncher(0)
|ERROR|011.202000|SERVER> Unable to connect device: VideoDevice.; in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(306) | in PlusServerLauncher(0)
|ERROR|011.203000|SERVER> Datacollector failed to connect to devices; in ..\..\..\..\PlusLib\src\PlusServer\Testing\PlusServer.cxx(132) | in PlusServerLauncher(0)
|ERROR|011.289000| Server stopped unexpectedly. Return code: 0| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(333)
|INFO|011.290000| Disconnect request successful| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(209)
|INFO|225.981000| Connect using configuration file: D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(215)
|INFO|225.982000| Server process command line: "D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/bin/PlusServer.exe" --config-file="D:\Software\PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32\config\PlusDeviceSet_Server_Ultrasonix_4DL14-5_Porta_calibrated.xml" --verbose=3| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(135)
|INFO|226.641000| Server process started successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(142)
|INFO|231.881000|SERVER> Software version: Plus-2.3.0.4338 - Win32 | in PlusServerLauncher(0)
|INFO|231.881000|SERVER> Logging at level 3 (INFO) to file: D:/Software/PlusApp-2.3.0.4338-Ultrasonix-6.1-Win32/data/090415_140256_PlusLog.txt | in PlusServerLauncher(0)

|INFO|231.882000|SERVER> Selected US image orientation: UF | in PlusServerLauncher(0)
|INFO|231.882000|SERVER> VideoDevice: Local time offset: 0ms | in PlusServerLauncher(0)
|ERROR|251.315000| Server process error: Crashed| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(326)
|ERROR|251.317000| Server stopped unexpectedly. Return code: -1073741676| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(333)
|INFO|251.317000| Disconnect request successful| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(209)
#### By Andras Lasso on 2015-09-04 14:13
According to the log above it still cannot connect and Pci is still 3:

Porta could not be initialized: (unknown) PortaFirmwarePath=D:/sdk/sdk611/porta/fw/ PortaSettingPath=D:/sdk/sdk611/porta/dat/ PortaLicensePath=D:/Ultrasonix Settings/ PortaLUTPath=D:/Ultrasonix Settings/LUTS/ Usm=4 Pci=3 channels=64; in ..\..\..\PlusLib\src\DataCollection\SonixVideo\vtkSonixPortaVideoSource.cxx(501) | in PlusServerLauncher(0)

You can also try the porta_demo_qt.exe and propello_qt.exe applications to see what Pci and Usm numbers work on your system.
#### By Andras Lasso on 2015-09-04 14:38
I could reproduce the crash. Investigating...
#### By Adam Rankin on 2015-09-04 14:40
Is it fixed by commenting out:

PlusStatus vtkEpiphanVideoSource::NotifyConfigured()
line 348->361
?
#### By Andras Lasso on 2015-09-04 14:57
Probably the issue is that the build computer uses Ultrasonix SDK-6.1.0. There should not be big differences between different patch versions (and usually there are not), but actually many things have significantly changed in 6.1.1. I'm rebuilding with 6.1.1 to see if that was indeed the problem.

@rankin: Thanks for the tip. Epiphan was not used. Tried to comment out that part of the code anyway but it had no effect. Have you experience problems with the Epiphan notify configured method?
#### By Adam Rankin on 2015-09-04 14:58
Yes, I have that part commented out on our experiment machine as it was causing crashes. I haven't had time to investigate. I'll confirm and file a bug today.
#### By Ben.Xkang on 2015-09-04 15:12
@Andras Changing Pci=3 to Pci=4 was obtained by testing using porta_propello_qt demo.
#### By Andras Lasso on 2015-09-04 15:30
OK! In the meantime, I've done some testing and confirm that 6.1.0/6.1.1 mismatch caused the crash. Starting tomorrow, 6.1.1 SDK will be used for building Plus package Ultrasonix 6.1. I've created a new package that you can use now:
http://perk-software.cs.queensu.ca/plus/packages/experimental/PlusApp-2.3.0.4341-Ultrasonix-6.1-Win32.exe
#### By Ben.Xkang on 2015-09-04 15:39
The most up-to-date version is 6.1.2, while the 6.1.3 is in beta version. What do you think about using 6.1.2? Thanks for the package, will test it and let you know!
#### By Andras Lasso on 2015-09-04 15:42
Hopefully they don't make big changes in patch versions anymore (it would not be very convenient to add a new Plus package build for each Ultrasonix SDK patch version). Do you have 6.1.2 installed? Let me know if the new package works with 6.1.2.
#### By Ben.Xkang on 2015-09-04 16:07
Did a very quick test; the Plus Server Launcher started without error. Now will proceed on the remaining steps...
#### By Andras Lasso on 2015-09-04 16:33
Great! Let me know if you need any help.
#### By Ben.Xkang on 2015-09-04 17:24
(Comment removed)
#### By Ben.Xkang on 2015-09-04 17:25
Did not see a 3D volume. Seems there were still something wrong happened....
Scout-Scan.png	122 KB
LiveReconstruction.png	58.4 KB
#### By Andras Lasso on 2015-09-04 17:48
Could you please send the PlusServer log file?
#### By Andras Lasso on 2015-09-04 18:08
I remember having an issue earlier... Try to replace Ras by Motor everywhere and remove the Motor to Ras transform from the CoordinatesDefinition section.
#### By Ben.Xkang on 2015-09-07 10:55
Are you suggesting modifying source code of Plus Server on my computer? If so, please point out the file names and I could have a try.
#### By Adam Rankin on 2015-09-07 11:07
No, this would be a change in the <CoordinatesDefinition> section of the config file.
#### By Ben.Xkang on 2015-09-07 11:32
I found


<CoordinateDefinitions>
<Transform From="Ras" To="Motor"
Matrix="
1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1" />
</CoordinateDefinitions>

which is an identity matrix. In addition, I see

<VolumeReconstruction
ImageCoordinateFrame="Image" ReferenceCoordinateFrame="Ras"

Should I still go with the suggested modifications?
#### By Ben.Xkang on 2015-09-07 11:38
Found three places when searching "motor"
1. MotorRotationRangeDeg="29", which I think should leave as it is.
2. <Transform From="Ras" To="Motor", which is an identity matrix and I doubt it might cause problem
3. <Transform Name="MotorToRas" />, which I don't know
#### By Ben.Xkang on 2015-09-07 11:56
Errors in the log file for your reference. But I do find ScoutScanRecording.mha file under the 'data' folder, with file size 11.9M.

| in PlusServerLauncher(0)
090415_171644.417|INFO|4747.905000|SERVER> OpenIGTLink broadcasting started. No data was available between 0-14.452sec, therefore no data were broadcasted during this time period.
| in PlusServerLauncher(0)
090415_171843.226|INFO|4866.713000|SERVER> vtkPlusStartStopRecordingCommand::Execute:
| in PlusServerLauncher(0)
090415_171843.226|INFO|4866.714000|SERVER> vtkPlusStartStopRecordingCommand::Execute: StartRecording
| in PlusServerLauncher(0)
090415_171843.226|WARNING|4866.714000|SERVER> Compressed streaming of metaimage file requested. This is not supported. Reverting to nrrd.; in ..\..\..\PlusLib\src\DataCollection\VirtualDevices\vtkVirtualDiscCapture.cxx(183)
| in PlusServerLauncher(0)
090415_171859.171|INFO|4882.659000|SERVER> vtkPlusStartStopRecordingCommand::Execute:
| in PlusServerLauncher(0)
090415_171859.173|INFO|4882.660000|SERVER> vtkPlusStartStopRecordingCommand::Execute: StopRecording
| in PlusServerLauncher(0)
090415_171859.276|INFO|4882.763000|SERVER> Volume reconstruction from sequence file: ScoutScanRecording.mha, device: VolumeReconstructorDevice
| in PlusServerLauncher(0)
090415_171859.390|INFO|4882.877000|SERVER> Volume reconstruction failed, unable to open input file specified in InputSeqFilenameD:/Software/PlusApp-2.3.0.4341-Ultrasonix-6.1-Win32/data/ScoutScanRecording.mha
| in PlusServerLauncher(0)
090415_171859.391|ERROR|4882.878000|SERVER> Cannot uncompress the pixel data: uncompressed data is less than expected; in ..\..\..\PlusLib\src\PlusCommon\vtkMetaImageSequenceIO.cxx(390)
| in PlusServerLauncher(0)
090415_171859.391|ERROR|4882.879000|SERVER> Couldn't read sequence metafile: D:/Software/PlusApp-2.3.0.4341-Ultrasonix-6.1-Win32/data/ScoutScanRecording.mha; in ..\..\..\PlusLib\src\PlusCommon\vtkTrackedFrameList.cxx(478)
| in PlusServerLauncher(0)
090415_171859.393|ERROR|4882.880000|SERVER> Failed to read video buffer from sequence metafile: D:/Software/PlusApp-2.3.0.4341-Ultrasonix-6.1-Win32/data/ScoutScanRecording.mha; in ..\..\..\PlusLib\src\PlusCommon\vtkSequenceIO.cxx(80)
| in PlusServerLauncher(0)
090415_171859.394|ERROR|4882.881000|SERVER> Command execution failed; in ..\..\..\PlusLib\src\PlusServer\vtkPlusCommandProcessor.cxx(158)
| in PlusServerLauncher(0)
090415_171957.263|ERROR|4940.750000|SERVER> Command execution failed; in ..\..\..\PlusLib\src\PlusServer\vtkPlusCommandProcessor.cxx(158)
| in PlusServerLauncher(0)
090415_172047.703|INFO|4991.190000| Server process stop request sent successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(194)
090415_172049.670|INFO|4993.157000| Server process stopped successfully| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(212)
090415_172049.671|INFO|4993.158000| Disconnect request successful| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(234)
#### By Adam Rankin on 2015-09-07 11:59
It is possible that I broke reading from sequence metafile. Could you send me the .mha files involved?

Edit: Ah... in your config file rename any saved .mha file to .nrrd
#### By Adam Rankin on 2015-09-07 12:23
@lassoan I welcome your feedback as to whether I should fallback to nrrd or uncompressed mha
#### By Andras Lasso on 2015-09-07 12:56
@rankin This is a regression, please check/fix. Maybe the only thing to be changed is to disable compression by default. We would need to change a couple of things in PlusRemote to use nrrd instead of mhd.

Ben, please stand by for a fix. The volume reconstruction through PlusRemote module is broken due to a commit done a few days ago. Some improvements of support of 3D probes have been added a few days ago, too, so unfortunately you need to use the latest nightly version. We should be able to fix the issue by tomorrow.
#### By Andras Lasso on 2015-09-07 13:28
@rankin: Ideally, nrrd/mha should be decided based on the file name extension the user provides. Is this the current behavior? By default use uncompressed, as compression may take a long time, especially on systems with slow CPU, such as the embedded Ultrasonix systems.
#### By Adam Rankin on 2015-09-07 13:54
No at the moment the default is to keep compression and switch to nrrd. I will change it to switch to uncompressed mha
#### By Adam Rankin on 2015-09-07 14:03
Ok, default is now to capture uncompressed for mha when compressed mha is requested
Plus:4350
#### By Andras Lasso on 2015-09-07 22:09
@ben.xkang Tommorrow's nightly Plus build should work correctly with PlusRemote. Let us know if you run into any problem.
#### By Ben.Xkang on 2015-09-08 09:17
Thanks, Andras. Kindly let me know when the nightly build is ready to go and what should I do on Plus and Slicer.
#### By Adam Rankin on 2015-09-08 09:24
Well the build is complete but I'm not sure where the download button is. I will manually package the nightly build and send you a link. I'll be in the office in about 15 minutes.
#### By Andras Lasso on 2015-09-08 09:47
The nightly builds are ready (http://perk-software.cs.queensu.ca/plus/packages/nightly/).They are completed every day by about 4am EST.
#### By Ben.Xkang on 2015-09-08 13:19
Now it is working. Great thanks!! My next questions are 1) how to define a ROI and 2) how to change/select the rendering effect?
#### By Andras Lasso on 2015-09-08 13:54
Define the ROI using the GUI or programmatically? You can display the ROI and drag the colored handles to adjust it in the 2D and 3D views.

Adjust volume rendering settings: You can do that in the Volume Rendering volume. You may want to turn off the "show results automatically" check box in PlusRemote to prevent PlusRemote to override your manual settings.
#### By Ben.Xkang on 2015-09-09 11:14
Programmatically, if possible.

What I am seeing in Slicer through Plus Remote are B-mode images. Does PLUS Server support other modes?
#### By Andras Lasso on 2015-09-09 14:05
Modify ROI: Get a reference to the ROI node and adjust its properties.

Plus supports 8/16/24 bit images (grayscale, RF, color), but the Ultrasonix Ulterius interface in Plus currently can acquire B-mode and RF-mode data. It's easy to add other imaging modes if needed.
#### By Ben.Xkang on 2015-09-09 16:01
I guess the Plus Server is using Porta, instead of Ulterius. Is it?

Could you kindly point out more precisely which file(s) I should start to learn how to collect 3D volumetric data? And how to do "Get a reference to the ROI node and adjust its properties." Sorry for not familiar with Plus source code and structure. Thank you very much!
#### By Andras Lasso on 2015-09-09 16:26
Plus can either use Porta or Ulterius. We only use Porta for the motorized probes, most of the time we use Ulterius (so that we have the Exam software that the user can interact with).

I would recommend to use Slicer for controlling data acquisition and visualization. Probably it can already do everything that you may ever want to implement. With simple Python scripting you can create a standalone application with a custom GUI (so you don't need to show all the bells and whistles of the default Slicer GUI). This is what most companies do that develop their software based on Slicer. An open-source custom application is LumpNav, available in the extension manager (you can try it by starting Slicer as usual then switch to the 'Lumpectomy Navigation' module and click "Start LumpNav"). You can build custom installer of Slicer that contains all the necessary modules, extensions, settings; and when you start the application it launches your module automatically).
#### By Ben.Xkang on 2015-09-09 16:44
Thanks for your suggestion! But we may not want to use Slicer. What if using PlusLib? Would it possible to point out which API function(s) should be called to get a volume? Or a stack of images and their associated transformations? Or is there something could be used for a quick start (e.g., something in PlusApp or testing)? Thanks!
#### By Andras Lasso on 2015-09-09 17:12
You can use PlusLib in your applications as applications in the PlusApp directory demonstrate it. There is also vtkDataCollectorTest1.cxx, which is a simple example for a console application for data collection from devices. You can find APIs that you may need for start/stop recording in vtkPlusStartStopRecordingCommand.cxx and volume reconstruction in vtkPlusReconstructVolumeCommand.cxx.
#### By Ben.Xkang on 2015-09-11 10:11
Hi Andras, I was wondering if PLUS support acquiring color Doppler data (color v/v) using Porta sdk? Thanks!
#### By Andras Lasso on 2015-09-11 10:18
Plus supports acquisition and processing of color IJCARS images, but the Porta device in Plus currently does not handle Doppler images. With slight modifications in the Porta device class you could add support for Doppler.
#### By Ben.Xkang on 2015-09-30 10:01
Hi Andras, Can we use MatlabOpenIGTLink to receive data from PlusServer? I found a Matlab script showing how to receive transformation from PlusServer. If knowing the format of the streamed data (e.g., header, data block), I guess the images and other information could be received too. But the problem is how to receive images. Thanks!
#### By Andras Lasso on 2015-09-30 10:16
You can receive images, too. This is the MatlabOpenIGTLink version that we are working on:
https://github.com/SlicerIGT/MatlabOpenIGTLink

The only problem we had with images was that bulk data transfer was not available in earlier Matlab versions and so we had to copy pixel data in small chunks. Recent Matlab versions have a solution for this (see https://github.com/SlicerIGT/MatlabOpenIGTLink/issues/2), we would just need to update the script so that it takes advantage of this when it is available.

It should not be difficult to implement at all, it was just not a priority for us. It would be great if you could work on this, we would be ready to help you if you have any question.
#### By Ben.Xkang on 2015-09-30 10:59
No problem. If you could let me know how to do this, I would like to try with your kind help.
#### By Andras Lasso on 2015-09-30 17:47
I've added detailed steps here:
https://github.com/SlicerIGT/MatlabOpenIGTLink/issues/2

Let's continue the discussion there.


## Ultrasonix bi-plane PAXY probe (PA2.75/2x64 - 1241F1005)
#### Posted by orajput on 2015-09-07 12:00

Hello all,

We are looking to use the bi-plane PAXY probe with UltrasonixTouch device for a robotic tracking project. So far, we have successfully used the PlusServer to acquire ultrasound images over the network using prebuilt PLUS binaries (PlusApp-2.2.0.4177-Ultrasonix-6.1-Win32.exe).

The problem we are facing is that we are only able to acquire images from one of the two planes of the probe. Is there a way to acquire both planes as two streams by some parameters in XML config file? If not, then could you please identify a direction to take in order to use the C++ API to acquire both planes over the network?

Background:
Previously, we were using the Ulterius SDK provided by the Ultrasonix, in order to use the Ultrasonix device over the network using TCP/IP. However, all frames only from the probe LA14-5/38 were acquired using Ulterius. With the PAXY probe (PA2.75/2x64), we are only able to receive images of one of the planes. When we tried to dig a little deeper by looking into the type, size, cine, and frame_number variables set by the Ulterius SDK for the callback function, we noticed that the frame_numbers are consecutive for the LA14-5/38 probe, while the frame_numbers for the PAXY probe are odd numbers. This, probably, indicates that the Ulterius SDK is skipping frames from one of the planes. In contrast, the Texo SDK is insufficient in a way that it doesn't provide any network interface to communicate with the Ultrasonix device over the network.

Therefore, we turned to the open-source PLUS project to solve our problem.

Thanks and regards,
Omer Rajput

#### 29 Comments
#### By Adam Rankin on 2015-09-07 12:03
Hello and welcome!

This sounds like a terrific use case to support. I will look into our implementation of the Sonix device and see what might be needed to support biplane capture over the network. I will get back to you.

To clarify, when you mean you were using the ultrasonix SDK, did you write your own app? Did you use one of their built-in apps? Were you using PLUS?

Thanks for reaching out!
#### By Adam Rankin on 2015-09-07 12:28
Early feedback:

It appears there is an imaging mode for biplane, I will investigate further.
ImagingModes.h::34
  BiplaneMode = 20,
#### By Andras Lasso on 2015-09-07 13:53
Which probe do you have? The transrectal biplane probe (http://www.ultrasonix.com/webfm_send/879)?
Can the Ultrasonix Exam software access both planes? Simultaneously?

Plus supports Ulterius and Porta interfaces. The Porta console demo has some biplane mode support (sdk-6.1.1\porta\demo\console\main.cpp). Could you please test if this porta demo app can access both planes simultaneously?

Also, ask on the Ultrasonix research forum which Ultrasonix interfaces support simultaneous data acquisition from a two planes.
#### By Adam Rankin on 2015-09-07 14:09
I will have to continue experimentation tomorrow when I am at the lab with our Sonix machine. I agree that if the callback is not returning consecutive frames, then the SDK is crippled for biplane. I will confirm tomorrow. Apologies for the delay.
#### By Adam Rankin on 2015-09-08 10:20
The Peters group doesn't have a biplane probe, so I am asking our neighbors and will try to locate a probe to test.
#### By Orajput on 2015-09-08 10:30
Hello Rankin and Andras,

I am thankful for your prompt and encouraging responses. It is like a breath of fresh air, after the waiting for responses from research.ultrasonix.com forum :).

@Rankin "To clarify, when you mean you were using the ultrasonix SDK, did you write your own app? Did you use one of their built-in apps? Were you using PLUS? ": We sort of built an app by modifying the Ulterius SDK's console demo app.

@lassoan:
The probe, that we are using, is not mentioned in the Transducer Guide document (http://www.ultrasonix.com/webfm_send/879). It is an experimental/research based probe integrated but not released for full clinical by Ultrasonix. It is a Biplane phased array probe, referred to as 'PAXY' in the Porta/Texo/Matlab SDK configuration files (e.g., Sonix\sdk607\porta\dat\config\probes.xml).

Actually, the Ultrasonix Exam software (if you mean the one running on Sonix PC by default) also shows only one plane. TBH, we also need to figure out a way to switch the plane in the Exam software. The only way, we see the data from the both planes simultaneously, is to run the Texo SDK's QT demo application on the Sonix PC. However, this shows the raw RF data and not the US images.

As I said earlier, we have been posting on Ultrasonix research forum for a few months now, but aren't any responses there yet.

@rankin Thank you for looking into this. Please do not apologize, your help is highly appreciated!

Thank you and best regards,
Omer
#### By Adam Rankin on 2015-09-08 12:09
Ok, one of our colleagues has a endorectal T probe, I will try biplane capture with it.

Adam
#### By Andras Lasso on 2015-09-08 12:53
Please try the Porta console demo application if that can access both planes at the same time (probably it can; the planes are probably available on display 0 and 1). If Porta works then you can get a B-mode image directly from the SDK and it's also possible to add support for thus in Plus without too much effort. Acquiring data from Texo should be doable, too, just more work.
#### By Orajput on 2015-09-08 13:56
Ok, I am trying to make this work with Porta.

Porta console demo is not pre-compiled by the Ultrasonix. I just tried to compile it using CMake and Visual Studio 13. Apparently, the compilation is successful but I am getting an error about dll when running the app.

Thanks!
porta_err.PNG	11 KB
#### By Andras Lasso on 2015-09-08 14:14
I see that a DLL in SDK 6.0.7 had an error. There have been huge changes in the Ultrasonix SDK recently. The best would be to upgrade to at least 6.1.1. (both the Exam software, which upgrades the firmware; and the SDK).
#### By Orajput on 2015-09-09 03:50
In Wikisonix (http://www.ultrasonix.com/wikisonix/index.php/Upgrading), they say "SonixTouch™ and SonixTablet™ can only be upgraded to 6.0.x software." Since, ours is a SonixTouch device, is it worth taking the risk to upgrade the firmware? (As there have been a reported problem (http://research.ultrasonix.com/viewtopic.php?f=25&t=1312&p=5087&hilit=sonixtouch#p5087)).
#### By Andras Lasso on 2015-09-09 10:15
We've upgraded several SonixTouch and SonixTablet systems to 6.1.1 without problems, we just had to contact Ultrasonix support to regenerate licenses. If you encounter any issues you can downgrade anyway (downgrade is not always automatic, you may need to contact Ultrasonix support for that).
#### By Orajput on 2015-09-09 11:29
OK, I will give it a try. Thanks!
#### By Orajput on 2015-09-14 07:38
I updated the SonixTouch to 6.1.2. At first everything looked good, as there seemed to be no issue with licensing. But, the SDK demos of Ulterius (Error: Cannot connect.) and Texo (Error: License not valid) are not working - see the attached screenshots. However, porta qt demo seems to work (But, I am not sure what the demo show in the black rectangles in the screenshot). Probably the licenses need to be regenerated (I have asked the Ultrasonix support for that).

Since, the exam software seems to work and allows us to switch the planes and it also is able to show both planes in the dual mode. Is it possible to use PLUS server running in the Sonix machine to transmit the images from the exam software to other clients in the network?

Thanks!
ulterius_err.bmp	4.01 MB
license_screenshot.bmp	4.01 MB
texo_err.bmp	4.01 MB
porta.bmp	4.01 MB
#### By Andras Lasso on 2015-09-14 08:48
We've upgraded several machines and we had to regenerate the licenses every time to have a working Ulterius connection. You need to enable SonixLive (Menu / SonixLive / Enable streaming checbox), but the checkbox is only enabled if the "SonixTelemed" licensing option is enabled.
#### By Orajput on 2015-09-14 11:21
Yes, the enable streaming checkbox is inactive (greyed out). I am waiting for the upgraded licenses from Ultrasonix. I guess after upgrading the licenses, I will be able to see the "SonixTelemed" option; as currently there is no such licensing option.

Thanks!
#### By Orajput on 2015-09-21 07:11
Hello,

After successfully upgrading to the version 6.1.2, we are encountering another problem related to the size of the new frame from the callback function in the Ulterius SDK. It no longer complies with the image size 480x640=307200. In the new SDK it is 406560. Therefore, we are unable to interpret the data in the new frame. Could you please provide any hints about how to read the new frame data?

Thanks!
#### By Andras Lasso on 2015-09-21 08:00
Does Plus have any problem retrieving the frame size? Using which interface: Porta or Ulterius?
#### By Orajput on 2015-09-21 08:33
With PLUS it seems to work fine (at least for frequencies other than 10.0M and 14.0M which only have data in half of the image. See screenshots). I am using the Device set PlusDeviceSet_Server_SonixTouch_L14-5.xml for the PLUS server. Since the type in this xml file is 'SonixVideo', therefore it should be Ulterius interface.

However, in our custom app based on Ulterius. We are getting a completely garbled image, probably due to the fact that we are trying the interpret the data as a 480x640 OpenCV image with 8-bits per pixel (i.e. Mat(480, 640, CV_8UC1, gBuffer);).

When I go through the code of vtkSonixVideoSource, the PLUS framework is trying to find the write frame size and bytes per pixel in order to interpret the data properly. (I apparently can't decipher 'how' at the moment).
plus_fcal_screenshot_freq10M.png	239 KB
plus_fcal_screenshot_freqH10M.png	520 KB
custom_ulterius_app_screenshot_freqH10M.png	163 KB
#### By Adam Rankin on 2015-09-21 08:46
Just fyi, if you set parameters in the config file, PLUS sends those parameters to the Sonix device as SetXYZ commands. It also parses the data sources for all "requested" data types and asks the Sonix to provide said data types.

So if you had a single data source such as
<DataSource Type="Video" Id="Video" PortName="B" PortUsImageOrientation="UF"  />

then PLUS would request b-mode from the device.

Also, silly thing, but have you tried interpreting it as 640x480 instead of 480x640?
#### By Orajput on 2015-09-21 09:10
@rankin If you are referring to the cv::Mat constructor, then I am pretty sure that Mat(480, 640, ...) will result in a 480(rows)x640(cols) image (see: http://docs.opencv.org/modules/core/doc/basic_structures.html#mat-mat). Unless, you are referring to a certain byte order in the received data.

@lassoan: I am now trying to compile the PLUSLib from source in order to dig into how PLUS is interpreting data correctly from Ulterius. In this regard, could you please provide the access to PLTools repository?

Thanks.
#### By Orajput on 2015-09-21 09:22
Actually, when I save the Snapshot from fCal/Capturing. The resulting mha shows the image size to be 446x460 ('DimSize = 446 460 1'). Do you have some idea where does this image dimension come from?
#### By Adam Rankin on 2015-09-21 09:27
vtkSonixVideoSource.cxx::525, all calls below this query the device and set up the data source for receiving data.
#### By Andras Lasso on 2015-09-21 09:50
For R&D projects I would suggest to not reimplement low-level hardware interfaces (i.e., what Plus does) in your application. That was acceptable 10-15 years ago, because there was no alternative but now there is Plus/SlicerIGT, CustusX, MITK-IGT, etc. You waste a lot of time and lose all flexibility if you reimplement such low-level interfaces in your software. Just choose your Ultrasound IGT platform and use that. If you need fixes and improvements then you may contribute those back to the platform and you don't have to worry about maintaining it.
#### By Andras Lasso on 2015-09-21 09:55
You don't need access to PLTools, as you already have access to Ultrasonix SDK. Just set PLUS_ULTRASONIX_SDK_MAJOR_VERSION, PLUS_ULTRASONIX_SDK_MINOR_VERSION, PLUS_ULTRASONIX_SDK_PATCH_VERSION, and set ULTRASONIX_SDK_DIR to your Ultrasonix SDK directory in CMake.
#### By Orajput on 2015-09-21 10:57
I understand your suggestion of not re-implementing low-level interfaces. But the issue is that we haven't really used PLUS toolkit before, rather we just developed our own app on top of the Ultrasonix SDK. A few other people are depending on those apps to work. So, we need those custom apps to continue to work until we have a good client ready with PLUS toolkit.
#### By Orajput on 2015-09-21 12:48
From the help from ultrasonix research forum, it was found that the image width/height can be determined using getDataDescriptor method. Pretty straightforward, I suppose :). And, the image dimensions are 616x660. So, the PLUS toolkit is determining the image dimensions (446x460) based on the ROI.
#### By Adam Rankin on 2015-09-21 12:54
If you look at the link above and follow it to the function
PlusStatus vtkSonixVideoSource::ConfigureVideoSource( uData aValue )
you'll find that PLUS uses getDataDescriptor to retrieve information about the current Ultrasonix device settings.
See vtkSonixVideoSource::1128--1213
#### By Orajput on 2015-09-22 03:54
Thanks Rankin.


## Measure update rate on client side
#### Posted by Mikael Brudfors on 2015-09-14 07:20

Hello all!

If I would like to measure the update rate of PLUS acquired data, on the client side (e.g. 3D Slicer). Do you have any suggestions on how do this?

I was thinking of putting a modifed callback on the input transform and then use a timer to get an idea of the update rate, but then I thought maybe there is another, better way of doing this?

Thank you,

Mikael

#### 7 Comments
#### By Andras Lasso on 2015-09-14 08:11
For 3D view you can enable showing FPS (pin icon/.../Show FPS). It can be used when you use 3D visualization or 2D and 3D visualization. If you need to quantify 2D visualization or data reception rate then you need to count Modified() events per elapsed time to compute update rate.

It could be nice to implement a simple Python module that computes statistics (average, stdev, min, max, latest) on time elapsed between Modified() event for selected nodes.
#### By Mikael Brudfors on 2015-09-15 05:37
Enabling showing FPS in the 3D viewer did the trick; but I also created such a module you mentioned, to acquire more statistics, available here: https://github.com/brudfors/NodeModifiedStatistics
#### By Andras Lasso on 2015-09-15 14:19
Thanks Mikael, the module is awesome. Tried it and it is very useful (also made some fixes and improvements).

I think we should add it to an extension. Probably the best place would be a new ModuleDeveloperTools extension, which would contain PyDevRemoteDebugger and this extension.

What do you think?
#### By Adam Rankin on 2015-09-15 14:49
Yes please!
#### By Andras Lasso on 2015-09-15 23:16
The new extension containing PyDevRemoteDebug and NodeModifiedStatistics should appear in the nightly builds tomorrow:
https://github.com/SlicerRt/SlicerDebuggingTools
#### By Mikael Brudfors on 2015-09-16 04:49
Great that you liked it! Yes, such en extension sounds very useful.

I just pushed a couple of fixes and enhancements to NodeModifiedStatistics in ModuleDeveloperTools by the way.

Over and out
#### By Andras Lasso on 2015-09-16 12:25
This is great, thank you Mikael!
 

## Is there has parameters table for pattern recognition in different imaging depth?
#### Posted by Jason... on 2015-09-11 04:50

Hi,
i was doing a new topic of prostate biopsy recently, and i need to redo the probe calibration with the imaging depth in 7cm by using calibration phantom fcal-2.0. But i cannot set pattern recognition parameters right to get the 9 green dots in 7cm(more specifically, i can just set it right in 4cm imaging depth). So i'm wondering if there is recommended parameters table for pattern recognition in different imaging depth.

regards,
Jason

#### 2 Comments
#### By Adam Rankin on 2015-09-11 09:17
Hi Jason,

Just as a first check, have you adjusted the spacing items in the segmentation parameter dialog?
#### By Jason... on 2015-09-12 00:13
yeah, i forgot to change the initial spacing. It's ok now.


## how to add new files into fcal project ?
#### Posted by Jason... on 2015-09-07 10:48

Hi,
I'm going to update the plusBulid source files, and have some problems while adding my script files into fcal project. (something like: error LNK2001: unresolved external symbol "public: virtual struct QMetaObject).

In the previous version, i just need to add my files into the CMakeLists.txt in ../PlusApp/fCal. But in the latest version, it has a a new feature(fcal_automoc) to handle the moc file.

So , what should i do to add new files into fcal project?

Regards,
Jason

#### 8 Comments
#### By Adam Rankin on 2015-09-07 11:07
Hi Jason,

You simply add your .cxx, .h, .ui and .qrc files to
fCal_SRCS, fCal_UI_HDRS, fCal_UI_SRCS and fCal_QT_Resources respectively (see fCal\CMakeLists.txt)

The, the Qt build system will automatically automoc .ui files, autorcc .qrc files, etc...

What type of files are you trying to add?
#### By Andras Lasso on 2015-09-07 11:27
What is your CMake version?
#### By Adam Rankin on 2015-09-07 11:29
Just a side note, I believe I protected against version issues by setting
CMAKE_MINIMUM_REQUIRED(VERSION 2.8.11).

Automoc was introduced in 2.8.6
#### By Jason... on 2015-09-07 20:04
The CMake version i am using is 3.2.1.

i am trying to add .cpp, .h , and .ui files to fCal_SRCS, fCal_UI_HDRS, fCal_UI_SRCS. There is no Generated files in the fcal project(picture attached) after compiling.
Is that something i forgot to set?
fcalproject.png	28.9 KB
#### By Andras Lasso on 2015-09-07 21:14
If you can send a link to your repository then we can have a look. Otherwise you have to find out yourself what is different in your class compared to other classes in fCal. Searching the web may help, too, for example:
http://stackoverflow.com/questions/14170770/unresolved-external-symbol-public-virtual-struct-qmetaobject-const-thiscal
#### By Jason... on 2015-09-07 23:08
I have solved this problem. The reason is when i rebulid the plusapp project after adding my files into CMakeLists.txt, the fcal_automoc.cpp file is not refresh. So i add the moc files(for my .h file) into fcal_automoc.cpp, then just rebuild fcal project and it works.
#### By Adam Rankin on 2015-09-08 07:28
Would you attach your CMakeLists.txt?
#### By Jason... on 2015-09-08 07:57
the CMakeLists.txt in ../PlusApp/fCal is attached.
CMakeLists.txt	3.39 KB


## Suitable JSON package to use with Plus
#### Posted by Siavash Khallaghi on 2015-08-31 19:41

Hello,

I am writing a viewer on top of Plus. The network layer should use JSON for communicating with a server. This server hosts the images that are input to the viewer and the configuration of my app.

To the best of my knowledge, Plus uses xml for its configuration files. Does it support JSON as well?

My JSON messages are very simple at the moment (asking for image regions, patient names, etc), so I could try writing my own JSON class. But if there is already a suitable JSON package for Plus, I would rather not reinvent the wheel.

Thanks,

Siavash

#### 2 Comments
#### By Andras Lasso on 2015-08-31 21:17
There is already a JSON parser in VTK that you can use (vtk\ThirdParty\jsoncpp).

For new configuration files you can use this JSON parser in your application. You could also write a converter between vtkXMLDataElement and Json:: Value if you prefer to store Plus configuration files in JSON (I would not recommend though, unless it's really necessary).

For controlling Plus using JSON-RPC (http://www.vtk.org/Wiki/JSON-RPC_Protocol or something similar) instead of OpenIGTLink XML commands: The two protocols are very similar (message payload is basically the same, only the syntax is different) and OpenIGTLink is only used in Plus at low level only, so it's not difficult to add JSON-RPC-based communication. Probably you only need to write your own vtkPlusJsonRpcServer class, which would do the same as the existing vtkPlusOpenIGTLinkServer but it would send/receive JSON-RPC messages instead of OpenIGTLink messages. Another option would be to implement all these at even lower level, in OpenIGTLink, by rewriting the Pack() and Unpack() to serialized in JSON instead of OpenIGTLink. Finally, you could implement a JSON-OpenIGTLink bridge, which could either run inside Plus or as a separate process and translate messages between the two protocols; this would not require any change in Plus, but would mean an extra communication layer.
#### By Siavash Khallaghi on 2015-09-01 17:05
Thanks! This is a very comprehensive answer. Right now, we are not implementing the network layer of our application, but we would like to know our options ahead of time. I will revisit this topic when we start implementing the client/server sides of our framework.


## Error: VirtualStreamCapture has not been found (auto-detect)
#### Posted by ckychen on 2015-08-26 15:57

Hi,
I am trying to track and visualize a tool in 3D Slicer using an NDI Polaris Passive Optical Tracker. I'm unable to visualize any movement, and when I try to record using PLUS remote, I get the error: VirtualStreamCapture has not been found.
Does anyone know what the VirtualStreamCapture is, or how to resolve this error?

Any help will be appreciated, thank you!

Connie

#### 1 Comments
#### By Andras Lasso on 2015-08-26 16:14
VirtualStreamCapture is only needed if you want to start/stop data recording from Slicer.

Have you tried to follow these instructions?
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ProcedureStreamingToSlicer.html


## Possible bug in PlusApp?
#### Posted by Siavash Khallaghi on 2015-08-24 19:20

Hi,

When PLUSBUILD_USE_OpenIGTLink is set to OFF, PlusApp should not include projects that depend on OpenIGTLink, i.e. PlusServerLauncher and DiagnosticTools. I have attached a small patch for PlusApp/CmakeLists.txt

Siavash
CMakeLists.txt.patch	895 Bytes

#### 1 Comments
#### By Andras Lasso on 2015-08-25 01:11
Thanks for reporting this. Actually, there is no need to disable all these apps, just remove the OpenIGTLink dependencies. Fixed - see #1027.


## PLUS_USE_MMF_VIDEO missing in DataCollection\CMakeLists.txt
#### Posted by sordas on 2015-08-15 18:31

Hello Team,

I would like to send over IGTLink the video stream from my webcam using PlusServer

I do have Windows Platform SDK 7.1 or later already installed
but PLUS_USE_MMF_VIDEO is missing in \plus\PlusLib\src\DataCollection\CMakeLists.txt
(only PLUS_TEST_MMF_VIDEO is defined)

How can I enable Microsoft Media Foundation compatible devices in PlusServer?

btw, what is the "PlusBuild" folder for? I noticed that PLUS_USE_MMF_VIDEO is defined in PlusBuild\CMakeLists.txt

thank you,
sebastian

#### 9 Comments
#### By Andras Lasso on 2015-08-15 18:39
PlusBuild contains a superbuild for convenient configuration of PlusLib and PlusApp. It downloads source code of all projects, configures, and builds them. See build instructions page on how it is intended to be used:
https://www.assembla.com/spaces/plus/wiki/Windows_Build_Instructions

If you enable MMF in PlusBuild then it will build PlusLib and PlusApp with MMF support.
#### By Adam Rankin on 2015-08-15 18:55
Oops... I suspect it was me that did not set up the CMake correctly. I will add a ticket and submit a fix.
#### By Adam Rankin on 2015-08-15 18:56
See https://www.assembla.com/spaces/plus/tickets/1021-option-for-mmf-video-source-not-available-without-plusbuild-system#/activity/ticket:
#### By Adam Rankin on 2015-08-15 19:06
Sorry about that, I hope you didn't lose too much time!
#### By Andras Lasso on 2015-08-15 19:29
#### By the way, if you don't need to add new features to Plus just use it (as most people do) then you can simply install the Plus package, available in the download section.
#### By Sordas on 2015-08-15 19:57
ufff! I´m so sorry :-) I should have read the building instructions first
#### By Sordas on 2015-08-15 20:04
thanks for your suggestion Rankin, but I would like to get into the code for better understanding. I am specially interested in streaming live 3DUS together with its tracker data. ie33 interface is a great feature. Hopefully we will setup new ones in the future.
#### By Adam Rankin on 2015-08-15 20:06
No worries!

Just a point about the iE33 interface. It look Dr. Peters (my supervisor) years to negotiate with Philips for a research interface and even then it was a one-off solution. I highly recommend reaching out to Philips first to ensure that they are interested in entering into a research agreement.
#### By Sordas on 2015-08-16 09:02
I see. Thank you for the advice! I will see how it goes.


## Qt 5.x and Plus
#### Posted by Siavash Khallaghi on 2015-08-12 16:00

Hello,

Is Plus compatible with Qt 5.x? If not, are there any plans to migrate to Qt 5.x in the future? There are some useful C++11 features, such as using Lambda expressions in slots which are not available in Qt 4.8.

Siavash

#### 27 Comments
#### By Adam Rankin on 2015-08-12 16:12
The short answer is that yes, in the future we will eventually migrate to Qt5 (probably when Slicer migrates to Qt5).

However, this isn't an active conversation at the moment. You could try building it with Qt5, but I have no idea how close to compatible it is as I've never developed for Qt5 myself.

Sorry,
Adam
#### By Siavash Khallaghi on 2015-08-12 16:15
Thanks. I will try building Plus with Qt 5.x and I will post the results on this thread.
#### By Andras Lasso on 2015-08-12 16:21
PlusLib does not use Qt, so it is compatible :) PlusApp applications are quite small, so if there were a few incompatibility issues they can be probably easily fixed. The main question is how much VTK is compatible with Qt 5.

Please post
####  comments on Qt 5 build issues at this ticket that I've just created: #1020. Thanks!
#### By Sordas on 2015-08-12 21:01
Hello, I´m new to Plus. The toolkit looks very powerful! I was able to build PlusLib and modified PlusApp for Qt5.
The adaptation was pretty easy. May I setup a ticket to paste down the necessary changes?
How much VTK is compatible with Qt 5? Enough, I would say. It´s been used in MITK for a while, now.
I do have one link error though that might not be related to my Qt5 migration. I will paste it here just FYI as I did not give up with it yet :-)

Error 2 error LNK1169: one or more multiply defined symbols found D:\binX64\plus\bin\Release\fCal.exe 1
Error 1 error LNK2005: "public: __cdecl PlusTransformName::PlusTransformName(class PlusTransformName const &)" (??0PlusTransformName@@QEAA@AEBV0@@Z) already defined in SpatialCalibrationToolbox.obj D:\binX64\PlusApp\fCal\vtkPlusCommon.lib(vtkPlusCommon.dll)

thanks again,
sebastian
#### By Sordas on 2015-08-13 08:15
Hi again, so here are the first adaptations:

All references of

FIND_PACKAGE(Qt4 REQUIRED)
SET(QT_USE_QTXML TRUE)
INCLUDE(${QT_USE_FILE})

should be changed by:

find_package(Qt5 COMPONENTS Core Widgets Gui Xml)
include_directories(${Qt5Widgets_INCLUDES})
include_directories(${Qt5Xml_INCLUDES})

// if not set already:
set(CMAKE_INCLUDE_CURRENT_DIR ON)
#### By Sordas on 2015-08-13 08:17
QT4_WRAP_CPP, QT4_WRAP_UI, QT4_WRAP_CPP, QT4_ADD_RESOURCES
#### by
QT5_WRAP_CPP, QT5_WRAP_UI, QT5_WRAP_CPP, QT5_ADD_RESOURCES
#### By Sordas on 2015-08-13 08:18
not sure why this one:

Treat wchar_t as built-in type - makes shell executes possible
if (WIN32)
ADD_DEFINITIONS(/Zc:wchar_t-)
endif (WIN32)

#### by

Treat wchar_t as built-in type - makes shell executes possible
if (WIN32)
set_target_properties(${TARGET} PROPERTIES COMPILE_FLAGS "/Zc:wchar_t-")
endif (WIN32)
#### By Sordas on 2015-08-13 08:21
do not use ${QT_LIBRARIES} when referring to Qt libraries. Do it like this:
${Qt5Core_LIBRARIES} ${Qt5Widgets_LIBRARIES} ${Qt5Gui_LIBRARIES} ${Qt5Xml_LIBRARIES}

Example in CommonWidgets module:

SET (CommonWidgets_LIBS
${CommonWidgets_LIBS}
${Qt5Core_LIBRARIES} ${Qt5Widgets_LIBRARIES} ${Qt5Gui_LIBRARIES} ${Qt5Xml_LIBRARIES}
${VTK_LIBRARIES}
)
#### By Sordas on 2015-08-13 08:28
#include <QtGui/QMainWindow>
#### by
#include <QMainWindow>
#### By Sordas on 2015-08-13 08:30
search for all Qt::WFlags

and replace e.g. SegmentationParameterDialogTest(QWidget parent = 0, Qt::WFlags flags = 0);

#### by:

in the header file:

#if QT_VERSION >= QT_VERSION_CHECK(5, 0, 0)
//! constructor for Qt 5
SegmentationParameterDialogTest(QWidget parent = NULL);
#else
//! constructor for Qt 4
SegmentationParameterDialogTest(QWidget* parent = NULL, Qt::WFlags flags = 0);
#endif

and in the implementation file:

#if QT_VERSION >= QT_VERSION_CHECK(5, 0, 0)
//! constructor for Qt 5
SegmentationParameterDialogTest::SegmentationParameterDialogTest(QWidget *parent)
: QDialog(parent)
#else
//! constructor for Qt 4
SegmentationParameterDialogTest::SegmentationParameterDialogTest(QWidget *parent, Qt::WFlags flags)
: QDialog(parent, flags)
#endif
#### By Andras Lasso on 2015-08-13 08:34
Thank you for the information. Could you please attach a patch file (you can generate it using your SVN client) that contains all your changes?
#### By Sordas on 2015-08-13 10:43
sure, find it attached

I´m still getting the link error below, which I don´t think is Qt5 related but with how libraries are linked to fCal

Error 2 error LNK1169: one or more multiply defined symbols found D:\binX64\plus\bin\Release\fCal.exe 1
Error 1 error LNK2005: "public: __cdecl PlusTransformName::PlusTransformName(class PlusTransformName const &)" (??0PlusTransformName@@QEAA@AEBV0@@Z) already defined in SpatialCalibrationToolbox.obj D:\binX64\PlusApp\fCal\vtkPlusCommon.lib(vtkPlusCommon.dll)
0001-Qt5-migration.patch	121 KB
#### By Andras Lasso on 2015-08-13 10:50
Thanks! Do you build PlusLib as static lib?
#### By Sordas on 2015-08-13 10:50
ah, two last modifications in PlusLib for you guys to evaluate:

1) vtkFloatingPointType -> double (needed with latest VTK)
2) PLUSLIB_VERSION already has the revision (PLUSLIB_REVISION is not recognized in my setting)
std::string plusLibVersion = std::string("Plus-") + std::string(PLUSLIB_VERSION);// + "." + std::string(PLUSLIB_REVISION);
#### By Siavash Khallaghi on 2015-08-13 12:44
Hello Sordas and Andras,

1. It seems that Qt::WFlags should be replaced with Qt::WindowFlags in PlusApp. Also QString::toAscii() is no longer supported and needs to be replaced with toLatin1(). See:

https://wiki.qt.io/Transition_from_Qt_4.x_to_Qt5#toAscii.28.29_and_fromAscii.28.29_Methods_are_deprecated
and
http://doc.qt.io/qt-5/qstring-obsolete.html#toAscii

2. I managed to build VTK, PlusLib and /PlusApp/CommonWidgets, however I am stuck with a final linking error in fCal:

2>------ Build started: Project: fCal, Configuration: Release x64 ------
2>CommonWidgets.lib(DeviceSetSelectorWidget.obj) : error LNK2019: unresolved external symbol "__declspec(dllimport) public: int __cdecl QString::toWCharArray(unsigned short *)const " (__imp_?toWCharArray@QString@@QEBAHPEAG@Z) referenced in function "protected: void __cdecl DeviceSetSelectorWidget::EditConfiguration(void)" (?EditConfiguration@DeviceSetSelectorWidget@@IEAAXXZ)

2>C:\devel\PlusExperimental-Qt5-bin\bin\Release\fCal.exe : fatal error LNK1120: 1 unresolved externals

Any hints on how to solve this?

Siavash
#### By Sordas on 2015-08-13 12:54
yes, make sure you have this in CommonWidgets' CmakeLists.txt

Treat wchar_t as built-in type - makes shell executes possible
if (WIN32)
set_target_properties(${TARGET} PROPERTIES COMPILE_FLAGS "/Zc:wchar_t-")
endif (WIN32)
#### By Adam Rankin on 2015-08-13 13:20
Thanks for all your work guys! I am focused on the SPIE 2016 submission deadline but after that I can work on integrating your changes!
#### By Siavash Khallaghi on 2015-08-13 13:26
I can run fCal now! I managed to solve it by changing Treat WChar_t As Built in Type to Yes in properties->C/C++->Language. What is confusing to me is that this seems to be equivalent to adding the compiler flags in CMakeLists.txt.

I don't know if it was because of my own mistake when I was tweaking VS. Anyways, I doubt if adding the compile flags is required since the original CMakeLists.txt has the following definition in line 79, which I think does the exact same thing:
# Treat wchar_t as built-in type - makes shell executes possible
if (WIN32)	
  ADD_DEFINITIONS(/Zc:wchar_t-)
endif (WIN32)
fCal_screenshot.png	210 KB
#### By Andras Lasso on 2015-08-13 13:45
Thank you all. I've assigned the integration work (#1020) to Adam.
#### By Siavash Khallaghi on 2015-08-13 13:51
I will have a patch for Adam probably by the end of today, so that Adam has two patches to choose from! I will try to follow the coding style in Plus to fascilitate the integration.

Siavash
#### By Siavash Khallaghi on 2015-08-13 16:00
How would you create the definition macro for Qt version in Plus? I am trying to modify /PlusLib/src/PlusConfigure.h.in to produce something like:
#define QT_VERSION_MAJOR

I am looking at
#define PLUSLIB_VERSION_MAJOR @PLUSLIB_VERSION_MAJOR@

as an example.
#### By Adam Rankin on 2015-08-13 16:13
That is a good approach Siavash. You could do some checking in PlusBuild/CMakeLists.txt lines 202-217ish and if it finds Qt4, set QT_VERSION_MAJOR to 4 and if it finds Qt5, set QT_VERSION_MAJOR to 5.
#### By Sordas on 2015-08-13 19:04
As for packaging, in plus\PlusApp\InstallFiles.cmake you may modify the following:

Install Qt libs
TODO replace C:/Qt/5.2.1/msvc2012_64_opengl/bin/ with ${QT_BINARY_DIR} or similar

INSTALL(FILES
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Core${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Widgets${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Gui${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Network${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Sql${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5WebKit${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5XmlPatterns${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/phonon4${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5OpenGL${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/Qt5Xml${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/icudt51${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/icuin51${CMAKE_SHARED_LIBRARY_SUFFIX}
C:/Qt/5.2.1/msvc2012_64_opengl/bin/icuuc51${CMAKE_SHARED_LIBRARY_SUFFIX}
DESTINATION ${PLUSAPP_INSTALL_BIN_DIR}
COMPONENT RuntimeLibraries
)
#### By Siavash Khallaghi on 2015-08-13 20:59
I am facing a couple of minor issues that I am unsure how to solve. The most difficult one is passing QT_VERSION_MAJOR from the top level CMakeLists.txt to lowere levels. I have not been able to do this properly yet, so I have
redefined the variable in lower level CMakeLists where I needed it.

Let me explain what I mean. Ideally, I would like to do the following in /PlusExperimental-build/CMakeLists.txt :
OPTION(PLUSBUILD_USE_QT5 "Plus uses QT5 instead of QT4" ON)
IF (PLUSBUILD_USE_QT5)
    SET(QT_MAJOR_VERSION 5 CACHE STRING "Qt major version")
ENDIF()

and then I would like to receive QT_MAJOR_VERSION cache variable in /PlusLib/CMakeLists.txt so I can pass it to /PlusLib/src/PlusConfigure.h.in so I can create
#define QT_VERSION_MAJOR 5

I would also like to pass the same QT_MAJOR_VERSION cache variable to /PlusApp/CMakeLists.txt so that I can load the proper version of Qt in fCal.
#### By Andras Lasso on 2015-08-13 22:21
The selected Qt version should only be passed to VTK through VTK_QT_VERSION. PlusApp can get the Qt version from VTK. See an example for configuring Qt4/5 in vtk\Examples\GUI\Qt\FourPaneViewer\CMakeLists.txt.

PlusLib does not depend on Qt, so nothing Qt related should be put in PlusLib.
#### By Siavash Khallaghi on 2015-08-14 12:57
I don't know why I was reinventing the wheel :P
#### By Siavash Khallaghi on 2015-08-14 15:23
I updated the ticket with my progress. Adam, when you are done with SPIE, please have a look. This was a great learning experience for me.


## question about the Probe Calibration
#### Posted by Jason... on 2015-03-06 22:24

I have done the probe calibration a few weeks ago. And I have checked the position between phantom and probe in "Show all device" is good .

But now, when I use the earlier results, I found that the position between phantom and probe in "Show all device" is totally wrong.

The sensors, the probe and the phantom is physically fixed in the same surroundings.

Does any ideas about how this happen? Is that means I have to do the calibration every few weeks?

Best regards,
Jason
config_version0.xml	7.94 KB

#### 32 Comments
#### By Andras Lasso on 2015-03-06 23:24
Usually it's enough to calibrate once and it works well as long as the sensor on the probe does not move. Is it possible that the sensors that you put on the probe or the phantom have moved? Do you use the same imaging settings, resolution, etc. as before?
#### By Jason... on 2015-03-07 02:12
The setting, resolution, configuration, sensors on the probe and phantom....all of it, is the same as before.

I will try to calibrate again and see what's going to be happened.

Another question: If I use the endocavity probe(probe_EC9-5_10.stl), what the ModelToObjectTransform in configuration file supposed to be?
#### By Jason... on 2015-03-07 07:22
Hi, Andras, I have done the stylus calibration(error is 0.29928 mm) and phantom registration(error is 0.642643 mm). The errors are acceptable.

But I found that there is obvious difference between the position of stylus and phantom in "Show all device" when I point the stylus to phantom at a specific position.

Do you have any idea of how this happen?
030715_195741_PlusLog.txt	5.67 KB
#### By Andras Lasso on 2015-03-07 08:37
See the FAQ on this page for potential errors and solutions:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html

If you send a screenshot of the 3D view then I might be able to give more specific advice. If you record 300 frames while you are scanning the calibration phantom and send it to me (through dropbox, yousendit, etc) then I can most probably tell what's wrong.
#### By Andras Lasso on 2015-03-07 10:45
I could not find model to transducer origin transform for EC9-5. Follow the model registration tutorial described at www.slicerigt.org to obtain the transform.
#### By Jason... on 2015-03-12 21:25
Sorry for the delayed reply. I have tested it several times and found this:

The relative position between stylus and phantom is correct showed in 3D view just after the stylus calibration and phantom registration.(first.png)
After finishing the spatial calibration part, I touch the same position at the phantom with the stylus and find its position in 3D view is wrong.(sencond.png)
second.png	166 KB
first.png	465 KB
#### By Jason... on 2015-03-12 21:45
Cannot visit the websites of dropbox and yousendit because of the network access restrictions from the goverment.
#### By Andras Lasso on 2015-03-13 15:18
Try with the latest nightly version. Set the log level to debug and perform the workflow that you described (stylus calibration, phantom calibration, check if 3D positions are correct, probe calibration, check if 3D positions are correct) and attach the resulting log file.
#### By Jason... on 2015-03-18 07:56
I take the version 2.1.2.4056(win64) for a new test. The result is the same as before: stylus calibration, phantom calibration,3D positions are correct, probe calibration, 3D positions are not correct.
031815_094458.Calibration.results.xml	1.2 MB
031815_094458_PlusLog.txt	27.6 KB
#### By Jason... on 2015-03-28 22:39
Hi, Andras
I have also tested with Plus-2.1.2.3879 (debug build) - Win32, there is the same problem with the position of stylus and phantom. Does this will affect the accuracy of spatial calibration?

Thanks a lot !
#### By Andras Lasso on 2015-03-30 10:01
I'll try today if I can reproduce the problem.
#### By Andras Lasso on 2015-05-15 10:18
I couldn't reproduce this problem. Let me know if you still have it.
#### By Jason... on 2015-06-08 09:20
Hi, Andras I still have that problem. (After the spatial calibration with a 0.5mm error, point the needle tip onto 'M', and the picture doesn't show the right relation between needle and phantom in 'Show all device' )

And another question: if I change the depth of the Ultrasound device, it that means I have to carry out another probe calibration?
#### By Andras Lasso on 2015-06-08 09:32
What do you mean by "the picture doesn't show the right relation between needle and phantom in 'Show all device'"? Can you attach a screenshot?

If you use a framegrabber then you have no control or information whatsoever about how the image is changed on the ultrasound machine when you change imaging depth. Usually the image shape, size, position, pixel spacing, and transducer origin on the frame are all changed when the imaging depth is changed, so you are forced to calibration at each depth. Typically calibrating at 1-3 different depths are enough.

If you use an ultrasound system with a direct digital interface (Ultrasonix, Telemed, etc.) then you can query the transducer origin position and spacing information from the ultrasound system and you can compute the calibration at different depths from a single calibration.
#### By Jason... on 2015-06-08 21:35
The screenshot is the same as I had mentioned above in 2015-03-13(first.png and second.png)
#### By Andras Lasso on 2015-06-08 23:04
The config files an log files look all good. If you send the StylusToTracker, ReferenceToTracker, Image in Tracker coordinate system through OpenIGTLink to Slicer/SlicerIGT does everything look good, too? If you are not sure how to do it we can schedule a Skype session with screen sharing. Contact me at lasso@queensu.ca for details.
#### By Jason... on 2015-07-18 03:26
It's been a while. And it is also not good when shows through 3DSlicer.

I have made hundreds of tests to find out what should be responsible for this. (wrong operation for calibration/external magnetic field changes)
And I found that the matrix of ProbeToReferenceTransformMatrix is different at different time(not move the probe and reference ), but I'm not sure this can explain the problem is caused by the external magnetic field changes or not.

The two matrix of ProbeToReferenceTransformMatrix :
[0.946192 -0.124884 -0.298538 -27.298
-0.30901 -0.074742 -0.948117 -19.9778
0.096091 0.989352 -0.109311 46.6628
0 0 0 1 ]

[0.811771 -0.152407 -0.563737 -31.7906
-0.57359 -0.026883 -0.818698 -10.6524
0.10962 0.987952 -0.109243 46.3861
0 0 0 1 ]

But I check out through NDI Tacker when I get the matrix of ProbeToReferenceTransformMatrix from PLUS, and found the position and quaternion is not changed at different time.
why is that?
#### By Stephen.H on 2015-07-18 09:54
I have that problem too, and i take a stupid solution to take it down : do the calibration again when i need it.
#### By Andras Lasso on 2015-07-18 09:56
Could you try to describe the problem with more details? From the description above it is not clear for me what your problem is.
#### By Jason... on 2015-07-18 10:06
Hi, Stephen that is a stupid and very trouble way.

My problem is when i finish the stylus calibration and phantom registration, i point the stylus tip at the 'M' mark on the phantom to see if its position is correct or not , and found it good.
then i save the result, turn off the program and use the new xml file to initial the peogram, pointing the stylus tip at the 'M' mark and i found its relation is not good.

Or when i finish the stylus calibration and phantom registration, i point the stylus tip at the 'M' mark on the phantom , the position is correct , and after i finish the spatial calibration, the position is wrong
#### By Stephen.H on 2015-07-18 10:14
I think the environment magnetic field should be the reason for this.
#### By Jason... on 2015-08-10 05:25
Hi, Andras

The problem is the relative position of stylusTip and phantom is not the same as the reality when I rotate the phantom or stylus after the stylus calibration and phantom registration.
And it seems that the type of sensors should be responsible for that. In prior, I use NDI Aurora Tracking system with two 6D Catheter Type 2(item ID: 610060) for probe and phantom, one 5D Catheter Type 1(Item ID: 610017) for stylus. And now, I can get rid of the problem I have mentioned before by using Aurora Mini 6DOF sensor(610029) for probe and phantom, Aurora 5DOF sensor(610006) for stylus.

The problem is taken down, but I don't know why is that(in technically).
#### By Andras Lasso on 2015-08-10 07:51
This explains everything! 5-DOF sensors don't provide full orientation information, so they are only suitable for tracking rotationally symmetrical objects (for example a needle) and only when the axis of symmetry is perfectly aligned with the sensor's missing rotation axis; or for tracking object position only.

5-DOF sensor is certainly not suitable for tracking the probe or reference. If you don't have enough 6-DOF sensors then you can fix the calibration phantom position relative to the field generator throughout the complete calibration procedure and then you don't need to track the phantom (and you can just add identity PhantomToReference and ReferenceToTracker transforms to the coordinate system list in the config file and remove the reference sensor completely).
#### By Jason... on 2015-08-10 08:21
I did use 6 DOF sensors for tracking the probe and phantom, not 5 DOF. I just change the type of the sensors. And these sensors I used are all good by testing in NDI Track software.

Do you have tested the Catheter sensors(6DOF with item ID: 610060, 5DOF with item ID:610017) with plusApplication? The different types of sensors are not in common? I don't know.
#### By Jason... on 2015-08-10 08:27
In addition, I use three 6-DOF sensors(6D Catheter Type 2, item ID: 610060) for probe, phantom and stylus. Keep the phantom and stylustip still, then rotate the stylus, and the relative of stylusTip and phantom will be changed.
#### By Andras Lasso on 2015-08-10 08:28
Maybe the small sensor is just too inaccurate. You may not see the inaccuracy if you track small objects or visualize only the sensor; but when you track a larger objects, such as the calibration phantom then a small angular error can cause large errors. You can improve results by using larger sensors, moving closer to the field generator, removing all interfering objects (the ultrasound probe may cause interference, too).
#### By Andras Lasso on 2015-08-10 08:38
After stylus calibration is completed rotating the stylus around its tip should keep the stylus tip displayed in the same position. You can verify the behavior using 3D Slicer/SlicerIGT:
display raw tool positions (StylusToTracker, ReferenceToTracker, ProbeToTracker) in 3D, verify that position and orientation tracking is consistent (create 3D model using "Create models module", apply transform to the model)
perform pivot calibration for calibrating the stylus, place the computed StylusTipToStylus transform between the generated needle model and the StylusToTracker transform, verify that the tip remains stationary when you pivot it around
load the phantom model STL file into Slicer, perform landmark registration using the Fiducial registration wizard, apply registration result to the model, verify if everything is consistent

See detailed instructions on the tutorial pages at www.slicerigt.org.
#### By Jason... on 2015-08-11 23:32
I have tested with 3D Slicer/SlicerIGT, everything is good for that two kinds of sensors, but I still have two more questions:

1) With 3D Slicer/SlicerIGT application, I use a 5-DOF sensor for tracking Stylus, tied the phantom and stylus together(in parallel) after those calibration/registration, rotate it, and then I found stylus and phantom's position is not consistent, but it's fine if just have translation(without angle change, take Tracker as reference).
2) When I use 6-DOF sensor for tracking stylus, everything is fine with 3D Slicer/SlicerIGT application, but not PLUS application.why is that? If I want to develop my own requirement in PLUS application, how should I handle it ?
#### By Andras Lasso on 2015-08-12 08:02
1) Parallel is not enough. The stylus tip must be on the untracked axis of the sensor to have a correct stylus tip position. The stylus axis of symmetry must be equal to the untracked axis of the sensor to have correct stylus position and orientation.

2) Use the 6-DOF sensor and report any specific problem that you have. If you develop a medical image computing application, I would highly recommend to use an application platform (for example 3D Slicer/SlicerIGT), because you can develop a complete application with fully customized GUI and workflow in a few months. If you start from scratch the same work takes several years.
#### By Jason... on 2015-08-12 11:49
After Stylus calibration and phantom registration with using 6-DOF sensor for tracking stylus, keep stylus tip at phantom(eg: tip at 'M' mark position) ,rotate the phantom by 90/180/270 degree, then i found stylus tip will slip away from the 'M' mark position (in reality,stylus tip is still at 'M' position, but from the model showed in SlicerIGT/plus, stylus tip has moved far away from 'M' ).

I have already complete most of functions I needed based on plus, but only the accuracy is not high enough.
#### By Jason... on 2015-08-14 04:17
I have done lots of test, and I am finally sure the Aurora Catheter Type sensor(5 or 6-DOF) is not work well with Plus and 3D Slicer/SlicerIGT. I don't know why is it. But whatever, I can solve my problem by using other type of sensors.
Thank you very much for helping me out of this.
#### By Tamas Ungi on 2015-08-14 13:57
We have used Aurora catheter type sensors recently, and there was no problem. It is also unlikely that the sensor has any effect on how Plus works, because the NDI control box hides the sensor details from Plus. Anything that comes from the NDI control box should work the same way. 3D Slicer or SlicerIGT has definitely nothing to do with the sensors, because OpenIGTLink totally hides the hardware details. Slicer doesn't even know if a real hardware or a simulator is connected. I would try to search for the problem somewhere in the control box, interface box, or sensor. Using the latest version of Plus.


## NDI Polaris Tracker
#### Posted by alyssasims93 on 2015-07-24 14:39

Hi,

I am working with the NDI Polaris tracker and wanted to know if it was possible to edit the config file for this device set (PlusServer: NDI Polaris tracker with passive markers) in order to allow the tracker to process RAS coordinates of a moving fiducial to later be stored in Matlab. If so, what changes need to be made to the config file?

Thank you for your time,

Alyssa

#### 1 Comments
#### By Andras Lasso on 2015-07-30 00:03
Yes, sure. If you know the RasToTracker or RasToReference transform then just add it to the CoordinateDefinitions section (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CoordinateSystemDefinitions.html) and broadcast the (Tool)ToRas transforms through OpenIGTLink using PlusServer (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationPlusServer.html#ApplicationPlusServerConfigSettings). To get the RasToTracker or RasToReference matrices you can use 3D Slicer and SlicerIGT (http://www.slicerigt.org/wp/user-tutorial/, tutorial U-12).


## Stylus Calibration
#### Posted by jdgreer on 2015-07-23 21:48

Hello,

I am having large errors (on the order of 10 mm) when doing a stylus calibration and I am trying to troubleshoot why this is happening.

I am using fCal 2.0 and Ascencion EM trackers for the probe, reference, and stylus. I want to sanity check a couple things:

- Does the location and orientation of the reference tracker matter? I am working under the assumption that as long as the reference tracker is rigidly attached to the phantom and well within range of the base station that this should work, but maybe this is wrong. (We built a custom fixture to attach our reference tracker to the calibration phantom since we only have model 55 Ascencion trackers, not model 800, so it is not in the same place as is shown in the tutorials.)

- Currently, our stylus only has around 5 cm of distance between tracker and tip. I am guessing this is the source of the large calibration error. (The small distance is due to the fact that we 3D printed a custom stylus and the length of objects it can print is limited. I can modify the design to make it longer, but I want to eliminate any other easy fixes before going this route.)

- Finally, is there any status indicator of the quality of the tracker signal?

Thanks in advance and sorry if the answers are obvious. I have done my best to scan through the documentation, messages, and FAQ before asking!
Joey

#### 3 Comments
#### By Andras Lasso on 2015-07-23 23:23
The stylus is tracked relative to the Reference sensor. Therefore, it is important to not move the StylusTip relative to the Reference sensor during stylus calibration (and keep the Reference sensor in the tracker's field of view).

The model 55 sensor is quite sensitive, it only works accurately in a fairly small range. fCal cannot show the quality value (you can stream the quality value to 3D Slicer and see it there), but that's not a very reliable indicator anyway. Instead, for evaluating signal strength/random noise check if the stylus on the screen jitters a lot, if it does then try to move closer to the field generator (but keep at least 5-10cm distance). For checking presence of field distortion, put a sensor at a fixed position relative to the field generator and check if the position changes and/or fix two sensors on a rigid body and move it around and see how much the relative pose is changing (if there is no distortion, the relative pose should not change at all).

5cm between the Stylus and StylusTip is enough. Don't move the stylus too fast, keep the sensors in the field of view, and pivot at least 30deg.
#### By Jdgreer on 2015-07-24 20:35
Hi Andras,

Thanks for the quick reply. It looks like it was the sensitivity of the model 55 sensor as you suggested. By re-positioning the transmitter very close to my workspace, I was able to get calibration error down to 0.5 mm.

Thanks,
Joey
#### By Andras Lasso on 2015-07-24 20:52
Great!


## Static linking to Plus
#### Posted by naimulkhan on 2015-07-22 15:01

I am trying to build Plus as a static library so that I don't have to copy over all the dlls to a new project. To do that, in CMake, I ticked "BUILD_SHARED_LIBS" off. Then configured and generated, then tried to build. However, I am getting some CMake related errors when the project gets to building of Plus-lib. Am I missing a step here? Thanks!

#### 2 Comments
#### By Naimulkhan on 2015-07-22 16:18
Here's the error I am getting
http://crunch.cs.queensu.ca/CDash/viewBuildError.php?buildid=37496
#### By Andras Lasso on 2015-07-22 18:01
I've committed a fix, see #1016. Please test and let us know if it worked (let's continue the discussion at the ticket #1016).


## NDI Aurora Tracker support
#### Posted by naimulkhan on 2015-07-15 16:36

hi there,

We have an NDI Aurora tracker. But by default aurora tracker is not supported , tried with fcal, it says "unknown device type". Do we have to get access to to PLTools space to enable aurora tracker with Plus when I build the project myself? The Windows build instructions does ask to do that, however, I haven't been able to find a way to request access to the space. Apologies if this is trivial.

#### 8 Comments
#### By Andras Lasso on 2015-07-15 16:54
To build Plus with NDI Aurora support enable PLUS_USE_POLARIS option in CMake (the name is "Polaris" because Polaris and Aurora uses the same "NDI Common API" - I've added ticket #1013 to change this name to avoid confusion in the future). You don't need to have access to any device SDKs for connecting to (and so you don't need access to PLTools repository).
#### By Naimulkhan on 2015-07-16 10:44
Thanks, that worked.

I am stuck at the next step now i.e. connecting to the sensor. Since the sensor rom is broken, we were provided a virtual rom file by NDI, which works fine with NDI provided software. I tried to modify the PlusDeviceSet_Server_NDIAurora.xml to add the following:


<DataSource Type="Tool" Id="Needle" PortName="0"  RomFile="NdiToolDefinitions/610063-5D.rom"/>



I get a warning that portname will be ignored. If I remove PortName, the warning is gone. In any case, I get the following error after a successful connection with the SCU:


|ERROR|016.619000| Invalid command| in vtkNDITracker.cxx(875)
|ERROR|016.633000| Failed to determine NDI port handle for tool NeedleToTracker|  in vtkNDITracker.cxx(557)
|ERROR|016.651000| Failed to enable tool ports| in vtkNDITracker.cxx(309)


Any idea what I am doing wrong? Thanks again for your help, really appreciate it.
#### By Andras Lasso on 2015-07-16 11:07
Plus currently supports ROM files only for wireless sensors. As managing a broken sensor with a virtual ROM file is a very rare use case, implementing support for that would have low priority for us. I would suggest you to modify the vtkNDITracker.cxx file to enable specifying a ROM file for wired sensors. We'd be happy to help if you have any further specific questions.
#### By Naimulkhan on 2015-07-16 11:09
Thanks! I found that IGSTK has this functionality implemented already, I will port some code from there into PLUS. Will contribute back if I am successful. Thanks again :)
#### By Andras Lasso on 2015-07-16 11:16
Great, thanks! Maybe you just need to change the code at two places:
- vtkNDITracker::ReadConfiguration: after the "NDI PortName and RomFile are both specified for tool" warning is logged, set toolDescriptor.WiredPortNumber anyway
- vtkNDITracker::EnableToolPorts: send ROM when it's available, even for wired tools (instead of checking for toolDescriptorIt->second.WiredPortNumber == -1, check if a ROM file is specified)
#### By Naimulkhan on 2015-07-16 15:06
It's working now, thanks a lot for the guidance!
#### By Andras Lasso on 2015-07-16 19:36
Were you able to make it work using Plus? What changes did you have to make?
#### By Naimulkhan on 2015-07-20 09:58
The changes you suggested were good enough. Attached is the modified vtkNDITracker
vtkNDITracker.cxx	35.9 KB


## PLUS bulid with 3D Slicer
#### Posted by Stephen.H on 2015-07-18 09:51

I have a problem when building with Slicer.

I take the follow order: turn on PLUSBUILD_USE_3DSlicer option and set the PLUSBUILD_SLICER_BIN_DIRECTORY to your 3D Slicer binary folder.
configure and error comes out:
CMake Error at CMakeLists.txt:285 (MESSAGE):
Unable to find Slicer at D:/Program File/Slicer 4.4.0/bin directory.
Please verify configuration

I have no idea about this, anyone help?

Thanks in advanced

#### 5 Comments
#### By Andras Lasso on 2015-07-18 09:54
PLUSBUILD_USE_3DSlicer option is only needed if you build a loadable module for 3D Slicer that uses Plus. Is this what you are trying to do?
#### By Jason... on 2015-07-18 09:57
(Comment removed)
#### By Stephen.H on 2015-07-18 09:59
yeah i'm trying to develop my own module for slicer based on plus
#### By Andras Lasso on 2015-07-18 10:03
To build Slicer loadable modules, you need to build Slicer from source and specify your Slicer build tree in Plus PLUSBUILD_SLICER_BIN_DIRECTORY.
#### By Stephen.H on 2015-07-18 10:09
ok, i get it


## Interson USB probe and ThorLabs video missing dlls
#### Posted by Tamas Heffter on 2015-07-10 18:27

When PLUS_USE_INTERSON_VIDEO option is enabled a missing wdapi1010.dll error message displayed when tried to run e.g. fCal.
Dependency walker referenced this dll under usbprobe.dll (PLTools\Interson\iSDK2012_4.83.4363\lib\32bit\USBprobe.dll)

When PLUS_USE_THORLABS_VIDEO option is enabled a missing TLCCS_32.dll error message displayed when tried to run e.g. fCal.
Please add ThorLabs shared libraries to External_Libraries_Install variable in DataCollection CMakeList file

Turning off these options resolved the missing dll errors.
Branch: Plus-2.2
Architecture: Windows x86

#### 2 Comments
#### By Andras Lasso on 2015-07-10 21:44
Yes, this is the behavior of the ThorLabs and Interson and some other SDKs and that's why there are so many Plus package editions.

These "missing" DLLs are part of the device driver, which are installed in Windows system libraries by the driver installer and so cannot be shipped with the Plus package. The only solution compile Plus with support for these devices and run Plus applications without installing the drivers would be to delay-load DLLs. Then only those DLLs would be loaded that are actually used. See detailed description at #1005.
#### By Tamas Heffter on 2015-07-13 16:15
I see. Delay-load dlls seems to be a good option, this is what we use also with the RUF matlab library in a different project. Thanks for the clarification.


## DataCollector devices
#### Posted by Tamas Heffter on 2015-07-03 11:32

Hi Guys,

vtkDataCollector devices are gets created in ReadConfiguration method only and unfortunately you don't handle it properly when ReadConfiguration gets called multiple times.
Either clean devices function would be useful, or ReadConfiguration method should clean devices before starts creating them based on the configuration file.
I'm using the latest stable branch, branches/Plus-2.2/PlusLib rev 4207

You can test it something like this:
LOG_INFO("Reading devices first time...");
if (this->m_DataCollector->ReadConfiguration(vtkPlusConfig::GetInstance()->GetDeviceSetConfigurationData()) != PLUS_SUCCESS)
{
  LOG_ERROR("Reading devices first time failed");
  return PLUS_FAIL;
}
LOG_INFO("Reading devices second time...");
if (this->m_DataCollector->ReadConfiguration(vtkPlusConfig::GetInstance()->GetDeviceSetConfigurationData()) != PLUS_SUCCESS)
{
  LOG_ERROR("Reading devices second time failed");
  return PLUS_FAIL;
}

Any thoughts how should I handle this?

Thanks,
Tomi

#### 13 Comments
#### By Adam Rankin on 2015-07-03 11:41
What is the use case for this code?
#### By Tamas Heffter on 2015-07-03 11:46
I'm using the library on a third party software and we keep DataCollector instances when we select different config files (or the user can use the same config file again).
#### By Adam Rankin on 2015-07-03 12:02
Ok! I don't think we've ever "re-used" a data collector before. We should add this support.

I would recommend that a data collector should be cleaned when a function is explicitly called, and we can discuss whether a second call to ReadConfiguration calls this clean function or returns an error.

@lassoan Thoughts?
#### By Adam Rankin on 2015-07-03 15:45
I have an implementation that protects against this and allows resetting of the data collector. @heffter will this do?
#### By Andras Lasso on 2015-07-03 16:36
The "read" method should work as a sequence of "set" methods that read the input from an external source. It should be an update only, the devices should not be deleted and recreated because some settings might be lost.
#### By Tamas Heffter on 2015-07-03 17:09
It sounds good to me, we just need access to devices, so we can remove them when needed.
#### By Tamas Heffter on 2015-07-06 11:22
I have another idea, that might solve my issue too and makes the code more robust. Sounds like you want to keep all the devices, and just keep adding new devices when we call ReadConfiguration. However, I miss the device ID check in ReadConfiguration. You just check the IDs in the actual config file, and you don't check the already defined IDs in the DeviceCollection list which could lead to have the same devices defined multiple times (run the suggested test from the first message). So adding the following check would make sense to me:
~~~~
bool deviceIDdefined = false; 
for( DeviceCollectionIterator deviceIt = this->Devices.begin(); deviceIt != this->Devices.end(); ++deviceIt)
{
  if ( STRCASECMP((*deviceIt)->GetDeviceId(), deviceId) == 0 )
  {
    deviceIDdefined = true; 
    break;
  }
}

if ( deviceIDdefined )
{
  // Either log that the ID is already defined or update it's settings if you want, 
  // but do not return with PLUS_FAIL if possible
  continue; 
}
~~~~
#### By Adam Rankin on 2015-07-06 13:11
Does that fit the use case? You want to add more devices to an existing set of devices? If that is the use case, then this solution will work, but calling readconfiguration twice should be heavily documented.

I think PlusApp destroys the data collector (thus disconnecting/deleting all the devices) before connecting to a different config file. This is how it handles repeated calls to readconfiguration.
#### By Tamas Heffter on 2015-07-06 18:23
Yes, I think it would fit the use case for now, I've changed the design on our side. The device ID check still would be a useful check in my opinion. Thanks for your support.
#### By Adam Rankin on 2015-07-06 18:25
Ok, I think an entire check for repeated calls to ReadConfiguration should be made. I will add it.

Thanks for bringing this up!
#### By Tamas Heffter on 2015-07-09 14:44
I have another question regarding datacollector devices. If I already have a DataCollector instance with some (1 or more) devices defined and I want to connect to another device that was not defined in the original configuration file, how could I connect to the new device without disconnecting from rest of the devices?

Here is a scenario:
Client1 need data from Device1 Channel1 -> We connect to Device1 and transder data from Channel1 (it was defined in the config file)
Client2 connected and request data from Device1 Channel2 -> We use the already connected Device1 Channel2 stream (it was defined in the config file)
Client3 connected and request data from Device2 Channel1 that was not defined in the original DataCollector config file -> How can we connect to Device2 and start recording without breaking connection with Client1 and Client2?
#### By Adam Rankin on 2015-07-09 14:47
Currently this is not supported. Submit a feature request ticket and Andras and I can figure out an acceptable solution!
#### By Tamas Heffter on 2015-07-09 15:08
Ok, #1012 added to keep track of the request


## PlusServer and PlusServerLauncher
#### Posted by Tamas Heffter on 2015-07-09 12:54

When BUILD_TESTING is not enabled, it doesn't build PlusServer, but PlusServerLauncher still tries to start the process, however logging does not tell exactly what could be the issue.
It would be good to notify the user, if the plusServerExecutable file does not exist (in bool PlusServerLauncherMainWindow::startServer), or build PlusServer executable even if BUILD_TESTING is off.

Here is the output from the log using Plus 2.2 branch:
|ERROR|005.483000| Server process error: FailedToStart| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(326)
|ERROR|005.483000| Failed to start server process| in ..\..\PlusApp\PlusServerLauncher\PlusServerLauncherMainWindow.cxx(147)

#### 4 Comments
#### By Andras Lasso on 2015-07-09 13:31
Actually, PlusServer is not a test tool anymore, so the CMakeLists.txt should be changed to always build it. Could you make that change? Thanks!
#### By Adam Rankin on 2015-07-09 13:32
On it. #1011
#### By Adam Rankin on 2015-07-09 13:33
In my brain I was like "It should be built regardless of testing scenario... !?!?" but now this makes sense.
#### By Tamas Heffter on 2015-07-09 13:47
Thanks!


## Plus Matlab Interface
#### Posted by Siavash Khallaghi on 2015-07-06 20:01

Hello,

I have a question regarding the MatlabOpenIGTLinkInterface. I can see how transforms are passed using TCP/IP (?), is it also possible to dynamically adjust imaging parameters using the MatlabOpenIGTLinkInterface in a similar manner?

#### 2 Comments
#### By Andras Lasso on 2015-07-06 22:36
You can send OpenIGTLink messages through OpenIGTLink (which is a very simple TCP/IP based protocol for IGT). However, right now you cannot control imaging parameters in Plus using OpenIGTLink commands. It seems to be a common need (see #867), so it'll be implemented at some point. If you have time that you can contribute to work on this (or it is part of the work package that we are going to implement for Purang) then we can give higher priority to this.
#### By Siavash Khallaghi on 2015-07-07 12:34
I do not know if this is part of the collaboration package between Queen's and UBC as I am no longer directly involved in projects at UBC. There are a couple of new students that are proficient in Matlab but have had limited exposure to C++, and they would like to use Plus for their projects. I was wondering if it was possible to do so with the Matlab interface.

I would love to help with OpenIGTLink, but my new job has me busy at the moment. But good luck with #867! :)


## Building issues
#### Posted by Dzenan Zukic on 2015-07-02 13:08

I can't build the current revision, the errors are related to ITK, such as:
error C1083: Cannot open include file: 'ITKIOImageBaseExport.h': No such file or directory [C:\Dev\PlusBuild-bin64\PlusLib-bin\src\PlusCommon\vtkPlusCommon.vcxproj] C:\Dev\PlusBuild-bin64\itk\Modules\IO\ImageBase\include\itkImageIOBase.h 20

#### 5 Comments
#### By Adam Rankin on 2015-07-02 13:09
I'll check it out.

What hardware options do you have enabled?
#### By Adam Rankin on 2015-07-02 14:23
494 warnings, 0 errors. Any modifications or hardware options enabled?
#### By Andras Lasso on 2015-07-02 21:02
Does the missed header file exist? Have you built ITK in the configuration that you are trying to build PlusLib (debug/release)? What configuration you are trying to build?
#### By Dzenan Zukic on 2015-07-03 10:03
I built it successfully on another computer, and release 2.2 on the ultrasound computer. It must have been due to unclean build directory and possibly mix-up of SVN versions. Sorry for false alarm,
#### By Adam Rankin on 2015-07-03 10:04
No problem! Better safe than sorry.


## Problem printing a 3d model
#### Posted by gkno on 2015-07-02 18:03

Hello,

I've been trying to print the "Phantom for freehand spatial ultrasound calibration for deep structures" using the stl files, however it seems to be some holes because some triangulation in the surface are missed. I was wondering if it is possible to have the original files from where the .stl files were generated. Or whom should I contact about this.

Thanks a lot

#### 1 Comments
#### By Andras Lasso on 2015-07-02 20:22
Link to the source CAD files are in the ID column of the Plus model catalog.


## Template interface for adding a new device to PLUS
#### Posted by Mikael Brudfors on 2015-07-02 05:08

Hello PLUS developers,

Is there a template interface for adding a new device to PLUS?

Thank you,

Mikael

#### 2 Comments
#### By Andras Lasso on 2015-07-02 08:21
We usually pick an existing device that is most similar to the new one and clone&modify it. For bone enhancement there is a work-in-progress device that you can modify as is (no need to clone it).
#### By Mikael Brudfors on 2015-07-02 09:01
Okay, that is what I thought.

No, this work is not related to the bone enhancement.

Thank you!


## No effect when using: ClipRectangleSizeClipping ClipRectangleOriginClipping
#### Posted by wpliu25 on 2015-06-29 17:15

Hi,

I'm running the example vtkDataCollectorVideoAcqTest, using a 1080 Mmf video and would like to crop the image in order to save smaller images. I've configured the ClipRectangleSizeClipping ClipRectangleOriginClipping parameters as below but the original size images are saved. How do I achieve cropping (half the image, centered at optical center)?

In a semi-related question: If the images are RGB, how do I create a grayscale mask?

Thanks,
Wen

<Device
Id="VideoDevice"
Type="MmfVideo"
FrameSize="1920 1080"
VideoFormat="YUY2"
CaptureDeviceId="1" >
<DataSources>
<DataSource Type="Video" Id="Video" PortUsImageOrientation="MF" ClipRectangleOriginClipping="0 0 0" ClipRectangleSizeClipping="960 540 0"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="VideoStream" VideoDataSourceId="Video" />
</OutputChannels>
</Device>

#### 2 Comments
#### By Andras Lasso on 2015-06-30 14:00
The attribute name is incorrect (no "Clipping" at the end). Have a look at the MMF video source config file examples to see how to configure grayscale image acquisition.
#### By Wpliu25 on 2015-06-30 17:24
Thanks Andras! This worked nicely!


## IGTL Matlab Receive Images
#### Posted by wpliu25 on 2015-06-18 10:27

Hi,

I'm capturing video (Mmf) and tracking (Polaris) info that I would like to stream to Matlab through OpenIGTlink to process online. From the MatlabOpenIGTLinkInterface I was able to run and use the transform scripts without a problem. Are there similar scripts available for images? Should the video data be streamed as type 'image' or 'video'?

Thanks,
Wen

#### 3 Comments
#### By Andras Lasso on 2015-06-18 10:58
We are developing this more comprehensive interface that supports more message types, including images:
https://github.com/lassoan/MatlabOpenIGTLink/

However, image transfer is somewhat slow. We plan to switch from Java sockets to the recently added Matlab tcpclient functions, which supports block transfer and so should be 10-100x faster for longer messages. It would be great if you could help with that.
#### By Wpliu25 on 2015-06-29 17:18
Hi Andras, I would be interested in expanding the interface. What should I look at to start?
#### By Andras Lasso on 2015-06-30 14:06
https://github.com/SlicerIGT/MatlabOpenIGTLink/blob/master/src/OpenIGTLinkMessageReceiver.m may work already for image receiving. If it's too slow then you need to implement what is described at https://github.com/SlicerIGT/MatlabOpenIGTLink/issues/2


## Set camera device parameters
#### Posted by wpliu25 on 2015-06-18 17:16

Hi,

I'm using an Intel Real Sense 3D camera as a vtkMmfVideoSource and its auto-white balance is over saturating features in certain settings. How do we either configure white balance or turn off the auto setting? Also the only video formats detected are YUY2 and the video renders in grayscale. How can this be changed to RGB? How is the grayscale image being converted? Can these parameters set in Plus, VTK, Microsoft, or at the level of device drivers?

Thanks,
Wen

#### 2 Comments
#### By Andras Lasso on 2015-06-18 17:57
For color image acquisition set ImageType="RGB_COLOR", for a complete example see:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceMicrosoftMediaFoundation.html

To configure white balance and other exposure parameters you need to use the software that comes with the camera (Plus, VTK, Windows does not know about it). Windows may be able to show you a device setup dialog box (and this is used by Skype and other similar software that uses imaging devices).
#### By Wpliu25 on 2015-06-29 17:16
Thanks Andras!


## PlusServer and Ultrasonix
#### Posted by jannebea on 2015-02-25 06:00

Hello.

I’ve been looking at the Plus server to see if we might be able to use it to acquire images and tracking data (using a OpenIGTLink connection) from an UltrasonixMDP with the GPS module installed. It seems to be a very nice framework which I would love to use if I can.

From what I have been able to gather, I can get both images and transforms, which is good news. :)

Short background:
I have a client which I would like to connect to the Ultrasonix machine over OpenIGTLink to gather images and tracking data of a ultrasound probe and a needle using ulterius (because I would like to run the needle application inside Exam at the same time).

I have been reading some source code, both in the PlusServer/Lib and ulterius, and I’ve also tried finding answers to my questions on the forums, but I have several questions have have not been able to find answers for.

1. I want to run the Exam software while querying ulterius (SDK version:6.1.1) for both image and tracking data. If I understand the code correctly, it seems PlusServer don’t use ulterius for acquiring tracking data. From what I have read on the forums I understand that I have to uinstall the GPS license to free up the tracking drivers for the PlusServer. This is not ideal for me because I would like to be able to run the needle assistant in Exam at the same time. Why are you not using ulterius for getting tracking data? Is it because ultrerius only gives tracking data for only two connectors?

2. Which transforms will I get? Which coordinate systems do you operate in? I’m planning to track a probe and a needle, and to use the tracker itself as reference. (I realise there might be some accuracy issues with this approach.)

3. Is the image and tracking data synced in some way?

4. Can I get additional probe data? Like the size and shape of the ultrasound probe sector? Are there sent any packages with this data? I know I can get this data using ulterius directly. I need this information because I want to create a clipping mask equivalent to the probe sector in my client.

5. How much of the ultrerius api is there support for using the plus server? Can I put the Ultrasonix machine in any imaging mode and request any (of the available) data types? For example can I get doppler data? I tried to acquire doppler data on the Ultrasonix machine and stream the data into 3DSlicer using SlicerIGT and PlusServer, but I could not get any color. (I’m new to 3DSlicer, SlicerIGT and PlusServer, so bear with me if I missing something.)

I realise I’m asking many questions, but I hope someone can help me.

In advance, thanks!

#### 29 Comments
#### By Andras Lasso on 2015-02-25 09:05
1. Plus directly connects to the Ascension tracking device (SonixGPS) and only one software can connect to the device at a time, so the Exam software and Ulterius cannot access the tracker at the same time and therefore you need to disable the GPS license. It would be quite simple to implement tracking data receiving in Plus through Ulterius, We did not implement tracking data acquisition through Ulterius option because we did not need it (we have much more advanced navigation solutions using SlicerIGT - www.slicerigt.org, during intra-operative use we often cover the whole ultrasound with sterile drape, we don't even see the Ultrasonix screen, we use many other tracker devices) and the Exam software/Ulterius had some limitations (when we started working on tracked ultrasound SonixGPS did not even exist, then it did not have Ulterius interface, and even then some limitations remained - using only needle and probe sensors, no temporal synchronization, etc).

Nevertheless, I can imagine applications where keeping SonixGPS features in the Exam software enabled, and the implementation in Plus would be quite simple, so if you are willing to spend some time implementing it (probably a few 10 lines of code) then we would be happy to help.

2. In Plus you can get any transforms. Plus can combine, concatenate, invert all known transforms (varying transforms that it gets from the tracker, fixed calibration and other transforms) just from their names. This is enabled by the consistent naming convention that we apply throughout the toolkit (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CoordinateSystemDefinitions.html#TransformationMatrix). For example, if you need Needle position in Reference coordinate system then you ask for NeedleToReference. If you need it relative to the probe then you ask for NeedleToProbe.

3. Yes, there is a high-accuracy temporal calibration (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmTemporalCalibration.html), timestamp jitter filtering, and temporal interpolation of tracked data to ensure consistency between imaging and tracking data. Temporal calibration is not needed for needle guidance (motion is slow and the operator only needs the latest image and position) but essential for volume reconstruction.

4. You can only set parameters: parameters that are specified in the device set configuration file are sent to Ultrasonix on connect (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html). Clipping fan and rectangle can be set in the configuration file (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html) and it is only used for volume reconstruction. Plus can also detect the actual clipping fan based on the image content (https://www.youtube.com/watch?v=ss7ZTRTNWio), so for example if only the center of the transducer touches the skin surface then the sector size is reduced automatically in real-time.

5. We mostly use B-mode images, sometimes RF data. We have not used color images with Ultrasonix but color images are fully supported by the infrastructure, so it would just need some small changes in the Ultrasonix device class in Plus to make it work.
#### By Jannebea on 2015-02-26 06:44
Hello again!

First of all I would like to thank you for your quick and thorough answer.

I’ve been discussing your response with my team and we’ve decided try out the PlusServer.

We will have to solve all the challenges mentioned in my previous post, but we’ll do so in iterations. We’re thinking to do the following:

1. Run the PlusServer “as is” on the Ultrasonix machine with a configuration for probe and needle, turn off the SonixGPS license to begin with
2. Implement connecting to the PlusServer and handling of the incoming packages in our client
3. Make changes to the PlusServer so that we can get tracking data from ulterius and be able to reinstall the GPS license on the Ultrasonix machine
4. Make changes to the PlusServer so that it can send doppler images

When we get to task 3 and 4 we would greatly appreciate any help.

One question still remains for us. What to with the clipping mask for the probe sector? Currently we have a simple OpenIGTLink server (this is the one want to replace with the PlusServer) that sends images from ulterius using standard OpenIGTLink packages and that sends probe sector information in a “homemade” OpenIGTLink package. This way we get a package with probe information each time someone, for example, changes the depth on the scanner. With this solution we don’t need to do any image processing to find the clipping mask in our client application.

To solve this when using the PlusServer we could use image processing in our client to calculate the clipping mask or just “hardcode” some presets for our probes, but what we would really like would be some “parameter” packages transferring the PlusServer config at connect and new “parameter” packages when someone adjusts something on the scanner. I don’t seen any packages suitable for sending such parameter information in OpenIGTLink and I am guessing this will make such a solution out of reach within the PlusServer. Please correct me if I’m wrong.

I’m not sure which solution we will go for, but if you know of any plans that will make parameter packages available in the future I’d love to hear about it. :)

Btw, I realise I forgot to introduce myself. I’m Janne Beate Bakeng, senior software engineer at SINTEF, Trondheim, Norway. **Hello**
#### By Andras Lasso on 2015-02-26 10:09
Hi Janne,

Thanks for the introduction and welcome to the Plus community.

The steps that you described sound reasonable and we'd be happy to assist you with steps 3 and 4.

There are several options for sending clipping information:
Option A: Create alpha channel by thresholding the image data: If you do clipping for display then you need to set up an alpha channel anyway. The idea is that you can easily obtain the alpha channel by thresholding the image data with a value of 0, because with a few exceptions only the pixels outside the clipping rectangle/fan are exactly 0. It is a trivial operation (if you work in VTK then you can use the vtkImageThreshold to get the alpha channel from the image and use vtkImageAppendComponents to append it as an alpha channel to your grayscale or RGB image). We do this in all of our applications in 3D Slicer (for example, see http://www.slicerigt.org/wp/needle-interventions-training/).
Option B: Instead of using the standard OpenIGTLink IMAGE message use the custom OpenIGTLink message type defined in Plus: TRACKEDFRAME. This message contains an image and a list of custom data fields that can store transforms, strings, or any other data (encoded as an XML element). You can add any custom data field to an image frame with a single line of code, no other modifications are needed.
Option C: Transfer the clipping fan information in one or more TRANSFORM OpenIGTLink messages. Repurposing TRANSFORM message type is not very nice but you may prefer this if you want to avoid using a custom message type and it is very simple to implement (something similar is done for storing wobbler probe motor position data in https://www.assembla.com/code/plus/subversion/nodes/4016/trunk/PlusLib/src/DataCollection/SonixVideo/vtkSonixPortaVideoSource.cxx#ln379). You can store 6 independent double values in a transformation matrix (fan origin x/y, fan angle min/max , fan radius min/max), so in one transform you can send all the data.
Option D: Create the alpha channel in Plus and send an image with alpha channel. A drawback is that you send the mask with each image (adding some data overhead) and not many OpenIGTLink clients expect to receive data with an alpha channel.
Option E: Send an OpenIGTLink STRING message whenever depth is changed. The message could contain an XML element that describes depth, sector, clipping, etc. information. This requires some enhancements in the message passing implementation in Plus, but we may implement this anyway to enable other features.

If you give more information about how you would use the clipping information, how much custom OpenIGTLink message types are acceptable, etc. then we can help in choosing the best option.
#### By Jannebea on 2015-03-02 05:43
Hello again!

Thanks for suggesting serveral options for sending clipping information.

Actually we don't send the clipping mask from our current OpenIGTLink server, but we send a information about the probe each time someone changes parameters on the scanner, like for example the depth, this information is used to calculate the clipping mask in our client application. The clipping mask is used for several things, like 3D reconstruction, displaying, in 2D and 3D, the probe with live ultrasound video in the attached probe sector, among other things. We also display the information about the probe directly to the user.

We would like to stick to the standard OpenIGTLink messages as long as we can, but if we cannot solve our problems, we might consider custom types. After discussing the options you suggested with my team we agree that option E seems to be the most appropriate way to go, for us. This give us a lot of flexibility as we can receive messages for several parameters we might want to react to.

You say that this requires some enhancements in the message passing in Plus and that you might implement this anyway. Could you elaborate on this? I'm curious as to what changes are required and what the time line might be.
#### By Andras Lasso on 2015-03-03 09:08
The implementation of the necessary enhancements is in progress, expected to be ready before the end of this week. You can monitor the status in #970.
#### By Andras Lasso on 2015-03-03 20:35
The implementation is ready. Now any custom frame fields can be streamed as an OpenIGTLink STRING message. For example, the image clipping fan and other parameters can be set as a custom frame field when adding the image to the recording buffer and that field is sent to the client as a STRING message.
#### By Ersmistad377977 on 2015-04-21 06:32
Great, thank you for your assistance.

Ideally, I think the image border should be removed on the server side, to avoid having probe information on the client side. Is this possible today? If so, how do we do this and how to handle changes in depth?

Does these new developments with the STRING message mean we can send change in depth by only defining the following in the configuration file:
<StringNames>
<String Name="Depth" />
</StringNames>

Is that all, or is more needed?
What other information can be get from the L14-5 probe?

Regarding the spacing in the IMAGE messages. How is it calculated in PLUS? It seems to be related to the Embedded transform.
Is it possible to get the actual pixel spacing somehow. We are using the L14-5 probe.

Cheers
- Erik Smistad, SINTEF
#### By Andras Lasso on 2015-04-21 21:58
The image border can be removed on the server side. You can either set a fixed rectangular region (using the ClipRectangleOrigin, ClipRectangleSize attributes of the DataSource element in the configuration file) or calling SetClipRectangleOrigin, SetClipRectangleSize methods of the DataSource object from the Device object.

In addition to writing <StringNames> <String Name="Depth" /> </StringNames> into the config file you also need to add a few lines to vtkSonixVideoSource to observe the depth (in vtkSonixVideoSource::vtkSonixVideoSourceParamCallback, store it in a member variable) and then save it as a custom field into each frame in vtkSonixVideoSource::AddFrameToBuffer (at aSource->AddItem). It is just a couple of lines of code - let us know if you would like to implement it as a learning exercise, or if you prefer that we do it (it can be ready by Thursday).

We compute spatial calibration (transform between the Image and the Probe sensor coordinate systems) using fCal for a particular depth and use that. We did not encounter a navigated procedure where it was necessary to change the depth dynamically during the intervention: we could always just prepare 2-3 presets (for different patient sizes) in advance, then at the beginning of the procedure choose one and use that throughout the whole intervention.

If you prefer, you can query the spacing and other scan conversion parameters from the Ultrasonix system (http://www.ultrasonix.com/wikisonix/index.php/Exam_B-SCVT) and send it the same way as the depth information. Then you can freely change the depth value on the ultrasound system and recompute the calibration matrix in the client.
#### By Andras Lasso on 2015-04-22 14:18
Sending of depth, pixel spacing, and transducer origin is now implemented.
See example configuration file here: https://www.assembla.com/code/plus/subversion/nodes/4111/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_SonixTouch_L14-5.xml
Implementation details: #986
Updated Plus package and documentation (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html) will be available in the next nightly release.
#### By Ersmistad377977 on 2015-04-23 06:55
Great. Thank you some much for the rapid reply and implementation. We will test it out on our setup and let you know how it works.
#### By Ersmistad377977 on 2015-04-27 07:01
We have tested the latest version and we now get the string messages, and the clipping works for the initial depth specified in the configuration file.

The IMAGE message already has a field for the pixel spacing. Is there any reason for not following the IGT link protocol and put this information in this message?
If not, how can we put the pixel spacing information into the IMAGE message?
#### By Andras Lasso on 2015-04-27 09:15
You can embed this information to the image message now. If you specify ImageToTransducerTransformName="ImageToTransducer" (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html) then you can embed the ImageToTransducer transform (that contains the spacing and origin information) into the image message by setting EmbeddedTransformToFrame="Transducer". I have not tested this feature, so it would be help if you could test it.

Note that if fCal will compute the TransducerToProbe transform if you set ImageCoordinateFrame="Transducer" and Plus can combine ImageToTransducer (coming from SonixVideo), TransducerToProbe (fixed transform, computed by fCal), ProbeToTracker (coming from the Tracker) and any other transforms. Therefore, you can embed not just ImageToTransducer but also ImageToReference, ImageToTracker, etc. transforms into the image, which will all have correct values, even if depth is changed.
#### By Ersmistad377977 on 2015-04-27 10:18
I tried it now, but it did not work. The error message was that it could not find the transform.

EDIT: OK, I see it's something you implemented just now.. I will try it out again tomorrow.
#### By Andras Lasso on 2015-04-27 11:26
Yes, these changes will appear in tomorrow's nightly build.
#### By Ersmistad377977 on 2015-04-28 03:34
I just tested it and it works. Once again, thank you.
#### By Andras Lasso on 2015-04-28 08:44
Great! Thanks for testing.
#### By Ersmistad377977 on 2015-05-21 10:11
Hi again

We have some more questions regarding the information in the Image message:

Consider the setup in which the EmbeddedTransformToFrame is set to Transducer.

1) When ImageToTransducerTransformName="ImageToTransducer" and ImageGeometryOutputEnabled="TRUE" is set on the Device, we get an Y offset of 20 mm. Why is this on Y, should it not be on X? The Y axis is defined as the axis far from the probe (UF).

2) If ImageToTransducerTransformName and ImageGeometryOutputEnabled are NOT set, we get an X, Y and Z offset which is the dimension of the image divided by 2, what is the logic of this?

3) The spacing we get from the image message is "0.087, 0.082, 0.087", while the spacing we get from the string message is "0.087 0.087". If the latter is correct, should not the spacing in the image message be "0.087, 0.087, 1" and where did the 0.082 come from?

4) Are there floating point errors when these transformations are put together? Because if we set a calibration matrix in the config file and EmbeddedTransformToFrame is set to Probe, what we get from the image message is slightly different.

Thanks for you help.
#### By Andras Lasso on 2015-05-21 11:32
> When ImageToTransducerTransformName="ImageToTransducer" and ImageGeometryOutputEnabled="TRUE" is set on the Device, we get an Y offset of 20 mm. Why is this on Y, should it not be on X? The Y axis is defined as the axis far from the probe (UF).

Where did you get this offset?

> If ImageToTransducerTransformName and ImageGeometryOutputEnabled are NOT set, we get an X, Y and Z offset which is the dimension of the image divided by 2, what is the logic of this?

Where do you get these offset values?

> The spacing we get from the image message is "0.087, 0.082, 0.087", while the spacing we get from the string message is "0.087 0.087". If the latter is correct, should not the spacing in the image message be "0.087, 0.087, 1" and where did the 0.082 come from?

It comes from the computations described here:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html

The root cause of the issue is the different y spacing in the "calibration matrix" provided by Ultrasonix (http://www.ultrasonix.com/wikisonix/index.php/GPS_Data_Collection). The norm of the calibration matrix corresponding to x vector (third column) is 1.0, the norm corresponding to y (second column) is 0.9478. Most probably it's a mistake (both should be 1.0), maybe you could ask on the Ultrasonix research forum why it is so.

> Are there floating point errors when these transformations are put together? Because if we set a calibration matrix in the config file and EmbeddedTransformToFrame is set to Probe, what we get from the image message is slightly different.

Yes, of course there are always floating point inaccuracies. The "calibration matrix" values provided by Ultrasonix have 4 digits after the decimal point, so you can expect differences after 3-4 digits. Does the difference look significant?
#### By Ersmistad377977 on 2015-05-21 13:59
The offsets are from the translation part of the 4x4 transformation matrix in the image message.
#### By Andras Lasso on 2015-05-21 14:30
> When ImageToTransducerTransformName="ImageToTransducer" and ImageGeometryOutputEnabled="TRUE" is set on the Device, we get an Y offset of 20 mm. Why is this on Y, should it not be on X? The Y axis is defined as the axis far from the probe (UF).

For example an ImageToTransducer transform matrix that I get looks like this:

0.087 0 0 -19.401
0 0.087 0 0
0 0 0.087 0
0 0 0 1

The x offset is about 20mm, there is no Y offset.

Configuration parameters:

<Device
Id="VideoDevice" Type="SonixVideo" AcquisitionRate="30" LocalTimeOffsetSec="-0.2976" IP="127.0.0.1"
AutoClipEnabled="TRUE"
ImageToTransducerTransformName="ImageToTransducer"
ImageGeometryOutputEnabled="TRUE" > ... </Device>

If you send your configuration file then I may be able to tell why you see a different result.

> If ImageToTransducerTransformName and ImageGeometryOutputEnabled are NOT set, we get an X, Y and Z offset which is the dimension of the image divided by 2, what is the logic of this?

If you don't set the ImageToTransducerTransformName then the "Transducer" coordinate system will be unknown, so Plus will not be able to send the image. If you attach the config file then I can investigate more.
#### By Andras Lasso on 2015-05-21 14:37
What may be confusing for you that in OpenIGTLink messages the image coordinate system origin is the center of the image. See specification here:
http://openigtlink.org/protocols/v2_image.html

If you use an image coordinate system that has origin in the corner then you need a transformation similar to the one in
vtkPlusIgtlMessageCommon::UnpackImageMessage:

// Save the transform that is embedded in the IMAGE message into the tracked frame
// igtlMatrix origin is in the image center
// vtkMatrix origin is in the image corner
vtkSmartPointer<vtkMatrix4x4> igtlMatrix = vtkSmartPointer<vtkMatrix4x4>::New();
{
igtl::Matrix4x4 igtlMatrixSource;
imgMsg->GetMatrix(igtlMatrixSource);
for ( int row = 0; row < 4; ++ row )
{
for ( int col = 0; col < 4; ++ col )
{
igtlMatrix->SetElement(row, col, igtlMatrixSource[row][col]);
}
}
}
vtkSmartPointer<vtkTransform> igtlToVtkTransform = vtkSmartPointer<vtkTransform>::New();
igtlToVtkTransform->Translate( -imgSize[ 0 ] / 2.0, -imgSize[ 1 ] / 2.0, -imgSize[ 2 ] / 2.0 );
vtkSmartPointer< vtkMatrix4x4 > vtkMatrix = vtkSmartPointer< vtkMatrix4x4 >::New();
vtkMatrix4x4::Multiply4x4( igtlMatrix, igtlToVtkTransform->GetMatrix(), vtkMatrix );
trackedFrame.SetCustomFrameTransform(embeddedTransformName, vtkMatrix);

(https://www.assembla.com/code/plus/subversion/nodes/4146/trunk/PlusLib/src/PlusOpenIGTLink/vtkPlusIgtlMessageCommon.cxx)
#### By Ersmistad377977 on 2015-05-21 16:07
That explains a lot! Thank you.
#### By Ersmistad377977 on 2015-06-22 05:47
Hi again.

We have now been using Plus with our ultrasonix setup and it seems to work very well.
However, we have one issue still. The automatic cropping (AutoClipEnabled="TRUE") crops incorrectly if the depth is changed on the scanner.
Is it possible to fix this somehow?
#### By Andras Lasso on 2015-06-22 05:57
The image clipping rectangle is static so that we can allocate all memory for the image buffer at once. You can set the clipping to a rectangle that covers the depth range that you use (it will have black borders depending on the aspect ratio of the image). We could implement dynamic reallocation of the image buffer, but we have not found this to be an issue for our applications so far. Note that you can exclude black borders (and shadows) from volume reconstruction by setting the PixelRejectionThreshold attribute in the volume reconstructor to 1 or above.
#### By Andras Lasso on 2015-06-22 05:59
The current behavior is consistent with the specification: "Image will be clipped to the region of interest that was specified at the time when the connection to the device was established" (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html)
#### By Ersmistad377977 on 2015-06-22 06:19
In our applications, which are intra operative procedures, the operator will often want to change the depth.
So for us this is quite crucial.
Shouldn't it be relatively easy to detect if the depth has changed, and if so, reallocate the image buffer. When there is no change, use the current buffer.
#### By Adam Rankin on 2015-06-22 06:31
The ultrasonix SDK does not work very cleanly with calling GetDepth on the same callstack as the new image callback. I had to asynchonously update metadetails.

I got it to work, but it was not a clean implementation. I'm afraid the implementation has been lost but if you want to reimplement it I could provide some information.
#### By Tamas Ungi on 2015-06-22 06:42
Andras made some updates recently. I've seen tracked ultrasound (using Ultrasonix gps) changing depth continuously, and the tracking (probe calibration) was always correct. It is very recent, so I'm not sure if the example config file is shared already or not. But it is working nicely.
#### By Andras Lasso on 2015-06-27 10:42
For Ultrasonix there are several options to do without dynamic image clipping (for example, you can just clip the image by intensity using the PixelRejectionThreshold attribute, http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html), but I understand that dynamic clipping would be more convenient. Also, multiple groups asked for this feature for framegrabber-based systems, where there is no simple alternatives are available. I've added a ticket to track this request (#1008), but this is several-week long development that we cannot start before end of August. However, if you were interested and you have time, you could try to work on this, we'd be glad to help to get started and whenever you have any questions.


## Origin of the US image
#### Posted by Jason... on 2015-06-22 06:57

Hi, Andras,

I'm working on a new module based on the Plus with a capture video device, and i was wondering the origin point in US image for ImageToReferenceMatrix is the top center of the image or the top left of the image ?

Best regrads,
Jason

#### 7 Comments
#### By Tamas Ungi on 2015-06-22 18:22
Hi Jason,

See this page for definition of all coordinate systems used in Plus:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CommonCoordinateSystems.html

The "Image" coordinate system origin is in a corner of the image that is near the ultrasound transducer and on the unmarked side. (Origin of the MF oriented image.) For definition of MF, see this page:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/UltrasoundImageOrientation.html

Tamas
#### By Jason... on 2015-06-22 22:28
Thanks, Tamas, that helps a lot !
#### By Jason... on 2015-06-24 07:36
Hi, Tamas

I'm wondering do you have made some research on how to choose the phantom according to different probe or different depth of imaging?
why don't you use the Cambridge phantom, which can Provide more accuracy to the calibration?
#### By Andras Lasso on 2015-06-24 08:36
There are many (probably too many) calibration methods for spatial calibration of tracked ultrasound, each with different advantages/disadvantages.

So far we have been able to cover all our needs with automatic multi-N-wire based calibration (http://perk.cs.queensu.ca/contents/improving-n-wire-phantom-based-freehand-ultrasound-calibration) and manual tracked stylus based calibration (http://www.slicerigt.org/wp/user-tutorial/, U31). The calibration results seems to be at least as good as with alternative methods.

The Cambridge phantom is for single-wall calibration and it improves the robustness of the method, but that phantom is not easy to fabricate and most drawbacks of single-wall calibration still apply. We were considering adding basic single-wall calibration to Plus, but the method seemed to be so sensitive that we gave up on that.
#### By Tamas Ungi on 2015-06-24 10:14
I second Andras. I could not reproduce results in those papers that compare accuracy. I don't think it matters what phantom you chose, as long as you do the calibration properly and carefully. Calibration with tracked stylus proved to be a very handy skill to me, because you cannot always carry a phantom with you. But if you need a sterile phantom for a sterilized probe, then of course you need a phantom.
#### By Jason... on 2015-06-24 23:44
Hi,Tamas

I think the calibration with tracked stylus is not good enough. I found that you have mentioned it will imaging along the stylus in SlicerIGT Tutorial, but it seems it cannot be sure the 2D image contains the feature of stylusTip(maybe there is an angle between image and stylus and this would be obvious for intracavitary probe)
#### By Tamas Ungi on 2015-06-25 05:24
Yes, you need to recognize when the stylus tip crosses the image plane, to get accurate stylus-based calibration. It takes a little practice to recognize that visual feature, but the practice pays off on the long run. If you learn it (takes about 15 minutes), you will be able to accurately calibrate any ultrasound probe (any size, any shape, 2d, 3d, etc.) without phantoms.


## Volume Reconstruction using CHRobotics UM6 MARG sensor?
#### Posted by mrmorgan14 on 2015-06-09 13:14

Hi All,

Has anyone used the CHRobotics UM6 MARG sensor to perform any volumetric reconstructions (either on its own or in conjunction w/ other sensors) using PLUS & 3D Slicer? Would really appreciate some insight into its capabilities in terms of photos/videos/descriptions etc. I'm looking into its feasibility as a volume recon tool.

Thanks,
Matt

#### 7 Comments
#### By Andras Lasso on 2015-06-09 13:59
We use MARG sensor (not the CHRobotics but the PhidgetSpatial) for prostate US volume reconstruction: http://perk.cs.queensu.ca/contents/towards-open-source-infrastructure-joint-mritrus-guided-prostate-interventions

As long as the center or axis of rotation is fixed or known, the reconstruction has very good quality (comparable to optical and electromagnetic pose trackers). When a stepper is used (such as for prostate imaging) then the rotation axis is known. For freehand reconstruction you have to be careful not to translate the transducer on the skin surface while rotating it (or estimate the translation). Probably without any compensation the freehand reconstruction error is up to a few millimeters; with a simple translation computation algorithm (that assumes that the transducer is rolling on the skin surface) the error could be probably go down to about a millimeter.
#### By Mrmorgan14 on 2015-06-09 20:35
Thanks, Andras.

Do you have any gimbal lock problems using that PhidgetSpatial sensor using only R/P/Y data? I noticed it doesn't seem to have a quaternion output (& correct me if I'm wrong). Or is that just avoided by how you fix the sensor to the transrectal probe (i.e. never pitch 90˚)? I could see that becoming an issue using a typical linear or curvilinear array in abdominal volumetric imaging for example, depending on scan location, patient orientation, etc.

Thanks!
#### By Andras Lasso on 2015-06-09 22:29
We never use Euler or RPY angles in the Plus toolkit for representing orientation due to gimbal lock issues. The PhidgetSpatial device in Plus provides orientation in a homogeneous matrix (position is always zero).

The PhidgetSpatial device uses the x-io AHRS algorithm, which represents orientation in quaternion and in Plus we convert it to a matrix. In general, it does not matter what orientation the tool is, you get a 3DOF orientation estimation.

The PhidgetSpatial device in Plus has a special "tilt sensor" mode, which only uses the accelerometer and gyroscope and requires the single rotation axis to be approximately horizontal (no gimbal lock issues, as the rotation is limited to a single axis).

If the performance of the x-io and its tilt sensor variant is not good enough then you can quite easily integrate any other AHRS algorithm for estimating orientation from the raw sensor data.
#### By Mrmorgan14 on 2015-06-17 20:03
Hi Dr. Lasso--so then if you had a typical linear or curvilinear array, and didn't translate the transducer on the skin surface and made some assumptions about the rotation axis, you could construct a volume simply from that? Or is it only designed for examples like the prostate where you would essentially use the sensor to turn the probe left and right (in-plane), and then use a stepper to translate it forward (& repeat)? Apologies if that's redundant--I want to make sure I'm understanding you correctly.
#### By Andras Lasso on 2015-06-17 23:58
Yes, by simply attaching a sensor to a free-hand operated ultrasound you can reconstruct a volume by tilting (rolling) the transducer on the skin. The reconstruction error can be reduced by measuring/computing how much the transducer translates while it is rolling on the skin and add that translation to the measured rotation.
#### By Mrmorgan14 on 2015-06-18 20:57
Does the software assume a single axis or point of rotation? Or does the software support volume recon from multiple axes or points of rotation? For example, multiple adjacent axes to stitch together for a larger FOV (assuming you knew the separation distance of the two axes).

What is the most straightforward approach to adapt this reconstruction routine into a new Plus-App? -for stitching together multiple adjacent sweeps, for example? I'm assuming we'd be able to leverage lots of the existing volume reconstruction code--Apologies, unfortunately I'm a bit of a novice when it comes to software development on a project of this scale.
#### By Andras Lasso on 2015-06-18 21:02
Arbitrary translation and/or rotation is allowed.


## New Plus release - PLUS-2.2
#### Posted by Andras Lasso on 2015-06-05 01:26

We are happy to announce the new stable release of the PLUS toolkit (PLUS-2.2.0) that contains several major features and many improvements. Check out the release highlights and corresponding short demo videos below.

Release highlights
-------------------------

Acquisition of 4D (3D+t) image data, biplane image data, color image data – demo: http://youtu.be/e9BNvxLnLmo
Live tracking, image, and registration data acquisition from Medtronic StealthStation – demo: https://youtu.be/UHmv5u-sB5g
Thorlabs optical spectrometer support for real-time navigated intra-operative tissue characterization – demo: http://youtu.be/ag7fWY27lus
Remote control interface for recording and volume reconstruction for 3D Slicer – demo: http://youtu.be/lfZeXabDjMg
Model catalog of 3D printable tracking fixtures and calibration tools – demo: http://perk-software.cs.queensu.ca/plus/doc/nightly/modelcatalog/
Spatial calibration for Ultrasonix systems can be dynamically updated as imaging depth is changing
Direct digital image acquisition from Telemed and Philips ultrasound systems

Details
-------------------------

Support for new devices:
Medtronic StealthStation (receive live tool position information, planning image volume, registration results; thanks to Ahmet Cakir) – demo: https://youtu.be/UHmv5u-sB5g, doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceStealthLink.html
Telemed ultrasound systems support (thanks to Matthieu Heitz and Dzenan Zukic from Kitware) – doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceTelemed.html
Interson pocket ultrasound systems with managed C++ interface (thanks to Matt McCormick from Kitware) – doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceIntersonSDKCxx.html
Phlips ie33 ultrasound systems, 4D data acquisition (thanks to Adam Rankin from Robarts Research Institute) – demo: http://youtu.be/e9BNvxLnLmo, doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DevicePhilips.html
Arduino microcontrollers (and similar devices that accept commands and provides data through serial interface) – doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceGenericSerial.html
ThorLabs optical spectrometer support – demo: http://youtu.be/ag7fWY27lus, doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceThorLabs.html

Improvements in calibration application (fCal):
Automatic landmark detection for phantom calibration: more convenient (no need pressing keys or foot pedal), more accurate (stylus tip position is averaged for several seconds, therefore effect of random measurement noise is reduced) => https://youtu.be/6Oi8baLmRNY
Timers are added for each calibration step to allow a single person to perform all steps without a foot pedal

Improvements in volume reconstruction:
Automatic fan detection: automatic exclusion of left and right side of the image fan that remained dark due to weak acoustic coupling (thanks to Rahul Sastry from BWH) (demo: https://www.youtube.com/watch?v=ss7ZTRTNWio, doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html)
Reduce artifacts in multi-sweep rendering by allowing exclusion of very dark regions using PixelRejectionThreshold parameter – doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html

Improvements in Ultrasonix ultrasound imaging system support (doc: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html):
Spatial probe calibration matrix can be updated dynamically when imaging parameters, such as imaging depth, are changed (use ImageToTransducerTransformName and the TransducerToProbe transform provided by Ultrasonix)
Support for volumetric data acquisition from motorized probes (thanks to Mikael Brudfors from UBC)
Auto-clip of images to non-empty image area (using AutoClipEnabled)
Ultrasonix SDK 6.1.x support

Other platform improvements:
Support added for acquiring, storing, processing, and streaming of 4D (3D+t) image data, biplane image data (create two image streams from a single input image), and full color image data
Data recording, off-line and real-time volume reconstruction, and configuration file update is available for remote clients, such as 3D Slicer through OpenIGTLink. PlusRemote client is available for 3D Slicer in the SlicerIGT extension – demo: http://youtu.be/lfZeXabDjMg
Model catalog is created for 3D printable tracking fixtures and calibration tools (http://perk-software.cs.queensu.ca/plus/doc/nightly/modelcatalog/)
Detailed application help included in the Plus installation package (online version: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/index.html)
Virtual device is added for integrating image processing algorithms, such as bone extraction, image enhancement into Plus (example: vtkImageProcessorVideoSource)

#### 4 Comments
#### By Siavash Khallaghi on 2015-06-05 15:19
It seems that you guys have a great vendor-invariant platform for the acquisition of ultrasound. What is the next big step in Plus? Is the development going to focus on the implementation of new algorithms (e.g. calibration) into the Plus framework?
#### By Tamas Ungi on 2015-06-05 16:02
The trend is that Plus is getting stronger in data stream handling and hardware support (no GUI). In the meantime, Slicer is getting better as a user application framework. You can now make relatively lightweight, stable, multi-platform applications, with fully custom GUI, by minimal coding using Slicer. So anything that requires user interactions, will probably be implemented in the Slicer framework. Fully automatic algorithms (like image filters) still have room in Plus.
#### By Andras Lasso on 2015-06-05 21:01
We develop Plus based on our and our collaborator's needs. Serving clinical and commercial translation needs better, improving 4D ultrasound support (calibration, volume reconstruction, etc), add endoscopic video (calibration, distortion correction, etc), are potential next steps, but we have several ideas. It depends a lot on which of our ideas turn out to be good ones and what fundings we get.
#### By Siavash Khallaghi on 2015-06-11 14:07
Thank you for the explanation! :)


## Plus Server on-line 3D data visualization and geometrical mapping
#### Posted by goby.dll173884 on 2015-06-08 11:01

I'm implementing a small software to receive Plus server Image and Transform messages and visualize them in 3D.
I'm using this configuration section:
~~~~~
<PlusOpenIGTLinkServer MaxNumberOfIgtlMessagesToSend="1" MaxTimeSpentWithProcessingMs="50" ListeningPort="18946" SendValidTransformsOnly="true" OutputChannelId="TrackedVideoStream">
<DefaultClientInfo>
<MessageTypes>
<Message Type="IMAGE"/>
<Message Type="TRANSFORM"/>
</MessageTypes>
<TransformNames>
<Transform Name="ProbeToTracker"/>
<Transform Name="ReferenceToTracker"/>
<Transform Name="ProbeToReference"/>
</TransformNames>
<ImageNames>
<Image Name="Image" EmbeddedTransformToFrame="Reference"/>
</ImageNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>
~~~~

I don't understand how to visualize the US image in the correct geometrical position with respect to ProbeToReference (or ProbeToTracker) transform, since the transform embedded in the image message is fixed.
Should I multiply the ProbeToReference transform with the Image Transform?

Is there any way to send the StylusTip position and orientation (instead of the Stylus marker)?

I made some tests and checked out the slicerIGT documentation, but I did not understand how to correctly map all the devices.

Thanks in advance for the support!
Diego

#### 5 Comments
#### By Tamas Ungi on 2015-06-08 11:25
Hi Diego,

If you use that config file, the transform in each image message is already ImageToReference. So any pixel position in the image system gets directly transformed to the Reference coordinate system when multiplied with the "Image Transform" (ImageToReference). If your hardware is working fine, then every Image message should have different transforms (if your ultrasound probe is moving).

If you put the StylusTipToStylus coordinate transform in your Plus config file, then you can add the line
<Transform Name="StylusTipToReference"/>
To your config file to make Plus send you the stylus tip position in the reference coordinate system.

Tamas
#### By Andras Lasso on 2015-06-08 17:36
Just to make sure: you'll use SlicerIGT for application prototyping, right?

Just decide what coordinate system you want to show everything in, and send all data in that coordinate system. E.g.,
<Transform Name="ProbeToReference"/>
<Transform Name="NeedleToReference"/>
or
<Transform Name="ProbeToTracker"/>
<Transform Name="NeedleToTracker"/>
#### By Goby.Dll173884 on 2015-06-09 09:30
Thanks for the support!

No, unfortunately I'm not using SlicerIGT.
Instead, I need to integrate the data coming from Plus Server with a previously developed software for percutaneous surgical navigation.
This software originally shows the 3D objects in the Claron Micron Tracker reference system.

Luckily, the software receives TRANSFORM and IMAGE messages from openIGTlink server, therefore receiving the data from Plus Server was straightforward.

I will double check the setup tomorrow, but currently the embedded transform in the IMAGE message is fixed, so if the Probe marker is moving the ProbeToTracker (or ProbeToReference) transformation is changing, while the IMAGE position and orientation is not changing.

Do I need to perform any additional reference system mapping (as far as I understood in SlicerIGT a mapping to RAS reference system is required)?
#### By Goby.Dll173884 on 2015-06-10 08:50
I found the problem! There was this wrong Transform Section under CoordinateDefinitions in my XML configuration file:
~~~~
    <Transform From="Image" To="Reference"
      Matrix="
        0.2 0 0 0
        0 0.2 0 0
        0 0 0.2 0
        0 0 0 1"
       Date="2015.06.03 14:33:00" />
~~~~
This section prevented the correct saving of calibration transformation (ImageToProbe) in the XML file and the correct streaming with Plus Server (the image position was linked with Reference instead of Probe marker).I have no idea how this section has been inserted in the file.

With this PlusServer configuration everithing is working fine, (i.e. it is equivalent from receiving the data from Micron Tracker Server):
~~~~
  <PlusOpenIGTLinkServer MaxNumberOfIgtlMessagesToSend="1" MaxTimeSpentWithProcessingMs="50" ListeningPort="18944" SendValidTransformsOnly="true" OutputChannelId="TrackedVideoStream">
    <DefaultClientInfo>
      <MessageTypes>
        <Message Type="IMAGE" />
        <Message Type="TRANSFORM" />
      </MessageTypes>
      <TransformNames>
        <Transform Name="ProbeToTracker" />
        <Transform Name="StylusTipToTracker" />
        <Transform Name="ReferenceToTracker" />
      </TransformNames>
      <ImageNames>
        <Image Name="Image" EmbeddedTransformToFrame="Tracker" />
      </ImageNames>
    </DefaultClientInfo>
  </PlusOpenIGTL
~~~~
Thanks again for your support!
Diego
#### By Andras Lasso on 2015-06-10 08:52
Great! Thanks for the update.


## Using plus on independently acquired image and position data
#### Posted by kola180330 on 2015-05-26 11:07

Hi,

Firstly, apologies if this topic has been dealt with in the past, but I did not find the information I need in the messages list.

Due to budget constraints we cannot afford a position tracker for our ultrasound machine (Mylab70). I have therefore used a Vicon system to track the position of the ultrasound transducer and I collected the image data separately using the Matlab image acquisition toolbox. So I have a mat file of images and a csv file of timestamped 6 spatial coordinates which I can link to each frame. Is it possible to feed this data into Plus to obtain a reconstructed 3D volume? If so how? If not can anyone suggest alternatives?

Thanks,
Kola

#### 1 Comments
#### By Andras Lasso on 2015-05-26 11:48
You can use Plus to acquire image data from your ultrasound machine (using Media Foundation or Video for Windows device). It should be also simple to add support for the Vicon. Then you could visualize the tracked image slices and reconstruct the volume in real-time. See https://m.youtube.com/watch?v=lfZeXabDjMg

Nevertheless, you can reconstruct a volume from the sequence of frames that you have. Just save your data as a sequence metafile. Specification is available here:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/FileSequenceMetafile.html

There is a script to write sequence metafiles from Matlab, the only limitation is that it does not write the transforms to the header, but you can modify the script to export them, too.
https://subversion.assembla.com/svn/plus/trunk/MatlabUtils/MatlabMetafileIO/


## Telemed-Win32 Package
#### Posted by SalvoVirga on 2015-05-26 04:21

Hi all,

I'm looking for the PlusApp-...-Telemed-Win32 package, which should be available on request.
I'm not sure if this is the right way to ask for it, please redirect me somewhere else if needed.

#### 1 Comments
#### By Goby.Dll173884 on 2015-05-26 05:16
You can find the experimental Telemed Package Here

Good Luck for your work!


## How to acquire B-mode images with their positions using SonixTab ?
#### Posted by Loïc_Tetrel on 2015-05-01 19:00

Hi everyone,

I’m a student working on image registration for my master’s degree. We have an Ultrasonix SonixTablet with the software version 6.0.7, a linear probe L 14-5\38 GPS with SonixGPS. I am running with “PlusApp-2.1.2.4121-Ultrasonix-6.1-Win32.exe” on the echograph in research mode.
I want to collect B-mode images with their position (x, y, z, thetax, thetay, thetaz), but I have some trouble to collect the GPS data. So I'm searching for the simpliest way to do that.

1) For the beginning, I just want to acquire the gps data without calibration (to see if I can acquire some positions), indeed ultrasonix told that they did the calibration. So I captured a sequence of images but the transformation matrix doesn’t change, I don’t have any problem for the B-mode images. I'm using Matlab too read the mha file (functions are available at : https://subversion.assembla.com/svn/plus/trunk/MatlabUtils/MatlabMetafileIO/)
It seems that I have to change something in the configuration file but I don’t know what.

2) After this for the calibration, do I have to perform all the process ?
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html
Indeed I don’t have a stylus but I can build the phantom. Is it possible to import the calibration matrix if I do the calibration in a other way ?

3) What are the advantages to use PLUSLib if I want to program in C++ ?

4) And last question but not the least !
Is your rotation matrix defined as the standard one :
https://engineering.purdue.edu/~bethel/rot2.pdf

Or as the one from ultrasonix :
http://www.ultrasonix.com/wikisonix/index.php/GPS_Data_Collection

Please see attached my configuration file and the screen of the problem with gps data.

Thanks a lot,
problem.JPG	30.4 KB
PlusDeviceSet_Server_SonixTouch_L14-5.xml	2.08 KB

#### 6 Comments
#### By Andras Lasso on 2015-05-02 00:28
Welcome to the PLUS community. The toolkit should be able to serve all your needs that you described.

1)
The config file that you attached only specifies that you acquire imaging data. Use (or copy the DataCollection section) of a config file that has both imaging and tracking data, for example:
https://www.assembla.com/code/plus/subversion/nodes/4123/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml

2)
You can follow the described process for calibration of any kind of ultrasound system with any kind of tracker. You can use a tracked needle as a stylus or you can make one by taping a tracking sensor to a sharp pencil.
In case of Ultrasonix systems with SonixGPS you can choose to use the default calibration that Ultrasonix provides. I'll post a sample configuration file by mid next week.

3)
> What are the advantages to use PLUSLib if I want to program in C++ ?
I don't understand the question. You should be able to build complex ultrasound-guided systems with several tools, image fusion, 2D/3D views, DICOM imaging, real-time volume reconstruction, volume rendering, segmentation, registration, etc. without ANY programming if you use PLUS with SlicerIGT (www.slicerigt.org).

4)
We use a standard homogeneous matrix to represent a linear transformation (translation, rotation, scaling) between two coordinate systems.
See detailed explanation here:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CoordinateSystemDefinitions.html#TransformationMatrix

And definition of coordinate systems here:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CommonCoordinateSystems.html
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCalCoordinateSystemDefinitions.html
#### By Loïc_Tetrel on 2015-05-04 17:10
Hi Andras,

So I modified the configuration file and now it's working ! I had some problems to acquire GPS data because first I had to disabled the GPS on Ultrasonix software (as preconised in http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceAscension3DG.html).

But what is the difference between your calibration and the default one ?

My question on 4) was :
What is the math formulation for the differents element ? For example
Ryx = (-1) * cos(theta_y) * sin(theta_z) (Standard)
OR
Ryx = cos(theta_y) * sin(theta_z) (Ultrasonix)
But it's not so important, just a matter of angle's signs.

Is optical tracking with MicronTracker working on "Ultrasonix-6.1-Win32" ? In the download page it's written that no but I see it in the list of device :
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceMicron.html

Thank you a lot, I'm waiting the sample configuration file for the calibration,
PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml	3.16 KB
#### By Andras Lasso on 2015-05-04 18:08
MicronTracker does not work on Windows XP embedded (operating system installed on most SonixTablet systems). If you want to use MicronTracker, then you have to set it up on another computer that has Windows 7 or 8 and run a PlusServer instance there. You can then receive the images from another PlusServer instance that runs on the SonixTablet.

If your SonixTablet has Windows 7 or 8 and you can find a Firewire interface that you can install on it then you can probably connect MicronTracker to the SonixTablet directly.

I'll have a look at the Ultrasonix transform specification later this week.
#### By Loïc_Tetrel on 2015-05-11 11:29
Hi Andras,

You said that you will post a sample configuration file past week for the calibration.
Because with PLUS I get the "ProbeToTracker transform" but I need the "ImageToTracker" transform. How can I specify the calibration matrix in the configuration file ?
Does Ultrasonix have the "ImageToProbe transform" (calibration provided by the manufacturer) ?
#### By Andras Lasso on 2015-05-12 19:38
Sorry for the delay, I'll provide the sample probably by tomorrow.
#### By Andras Lasso on 2015-05-14 23:06
Here are the configuration files for linear and curvilinear probes:
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_SonixTouch_L14-5_Ascension3DG.xml
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_SonixTouch_C5-2_Ascension3DG.xml

Let me know if they work as you expected.


## Volume reconstruction crashes
#### Posted by Dzenan Zukic on 2015-05-08 10:43

I acquired 4 different sweeps and recorded them in MHA file. When I pass one of those files to VolumeReconstructor, a crash occurs in PlusLib\src\VolumeReconstruction\vtkPasteSliceIntoVolume.cxx line 251. The only difference I have noticed between recording file and the other 3 recordings is that the offending one has 10 out of 873 invalid transforms. I traced the execution and I still don't get why it crashes, especially there. I can supply the offending recording (35 MB). The parameters passed to VolumeReconstructor:
--config-file=M:\Dev\OrthoConfig\EpiphanMicron.xml --image-to-reference-transform=ImageToTracker --output-volume-file=M:\Dev\OrthoConfig\Reco.mha --source-seq-file=M:\Dev\OrthoConfig\JawRightDzenan.mha

#### 8 Comments
#### By Andras Lasso on 2015-05-08 11:52
We are not aware of any issues in the volume reconstructor that could cause crash other than running out of memory. See notes "I got an error from PlusServer when trying to reconstruct a volume: StartReconstruction failed due to out of memory." at:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmVolumeReconstruction.html

It is also helpful to create a model of the image slices using this tool:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationCreateSliceModels.html
#### By Dzenan Zukic on 2015-05-08 15:50
I had an out of memory error, that's why I built VolumeReconstructor in 64 bits. I am using 64-bit version.

With FillHoles="ON" my computer freezes (Win7 x64). If I debug it and step in a lot, it does not freeze then. If I set NumberOfThreads="1", the freezing does not happen. This makes me think that some threading issue is to blame.

I tried using CreateSliceModels. The file is produced, but the content is invisible in paraview and slicer. The file is attached.
Jaw2LeftDzenan.vtk	758 KB
#### By Andras Lasso on 2015-05-08 16:02
You can see the surface if you disable backface culling but the result is not nice. The transforms seem to be completely messed up. Can you share the source sequence and config file and the VolumeReconstructor command-line parameters?
#### By Andras Lasso on 2015-05-08 16:07
> With FillHoles="ON" my computer freezes (Win7 x64)

We have not observe issues related to threading (other than slight variations at the seams, as we don't add ghost cells at the thread processing boundaries), so most likely the "hang" is an extreme slowdown due to requesting a lot of memory (that is more than the virtual memory space you set in your system settings; or simply everything gets very slow due to too much memory swapping).

Disable hole filling and set spacing to several millimeters until you get a reasonable volume reconstruction result.
#### By Dzenan Zukic on 2015-05-08 17:02
I don't think memory usage is the issue. My laptop has 16GB, the mainPC with ultrasound has 24GB. VolumeReconstructor uses around 3GB.
VolumeReconstructor.exe --config-file=M:\Dev\OrthoConfig\EpiphanMicron.xml --image-to-reference-transform=ImageToTracker --output-volume-file=M:\Dev\OrthoConfig\Reco.mha --source-seq-file=M:\Dev\OrthoConfig\JawRightDzenan.mha
JawRightDzenan.7z	35.4 MB
EpiphanMicron.xml	9.35 KB
#### By Andras Lasso on 2015-05-09 00:32
Works for me with this config:
~~~~
<VolumeReconstruction
OutputSpacing="1 1 1"
Interpolation="LINEAR"
Optimization="FULL"
CompoundingMode="MEAN"
NumberOfThreads="1"
FillHoles="OFF"
>
<HoleFilling>
<HoleFillingElement Type="GAUSSIAN" Size="5" Stdev="2" MinimumKnownVoxelsRatio="0.25" />
</HoleFilling>
</VolumeReconstruction>

OutputSpacing controls the output resolution, which determines the memory consumption.

<VolumeReconstruction
OutputSpacing="0.1 0.1 0.1"
Interpolation="LINEAR"
Optimization="FULL"
CompoundingMode="MEAN"
NumberOfThreads="1"
FillHoles="OFF"
>
<HoleFilling>
<HoleFillingElement Type="GAUSSIAN" Size="5" Stdev="2" MinimumKnownVoxelsRatio="0.25" />
</HoleFilling>
</VolumeReconstruction>
~~~~
The CreateSliceModels tool required the config file to contain ClipRectangleOrigin="0 0" ClipRectangleSize="488 440" (will remove this requirement later)
#### By Dzenan Zukic on 2015-05-09 00:48
I also figured out that using a different spacing such as 0.2 avoids the crash. However, the crash with 0.1 spacing is a bug, and it is annoying. Even more annoying because the program has no reason to crash there!

Thanks for the help again, Andras!
#### By Andras Lasso on 2015-05-09 01:07
With 1mm spacing the image size: 113 x 154 x 76 x 2 bytes (intensity+accumulation) = 0.002GB
With 0.2mm spacing the image size: 0.3GB
With 0.1mm spacing the image size: 1130 x 1540 x 760 x 2 bytes = 2.5GB

So, probably the 0.1mm spacing is caused by an integer indexing problem (signed int maximum range is 2GB). The issue may be at VTK level (VTK might need to be built with VTK_USE_64BIT_IDS enabled) and/or there could be 32-bit signed integer indexes or sizes used in Plus.

In practice you probably don't want images larger than a few hundred MB, so I'm not sure it is worth the time to switch to 64-bit IDs in VTK and add full support for it in Plus (unless there is a specific need to reconstruct >2GB volumes). Added a ticket anyway (#992) to keep track of this.


## VS2013 building
#### Posted by Dzenan Zukic on 2015-05-08 15:16

What is the reason for using such old versions of ITK and VTK? Newer versions, such as ITK 4.7.2 or VTK 6.2.0 build properly on Visual Studio 2013.

#### 1 Comments
#### By Andras Lasso on 2015-05-08 15:35
We update ITK and VTK time to time (or when there is any specific need) to the version used by 3D Slicer. We plan to release a new stable version soon, so it's probably a good time to upgrade, so I've entered a ticket: #991.


## Wire segmentation not working properly
#### Posted by Dzenan Zukic on 2015-05-01 19:02

I built the PLUS config file using recent examples. The phantom model is visually aligned with the wires. I set proper ultrasound parameters to have wires nicely visible - I committed some code recently to pass those properly to Telemed drivers. I fiddled with segmentation parameters to have a decent point detection.

However, in spite of exactly 9 red points being detected, they are not green (attachment fCal-noGreen). Also, green points occasionally flash up when some noise is caught on the image (fCal-Green). Physical phantom (myPhantom) matches the rendering (fCal-phantom) quite well. I am stuck again.
TelemedMicron.xml	8.16 KB
fCal-Green.png	106 KB
fCal-noGreen.png	51.1 KB
myPhantom.jpg	732 KB
fCal-phantom.png	32.2 KB

#### 17 Comments
#### By Andras Lasso on 2015-05-01 19:24
Make sure you set the initial spacing correctly as described here:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html
#### By Dzenan Zukic on 2015-05-01 19:32
In Segmentation node, there is property ApproximateSpacingMmPerPixel. Can I set different values for NF and MU axes?
#### By Andras Lasso on 2015-05-01 19:35
Set that approximate spacing in the GUI by dragging the horizontal and vertical rulers to known distances. It is just an approximate spacing value, does not need to be very accurate, that's why no lateral and axial spacing value can be set separately.
#### By Dzenan Zukic on 2015-05-01 20:21
Thank you Andras, that was it.

However, now when I finish the spatial calibration, I get a warning that the error is too high. A possible explanation is that frequently, green dots get overlaid one over the other (attachment ConfusedPoints). Is this a bug?
ConfusedPoints.png	55.8 KB
CalibrationError.png	35.9 KB
#### By Dzenan Zukic on 2015-05-01 20:23
Also, my phantom is flimsily attached to the reference marker. How much of a contributing factor is that?
#### By Andras Lasso on 2015-05-01 20:26
Please attach a screenshot of the spacing setting (when I see the distance values and the ruler lines)
#### By Dzenan Zukic on 2015-05-01 20:30
Attached
SpatialSettings.png	57.4 KB
#### By Andras Lasso on 2015-05-01 20:32
The second reference length is 10mm, while in the image you marked the distance between the top and bottom layer, which is 20mm
#### By Dzenan Zukic on 2015-05-01 20:37
Separation between layers is about 5 mm, so distance from top to bottom layer is about 10mm. If I try to say that blue line is 20 mm, I get no green points at all.
#### By Andras Lasso on 2015-05-01 20:39
In the fCal 2 phantom the recommended wiring uses 10mm separation between layers. If you use a different wiring pattern then update the wire pattern description in the config file.
#### By Dzenan Zukic on 2015-05-01 20:41
Judging from the wiring description in the config file, distances should be 30x10 mm.
<Description Name="fCAL" Type="Multi-N" Version="1.2" WiringVersion="1.1" Institution="Queen&apos;s University PerkLab" />
#### By Andras Lasso on 2015-05-01 20:50
Have you printed an fCal 1 or fCal 2 phantom? fCal 2 with 1cm distance plances is very much recommended, as the labeling is more robust and the calibration result is more accurate.
You can make the wire intersection appear smaller by decreasing the gain, which may help with the mislabeling.
Also, you can tighten the tolerances, especially the angle tolerance to make sure only parallel lines are recognized.
#### By Dzenan Zukic on 2015-05-01 20:53
Thank you, I will try that either on Monday or perhaps tomorrow.
#### By Dzenan Zukic on 2015-05-04 11:50
Decreasing gain did not help much. Tightening angle tolerance and collinear max distance, on the other hand, did.

Now the wires don't get confused, at the expense of not frequently seeing the green dots.

I am still able to get through spatial calibration (fill the progress bar), but the calibration error is still on the order of 10 mm. The visual inspection of probe's transformation reveals bad result. In the attached file Probe_misalignment, red line indicates position where I hold the probe and where black slice should be, and black slice has (as displayed) a severe rotation component.
Probe_misalignment.png	20.9 KB
#### By Andras Lasso on 2015-05-04 12:11
Make sure you hold the probe right (not rotated 180deg around).

“Probe orientation: make sure that the probe orientation is correct (for fCal_2.x_Wiring_1.x the marked side of the probe shall be close to the A1 point). The wire numbers are shown in fCal during spatial calibration and in the segmentation parameter setting dialog box, which can help in verification of the correct orientation. To verify the probe orientation: touch a w1 wire with your finger => your finger should appear near w1 wire on the US image. If your finger appears at a different wire (and you are sure that the image orientation is set correctly) then you do not keep the marked side of the probe on the w1 wire's side - in this case simply rotate the probe by 180 deg (and keep it in this orientation while collecting the calibration data). #435 will enable automatic detection of the probe orientation.”

http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html
#### By Andras Lasso on 2015-05-04 12:12
Make sure you hold the probe right (not rotated 180deg around).

“Probe orientation: make sure that the probe orientation is correct (for fCal_2.x_Wiring_1.x the marked side of the probe shall be close to the A1 point). The wire numbers are shown in fCal during spatial calibration and in the segmentation parameter setting dialog box, which can help in verification of the correct orientation. To verify the probe orientation: touch a w1 wire with your finger => your finger should appear near w1 wire on the US image. If your finger appears at a different wire (and you are sure that the image orientation is set correctly) then you do not keep the marked side of the probe on the w1 wire's side - in this case simply rotate the probe by 180 deg (and keep it in this orientation while collecting the calibration data). #435 will enable automatic detection of the probe orientation.”

http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html
#### By Dzenan Zukic on 2015-05-06 16:12
For those who stumble on this thread in the future:

1. The wires are asymmetric, so their orientation can be detected automatically. However, automatic detection of orientation is not yet implemented so orientation of probe in relation to the phantom matters a lot.
2. Orientation of the ultrasound image matters (M vs U, N vs F). The MF axes in spatial calibration mean that marked and far ends of the image are in the directions pointed by the arrows, not at coordinate origin (as I misunderstood).

Thanks Andras!


## Missing transforms in volume reconstruction
#### Posted by Dzenan Zukic on 2015-05-04 17:29

Despite high calibration error, I am trying to do a volume reconstruction to see some results. And I am encountering problems again.

I record a sweep using PlusRemote in Slicer, and then I try to run volume reconstruction on it:
VolumeReconstructor.exe --config-file=c:\Dev\OrthoConfig\TelemedMicron.xml --image-to-reference-transform=ImageToReference --output-volume-file=C:\Dev\OrthoConfig\Reconstructed.mha --source-seq-file=C:\Dev\PlusBuild-bin\bin\Release\Output\Sweep20150504_165307.mha

I get these errors:
Software version: Plus-2.1.2.4121 (debug build) - Win32 (debug build)
Reading configuration file:c:\Dev\OrthoConfig\TelemedMicron.xml
Reading image sequence C:\Dev\PlusBuild-bin\bin\Release\Output\Sweep20150504_164600.mha
Set volume output extent...
|ERROR|000.315000| Transform path not found from Image to Reference coordinate system. Available transforms in the repository (including the inverse of these transforms): ImageToProbe (valid, persistent), PhantomToReference (valid, persistent), StylusTipToStylus (valid, persistent), TransducerOriginPixelToTransducerOrigin (valid, persistent)| in C:\Dev\PlusBuild-bin\PlusLib\src\PlusCommon\vtkTransformRepository.cxx(535)
|WARNING|000.335000| Failed to get transform 'ImageToReference' from transform repository!| in C:\Dev\PlusBuild-bin\PlusLib\src\VolumeReconstruction\vtkVolumeReconstructor.cxx(367)

It looks like tracking information is not recorded. Recording file's header looks like this:
ObjectType = Image
NDims = 3
AnatomicalOrientation = RAI
BinaryData = True
BinaryDataByteOrderMSB = False
CenterOfRotation = 0 0 0
CompressedData = False
DimSize = 512 512 111                            
ElementNumberOfChannels = 1
ElementSpacing = 1 1 1
ElementType = MET_UCHAR
Offset = 0 0 0
TransformMatrix = 1 0 0 0 1 0 0 0 1
UltrasoundImageOrientation = MFA
UltrasoundImageType = BRIGHTNESS
Seq_Frame0000_Timestamp = 123.6299999999992
Seq_Frame0000_ImageStatus = OK
Seq_Frame0001_Timestamp = 123.663999999999
Seq_Frame0001_ImageStatus = OK
...
Seq_Frame0110_Timestamp = 127.3649999999995
Seq_Frame0110_ImageStatus = OK
ElementDataFile = LOCAL
...

I tried copying a few different IGTLink parameters from example config files, e.g.:
~~~~
  <PlusOpenIGTLinkServer MaxNumberOfIgtlMessagesToSend="1"
  MaxTimeSpentWithProcessingMs="50" ListeningPort="18944"
  SendValidTransformsOnly="true"
  OutputChannelId="TrackedVideoStream">
    <DefaultClientInfo>
      <MessageTypes>
        <Message Type="IMAGE" />
        <Message Type="TRANSFORM" />
      </MessageTypes>
      <TransformNames>
        <Transform Name="ProbeToReference" />
      </TransformNames>
    <ImageNames>
      <Image Name="Image" EmbeddedTransformToFrame="Reference" />
    </ImageNames>
    </DefaultClientInfo>
  </PlusOpenIGTLinkServer>
~~~~

... but no configuration of PlusOpenIGTLinkServer worked. The whole config file is attached too.

Why doesn't the tracking information get recorded? What is the proper way to do the sweep recordings for offline volume reconstruction?
TelemedMicron.xml	9.62 KB

#### 6 Comments
#### By Andras Lasso on 2015-05-04 18:03
Make sure you record the "TrackedVideoDevice" output.
#### By Dzenan Zukic on 2015-05-05 10:39
I am recording TrackedVideoStream which is the OutputChannel of TrackedVideoDevice.
#### By Dzenan Zukic on 2015-05-05 16:27
Does the version of Slicer matter? I am using 4.4.0.
#### By Andras Lasso on 2015-05-05 17:11
If you record TrackedVideoStream then the saved file should contain the tracking data as well. I would suggest to use the latest Slicer and Plus, but I don't see any obvious reason why it would not work with 4.4

We can talk on skype tomorrow from 11am.
#### By Dzenan Zukic on 2015-05-05 18:32
OK, 11am suits me well. Thanks in advance!
#### By Dzenan Zukic on 2015-05-06 11:46
For those who might stumble onto this thread in the future: what gets recorded is not the OutputChannelId of PlusOpenIGTLinkServer, but InputChannel of VirtualDiscCapture Device.

Thanks again Andras!


## Phantom model visually misaligned
#### Posted by Dzenan Zukic on 2015-04-28 18:52

I created a working config file for PLUS (thanks for help Andras). I went through stylus calibration which was easy. I then went through phantom landmark registration, which was a bit harder because Micron's factory-made stylus has kind of a lousy detection (its tracking frequently gets interrupted, even with direct line of sight).

However, what I had ended up with is a weird-looking phantom, having misaligned body with wires and landmark points (which seem to be aligned with each other). See attached screenshot.

~~~~
<PhantomDefinition> has <Description Name="fCAL" Type="Double-N" Version="1.2" WiringVersion="1.1" Institution="Queen&apos;s University PerkLab" />
The phantom definition was copied from somewhere within PLUS.

In <Rendering> I have <DisplayableObject Type="Model" Id="PhantomModel" ObjectCoordinateFrame="Phantom" Opacity="0.6" File="fCal_1.0.stl" />
~~~~
If I put there fCal_1.2.stl instead, the misalignment is even worse (the model is rotated with respect to wires). The complete config file is attached.

What am I doing wrong? And does this matter for proper calibration?
TelemedMicron_20150428_152716.xml	7.89 KB
PhantomRegistration_20150428_174041.png	102 KB

#### 1 Comments
#### By Andras Lasso on 2015-04-28 19:07
The STL file of the phantom is not consistent with the defined wire positions. I would suggest to make your config file based on recent sample configuration file. You can probably keep the DataCollection section as is but replace everything else.


## Wrong transform names passed through OpenIGTLink
#### Posted by Dzenan Zukic on 2015-04-22 11:12

I have a computer with MicronTracker (telemedusmicron.kitware.com), on which PlusServer is running with MicronOnly.xml configuration file (attached). When I connect to this PlusServer from another computer (let's call it mainPC) using Slicer's OpenIGTLinkIf, I can see the transforms (depending on the tool visibility).

Now I want to connect to that PlusServer on telemedusmicron.kitware.com, so I can use tracking information for the ultrasound probe which is connected to mainPC in order to do calibration for tracked volume reconstruction. So I am running fCal with TelemedMicron.xml as configuration file (attached). The TrackerDevice section of this configuration file is set up according to: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceOpenIGTLinkTracker.html

When I run fCal, I get infinitely repeating errors (attached fCalErrors.txt), and PlusServer spits out it's own errors (attached ServerError.txt). If I debug the PlusServer, strXmlData parameter to method PlusIgtlClientInfo::SetClientInfoFromXmlData on line 10 of PlusIgtlClientInfo.cxx clearly has wrongly named transforms. Content of strXmlData is attached too.

What am I doing wrong? Or is this a bug in Plus?
ServerError.txt	1.25 KB
strXmlData.xml	363 Bytes
MicronOnly.xml	1.56 KB
fCalErrors.txt	2.02 KB
TelemedMicron.xml	5.94 KB

#### 15 Comments
#### By Andras Lasso on 2015-04-22 14:40
This may be due to a recent regression that has been fixed in rev 4102. Please update to the latest version and try again.
#### By Dzenan Zukic on 2015-04-22 16:56
Updating to the current svn version solved that problem. After that I had to change MessageType from TDATA to TRANSFORM and id from TrackerDevice to Tracker (to match the name in server's config file) to get rid of some additional error messages.

However I am stuck again. fCalErrors contains the excerpt from the error log (the errors about missing time-stamp repeat for as long as I am on Configuration page). Capturing page doesn't display ultrasound image.
fCalErrors.txt	2.39 KB
MicronOnly.xml	1.56 KB
TelemedMicron.xml	6.13 KB
#### By Andras Lasso on 2015-04-22 20:50
Ultrasound image is not shown: The "No default channel selected, first channel found is now active: TrackerStream" message indicates that no default channel is selected (TrackerStream, VideoStream, TrackedVideoStream), therefore fCal just picked the first one, TrackerStream, which only contains tracking information. Either add DefaultSelectedChannelId="TrackedVideoStream" to the config file or choose the TrackedVideoStream on the GUI (click "objects" icon at the top, select the channel in the popup menu that appears).

"Unable to get timestamp from ProbeToTracker tool tracker..." indicates that you don't receive valid tracking data. This may be caused by not synchronizing the clocks of the sender and receiver computer. Either synchronize the clocks or set UseReceivedTimestamps ="false" (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceOpenIGTLinkTracker.html).
#### By Andras Lasso on 2015-04-22 20:51
I've slightly modified these two example config files to demonstrate a working combination:
PlusDeviceSet_Server_Sim_NwirePhantom.xml	3.38 KB
PlusDeviceSet_Server_SimulatedUltrasound_3DSlicer.xml	8.89 KB
#### By Dzenan Zukic on 2015-04-23 11:30
Regarding image shown: both DefaultSelectedChannelId and choosing manually (which I didn't know of) work.

Regarding timestamps, synchronizing clocks to internet server did not help. Neither did direct synchronization between computers using command: net time \\telemedusmicron /set /y

Setting UseReceivedTimestamps="false" had no effect either (modified config file attached).

Trying to disregard these errors and proceed with calibration, I ran into the problem of tools not being tracked, and "Start" button grayed out on calibration pages.

When I try the 2 example files you provided, I get some errors, continuous warnings and also grayed-out "Start" button. fCal log attached (Example.log).

Thanks for your help thus far.
TelemedMicron.xml	6.24 KB
Example.log	40.6 KB
fCalErrors.txt	2.84 KB
#### By Andras Lasso on 2015-04-23 11:58
I could reproduce the error in release mode (worked fine in debug). I'm investigating...
#### By Andras Lasso on 2015-04-23 13:23
Actually, the error that I saw was due to higher simualted image refresh rate than tracker update rate. So, it's not really an error, an unrelated anyway.

Your problem might be related to tools being out of view. Can you try if things works when all the tools are in the field of view?

If you have time, we can have a skype/screen sharing session at 2pm today.
#### By Dzenan Zukic on 2015-04-23 13:26
OK, let's Skype at 2pm.
#### By Andras Lasso on 2015-04-23 14:31
The problem was that some tools were out of view. Plus should not log warnings for this but simply set the tool status to invalid - added ticket #987 to track the implementation of this new mechanism.
#### By Dzenan Zukic on 2015-04-23 16:04
Tracker needs to be the currently selected channel in order to be able to start stylus calibration.
#### By Andras Lasso on 2015-04-25 10:58
I've made some improvements in the OpenIGTLinkTracker (#987) so that it reports tools that are not updated as missing. This should take care of the error messages and maybe other issues (such as with the stylus calibration). It would be great if you could update to the latest revision and test it.
#### By Dzenan Zukic on 2015-04-25 13:09
Thank you Andras, I will test this on Monday.
#### By Dzenan Zukic on 2015-04-28 13:36
The update gets rid of the infinitely repeating error messages. The number of messages is now finite. Thanks Andras!

I have discovered a strange thing meanwhile. When I connect to the mainPC using remote desktop connection, tracking tool indicators (which display "OK" or "MISSING") are constantly cycling between OK and MISSING (while tools are static and visible). Could this be due to higher delay and lower frame-rate of display?
#### By Andras Lasso on 2015-04-28 14:00
You may get missing if you don't get updates from the tracker with the expected frequency. Try to set a lower the AcquisitionRate in the OpenIGTLinkTracker device.
#### By Dzenan Zukic on 2015-04-28 14:07
AcquisitionRate="10" takes care of that. Thanks.


## vtk files in plus application
#### Posted by Jason... on 2015-04-27 02:07

Hi, I'm trying to add some new module into fcal application, and I found that many vtk files have been rewrited in plus application.

For example, the class of vtkImageViewer2(vtkInteractorStyleImage) will leads to interactor error with left mouse button down and drag to change the color level.

I just wanted to let you know about this.

Regards,
Jason

#### 1 Comments
#### By Andras Lasso on 2015-04-27 09:26
No VTK files are rewritten in Plus. Actually, it is not even possible to rewrite any classes in C++, as if you redefine the same class then you get a linker error.

What you might have noticed that in some tests we use vtkImageViewer2 and we use the VTKI_TIMER_UPDATE for updating the viewer content, which somewhat interferes with the interactors. It's only in tests, so it should not cause problem in your application.

Let us know if you have more specific information about potential errors in Plus.


## Is transmit power controllable?
#### Posted by Dzenan Zukic on 2015-04-22 16:59

Looking at this page: http://perk-software.cs.queensu.ca/plus/doc/nightly/dev/classvtkUsImagingParameters.html
there is no parameter called power. Is ultrasound transducer's power controllable using plus? If yes, how?

#### 1 Comments
#### By Andras Lasso on 2015-04-22 20:14
Power is usually kept at the default (maximum) value. It is very rarely necessary to reduce it.

Image brightness/contrast is controlled by gain and dynamic range parameters.


## Calibration Laparosopic Ultrasound Probe
#### Posted by MattClarkson on 2015-04-14 03:57

Hi there,

does anyone have experience calibrating a laparoscopic ultrasound probe. We have an Ultrasonix MDP, and a Vermon LAP7, and would like to use an NDI Aurora.

Can anyone recommend a good setup, and procedure? Then I'll give it a shot and report back.
We have already printed the fCal-2.

But what size/type of wire do people use? What configuration?
How do people attach the sensor to the probe such that it survives being pushed through a troccar.

Thanks for any advice!

Matt

#### 2 Comments
#### By Andras Lasso on 2015-04-14 21:40
The only group I know that uses Plus for laparoscopic US calibration is at Children's National Medical Center (Raj Shekhar). You can find the details in this paper:
https://www.assembla.com/code/plus/subversion/nodes/4100/trunk/doc/references/Kang2013.pdf?_format=raw
The tracking marker is outside the body, at the end of a rigid probe.

Sensors are sometimes placed outside the probe, which does not require modification of the probe but you need to fabricate a protective sleeve (it's used for example at Robarts Research Institute for TEE probes by Terry Peters' group; I'm not sure it's feasible in your case).

You may put the sensor inside the tool, which is trivial if the tool has a working channel, but probably there is no channel in US probes, so it requires modification of the tool.

US probes with embedded position sensors are available and they are very convenient (e.g., Ultrasonix SonixGPS probes), but I'm not aware of any laparoscopic probes with built-in sensor.

The wire pattern should be about the same size and should be placed at approximately at the same location as your anatomical target.
#### By MattClarkson on 2015-04-22 03:55
OK, thanks for your help.


## create a 3D model of tongue tumor using the ultrasonix device.
#### Posted by abramolaurent on 2015-03-31 10:12

Hello,

I would like to create a 3D virtual model of tongue tumor using the ultrasonix device.

What do you think about the use of Plus server and slicerIGT to do a precise segmentation of the tumor ‘s boundaries to build the 3D virtual tumor model ?

Do I have to :
- install slicerIGT in a computer that has a network connection to the Ultrasonix computer
- and Plus in the ultrasonix computer to allow for this network ?

Is there other ways (other software…) i could use to segment tumor's boundaries from US slides in order to generate 3D model?

Thank u for your interest.

L.A.

#### 7 Comments
#### By Andras Lasso on 2015-03-31 10:42
Plus/SlicerIGT is intended exactly for applications such as segmenting tumor on ultrasound and use it for intra-operative guidance. Applications like this are already in clinical (research) use.

Although the Ultrasonix computer can run 3D Slicer, it is not a very fast computer and it is already busy with the ultrasound image acquisition and processing, so the display update rates may not be optimal. I would suggest to:
Install just Plus on the Ultrasonix computer, where it acquires data and sends it to 3D Slicer
Install 3D Slicer and the SlicerIGT extension on a separate computer with a strong graphics card, at least 8GB RAM and 64-bit operating system

There are many segmentation tools available in 3D Slicer - more information is needed to give advice on the most suitable tumor segmentation approaches. Is the segmentation intended to be done during the procedure or you acquire data and then later you segment the tumor? How much time do you have for the segmentation? How different the tumor from the healthy tissue? How much user input may be given to guide the segmentation? What do you do with the tumor segmentation information (use for tumor resection guidance, ablation, biopsy, ...)? Do you need to register to pre-operative images (MRI, CT, etc.)?
#### By Abramolaurent on 2015-04-01 09:58
Hello,
my purpose is to obtain a 3D tumor reconstruction (approximation) from only ultrasound slices.

I thought to do a ultrasound slice series acquisition using the automatic scanning of the 3D transducer.
Then, import slices in a software where i could segment in each slice the tumor’s contour as of now manually, and then, obtain a 3D virtual model.

What do you think i could use to do it ?
#### By Andras Lasso on 2015-04-01 12:00
We do ultrasound slice based intra-operative tumor segmentation in the following way:
Set up Plus to send live ultrasound frames to 3D Slicer
Set up 3D Slicer to receive the ultrasound frames and show them in correct position in 3D and in a slice viewer; and set up "Clip volume with model" module to create a surface model from markup fiducials (http://www.slicer.org/slicerWiki/index.php/Documentation/Nightly/Extensions/VolumeClip)
Drop markup fiducials on the ultrasound image (in the slice viewer) at the tumor boundary => the tumor contours will be updated in real-time in 3D (similarly to the way it is shown here: https://www.youtube.com/watch?v=1mYNwJbE7dQ; but on US slices instead of MRI slices)
#### By Abramolaurent on 2015-04-02 13:25
thank u for your help!

I've started to connect the ultrasonix with 3D slicer through Plus server (Device set used: Ultrasonix ultrasound imaging device) to live display the ultrasound images in 3D slicer.

However, Plus server launcher gives me two messages:

1) "No input data available to capture thread. Wainting until input data arrives."
2) "ERROR. Received frame size (505120 bytes) doesnt match the buffer size".

It seems 3D slicer connects well with Plus server, but the latter doesn't transmit any data!

Please find the config file that i'm using attached.

Any hints?
PlusDeviceSet_Server_SonixTouch_L14-5.xml	2 KB
#### By Andras Lasso on 2015-04-02 13:28
Make sure you use a Plus release that matches your Ultrasonix Exam software version:

https://www.assembla.com/spaces/plus/wiki/Downloads

PlusApp-...-Win32-Embedded: can run on Windows XP embedded systems, Ultrasonix systems with Exam software 5.7.x is supported, MicronTracker and Microsoft Media Foundation imaging devices are not supported

PlusApp-...-Win32-US610-Embedded: can run on Windows XP embedded systems, Ultrasonix systems with Exam software 6.1.x is supported, MicronTracker and Microsoft ...
#### By Abramolaurent on 2015-04-09 11:43
Hello,

network finally works ! thank you!

To build the 3D model, I thought that i could acquire a 3D model with the ultrasonix using the « 4DL14-5/38 » probe and retrieve a series of 2D slices in DICOM format (or mha, or any compatible with 3D slicer), from which i could have segmented the tumor.

However it seems i can only retrieve.3DD files using the 4D probe, isn’t it ?

Well, I wonder how to convert 3DD files in a compatible format ?

If not, do you think I should use the Sonix GPS tracker with the 2D probe to build a 3D model through 3D slicer ?
#### By Andras Lasso on 2015-04-09 12:14
Do you need to move the transducer to see the entire tumor? If yes, then you need to move the transducer and track it using Sonix GPS tracker.

Do you plan to use the segmented model for guiding tumor resection, ablation, etc using a tracked tool? If yes, then you need to acquire a volume that has a known position and orientation relative to a reference sensor. I don't think that Ultrasonix can provide you this position and orientation information.

If any of your answers above was "yes" then probably you cannot rely on the 3dv file that the scanner can create but you need to reconstruct the volume and guide tools using Plus/SlicerIGT.


## ultrasound imaging (muscles) project
#### Posted by cimadoro.giuseppe711058 on 2014-11-21 08:12

Hello,

I came across your platform and I'd like to ask some advice to the community.

I'm new to electronics and ultrasound. However, I'd like to make some research about human muscle architecture.

I'd like to know about a typical ultrasound system for that purpose. Do you need any ultrasound transducer and a suitable board to be combined with the open source software?

How much does generally cost an acceptable ultrasound transducer (to acquire muscle images) ?

Thanks,
Giuseppe

#### 4 Comments
#### By Andras Lasso on 2014-11-24 14:14
You need an ultrasound scanner and a tracking device. If the ultrasound scanner does not have a digital interface that Plus supports then you also need a framegrabber to get the output from the scanner.

Ultrasound systems start from about $5000. The simplest, least expensive scanner that Plus supports and does not require a framegrabber is an Interson USB probe (http://www.interson.com/products/usb-probes). The image quality is not as good as expensive, cart-based systems, but those cost about 10x more.

Position tracker: if your field of view is less than about 30cm and up to 1mm tracking error is acceptable then I would recommend to use an electromagnetic tracker (Ascension 3DG or NDI Aurora). They are less expensive (less than $10000) than optical trackers and you don't have any line-of-sight problem, but their field of view and accuracy is not as good as for optical trackers. If you go for optical trackers, I would recommend NDI Polaris (about $15000) or Claron MicronTracker (about $8000).
#### By Abramolaurent on 2015-04-02 13:23
(Comment removed)
PlusDeviceSet_Server_SonixTouch_L14-5.xml	2 KB
#### By Gtang on 2015-04-02 13:33
For this purpose, why not just buy an ultrasound system with 4D motorized probe support? I had thought position tracker is mostly for biopsy (needle) using normal 2D probe.
#### By Andras Lasso on 2015-04-07 12:22
It's a good point: if you need only a small field of view then you may consider using motorized or electronically steered 3D/4D probes. Plus supports Ultrasonix motorized wobbler 3D probes and Philips matrix 4D probes. You can attach external trackers to any 2D, 3D, or 4D probes to reconstruct a volume that does not fit into the probe's field of view.


## Spatial Calibration difficulties
#### Posted by jnc74 on 2015-03-25 16:07

Hello,

We are unfortunately having difficulties performing a spatial calibration. I attached a couple of screenshots of what we are encountering. We cannot seem to get green dots to appear/indicate our wires. In the images attached, you can see our segmentation parameters chosen. The third image shows that no progress is made when we try to perform the calibration, and the program just stalls.

Do you have any advice as to what the problem may be?

Thanks,
Jackie
spatial1.png	260 KB
spatial3.png	233 KB
spatial2.png	263 KB

#### 8 Comments
#### By Andras Lasso on 2015-03-25 16:19
Do you use the fCal-2.x phantom with 3 N wires? On the image I only see two rows.
Also, make sure the initial spacing is correct (see "Check if initial spacing is correct" on http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html)
#### By Jnc74 on 2015-03-26 13:25
Hi Andras,

We are using Fcal 2.0 phantom with 2 N-wires. Will this cause a problem during spatial calibration? We will check the initial spacing as well. Thank you for your quick response.
#### By Andras Lasso on 2015-03-26 13:29
If you want to use 2 N-wires then you have to modify the configuration file accordingly. However, I would suggest to use 3 N-wires because with only 2 N-wires the calibration results are typically much less accurate.
#### By Jnc74 on 2015-03-27 14:43
Great, thank you for the advice Andras.
#### By Jnc74 on 2015-03-30 16:19
Hi Andras,

We have rewired our phantom and unfortunately are unable to obtain green dots in the spatial calibration portion. We have also been altering our segmentation parameters, and still have yet to achieve the optimum image. I have attached two screenshots that may help in figuring out what the problem may be. If you have any suggestions as to how to fix this problem, it would be much appreciated.

Thanks for all the help,
Jackie
errorspatial.png	71.2 KB
errorspatial2.png	215 KB
#### By Andras Lasso on 2015-03-30 16:32
Can we set up a skype call/google hangout with screen sharing to investigate the problem?
#### By Jnc74 on 2015-04-06 13:14
Hi,

Yes that would be great if we could set up a Skype call. Would you be able to call on either Thursday or Friday of this week (April 9th or 10th)?
#### By Andras Lasso on 2015-04-06 16:28
Both days work for me. Let's discuss the details in email (lasso@queensu.ca).


## connection problem SonixTablet to fCal
#### Posted by adiodato on 2015-03-18 10:27

Hello,

I have a problem to connect my device to the application Fcal. I use Ultrasonix Exam 6.1.0 and i run it in Reasearch Mode. I have this version of Plus "PlusApp-...-Win32-US610-Embedded" and I use this setting "PlusServer: Ultrasonix ultrasound imaging device" of application fCal. The log file is in attachments.

thank in advance,

Alessandro
031815_150047_PlusLog.txt	3.54 KB

#### 10 Comments
#### By Adiodato on 2015-03-18 10:37
In addition, the application fCal runs on Ultrasound machine.

Alessandro
#### By Andras Lasso on 2015-03-18 10:48
The Ultrasonix Exam software has to be running and Research mode has to be enabled.
#### By Adiodato on 2015-03-18 11:19
Thank you for your quick answer. Yes, I think that I was running Exam software in research mode (in attachments there is a screenshot).
Screen1.PNG	158 KB
#### By Andras Lasso on 2015-03-19 13:34
Could you please set the log level in Plus to DEBUG and send the result (you can set it in the fCal GUI or in PlusConfig.xml set LogLevel="4")?
Please also double-check the Ultrasonix Exam software version.
#### By Adiodato on 2015-03-21 06:59
Hello Andrea, sorry for my delay. There was a Ultrasonix software problem on our machine, fixed this problem, PLUS libraries work well. However, I want to thank you for your support.

Alessandro
#### By Andras Lasso on 2015-03-21 13:10
Great! Thanks for reporting back.
#### By Adiodato on 2015-03-24 07:27
Hello Andras,

I report you that the US calibration with ultrasonix 4dc7-3/40 probe works well (mean error: 0.68 mm).
I have another question: how can I check the dimension of the US image that has been used by PLUS libraries during the FreeHand calibration? Since I would like to transform the Image reference system into the TransducerOriginPixel reference system.
#### By Andras Lasso on 2015-03-24 10:30
Thanks for reporting back. Which phantom did you use for calibration? What was the imaging depth?

To get the ImageToTransducerOriginPixel matrix: Record a short sequence in an mha file and then open it in 3D Slicer or any other software that can read MetaIO image files. Then move the mouse pointer to the center of the transducer origin on the image and take note of the position (only the x, y coordinate is interesting, the third coordinate is the frame number). Update the row 1-2, column 4 of the ImageToTransducerOriginPixel transform matrix with these x and y values.
#### By Adiodato on 2015-03-31 06:27
Sorry for delay but we have a deadline. It has been used a phantom fCal-2.1 with an imaging depth of about 10 cm.

Thank you for your useful suggestion.
#### By Andras Lasso on 2015-03-31 09:26
Thanks for the information.


## Mailing list
#### Posted by gtang on 2015-03-28 23:10

Gentlemen,

Is there a mailing list that I can subscribe for Plus library development?

Thanks,
Guo

#### 2 Comments
#### By Andras Lasso on 2015-03-28 23:17
The Assembla "Messages" tool is used for posting/answering questions and sending general announcements. To get notified by email, go to Stream/Email Notifications and set "Messages" option to anything else than "Never".

You can also get notifications about any event that happens - they can all be set at the same place (https://www.assembla.com/spaces/plus/users/alert_settings).
#### By Gtang on 2015-03-28 23:25
Got it.

Thanks!


## MMF Video Grabbers - How to select proper "subdevice ID"
#### Posted by Bartolomejka on 2015-03-19 14:51

Dear PLUS team!
I am now experimenting with capturing video using Plus Server and MMF video capture from a USB TV card with svideo and composite inputs. There is no problem to capture the video from webcam, but if I am using this TV card, I have problem to properly set up the subdevice to use.
In config xml, I can set CaptureDeviceId="0" for webcam and 1 for TV card. But the TV card has something like "subdevices". Subdevice: 0 - tuner, 1 - svideo input, 2 - composite input. How can I set these subIDs in config xml? Now, I can comunicate with the card but it is sending no images, since the default subID is 0 and this is for the tuner, which is not tuned and I do not even want to use it, of course. Any idea?
Regards
Bartolomej

#### 6 Comments
#### By Isaiah Norton on 2015-03-19 17:40
Hi Bartolomej,

MMF has a concept of multiple streams per device, so the other sources might be present as a different stream. But right now PLUS only uses the first. If you have compiled from source you could try changing this line:

https://www.assembla.com/code/plus/subversion/nodes/4065/trunk/PlusLib/src/DataCollection/MicrosoftMediaFoundation/vtkMmfVideoSource.cxx#ln399

from `MF_SOURCE_READER_FIRST_VIDEO_STREAM` to 1 / 2 and see if that works. If so then it should be possible to add stream enumeration and selection to the device configuration.

Isaiah
#### By Andras Lasso on 2015-03-20 09:53
Thanks for the pointer, Isaiah,

I've cleaned up the implementation of the MMF device and also added a new configuration parameter - CaptureStreamIndex - that allows you to select any stream that the device provides (#976).

@Bartolomejka: I was not able to fully test it (all devices we have provide only one stream), so it would be great if you could give it a try and let us know if it works. You need to wait for tomorrow's nightly build (rev 4066 or later) or build latest trunk version of Plus to get this new version.
#### By Bartolomejka on 2015-03-20 11:23
Hi community!
I am impressed, how quick you are. To be honest, I was really scared to build PLUS by myself, because of my other projects in ITK, VTK, QT. I will test your new version for sure. Actually I have two grabbers, One with three streams (tuner, composite, svideo) and one with two of them (composite, svideo). I was bit looking into Andras's code and I am just in doubt with the default initializing of the stream to be 0. I am suspecting the two-stream device, that the stream IDs are not starting with 0. But it is just a doubt now. I will test it next week and let you know. Thanks!
#### By Andras Lasso on 2015-03-20 11:33
The StreamIndex selects an item from the list of streams provided by the source device. Therefore the values are always between 0..(number of streams -1).
#### By Bartolomejka on 2015-03-27 12:20
Finally, I did the test and my colleague spent few days with this problematic and here are the conclusions:
- None of four grabbers from three different vendors were working with MMF video capture.
- The problem is not in the streams since the streams are: 0-video, 1-audio, 2-other services (e.g. teletext).
- The key should be something called "crossbar" which connects particular input (svideo/composite) to the output of the grabber. See Working with crossbar. It seems that most of the new devices use it.
- Unfortunately, It seems that this is not supported by MMF and it should be done using DirectShow. See discussion here.
- So we have connected our grabber to Plus using an intermediate software (SplitCam) to do this crossbar operation and then everything works. This workaround is bit crazy but it works. Our lag between Ascension and images obtained this way was ~150ms.

So Andras, thanks for your updated code, but you can switch back to the previous one, because the functionality is the same. And the old one has better formatting of possible devices and their supported resolution (-:
I don't know, how interesting is this problematic for you, whether you are planning to rewrite the code for DirectShow, but it seems it is closed for us. At least for now. If you want more details, I will try to answer your questions.
#### Bye!
#### By Andras Lasso on 2015-03-27 12:37
Thanks for the feedback. We'll update our documentation based on this.

DirectShow/DirectVideo is obsolete (http://en.wikipedia.org/wiki/DirectShow), so we don't plan to add support for it. It may mean that older, consumer-grade grabbers will need the SplitCam workaround. Also, resolution of composite and svideo is so low that a USB converter, such as http://www.theimagingsource.com/en_US/products/converters/ - already supported in Plus - can deal with it easily.


## Plus Server communication questions
#### Posted by goby.dll173884 on 2015-03-12 12:00

Dear Plus Team,
I have implemented an external client able to receive information from the PlusServer starting from receiverClient in the openIGTlink distribution.
In particular my client receives TRANSFORM and IMAGE messages, thus I'm able to acquire tracker measurements and calibrated images.

Now I need to enable the remote control of the PlusServer to enable the recording of image datasets.
I plan to implement a second client able to sent (and receive?) STRING message to the server, is this a correct solution?
Is there a better solution to enable simultaneous streaming of poses and tracked images and remote control of the server?

Thanks in advance for your support

Diego

#### 1 Comments
#### By Andras Lasso on 2015-03-12 14:25
I would recommend to use the same socket for sending STRING commands as you use for receiving the TRANSFORM and IMAGE messages, but otherwise what you describe sounds good.


## Added transform status
#### Posted by Matthew Holden on 2015-03-09 13:00

Hi all,

We are using the EditSeqMetaFile to add a transform to a sequence metafile. When we do this, we notice that no associated status is created with the added transform. Is this expected? If so, is there any way to add the transform status?

In particular, we have recorded a set of StylusToTracker and ReferenceToTracker transforms in the mha file. Then, we want to add the StylusToReference transform at each timestamp. See: S:\data\SlicerIGT\BreastSurgery\2015-03-06_BreachWarningLightExperimentalData\Subject01\RecordingTumorA_20150306_125142.mha (this is the original), and S:\data\SlicerIGT\BreastSurgery\2015-03-06_BreachWarningLightExperimentalData\Subject01\RecordingTumorA_20150306_125142_StylusToReferenc.mha (this is with the StylusToReference transform added).

Thanks!

#### 2 Comments
#### By Andras Lasso on 2015-03-09 13:39
Good point. We always just added a static status OK field but actually the status may vary, so adding the status is not just convenience but a necessity. See the status of this request in #971. The fix is expected in tomorrow's build.
#### By Matthew Holden on 2015-03-10 12:55
Thanks for the quick fix Andras! We tested today and everything works.


## Cannot Connect
#### Posted by jnc74 on 2015-02-12 11:49

Hello,

I am currently trying to connect my devices but receive the following error message (attached).
I am using an L14-5 probe, with Ascension 3DG tracker, and a Phantom 2.0. My sensors are plugged in the correct order as well (Probe, Reference, Stylus). What does this error message mean?

Thanks,
Jaclyn
errormessage.png	104 KB

#### 38 Comments
#### By Jnc74 on 2015-02-12 11:59
I am also receiving this error message when trying to connect to the Plus server as well.
#### By Andras Lasso on 2015-02-12 14:52
As the error message describes, the problem is that Plus cannot connect to the Ultrasonix machine at the IP address 130.15.7.20.

To fix this, you need to change the IP address in the configuration file to match the actual IP address of your machine. If you run Plus on your ultrasound device then you can use the generic 127.0.0.1 IP address.
#### By Jnc74 on 2015-02-16 13:03
How can I go about changing the IP address in the configuration file? Is there anything I need to right click in the configuration screen? I've already obtained the IP address from the command prompt of Plus.
Thanks.
#### By Andras Lasso on 2015-02-16 13:14
Click the edit icon on the left side of the configuration file selector, make the changes, save the file, and connect again.
#### By Jnc74 on 2015-02-16 13:29
I've tried the IP address from my device and the generic one and still get the same error that you see attached. Please let me know what you think, Thanks.
error2.png	183 KB
#### By Andras Lasso on 2015-02-16 13:34
Open the configuration file that is shown in the log (above the errors), change it, save it, and it should work. If not then attach that configuration file.
#### By Jnc74 on 2015-02-16 13:39
I confirmed that I changed the IP address in the configuration file. Here is the file if you could take a look. Thank you again.
PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml	8.59 KB
#### By Andras Lasso on 2015-02-16 13:51
Change the Name attribute in the DeviceSet element to make sure you select the correct file.
#### By Jnc74 on 2015-02-16 15:34
I am still having difficulties.. the last file I sent you was the Plus DeviceSet file, so now I attached the Plus Configuration file. Maybe there is something I am missing in this file?
PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal1.xml	5.9 KB
#### By Andras Lasso on 2015-02-16 15:51
This config file is for a several-year-old version of Plus. Please use the latest stable or nightly developer snapshot version.
#### By Jnc74 on 2015-02-19 11:58
It's weird that that is an old version, because we just installed the software about a week ago. Do you suggest uninstalling and re-installing the software?
#### By Andras Lasso on 2015-02-19 12:00
Please try the latest development snapshot:
https://www.assembla.com/spaces/plus/wiki/Downloads
#### By Jnc74 on 2015-02-19 12:35
I just re-downloaded the latest development snapshot and still get the same error message. It is unable to connect to the IP address. The configuration file I am now sending you appears to be similar to the last, even after the new download. I'm sorry for all this trouble!
error.png	125 KB
PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal1.xml	5.9 KB
#### By Jnc74 on 2015-02-19 12:56
Here is my IP information I obtained from the command prompt. Ive tried all those IP addresses and still nothing.
ipinfo.png	111 KB
#### By Andras Lasso on 2015-02-19 12:58
OK, so you solved the IP address issue now, as the error message shows that you attempt to connect to the local computer (127.0.0.1).
Have you enabled Research Mode in your Ultrasonix Exam software?
What is your Ultrasonix Exam software version?
Which Plus package have you installed?
#### By Jnc74 on 2015-02-19 13:11
The Ultrasonix Exam software is 6.1.0
The plus package installed is Win32.exe and am now getting this error..
I believe that the research mode is enabled.
newerror.png	227 KB
#### By Jnc74 on 2015-02-19 13:17
Yes, research mode is enabled.
#### By Andras Lasso on 2015-02-19 13:17
The package that you downloaded is for 5.7.4.
For 6.1 use this:
http://perk-software.cs.queensu.ca/plus/packages/nightly/PlusApp-2.1.2.3992-Win32-US610-Embedded.exe
#### By Jnc74 on 2015-02-19 13:24
Alright, just downloaded that version and still getting an error...
err.png	173 KB
#### By Andras Lasso on 2015-02-19 14:00
Looks good. To solve this remaining error: in the Ultrasonix Exam software disable features that use the SonixGPS (Plus and the Exam software cannot use the SonixGPS at the same time).
#### By Jnc74 on 2015-02-19 15:36
Alright I did the above disabling, but now I am back to the "cannot connect to the IP address" error message. Its set to the 127.0.0.1. Do you think problem could be the internet in my lab?
#### By Andras Lasso on 2015-02-19 15:38
Keep research mode enabled. Only disable the one or two licenses related to SonixGPS.
#### By Jnc74 on 2015-02-19 15:39
Yes, Sonix GPS are the only ones disabled.
#### By Jnc74 on 2015-02-19 15:47
Hold on.. fcal finally connected the device successfully! I now am getting this message, however. Does this mean something?
new.png	175 KB
#### By Andras Lasso on 2015-02-19 15:50
This looks good.
#### By Jnc74 on 2015-02-19 15:50
Great, thank you SO much for all your help.
#### By Jnc74 on 2015-02-24 11:20
Hi Andras,

We've unfortunately come across another problem. We've successfully calibrated the stylus, but there is no option to begin the phantom registration, or any other options. The only available features are seen in the picture attached. What do you think could be the problem?

Thanks,
Jackie
error3.png	184 KB
#### By Andras Lasso on 2015-02-24 11:33
Thanks for reporting this. Please attach the Plus log file.

@rankin - Could you please have a look?
#### By Jnc74 on 2015-02-24 11:54
Is this the file you are referring to?
022415_110714_PlusLog.txt	1.23 KB
#### By Andras Lasso on 2015-02-24 11:59
Yes, this is it. Please set the log level to debug and send the resulting file - it may contain more useful details.
#### By Jnc74 on 2015-02-24 12:34
Here is the logexpert file
log224.lxj	1.65 KB
#### By Andras Lasso on 2015-02-24 14:42
The file that you've attached is some configuration file. Please attach the ...PlusLog.txt file (that you obtained with log level set to debug in fCal).
#### By Jnc74 on 2015-02-25 11:34
Sorry for the delay but here is the new file with the log level set to debug in fcal.
022515_112916_PlusLog.txt	18.4 KB
#### By Andras Lasso on 2015-02-27 19:16
The issue was probably that large font size was set on your system. We have changed the fCal application screen layout to better work on large font/low-resolution screens (#969). Please try the nightly snapshot tomorrow and let us know if you still have issues.
#### By Jnc74 on 2015-03-04 11:31
Everything is now resolved, thanks for the help :)
#### By Andras Lasso on 2015-03-04 12:54
Great! Thanks for letting us know.
#### By Jnc74 on 2015-03-04 17:06
Another question - We're onto our Temporal Calibration and we're unsure as to which options to choose under the Fixed and Moving sections. Do these matter? I have attached a screen shot of which ones we chose, but it is affecting our spatial calibration and it cannot obtain a transformation. Thanks for the help.

Jackie
temporalcalibration.png	264 KB
#### By Andras Lasso on 2015-03-05 09:59
"it is preferable to use video as fixed signal and tracker as moving signal"
See details in:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/AlgorithmTemporalCalibration.html

If you have problems with temporal calibration then you can just set all the time offsets to 0 (LocalTimeOffsetSec="0" in all Device elements) and move the probe slowly during probe calibration.

This temporal calibration question is not related to the connection problems, so if you have further questions related to temporal calibration then please create a new message instead of adding
####  comments to this one.


## Ultrasonix SDK 5.7.1
#### Posted by NaeimeH on 2015-02-26 10:12

Dear Andras Lasso,

I want to build the PLUS from source code by the help of "Windows Build Instructions" and I need the "Ultrasonix SDK 5.7.1" for Ultrasonix video. Without this I face an error when try to generate the PlusBuild project with CMake.
As your name was mentioned under the part "Device SDKs" I appreciate it if you let me have access to the PLTools space.

Thanks in advance.

Best regards,
Naeimeh

#### 1 Comments
#### By Andras Lasso on 2015-02-26 10:21
I can give access to the PLTools space if you already have the proper license from Ultrasonix. Please contact me at lasso@queensu.ca to discuss the details in private.


## Reconstructed volume is black
#### Posted by custillo on 2015-02-18 10:28

Dear Sir/Madam,

We are using 3D ultrasound probe visualizing (for now) a sawbone in a water bath.
Thus, we are using Plus Lib in order to reconstruct a 3D volume.

For this purpose, we use vtkPasteSliceIntoVolume .

We then do both steps:
1) Acquire images during the movement of the probe motor.
2)Reconstruct the ultrasound volume from a buffer (vtkImageData: imageData).

volumeReconstructor is an instance of vtkPasteSliceIntoVolume.
mat is a vtkMatrix4x4.
We use the following line code in order to insert each slice according to its orientation (ie the orientation of the motor):
volumeReconstructor->InsertSlice(imageData, mat);

We tested, imageData for different positions of the motor, and we visualise it (in order to make sure the buffer is being updated).
mat also is updated according to the orientation of the motor.

In the end of the reconstruction, volumeReconstructor->GetReconstructedVolume() provides an empty volume (full of zeros).

Knowing that we initialize columeReconstructor:

vtkSmartPointer<vtkPasteSliceIntoVolume> volumeReconstructor=vtkSmartPointer<vtkPasteSliceIntoVolume>::New();

volumeReconstructor->SetFanAngles(-0.5*fanAngle*180/PI,0.5*fanAngle*180/PI);
volumeReconstructor->SetOutputOrigin(0, 0, -B_IMAGEDEPTH/2*spacing);
volumeReconstructor->SetFanOrigin(B_IMAGEWIDTH/2*spacing, 0);
volumeReconstructor->SetOutputExtent(0, B_IMAGEWIDTH-1, 0, B_IMAGEHEIGHT-1, 0, B_IMAGEDEPTH-1);
volumeReconstructor->SetOutputSpacing(spacing, spacing, spacing);
volumeReconstructor->SetOptimization(vtkPasteSliceIntoVolume::FULL_OPTIMIZATION);
volumeReconstructor->SetInterpolationMode(vtkPasteSliceIntoVolume::LINEAR_INTERPOLATION);
volumeReconstructor->SetCalculationMode(vtkPasteSliceIntoVolume::WEIGHTED_AVERAGE);
volumeReconstructor->SetOutputScalarMode(VTK_UNSIGNED_CHAR);

// Activate compounding, if not it doesn't work
volumeReconstructor->SetCompounding(1);

// ResetOutput initializes the output volume with the given parameters
volumeReconstructor->ResetOutput();

We need help in order to understand why the reconstructed volume is full of zeros.

Thank you

#### 1 Comments
#### By Andras Lasso on 2015-02-18 10:56
OutputOrigin, OutputExtent, OutputSpacing is not set correctly. The simplest is to use SetOutputExtentFromFrameList to compute the output origin and extent (for the current output spacing).

If you save your tracked frames to file then you can use these tools to determine/visualize the output region:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationVolumeReconstructor.html
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationCreateSliceModels.html


## OpenIGTLinkTracker issues
#### Posted by Brennecke on 2015-02-17 06:41

I want to connect the A.R.T. tracking system using the OpenIGTLinkTracker device and I ran into some issues:

Our server uses the OpenIGTLink message type POSITION, which transfers the pose using a vector and quaternions. In Slicer everything was received and displayed correctly. In fCal only the translation was used. The problem was only the position was read out by the OpenIGTLinkTracker device. I fixed that by extending the pack and unpack implementation in vtkPlusIgtlMessageCommon.

Next it seems that only the rotation was now used by Plus. I couldn't see any translation in the fCal 3D visualization. While debugging I found that in vtkPlusBuffer the interpolation for the position was not set correctly in the resulting matrix. After fixing that I still had some strange behavior. It could only be solved by setting the position vector in the 4th row instead in the 4th column. It also seems to make no difference when I additionally set the position vector in the 4th column. I don't fully understand this.

I attached my fixes as a diff patch.
OpenIGTLinkTracker.patch	5.81 KB

#### 2 Comments
#### By Andras Lasso on 2015-02-17 08:09
Thank you for the patch. I confirm that the POSITION message unpacking implementation in Plus was incomplete (probably due to the misleading "position" name, which usually refers to translation component only). Your patch makes sense but I think there is some confusion about matrix indices (the indexing is matrix[rowIndex][columnIndex]).

There seems to be an error in the patch of vtkPlusIgtlMessageCommon::UnpackPositionMessage method:
This should be removed:
igtlMatrix[3][0] = position[0];
igtlMatrix[3][1] = position[1];
igtlMatrix[3][2] = position[2];

This method also seems to be patched incorrectly:
PlusStatus vtkPlusIgtlMessageCommon::PackPositionMessage(igtl::PositionMessage::Pointer positionMessage, PlusTransformName& transformName,
...
positionMessage->SetPosition( igtlMatrix[3][0], igtlMatrix[3][1], igtlMatrix[3][2] );
should be replaced by
positionMessage->SetPosition( igtlMatrix[0][3], igtlMatrix[1][3], igtlMatrix[2][3] );

vtkPlusBuffer should not be necessary to change.

Please make the above changes, test if it works correctly, and if it does then send an updated patch. Thank you!
#### By Andras Lasso on 2015-02-17 11:59
This has to be fixed in Plus, so I added #966 to track the resolution.


## failing dashboard build
#### Posted by wangk on 2015-02-13 08:52

Hi SlierIGT developers,

I am not sure if you noticed the failing build of SlicerIGT extension on Slicer dashboard. Good idea to fix that.

thanks,

Kevin

#### 1 Comments
#### By Andras Lasso on 2015-02-13 14:06
We keep an eye on the dashboard but it's good if you report issues that we might miss.

The SlicerIGT extension's site is a better place to report this, though: https://github.com/SlicerIGT/SlicerIGT

Reported: https://github.com/SlicerIGT/ToolWatchdog/issues/2


## Can't tracking a tool using PlusServer and 3DSlicer
#### Posted by coconetlero on 2015-02-09 18:46

Hello,

I tried to track my pointer tool using PlusServer and visualize with 3DSlicer, but the tracking don't work.
I followed the tutorial in the SlicerIGT web page [1] and all steps seems to work, even I saw the status "On" in the OpenIGTLinkIF module, but when I moved the pointer nothings happens and the transformation never changes.

I attached my config file, and additional information is that when I used fCal this program runs fine.

Thank for all and best regards


[1] https://onedrive.live.com/redir?resid=7230D4DEC6058018!3110&authkey=!ABKoXhTQrIlY2D4&ithint=file%2cpptx
PlusServer_Configuration_Polaris_Ultrasound.xml	2.78 KB

#### 2 Comments
#### By Andras Lasso on 2015-02-09 19:05
In the PlusOpenIGTLinkServer section of the config file you only have the StylusTipToStylus transform, which is a constant. Add transforms relative to the Reference or Tracker, such as StylusTipToReference.
#### By Coconetlero on 2015-02-12 15:33
That's it. I added the transformation StylusTipToReference and now works.

Thanks a lot.


## Send multiple Tracked Video to 3D Slicer
#### Posted by ah.z.afifi296576 on 2015-02-11 12:04

Hello,

I want to ask,

is it possible to send two tracked video streams to 3D slicer at Once?

Thanks in Advance.

#### 2 Comments
#### By Andras Lasso on 2015-02-11 15:40
Currently you need to start two PlusServer instances to do that. Probably in a few weeks you'll be able to broadcast multiple video streams from the same process (see #963).
#### By Ah.Z.Afifi296576 on 2015-02-11 19:25
Thank you very much


## Fcal Calibration Device set file missing
#### Posted by ilkerh on 2015-02-09 13:09

Dear All;

We have a sonix touch machine in the lab with a SonixGPS sensor. I am planning on performing the probe calibration using fcal based on the ppt document posted on the user manual website. Unfortunately, I can not find the device set file named 'SonixTouch GPS L14 + Reference + Stylus + Phantom '.

I have attached a screen shot of the options I have. Any help would be appreciated.

Ilker
fcal.jpg	304 KB

#### 3 Comments
#### By Andras Lasso on 2015-02-09 14:13
The name has slightly changed:
fCal: SonixTouch US (L14-5 probe) + Ascension3DG tracker (Probe, Reference, Stylus) - fCal Phantom 2.0
(filename: PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml)
#### By Ilkerh on 2015-02-10 09:49
Hi Andras;

Is there a place I can download the new xml file? The only files I can see are attached to the email (picture). Thanks
fcal.jpg	304 KB
#### By Andras Lasso on 2015-02-10 10:21
Ultrasonix only has a 32-bit SDK, so it is only included in the 32-bit Plus package (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceSonixVideo.html).

If you run Plus on the Ultrasonix PC then use the
PlusApp-...-Win32-Embedded.exe for Exam software 6.0.2 and earlier
PlusApp-...-Win32-US610-Embedded.exe for Exam software 6.1.0 and later


## Wrong RGB image
#### Posted by ah.z.afifi296576 on 2015-02-08 21:47

Hello,

I am using the Plus for the first time, and when I connected a usb cam and used the configuration file for
PlusDeviceSet_Server_MmfColorVideoCapture

In the received image the colors is not correct, the red color is blue (I think it is captured as BRG) and I do not know how to correct that.

I appreciate your cooperation.

#### 6 Comments
#### By Andras Lasso on 2015-02-08 21:52
Where do you see the image with wrong colors: in fCal, 3D Slicer, some other software?
#### By Ah.Z.Afifi296576 on 2015-02-08 22:57
in both fCal and 3D Slicer
#### By Andras Lasso on 2015-02-09 14:58
I've tried it with a couple of webcams on different computers and it worked well. Can you attach a screenshot of what you see on the screen and a debug-level log file?
#### By Ah.Z.Afifi296576 on 2015-02-09 19:56
At first,
There is a point I forget to clarify before, when I set the video format to "YUY2" I can not see the image at all, So I changed it to "RGB24". then I get the Image and errors as attached.

the object that looks orange in the picture is blue one.
fcal_screen.jpg	367 KB
#### By Andras Lasso on 2015-02-10 00:47
I've committed a potential fix (see #964). It'll be available in the development snapshot that is generated on Wednesday (rev 3970 or later, http://perk-software.cs.queensu.ca/plus/packages/nightly/).
#### By Ah.Z.Afifi296576 on 2015-02-10 01:51
Thank you very much for help


## Python connection
#### Posted by ah.z.afifi296576 on 2015-02-09 07:01

Hello,

I want to ask

Is there any way to transfer the transforms to python directly like Matlab.

I want to use the transforms directly in python to combine with a CV code.

Thanks in Advance

#### 4 Comments
#### By Adam Rankin on 2015-02-09 09:12
If python has an OpenIGTLink implementation, you could send it over the network via OpenIGTLink (with message of type "TRANSFORM")
#### By Ah.Z.Afifi296576 on 2015-02-09 09:52
Thank you for your replay,
But, I ask about that implementation,
#### By Andras Lasso on 2015-02-09 10:20
I'm not aware of an existing Python implementation but it would not be difficult to implement it at all (the same way as it is implemented for C++, Java, and Matlab already).
Ask on the OpenIGTLink email list (http://massmail.spl.harvard.edu/mailman/listinfo/openigtlink), maybe others have already implemented/plan to implement it/would help in implementing it.
#### By Ah.Z.Afifi296576 on 2015-02-09 19:16
Thank you very much for you concern


## unexpected y rotation in spatial calibration
#### Posted by Andrei State on 2015-01-24 18:31

I am trying to calibrate a laparoscopic transducer using fcal. I use the standard 9-cm phantom, an Epiphan DVI2USB3 for video capture, and an NDI Aurora tracker. After a few successful initial calibrations, I keep obtaining rotated ImageToProbe matrices and can no longer perform a good calibration. I have verified all sensors (probe, phantom, stylus) outside fcal and they work. The erroneous rotation is roughly around a vertical axis that goes through the center of the scan. The problem started as I was doing several calibrations during one scan. Restarting fcal afterwards failed to produce good calibrations.

I have data from the single run mentioned above. After two good calibrations, the subsequent two are rotated. The first of the good calibrations and the two bad ones are visualized in the attached annotated image and labeled GOOD, BAD, WORSE; BAD and WORSE are off by ~19 and ~33 degrees respectively. There is some additional weirdness in that the intersection lines between all three are exactly parallel in 3-space, as the parallel perspective view in the lower right emphasizes. To me, that indicates some math error rather than noise, bad temporal calibration, interference, etc, as these are all likely to cause random-appearing errors. Still, I don't want to discount them. Also, the second of the good calibrations, which is omitted in the attached visualization, is roughly parallel to the first good one (shown with a green outline) and does not exhibit the strange parallel intersection line characteristic. Nevertheless, it is quite surprising to be able to "aim" at a collection of calibrated scans (first, third and fourth in a sequence of four spatial calibrations in a single fcal run) such that they are all edge-on as shown in the lower right.

I am now getting the rotation error each time I calibrate, even though it no longer results in parallel intersection lines with the scans calibrated in the illustrated run. I also attached an XML output file from the newest calibration run, which yielded a ~20 degree y rotation and is thus also bad.


Andrei State
InnerOptic Technology Inc.
y-rotation_weirdness.png	625 KB
20150123_124401.xml	7.25 KB

#### 1 Comments
#### By Andras Lasso on 2015-01-24 19:01
The most probable root cause is that image or probe orientation is wrong. Fix is described in the "I get large (>2-3mm) probe spatial calibration error - what's wrong?" FAQ at http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html

Let us know if those instructions don't help.


## Support of the Plus project with an email
#### Posted by Andras Lasso on 2015-01-21 14:18

Dear Plus toolkit user,

If you find the Plus toolkit useful for your work and you would like to keep exciting new features and fixes coming then please contribute by help us by sending us a letter of support. See details below in the message from Stephen Aylward (Kitware).

Thanks in advance.
Andras

----------------------

Dear Slicer and PLUS communities,

Gabor Fichtinger and I are writing a grant proposal that is requesting NIH funding to support the continued development, maintenance, and distribution of 3D Slicer and the PLUS toolkit.

The title of our proposal is:
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis."

With the funding going to Kitware (me and JC), Queen's University (Gabor Fichtinger, Tamas, and Andras), Isomics (Steve Pieper), BWH, and many others, this proposal is meant to keep not only the software, but also the outstanding communities of Slicer and PLUS thriving for the next four years. The proposal uses the goal of adding real-time ultrasound RF signal processing into Slicer as its "moon shot." In general, it seeks to improve our support of GPU-based methods, custom workflows, and third party software integration. Our goal is to make certain that Slicer and PLUS continue to evolve as our community's research needs evolve.

To make our proposal a success, we need your help! Please take a few minutes to send us a letter of support for our proposal! To make it easy for you to show your support, we have drafted five sample letters. They are at
http://slicer.org/slicerWiki/index.php/2015.02.01_SlicerMaintenance_LettersOfSupport
Two sample letters also are given as text at the end of this email.

We need your letters of support by February 1, 2015! You can send your letter to me as a PDF document or simply as text in an email. My email address is
stephen.aylward@kitware.com

If you have any questions or suggestions, please do not hesitate to contact me or Gabor.

Best regards,
Stephen
--
====================================================
Stephen R. Aylward, Ph.D.
Senior Director of Operations, North Carolina, Kitware, Inc.
http://www.kitware.com and http://www.aylward.org
(919) 969-6990 x300
====================================================

=== SAMPLE LETTER OF SUPPORT #1 ===
~~~~
January 20, 2015


Stephen R. Aylward, Ph.D.
Senior Director of Operations, North Carolina
Kitware, Inc., USA

Gabor Fichtinger, Ph.D.
Professor and Cancer Care Ontario Research Chair
Queen’s University, Canada


Dear Drs. Fichtinger and Aylward

With this letter I am indicating my strong support for your NIH R01 proposal “Slicer+PLUS: Collaborative, open-source software for ultrasound analysis.”

3D Slicer and PLUS are foundational components of much of my research. The ability to have access to a variety of tracking technologies and streamed image (ultrasound) data from the combination of Slicer and PLUS is a great catalyst for innovation in image guided surgery. The online documentation and support that I’ve received from these communities is also outstanding. I strongly encourage the NIH to support the continued development and maintenance of Slicer and PLUS via your proposal.


Best regards,
<Your name here>
~~~~

=== SAMPLE LETTER OF SUPPORT #2 ===
~~~~
January 20, 2015


Stephen R. Aylward, Ph.D.
Senior Director of Operations, North Carolina
Kitware, Inc., USA

Gabor Fichtinger, Ph.D.
Professor and Cancer Care Ontario Research Chair
Queen’s University, Canada



Dear Drs. Aylward and Fichtinger,


I am writing to give my enthusiastic support for your NIH R01 proposal “Slicer+PLUS: Collaborative, open-source software for ultrasound analysis.”

I have been using 3D Slicer for the past several years, and it has become a critical tool in my research. It has allowed me to rapidly view, segment, and register medical images for my NIH-funded projects. It has the methods that I need, and I encourage the NIH to support its continued development and maintenance.

One of the aspects of 3D Slicer that sets it apart from other tools is its infrastructure. The website and email lists are excellent. The online and conference-based tutorials are extremely helpful. The quality of the software on multiple platforms is outstanding. Clearly, the infrastructure that is in place is one of the key components of Slicer’s broad success. It is difficult to imagine that Slicer’s ongoing and future success would be possible without direct support for that infrastructure.

Another aspect of 3D Slicer that sets it apart is its extensibility. Over the past six months there has been a significant expansion in the modules that are available for 3D Slicer via its “app store” (the extension manager). These community-contributed modules are touching on a wide diversity of challenging tasks in medical imaging. Via these plug-ins, Slicer is quickly becoming a hub for the development and exchange of cutting-edge research.

For these and numerous other reasons, I strongly encourage the NIH to support your proposal.



Best regards,
<Your name here>
~~~~

#### 1 Comments
#### By Siavash Khallaghi on 2015-01-23 15:42
I have distributed the message in our (RCL) group. I hope the funding goes through.


## 3D Ultrasound Probe Calibration
#### Posted by Jason... on 2015-01-21 19:50

Hello,

I'm wondering whether if the PLUS+3D Slicer can help to do the 3D probe calibration or not.

I found that it's very difficult to do the verification if I select the points manually from the volume data while imaging the fcal2.0.

Is that PLUS+Slicer has the application function for 3D probe calibration ?

Regards,
Jason.

#### 8 Comments
#### By Tamas Ungi on 2015-01-21 21:26
Hi Jason,

Although I haven't calibrated a 3D US probe before, but I have a feeling that U31 tutorial on this page: http://www.slicerigt.org/wp/user-tutorial/
would work well, especially using a candy cane stylus: http://perk-software.cs.queensu.ca/plus/doc/nightly/modelcatalog/
Look at Stylus_Candycane...
You still need to manually pick the tip of the stylus. But it should be accurate because its facing the probe.

Tamas
#### By Andras Lasso on 2015-01-22 00:12
An automatic 3D probe calibration (method described in http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1849134) is planned to be added to Plus. Contact @rankin for expected date.
#### By Adam Rankin on 2015-01-22 12:38
Hi Jason,

What probe model are you using?

@lassoan At the moment the 3D calibration is already written externally. Unless otherwise necessary, I plan on simply transforming those into the PLUS coordinate system and using them as is.
#### By Andras Lasso on 2015-01-22 14:37
OK, thanks for the information.

Just out of curiosity, is the 3D calibration algorithm available publicly?

It would be also possible to use the current fCal application for 3D calibration, using the same phantom, by just doing a couple of modifications in the calibration code.
#### By Jason... on 2015-01-22 20:37
Hi rankin,

I'm using the transrectal ultrasound probe, but the ultrasound device I'm dealing with is not for real time 3D imaging. The algorithm in “Solving for free-hand and real-time 3D ultrasound calibration with anisotropic orthogonal Procrustes analysis” has requested for real time 3D ultrasound and a special phantom. Is that possible to use the static, reconstructed volume and the fcal phantom to achieve the calibration in your module?
#### By Andras Lasso on 2015-01-22 22:38
Jason, It's very simple then, you have a tracked 2D ultrasound system and the fCal application in Plus (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationfCal.html) is developed exactly for calibrating this kind of systems.

Once you have the calibration, you can reconstruct 3D volumes with Plus and SlicerIGT (see for example https://www.youtube.com/watch?v=lfZeXabDjMg).
#### By Jason... on 2015-01-23 02:04
For some reasons, I have to reconstruct the 3D volume in the ultrasound machine, that means I cannot use the volume reconstruction module in plus.
#### By Andras Lasso on 2015-01-23 08:17
We most often reconstruct the volume on the ultrasound machine (see some info on volume reconstruction options here: http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ProcedureVolumeReconstruction.html).

If you give more information on what you want to achieve then we can give more specific help. Otherwise you can just browse the user manual (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/index.html) or check out the tutorials on the SlicerIGT website (http://www.slicerigt.org).


## Frame grabber for Hitachi EUB-7000HV
#### Posted by Mikael Brudfors on 2015-01-14 06:55

Hello,

We would like to access the b-mode images of a Hitachi EUB-7000HV US machine. It has an S-video output and (since we do not have access to the research interface of the machine) we were thinking of using a frame grabber that is compatible with Plus and has a USB hardware interface. I have been looking in the instruction manual of the machine but, unfortunately, I have not been able to locate its frame rate nor b-mode resolution. Could you perhaps recommend a suitable frame grabber?

Thank you,

Mikael Brudfors

#### 2 Comments
#### By Andras Lasso on 2015-01-14 07:10
We use Imaging Controls DFG/USB2pro for S-video capture. It is inexpensive (about $250) and it works well.
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceICCapturing.html
#### By Mikael Brudfors on 2015-01-14 07:20
Thank you Andras!


## Logo
#### Posted by Dzenan Zukic on 2015-01-12 15:17

Does Plus have a logo? Where can I find it? I need it for linking to you from our page: http://public.kitware.com/Wiki/PET-CT

#### 2 Comments
#### By Andras Lasso on 2015-01-12 18:00
The logo is available here (.svg is the source format, created in inkscape):
https://www.assembla.com/code/plus/subversion/nodes/3914/trunk/doc/overview
#### By Dzenan Zukic on 2015-01-12 22:03
Excellent, thank you!


## Volume Reconstructor on multiple scalar components
#### Posted by mignonp on 2014-12-09 08:18

Hi,


I am currently using Plus and volumeReconstructor to create a color-Doppler 3D volume but I wondered if volumeReconstructor only deals with B&W images because the reconstructed volume is B&W.

How I can get a RGB volume with volumeReconstructor ?


Thanks.

#### 4 Comments
#### By Andras Lasso on 2014-12-10 15:20
Thanks for reporting this.

As I see, the volume reconstructor can handle RGB images but at the end only once component is returned as an output.

Do you use perform offline reconstruction with the command-line application (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationVolumeReconstructor.html) or the volume reconstructor device (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceVirtualVolumeReconstructor.html)?

If you send me a sample color data set and a parameters that you tried to use for the reconstruction I'll try to make it work.
#### By Mignonp on 2015-01-05 06:26
Hi,

Thank you for your answer.

In fact I use directly the vtkPasteSliceIntoVolume (http://perk-software.cs.queensu.ca/plus/doc/nightly/dev/classvtkPasteSliceIntoVolume.html) and vtkFillHolesInVolume (http://perk-software.cs.queensu.ca/plus/doc/nightly/dev/classvtkFillHolesInVolume.html) to reconstruct my volume. My 2D images have 3 scalar components but the output as only 2 component (BW and alpha channel).
#### By Andras Lasso on 2015-01-05 09:28
Try to change the number of scalar components of the output volume in vtkPasteSliceIntoVolume::ResetOutput. Now it's hardcoded to 1 but we can make it configurable.
#### By Mignonp on 2015-01-06 03:03
Thanks, it works well.

Even if my case is uncommon I think it will be better for the number of scalar to be configurable as you said.

Thanks again.


## Spatial calibration error
#### Posted by Jason... on 2014-12-16 09:32

Hi, I met with a problem while dealing with the spatial calibration.

Here is it: I adjust the segmentation parameter in the edited dialog, and it can shows the 9 green dots. Apply and Close. But the green dots cannot show up in widget canvas, and when I click start spatial calibration, errors occurs.

Any ideas with this problem? I have attached the config file and the log file.

Best regards,
Jason.
seg.png	116 KB
spatial.png	149 KB
config2.0.xml	7.59 KB
121614_220827_PlusLog.txt	41.7 KB

#### 16 Comments
#### By Adam Rankin on 2014-12-16 09:38
Hi Jason,

There are a couple of things that can be cleaned up in the config file!

I have attached a cleaned up version. Here is what I changed:

11: ToolReferenceFrame="TrackerDevice" --> ToolReferenceFrame="Tracker"

19: <DataSource Id="stylus" /> --> <DataSource Id="Stylus" />
config2.0.xml	7.58 KB
#### By Adam Rankin on 2014-12-16 09:39
Could you give that a try and see what happens?
#### By Vpai132190 on 2014-12-16 11:28
Hi Adam,

I was just going to post a similar problem, when I saw this entry. I am having exactly similar issues as Jason is. I have tried a few things with adjusting the gain and trying to get the best possible image for segmentation. It works perfectly in the seg. toolbox. I close and apply, but the segmentation fails to apply! I have tried to replicate the parameters that you guys use as best as I can and then fine tuned them to get a segmentation. I would appreciate any help and guidance.

Jason my apologies for hijacking your post :)

Please find attached the images and my config. file.

best,

V
afterapplyingsegparm.png	181 KB
segmentedimage.png	99.5 KB
CUTTERS_TUS_1_20141215_195933.xml	7.04 KB
#### By Andras Lasso on 2014-12-16 11:31
Vpai, please attach the log file. It is very likely that the root cause of the problem is described there.
#### By Adam Rankin on 2014-12-16 11:31
Hi Vipul,

Could you attach your PLUS log? I see a red dot in the bottom right corner!
#### By Vpai132190 on 2014-12-16 11:35
Thanks for the quick reply. I have attached the log file.
121514_194057_PlusLog.txt	483 KB
#### By Andras Lasso on 2014-12-16 11:39
"I close and apply, but the segmentation fails to apply" -> segmentation results are only shown after you click start. Let us know if this was the problem or we should keep looking for issues in the log file.
#### By Adam Rankin on 2014-12-16 11:54
Based on where the log stops, I'm guessing you didn't start spatial calibration. As Andras mentioned, the segmentation result is only displayed if the spatial calibration is being performed.

Jason, any luck?
#### By Vpai132190 on 2014-12-16 12:15
Aah, I see. Thanks, it works. I am sorry for the trouble. I had tried and failed a couple of times, so I assumed there I was doing something wrong (Other than the obvious of not running the segmentation).
#### By Jason... on 2014-12-16 22:05
Thank you, Adam. Sorry for the delayed reply. The new config file can help, the green dots shows when I click start. But there is another question. Lots of warnings occurs like: Processing cannot keep up with aquisition! Try to decrease MaxTimeSpentWithProcessingMs parameter in device set configuration (it should be more than the processing time (the last one was 270), so if it is already small, try to increase RecordingIntervalMs too).

And when the progress bar goes to about 90%, the program has to been stopped because of a debug error.

I have attached the log file.
spatialerror.png	167 KB
config.xml	7.58 KB
121714_104344_PlusLog.txt	120 KB
#### By Adam Rankin on 2014-12-16 22:12
Don't worry about the processing keeping up with acquisition, the computer will do its best but it won't affect the calibration.

It looks like PLUS crashes because it is running out of memory. What are the specifications of the computer you are running on?
#### By Jason... on 2014-12-16 22:23
(Comment removed)
#### By Jason... on 2014-12-16 22:28
I'm using my laptop to do the calibration, and I find that there still has about 50G available space in my C disk.
#### By Andras Lasso on 2014-12-16 22:42
fCal runs out of RAM, not disk space. Maybe because of the image frames are relatively big.
You can reduce the memory consumption by decreasing the video buffer size.
Change this line:
<DataSource Type="Video" Id="Video" AveragedItemsForFiltering="20" BufferSize="500" PortUsImageOrientation="MF"/>
to this:
<DataSource Type="Video" Id="Video" AveragedItemsForFiltering="20" BufferSize="50" PortUsImageOrientation="MF"/>
#### By Andras Lasso on 2014-12-16 22:50
You get the warnings about processing cannot keep up with the acquisition because you've built Plus in debug mode. Debug builds typically 2-10x slower than release builds. They also consume more memory. The fix is easy: build Plus in release mode or use the pre-built nightly latest development snapshot package available at Downloads.
#### By Jason... on 2014-12-16 23:38
Thank you, Andras. I try the way you said ,and it works well.


## order and directions of transforms
#### Posted by eulbeul357867 on 2014-12-01 07:57

Hello everybody,

I am new to Plus and I have encountered some difficulties to transform a point from the Image frame to the Tracker coordinates or Reference.

I am using an Ultrasonix from which I get the frames via an Epiphan grabber and tracking is done with an Ascension tracker. I got the calibration working with reasonable calibration error. Please note that my lab is quite noisy so I see quite some movement of the tools even though they are in a fixed position.

After calibration I use the fCal application to acquire tracked frames in order to develop my own application. The goal is to track instruments in the 2D image frame and compute there 3D position (Tracker coordinates would be fine). Unfortunately, I wasn't able to find any documentation on how the transforms are supposed to be applied since order and direction of each transform is critical (any hints to the right documents are highly appreciated). Right now I compute my point tracker space (p_tracker); p_tracker = T_probe->tracker T_image->Probe T_TransducerOriginPixel -> TransducerOrigin p_image, where p_image is a point in the grabbed frame. However, if I use the VolumeReconstruction application to reconstruct a volume in tracker space and compare the 3D points with my tracked points I do not get the same results.

So, any hints to the right documents or in what order I should apply the transforms would be highly appreciated or perhaps there is something wrong somewhere else.

Thank you very much.

Kind regards,

Alex
PlusDeviceSet_fCal_Epiphan_Ascensio_WetLab_Recalibration_phatom1p2_20141127_173825.xml	7.68 KB

#### 3 Comments
#### By Andras Lasso on 2014-12-01 08:21
This page should explain everything:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/CoordinateSystemDefinitions.html#TransformationMatrix

Reconstruct the volume in the same reference coordinate system that you use as To coordinate system for the tool transforms and tracked image embedded To transform to make everything appear in the same coordinate system.

Let me know if something is still not clear.
#### By Andras Lasso on 2014-12-01 08:22
Also check out the detailed step-by-step tutorials at www.slicerigt.org
#### By Eulbeul357867 on 2014-12-01 13:46
Dear Andras,

Thank you very much for the quick reply. I will look into links that you posted and recheck my transformations. The slicerigt website looks quite good. Thanks!


## Missing #include <unistd.h>
#### Posted by Dzenan Zukic on 2014-11-28 11:15

In file src/PlusCommon/vtkPlusConfig.cxx function readlink() is called, which is defined in unistd.h. However, unistd.h is not included. To fix the compile error these lines are needed near the beginning of the file:

#ifndef WIN32
#include <unistd.h>
#endif

#### 4 Comments
#### By Adam Rankin on 2014-11-28 11:22
Hi Dzenan,

Under what OS and compiler are you building plus in?

Cheers
Adam
#### By Andras Lasso on 2014-11-28 13:27
We can certainly change this but it would be useful to understand why it fails for you so that we can fix it consistently throughout the toolkit.

In vtkPlusConfig.cxx unistd is already included with:
#if defined(unix) || defined(__unix__) || defined(__unix)
#include "unistd.h"
#endif

There is another unistd include in Plus (ndicapi_thread.h) with:
defined(unix) || defined(__unix__) || defined(__APPLE__)

Do you use Mac OSX?
Would defined(unix) || defined(__unix__) || defined(__APPLE__) work for you, too?
#### By Dzenan Zukic on 2014-11-28 14:56
Sorry, the project was using 2.0 release:
https://subversion.assembla.com/svn/plus/branches/Plus-2.0/PlusLib/src/PlusCommon/vtkPlusConfig.cxx
It has been fixed meanwhile.

However, API has changed slightly since 2.0, e.g. "vtkPivotCalibrationAlgo" no longer has a member "Initialize". I guess 2.0 release is not going to change any more?
#### By Andras Lasso on 2014-11-28 16:16
There have been huge amount of enhancements and fixes since 2.0, so I would suggest to use the latest trunk version. It's stable, we plan to make a new release very soon, and we don't plan to make major changes in the near future.


## Printable 3D model catalog
#### Posted by Andras Lasso on 2014-11-28 01:37

We have released the Plus 3D model catalog that contains printable models of tracking fixtures (modular system for attaching optical and electromagnetic tracker markers and sensors to various tools), commonly used tools (stylus, ultrasound probes), and calibration phantoms. Thanks to Tamas for designing and refining most of the models!

The catalog is available from the Download section or directly at this link:
http://perk-software.cs.queensu.ca/plus/doc/nightly/modelcatalog/

Any feedback is welcome.

#### 0 Comments


## how to search slice from reconstruction volume
#### Posted by Jason... on 2014-11-05 06:28

Hi,all

I am confused with how to search a image slice in the volume after the VolumeReconstruction operation based on the current slice information.

Does it use the formula of target image = current image * T current image to tracker * T tracker to target image ? If so, how to get the transformation of tracker to target image?


Thanks in advance for your support

Regards
Jason

#### 11 Comments
#### By Tamas Ungi on 2014-11-05 08:16
Hi Jason,

When you run the volume reconstructor, you specify a --image-to-reference transform in the command line, right? Are you using this program? http://research.cs.queensu.ca/perklab/plus/doc/nightly/user/ApplicationVolumeReconstructor.html
E.g. if you say --image-to-reference=ImageToTracer, then the reconstructed volume will be in the Tracker coordinate system. this is not recommended. If the Tracker is optical, the camera may move/shake. If EM tracker, then the EM Transmitter may move during recording.
It is recommended that you fix a Reference coordinate system to the patient, and reconstruct your ultrasound volume in that. --image-to-reference=ImageToReference.
How do you define you "target image" coordinate system? Is that another image of the patient? E.g. do you want to fuse MRI or CT with the ultrasound volume?
#### By Jason... on 2014-11-05 09:14
Thanks your reply!

I didn't run the volume reconstructor independently. I use the PLUS application to develop an ultrasound-guided intervention application. pre-operative 3D ultrasound images and intra-operative 2D ultrasound images will be used in the EM tracker coordinate. And the question is :

1. how to align the 2D image with pre-aquired 3D image(the 3D volume can be constructed by PLUS VolumeConstruction operation ).

2. And what about if the 3D volume gets by a 3D ultrasound probe directly? gets the image to tracker transform during 3D imaging? but in this situation, the probe to tracker transform is fixed, so the image to tracker transform is fixed.

Jason
#### By Andras Lasso on 2014-11-05 10:44
re 1: if you use the same reference coordinate system for both 2D and 3D images then they will be aligned

re 2: If you receive 2D images from a wobbler probe (e.g., Ultrasonix 4DC7-3/40) then the transform between the probe and the internally moving transducer is just one more transform and you reconstruct the volume as usual (e.g., see transforms at: https://www.assembla.com/code/plus/subversion/nodes/3831/trunk/doc/tutorials/MotorizedTransducerTransformsComputation.pptx). If you get a reconstructed 3D image from the ultrasound system then you need to determine the image to probe transform manually (e.g., by landmark registration in Slicer).
#### By Jason... on 2014-11-06 06:13
Actually, I still have a little confused with how to align the 2D and 3D images(in the same tracking coordinate), could you give me some more detail tips?---align the real time image with the slice in reconstructed volume.
#### By Andras Lasso on 2014-11-06 09:22
For more specific instructions we need more details about your environment and setup.
Do you use 3DSlicer and SlicerIGT for visualizing the 2D and 3D images?
Do you use a reference sensor?
#### By Jason... on 2014-11-06 20:58
The system environment is : PLUS + EM tracking + 3 sensors(one 5DOF for stylus/ two 6DOF for probe and N-wires phantom) + ultrasound machine. I have attached the config file, and in this case I choose to import a reconstructed 3D image from the ultrasound system, and I will take care of the image to probe transform.

no 3DSlicer, no SlicerIGT, I program the visualization of 2D and 3D images by myself.

no other sensors were used in the system, I take the tracking coordinate system is fixed for 2D and 3D images.
config2.0-backup_20141013_154708.xml	7.55 KB
#### By Andras Lasso on 2014-11-06 23:05
If you "import" the reconstructed 3D image from somewhere then you need to determine the transform between the 3D image and your chosen reference coordinate system. For example, you can determine the transform using landmark registration (algorithm is available in Plus, you need to implement GUI; or you can just use the Fiducial registration wizard module in SlicerIGT).

If you know the 3D volume's ReconstructedImageToRefefence transform and the 2D image slice's ImageToReferenceTransform and you use these transforms to set the position and orientation of the volume and slice then the rendering will be correct.

If anything is not clear about what I described, complete at least the Getting started tutorials at http://www.slicerigt.org/wp/user-tutorial/ (these explain basic IGT concepts that are essential, even if you don't plan to use Slicer for the final implementation).
#### By Jason... on 2014-11-08 02:06
(Comment removed)
#### By Jason... on 2014-11-08 02:23
Thanks, Andras. It helps a lot!
#### By Jason... on 2014-11-14 08:05
Hi Andras,

I have tried to figure out the transform between the 3D image(reconstructed from other place) and the reference coordinate system.I use the landmark registration by selecting points in the image volume (matching with the points defined in PhantomDefinition) manually, but I found the error was large.

You have mentioned the transform calculation algorithm is available in Plus.Is there have an interface function with that? And what the rules of selecting points is? Can you give me more details?

Best regards,
Jason
#### By Andras Lasso on 2014-11-14 11:28
The algorithm is implemented in vtkPhantomLandmarkRegistrationAlgo class.

The landmark registration algorithm is trivial and essentially the same in SlicerIGT and Plus, therefore if you don't get good results in Slicer (where you can visually check everything) then probably it'll be harder to make it work in Plus. I would suggest to learn to do the registration in SlicerIGT:
1. Check that the order of the landmarks is the same in the two lists
2. See if a good alignment can be actually obtained by doing manual registration (just apply a transform to one object and translate/rotate it using the Transforms module)


## Build Error with NDI Certus
#### Posted by caitlins on 2014-11-07 19:20

I am trying to build Plus (on a 32-bit ultrasonix machine) with the Certus option enabled. I think that I have the library, exe and include files correctly located, but I get an error (C1189) when building that the Host is not defined and my options are PLATFORM_X86 or LINUX. The error comes from ndhost.h

Do these need to be defined in CMake somewhere?

thank you,
Caitlin

#### 3 Comments
#### By Andras Lasso on 2014-11-07 20:24
We can build with Oapi-3.0.0.66 without any problems. We use the IBMPC version of the ndhost.h include file (it defines HOST_WIN32). If you use a different Oapi version then it may be possible that you need to make slight adjustments.
#### By Caitlins on 2014-11-10 14:19
Hi Andras, Thank you for your reply. Could you send me your version of ndhost.h so I can compare it to what I have here?

thank you!
#### By Andras Lasso on 2014-11-11 22:16
Let's continue this discussion in email.


## Beginner with PLUS. Need some guidance.
#### Posted by vpai132190 on 2014-11-06 11:11

Hello Everyone,

I am writing this because I want to use PLUS in my research work with tracked ultrasound. I have been trying to understand how I could use the library to develop my own application.I am using a Sonosite portable ultrasound system (http://www.sonosite.com/m-turbo) which I am interfacing with a desktop via an Eurasys (http://www.euresys.com/) frame grabber. I also have a polaris system setup for tracking and it communicates with the desktop via serial.

I have written libraries to use the frame-grabber and the tracking system around their manufacturer provided core API.

My questions are (and to check if I am in the right direction)
(1.) I understand that in order to acquire images I need to use a frame-grabber with PLUS. Considering the above setup, what is the best way to go about this? (I will have to write some code to use the frame grabber with PLUS)
(2.) Once I have the setup done, I can calibrate the probe and get the transformation matrix.I can then purely use the transformation matrix in my other application where I am doing visualization in VTK.

I am sorry if this seems a little confusing or vague. I will appreciate any help.

IDE: VS2012

Thanks,

Best Regards,

Vipul

#### 3 Comments
#### By Andras Lasso on 2014-11-06 12:27
Probably you don't need to write any code, just download a recent release and use it (https://www.assembla.com/spaces/plus/wiki/Downloads).

1. Your framegrabber hardware may be already supported by Plus: try the MmfVideo (recommended) or VFWVideo device.
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceMicrosoftMediaFoundation.html
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/DeviceVideoForWindows.html

If Sonosite had an API for getting the images without a framegrabber (e.g., through Ethernet) then you can implement a new device class in Plus to avoid the need for a framegrabber.

2. Yes, you can calibrate the probe using fCal application. SlicerIGT (www.slicerigt.org) probably offers all visualization that you need (slice view, 3D views, 2D/3D multi-modalidty image fusion, tools visualization, DICOM import, registration, segmentation, etc. these are all basic features nowadays, no time should be spent with reimplementing these). If your system works fine then you may do some coding to customize/simplify the GUI.
#### By Vpai132190 on 2014-11-07 14:58
Hello Dr Lasso,

Thank you for your reply. So I got in touch with Euresys (Frame-grabber manufacturer) support team to inquire if they have support for Microsoft Media Foundation, and as suspected they don't. In addition to their own drivers, they do have direct show filters. I looked at the way you guys implemented the Epiphan and ICC devices in the source code. Is that the way I might have to move forward?

Unfortunately Sonosite being a clinical system doesn't expose their API.

Best Regards
#### By Andras Lasso on 2014-11-07 15:46
To see the list of supported devices, run these tests on the computer where the framegrabber is connected to:

vtkMmfVideoSourceTest.exe --list-devices

vtkWin32VideoSourceTest.exe --show-dialogs

If the framegrabber is not visible through these interfaces then you might buy one that is already supported by Plus or implement a class similar to Epiphan and ImagingControls.

#### By the way, several clinical systems nowadays have API to access images without a framegrabber (BK, Siemens, Ultrasonix, Telemed, Interson, ...).


## Contributing a patch
#### Posted by Dzenan Zukic on 2014-11-06 21:05

PlusLib is a part of superbuild of a project I started working on recently. It does not compile with vtk6 - the vtkTypeRevisionMacro is the culprit. I guess that macro needs to be removed or encapsulated in a #if VTK_VERSION<=5. Which one of those is preferred, and how do I contribute a patch?

#### 3 Comments
#### By Andras Lasso on 2014-11-06 22:52
Plus can be built with VTK6 successfully (see the dashboard, for example: http://crunch.cs.queensu.ca/CDash/buildSummary.php?buildid=30232). I think the problem might be that you've enabled the VTK_LEGACY_REMOVE option. The quickest fix is to keep that CMake option disabled.

As vtkTypeRevisionMacro is useless anyway, we'll replace it with standard vtkTypeMacro. We'll also check if there is anything else that need to be changed to be compatible with VTK_LEGACY_REMOVE. You can track the status of this activity in #947.
#### By Dzenan Zukic on 2014-11-07 09:29
(Comment removed)
#### By Dzenan Zukic on 2014-11-07 09:33
Some errors remained - I added the patch file to the ticket.


## Z wire phantom calibration and quality assessment
#### Posted by goby.dll173884 on 2014-11-03 11:02

Hello to everyone,
first of all congratulation for the great toolkit!

I've just started working on US probe calibration with PLUS and I need to evaluate the quality of the geometrical calibration. I've read previous discussions and some papers about the topic and as far as I've understood I need to use a different phantom to assess the quality of the estimated calibration.

Is it correct to use a second Z wire phantom with a different number of Z layers and/or different cabling positions?
Is it better to use a single point phantom (for example cross-wire or a calibrated pointer) for the quality assessment?

Thanks in advance for your support

Regards
Diego

#### 2 Comments
#### By Andras Lasso on 2014-11-03 12:57
Ideally, for calibration accuracy assessment we would need ground truth measurements that are a magnitude more accurate (about 0.01mm) than the tested method. Unfortunately, there seems to be no practically usable method that could provide this ideal accuracy, but there are a number of methods that give comparable accuracy (about 0.1mm).

So, probably the best you can do is to double-check the results with an independent method. The more independent the better, because it's less likely that you underestimate the error because of making the same mistakes in calibration and validation.

Therefore, if you use Z wires for calibration then I would recommend to use a completely different method for validation. For example, measure the position of a wire crossing or a tracked stylus tip in both the Probe and the Image coordinate system.
#### By Tamas Ungi on 2014-11-03 21:08
I find the tracked stylus tip to be the best to check accuracy. Visualize the tracked stylus in 3D Slicer, and visualize the tracked ultrasound image too. Move the stylus around the image and check if the stylus and the image of the stylus are intersecting each other. This confirms that the calibration brings the image to a correct position, within a range that you are able to see in the image. Any error smaller than this range will have invisible effect, so usually you don't need to worry about that.
You can use tutorial U-31 on this page to see how to do this in practice: http://www.slicerigt.org/wp/user-tutorial/


## Epiphan DVI2USB connect to Olympus CV-180
#### Posted by Jasper Nijkamp on 2014-10-24 11:04

Dear all,

I finally received my Epiphan framegrabber to be able to read the videostream from my olympus laparoscope system.
Unfortunately, the Olympus CV-180 has no standard VGA or DVI output ports. In the attatchment there is an overview of the available connections.
Anyone a suggestion on a converter cable which would make it possible to use the Epiphan framegrabber?

Regards and have a nice weekend,
Jasper
OlympusCV180UserManual.pdf	126 KB

#### 1 Comments
#### By Andras Lasso on 2014-10-24 11:39
I think you need an active converter. Composite to VGA converters should be available for about $40.


## Build error
#### Posted by Jason... on 2014-10-19 11:58

Hi, I'm using the PLUS to develop a platform for 2D Ultrasound-Based Interventions of prostate. But when I add my own files(ui, cpp,h) into PLUS, errors occurs.

Here is the steps I took:
1. change the cmakelist.txt to add the files.
2. cmake the PluApp.
3. rebuild PlusBuild.

Here is the errors:(both in PlusBuild and PlusApp project)

11>1>moc_VolumeReconstructionToolbox.cxx
11>1>.\Toolboxes\moc_VolumeReconstructionToolbox.cxx : error C2471: cannot update program database 'c:\users\ocean\devel\plusexperimental-bin\bin\debug\fcal.pdb'
11>1>.\Toolboxes\moc_VolumeReconstructionToolbox.cxx(110) : fatal error C1903: unable to recover from previous error(s); stopping compilation
11>1>moc_PhantomRegistrationToolbox.cxx

11>1>VolumeReconstructionToolbox.cxx
11>1>..\..\PlusApp\fCal\Toolboxes\VolumeReconstructionToolbox.cxx : error C2471: cannot update program database 'c:\users\ocean\devel\plusexperimental-bin\bin\debug\fcal.pdb'
11>1>..\..\PlusApp\fCal\Toolboxes\VolumeReconstructionToolbox.cxx(626) : fatal error C1903: unable to recover from previous error(s); stopping compilation
11>1>PhantomRegistrationToolbox.cxx

The same errors with moc_PhantomRegistrationToolbox.cxx , moc_StylusCalibrationToolbox.cxx, moc_TemporalCalibrationToolbox.cxx, moc_SpatialCalibrationToolbox.cxx, moc_fCalMainWindow.cxx, moc_CapturingToolbox.cxx , moc_ConfigurationToolbox.cxx
StylusCalibrationToolbox.cxx
TemporalCalibrationToolbox.cxx
SpatialCalibrationToolbox.cxx
CapturingToolbox.cxx
ConfigurationToolbox.cxx
fCalMainWindow.cxx
fCalMain.cxx

Any advice to handle this problem?

Thanks,
Jason.

#### 1 Comments
#### By Andras Lasso on 2014-10-19 13:16
> error C2471: cannot update program database 'c:\users\ocean\devel\plusexperimental-bin\bin\debug\fcal.pdb'

This means that the file is not writeable. You might have run out of disk space, the file is in use (because a Plus executable is running, etc.), the file is corrupt (because of an interrupted build, because of a build that was failed due to lack of disk space or due to using VS2008 without VS2008 SP1 installed). Delete the offending .pdb file, make sure you've installed VS2008 SP1 (see prerequisites at https://www.assembla.com/spaces/plus/wiki/Windows_Build_Instructions), and restart the build.


## large variations at image acquisition
#### Posted by coconetlero on 2014-10-15 05:12

Hello,

I trying to make some bone reconstructions, but I don't get the expected results. Seems like there are a large variations in the position of each acquired image.I attach a screenshot of a reconstructed volume of a bone that exemplifies the problem. I made a spatial calibration with a 0.67mm of error and also a temporal calibration. Do you have an idea of what can be the error?

Thank in advance

Cheers
plus-problem.jpg	253 KB

#### 8 Comments
#### By Andras Lasso on 2014-10-15 08:39
Please attach your config file and log file of the image acquisition and volume reconstruction and a screenshot in Slicer that shows the scale of the image (click on Slice annotations button in the bottom left in the Data probe section and enable Scaling ruler).
#### By Coconetlero on 2014-10-15 09:32
Hello Andras.

Thanks for the quick response. Here are the files. I don't find the scaling ruler but put the volume information in the screenshot.

thanks a lot
101514_152248_PlusLog.txt	8.57 KB
plus-problem_02.jpg	334 KB
VolumeAquisitionZian.xml	5.71 KB
#### By Andras Lasso on 2014-10-15 10:32
Do you acquire the data in multiple sweeps?
The same structures may look quite different on US images when imaged from different angles (due to sound reflection properties and also potentially due to calibration and tracking inaccuracies) therefore if you sweep the same region multiple times then in the reconstructed volume you can have slices from different sweeps right next to each other.

Can you see the jitter in the image if you acquire the volume with a single sweep?
#### By Coconetlero on 2014-10-15 11:09
This particular volume are aquired in one sweep, and trying to keep a straight direction, so the jitter persist. I used one reference for the calibration proces that are attached to the model and other for acquiring the images, Now I use the same reference for both cases and the jitter was decreased but persist. The jitter is bigger in the more remote areas from the probe, I attach two images that exemplifies that process.
plus-problem_04.jpg	170 KB
plus-problem_03.jpg	168 KB
#### By Andras Lasso on 2014-10-15 11:59
On the images it looks that you do multiple sweeps (move the transducer back and forth to image the same region). Can you confirm that you acquired the volume with one straight sweep and you did not turn back?

Do you use a Polaris optical tracker?
How far is the probe marker from the transducer surface and the reference marker from the imaged region?
Do you see the jitter when you just visualize the tracked slice?
Do you keep both the model and the transducer in your hand and move them under water? is the speed of sound setting on the ultrasound system matches the actual speed of sound in the water/liquid you use?
#### By Coconetlero on 2014-10-15 13:08
I made a new volume for confirm, only one straight sweep and the jitter persist.

I use a polaris traker.
The probe marker ar at 5 o 6 cm from the transducer surface (see attachment).
I put the the US probe in a support in order to avoid the hand shake and the jitter is not present.
When I did the calibration, I let the model fixed and only move the probe
The speed of the ultrasound was a littlebit higer (1540m/s)
#### By Andras Lasso on 2014-10-15 13:34
Can you attach an image reconstructed from one straight sweep?

> I use a polaris traker.
Optical trackers do not have much jitter, so that should be OK.

> The probe marker ar at 5 o 6 cm from the transducer surface (see attachment).
That's about average, should be OK.

> I put the the US probe in a support in order to avoid the hand shake and the jitter is not present.
Some jitter in the reconstructed volume is inevitable if both the model and probe is kept hand while scanning, but the jitter should be greatly reduced if there is good temporal calibration. Try to redo the temporal calibration or try to different LocalTimeOffsetSec values (in about a +/-0.2 sec range). Altough it should not make any difference, you may also try to connect to the imaging device directly instead of going through OpenIGTLink.

> The speed of the ultrasound was a littlebit higer (1540m/s)
This can cause up to about 1mm error, so it might be a contributor, but should not have a very significant effect.
#### By Andras Lasso on 2014-10-15 13:48
Also make absolutely sure that the reference marker (whichever you define as reference for the volume reconstruction) is rigidly attached to the model. If the marker is slightly loose (e.g., because you attached it to the model with tape) then it can cause very visible errors (1 deg rotation error can cause 1-2mm displacement if the marker is 10cm away from the imaged region).


## warning of TrackerDevice-ProbeToTrackerDevice
#### Posted by Jason... on 2014-10-13 08:07

Hi,

I am using three 6DOF sensors tied to probe, reference and stylus to realize the probe calibration. But when connecting the system, an error occurs with "TrackerDevice-ProbeToTrackerDevice: Angle difference between

interpolated orientation is large, interpolation may be inaccurate".

I have attached the configuration file.


Thanks,
Jason.
config2.0-backup_20141013_154708.xml	7.58 KB

#### 6 Comments
#### By Andras Lasso on 2014-10-13 08:40
This message indicates that the angle difference between two subsequent pose measurements is too large.

Possible reasons:
- tool is moved (rotated) too quickly: move the tools slower
- acquisition rate is very low: increase AcquisitionRate attribute of the Device in the Device set configuration file
- pose tracking sensor is damaged: can be confirmed by visualizing the tool position in 3D and check if it follows the actual motion of the tool

There is also a small typo in the config file:
DataSource Id="stylus" />
should be
DataSource Id="Stylus" />

If the above hints did not help in resolving the issue then send a log file obtained with Debug log level.
#### By Jason... on 2014-10-13 10:14
Hi Andras,

Thanks for the hints! But the warning still occurs when I just connect the system.I don't even move the sensor.

I have increased AcquisitionRate,but it doen't work. And when I exchange the sensors tied on the probe and reference, the one attached on the reference works well and the warning still comes out. Maybe this can tell the tracking sensor is good.

I have attached the debug log file.

Regards,Jason
101314_214438_PlusLog.txt	35 KB
#### By Andras Lasso on 2014-10-13 10:32
Now that you changed the sensor the error is reported for the reference tool. It seems that you have a 5-DOF sensor (that is only usable for stylus or needle tracking) or a damaged sensor.
#### By Andras Lasso on 2014-10-13 11:13
You can also try the tracker test utility to see if the sensors work OK:
http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationTrackingTest.html
#### By Jason... on 2014-10-14 20:40
Thanks, Andras

The warning has been killed.
The sensor is unstable beause of its Poor contact.

Thanks you!
Jason
#### By Andras Lasso on 2014-10-14 21:54
Great! Thanks for reporting back.


## Send RGB images using VFWVideo
#### Posted by Jasper Nijkamp on 2014-09-24 11:54

Is it possible to send color images through OpenIGTlink using the VFWVideo type?

Thanks, Jasper

#### 8 Comments
#### By Andras Lasso on 2014-09-24 11:59
Microsoft Media Foundation should be used instead of Video for Windows (VfW was deprecated about 15 years ago, replaced by DirectShow, and then by MMF). MMF supports color image acquisition.

Epiphan supports color image acquisition, too. If you need a good framegrabber I would definitely recommend Epiphan.
#### By Jasper Nijkamp on 2014-10-03 12:14
Hi all,

I am able to read my webcam using the MMF in plusserver. Now I am trying to read my laparoscope (Olympus exera II CV180) using a build-in firewire card in my PC. The firewire card provides DVSD format data, but this is not supported by the Plus MMF video connection. Any clue how I could read my scope data into Plus to send it on through OpenIGTLink?

Regards, Jasper
#### By Adam Rankin on 2014-10-03 12:18
Hi Jasper,

Do you need color for the laparoscope?
#### By Andras Lasso on 2014-10-03 13:15
DVSD seems to be some special compressed format (http://www.fourcc.org/dvsd/). The simplest would be to configure your PC card to capture in uncompressed RGB24 or YUY2 format.

Check which formats are available:
Run this to get your device ID:
vtkMmfVideoSourceTest.exe --list-devices
If your capture device ID is 0 then you can get the list of available formats with this command:
vtkMmfVideoSourceTest.exe --list-video-formats --device-id=0
#### By Andras Lasso on 2014-10-04 08:17
Added a ticket (#940) to implement decoding in MmfVideoSource. It is only scheduled as a future development, we will probably not start working on it unless you or someone else specifically needs it.
#### By Jasper Nijkamp on 2014-10-06 07:13
Hi Adam and Andras,

Thanks for the fast suggestions. I do not neccesarily need color right now, but it would be nice in the future. I used vtkMmfVideoSourceTest to see what formats were available. I only get DVSD as option, so no changing there.
I am currently looking if I can change the format on the laparoscope side. Other option I am looking at is to buy a different firewire card with more option.
If you have any other suggestions, please let me know.

Regards, Jasper
#### By Andras Lasso on 2014-10-06 10:08
Epiphan framegrabbers are great, I would suggest to get one with an USB or Ethernet interface that matches your performance needs.

Recommended minimum model for single analog capture: VGA2USB-LR. The basic VGA2USB model is not suitable for most applications, because it provides interlaced output at a very low frame rate. Link to manufacturer's website: http://www.epiphan.com/.
#### By Jasper Nijkamp on 2014-10-07 03:08
Thanks Andras


## Exclude scaling from spatial calibration
#### Posted by erwinv on 2014-10-06 10:43

Hi,

Would it be possible to build in an option in Plus to disable (not take into account) the scaling during calibration? For us it would be beneficial to multiply the coordinates of a point with the mm/pixel ratio after calibration. We can chance the depth of the US scans, which changes the scale. It would be nice if we could use the calibration also for different imaging depths.

Thanks,
Erwin

#### 1 Comments
#### By Andras Lasso on 2014-10-06 11:19
In general when you change the depth then the size, scale, aspect ratio, and origin of the image changes. Therefore, updating only the scale does not help much.

Our recommended solution is to perform calibration at each allowed depth and then switch to the correct ImageToProbe matrix when the depth changes. There is experimental implementation for automatic, synchronized switching of ImageToProbe calibration matrix for Ultrasonix ultasound devices.

Anyway, if you prefer to do probe calibration only at a single depth and you are confident that you can extrapolate the result to other depth then you can very easily determine the spacing as it is done in vtkProbeCalibrationOptimizerAlgo:
https://www.assembla.com/code/plus/subversion/nodes/3800/trunk/PlusLib/src/CalibrationAlgo/vtkProbeCalibrationAlgo/vtkProbeCalibrationOptimizerAlgo.cxx#ln96

If you use a framegrabber then typically the fixed point in the image (if it exists at all) is the transducer center. Therefore you need to define a transducer center coordinate system, similarly as it is described here:
https://www.assembla.com/code/plus/subversion/nodes/3800/trunk/doc/tutorials/TransducerToProbeTransformComputation.pptx


## Accuracy evaluation
#### Posted by erwinv on 2014-09-17 10:19

Hi all,

With Plus fCal I can get very good calibration errors, but the accuracy is less good. If I hold the phantom in the same manner as during calibration, I get good accuracy (1.5mm). However, if I rotate the transducer such that the marker is in the opposite direction, I get bad results (>5mm). I now this is not allowed for calibration, but assume this should be possible for usage? Or is this a limitation?

I test the accuracy in two ways, using a similar US collecting procedure as in the paper "Improving N-wire phantom-based freehand ultrasound calibration":
- Simple (but biased): add one wire in N-Wire phantom to create cross wire phantom. The intersection can be accurately calculated to act as a ground truth. Then the intersection is selected on US image and via matrix conversions compared to the ground truth.
- Elaborate (worst-case orientation wise): we have a very small metal ball that is visible on US. We use stylus to pinpoint ball location for ground truth and select the ball on US from different angles and locations, with similar depth as with calibration.
The accuracy is measured as a 3D euclidian distance from the measured point to the ground truth. The question is about the first method (for now).

Errors:
- StylusTipToStylus: 0.3mm.
- PhantomToReference: 0.3mm.
- ImageToProbe (mean): 0.5mm.
- US spacing: 0.29 mm/pixel.

Setup:
- C5-1 Transducer (curvilinear probe).
- EM Tracking.
- Three N-wires in a "box" of 50x60mm.
- Scanning about 50mm above first wire. Translations only during calibration in 3 dimensions.
- Phantom fCal 3.1

Thanks,
Erwin

#### 8 Comments
#### By Andras Lasso on 2014-09-17 10:42
During calibration you have to scan so that the marked side of the probe is at the designated side of the phantom. This is because the wires are identified based on their relative location in the image. This applies only for calibration, later of course you can orient your probe any way you want.

If you see large misalignment between the wire model and the wire/image intersection in the image when you rotate the transducer by 180deg then the image is most likely tilted (there is out-of-plane rotation error in the spatial calibration). This is error is the hardest to reduce, as due to the thick US beamwidth.

Your reported error values seem to be OK.

Could you record a few hundred frames while you are scanning the calibration phantom (as you scan it during spatial calibration) and send it to me? (upload to somewhere and attach the link).

thanks
#### By Erwinv on 2014-09-18 09:54
Yes, I scan with the transducer's marked side to the phantom marker (M) during calibration. Here's a link to the archive: http://www.bigr.nl/files/forAndras.zip

Included are 2 slicer files, one similar as spatial calibration, and one with an extra wire creating a wire phantom (removed for/during calibration). Just saw that the included spatial calibration file has some rotation at the end; the real calibration had less rotations. Included are also two screenshots: one with slice with marker at M, one 180deg rotated such that marker is at the opposite site. In the last case there is some distance between the lines and the US dots.

It's quite hard to translate without rotation. If this could be problem we perhaps have to use an US probe holder, but that's not so easy to get/attach/use.

Thanks,
Erwin
#### By Andras Lasso on 2014-09-18 10:26
The screenshots shows that you have in-plane error. This is very likely caused by inconsistency between actual wire and landmark positions and the positions described in the config file.

Actually, if you have a look at the screenshot you can see that the wire positions do not match the positions of the holes in the 3D model. Maybe the slanted holes confused you (holes are not orthogonal to the wall to make sure that wires always touch the same side of the hole inside the box, regardless of which direction the wires go outside the box). Update the wire positions in the config file to make sure the wires always start and end in holes.
#### By Andras Lasso on 2014-09-18 10:28
Some probe rotation is OK, just try to keep it small. The quality of your sequences are good.
#### By Andras Lasso on 2014-09-18 10:52
You can verify the wire positions by performing phantom registration then touching the wires with the tracked stylus. When you actually touch the wire with the stylus you should see that the stylus touches the wires in the 3D model on the screen, too.
#### By Erwinv on 2014-09-23 08:48
Thanks Andras. The wire positions were indeed incorrect; I took the wrong point of origin. I did a lot of testing and have problems with both phantom and spatial calibration.

I accurately measured the location of the phantom points using the STL file in an STL viewer. The dimensions of the printed model are exactly like the STL file. However, I always get the blue points translated (see phantomregistration{1,2}.png), but I see no reason why, there are no "outlier" which could cause such translation. I had a previous post about this here: https://www.assembla.com/spaces/plus/messages/4519553#comment_4522793 .I fixed this by moving the points such that the blue points are correctly in the model. But probably this is not a good way, because these are not the actual points on the model when measured with a scaler from the origin. For know I ignored the blue points. I got little bit better results when configuring the holes less deep (0.5mm error). Do you know how deep the holes are? Any ideas how to correct the problem?

I'm not sure, but I think that the the wire positions shown visually in Plus exactly match with the wire positions as in the model, but the given positions in the config do not match when measured with a ruler in an STL viewer. I.e. 52.8 in the config for wire (visually correct) is 49.2mm in an STL viewer. I also still have the orientation problem after new calibrations (see spatial{1,2}.png). I also tested with a stylus as you suggested. When putting the stylus in one of the holes on the inside, in Plus there's an error of a few mm (see stylus1.png with red markings added).

The only thing I can think of is that the ModelToObjectTransform of the PhantomModel is incorrect. How does this influence the calibration and other visualizations? How can I determine the correct matrix? Any other ideas? I added my current config.

Thanks a lot,
Erwin

P.S. I'm assuming that the origin shown in my STL program is the "real" origin: "center side" A6 Front.
phantomregistration2.png	175 KB
phantomregistration1.png	227 KB
spatial2.png	272 KB
spatial1.png	291 KB
PlusDeviceSet_Server_NDIAurora__20140923_123008.xml	8.93 KB
stylus1.png	345 KB
#### By Andras Lasso on 2014-09-23 16:07
The Phantom coordinate system may be different from the PhantomModel coordinate system, the transform is specified by the ModelToObjectTransform attribute in:
<DisplayableObject Id="PhantomModel" ObjectCoordinateFrame="Phantom"... File="fCal_3.1.stl" ModelToObjectTransform="..." />

The origin of fCal-2.x and 3.x phantoms is supposed to be the inside end of the A5 hole on the front side (https://www.assembla.com/code/plus/subversion/nodes/3712/trunk/doc/specifications/fCalPhantom/fCal_3/fCal3.1-origin.png). I've updated the fCal-3.1 phantom STL file and config files accordingly and saved the STL with this origin so that the ModelToObjectTransform is identity (so that if you load the STL into any software you'll actually see coordinates in the Phantom coordinate system) - see #936.

Try using this updated fCal-3.1 STL file (https://www.assembla.com/code/plus/subversion/nodes/3712/trunk/PlusLib/data/CADModels/fCalPhantom/fCal_3.1.stl) and the origin definition described above.
#### By Erwinv on 2014-10-06 10:31
Thanks Andras, that works much better!


## Losing frames during acquisition - da Vinci and Ultrasonix machine
#### Posted by rsingla92 on 2014-08-22 19:19

Hi there,

I'm experiencing some significant data loss when trying to acquire tracked ultrasound images with the da Vinci tracker and an Ultrasonix machine. Individually, I can collect tracker data and acquire image data with no problems. Together, it seems like the PlusServer can't keep up with writing the frames at the desired rate.

The da Vinci is connected to an ultrasound machine. The ultrasound machine is running both the exam software and has two command windows running. In one, I run PlusServer with my specified configuration file. In the other, I use PlusServerRemoteControl to START and STOP acquisition.

I run start acquisition for approx 10 secs then stop. I expect about 200 frames.

I have attached the PlugLog from the recent data collection attempt, and the Plus config.

The general outline of the PlusLog file is as follows:
- Starts PlusServer
- Parses the config file
- Sets defaults for values it can't find
- "Dropped frame" messages are NOT dropped frames but rather ignored frames. This is a poor debug message on my part. Those messages come from the callback and will continue until the da Vinci is connected.
- Connects to the Sonix Video Device
- Receives command to start acquisition, replies
- Series of warnings regarding inteprolation of transforms, recording of frames, etc
- Intermittment writing of frames
- Stop acquisition command received, and replies
- Disconnected
082214_154914_PlusLog.txt	146 KB
PlusServerRecording_config.xml	2.33 KB

#### 1 Comments
#### By Andras Lasso on 2014-09-22 10:10
Sorry, assembla did not send a notification about this message and I've just found it now. Let me know if this is still a problem.


## Temporal Calibration from saved data
#### Posted by MattClarkson on 2014-08-19 07:50

Hi there,

Im struggling a bit with temporal calibration from saved data. It looks like there is something wrong with my input data.
I have attached, config, .mhd file, log file.
I get errors like:

081914_124650.631|WARNING|091.198000| Tool 'ProbeToTracker' has no matching transform in the file with name: ProbeToTracker|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(554)
081914_124650.643|WARNING|091.210000| Tool 'ReferenceToTracker' has no matching transform in the file with name: ReferenceToTracker|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(554)
081914_124650.653|WARNING|091.220000| Tool 'StylusToTracker' has no matching transform in the file with name: StylusToTracker|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(554)
081914_124650.738|WARNING|091.306000| vtkSavedDataSource LocalBuffer is invalid|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(929)
081914_124650.746|ERROR|091.314000| Local buffer is invalid|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.cxx(412)
081914_124650.754|ERROR|091.321000| TrackerDeviceSavedDataset: Cannot connect to data source, ConnectInternal failed|in ..\..\..\PlusLib\src\DataCollection\vtkPlusDevice.cxx(994)
081914_124650.764|ERROR|091.331000| Unable to connect device: TrackerDeviceSavedDataset.|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(280)
081914_124651.347|INFO|091.914000| Copy buffer to video buffer...|in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(803)
081914_124651.351|ERROR|091.918000| Unable to read Timestamp field of frame #0|in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(837)
081914_124651.359|ERROR|091.926000| Unable to read Timestamp field of frame #1|in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(837)

Please can someone help?

Thanks

Matt
merged.mhd	658 KB
081914_124519_PlusLog.txt	155 KB
PlusDeviceSet_fCal_Sim_MattTemporalCalibration.xml	7.35 KB

#### 1 Comments
#### By Andras Lasso on 2014-09-22 09:26
I'm very sorry for the delayed reply. Assembla seems to had some problems in sending out notifications about new messages and therefore we haven't noticed your question.

The problem in the attached mhd file is that it contains the header twice. ElementDataFile fields must be the last attribute, everything after that is assumed to belong to the image, therefore all the fields that you specified after that were ignored.


## Effect of LocalTimeOffsetSec when only one stream is captured
#### Posted by Jasper Nijkamp on 2014-09-18 11:28

Hi there,

I am using the NDI Polaris Spectra to retrieve dynamic positions of an optical tool. Simultaneously I am reading a video stream using a 3rd party component outside Plusserver. The videostream has a slight delay which I would like to correct. Can I use the LocalTimeOffsetSec parameter to delay the frames I receive from plusserver? I saw that it works nicely when I try to correct the lag between my NDI aurora system and my Polaris system, but then I am reading both sources through Plusserver. As far as I can see now, it does not work on a single stream.

Please enlighten me, can I use LocalTimeOffsetSec to delay my stream for a couple of frames?.

p.s. I could of course also use plusserver to read my videostream, but that would cost me more programming time to get the video within my own software.

#### 2 Comments
#### By Andras Lasso on 2014-09-18 11:54
It should not matter when an item is received, you should pair items from different streams based on their timestamp. LocalTimeOffsetSec does not delay the transmission if you have a single stream (it would not be useful, as it would just decrease system latency and available time for possible pre-processing), but it affects the timestamp that is assigned to the items. So, in your program you should just check the timestamps and find corresponding data items accordingly (with an adjustable time offset). If your other data stream does not provide timestamps then the best you can do is to assign a timestamp as soon as you receive it. If you assign timestamp then make sure you use an accurate timer, apply timestamp filtering as needed, and interpolate tracking data at the common timestamp. These are all implemented in Plus, so overall it may be easier to just add a new device to Plus that reads that video stream, too. What device provides the video stream?
#### By Jasper Nijkamp on 2014-09-19 02:20
Thanks Andras, clear story.
It is a firewire card I am using. I will try to get the data through the VFWVideo option.
Jasper


## Different shapes
#### Posted by erwinv on 2014-09-15 05:03

Hi all,

Is it possible to use other wireshapes than an N model, for example two (smaller) N-shapes next to each other?

We have a spatial calibration error around 1mm. On the US scans we can see that the diagonal wires look more like lines instead of dots, especially during rotations, which decreases the accuracy. We are quite sure that this is caused by the slice thickness of the US scans, which results in small lines for the diagonal wires. If we use a smaller N model, the lines would have a smaller angle, but because the model is smaller, it could be less accurate. Therefore, another shape, like two smaller N shapes next to each other could be a solution. We are currently using a deep curvilinear probe with three N-wires in a "box" of 50x60mm.

Thanks a lot,
Erwin

#### 3 Comments
#### By Tamas Ungi on 2014-09-15 06:53
With deep curvilinear probes you may get more accurate results using the pointer-based calibration method. There is a tutorial here. This and other SlicerIGT tutorials are accessible from www.slicerigt.org
The pointer-based method is independent from the size of the probe. I get excellent results with pointer-based method, but I think that is mainly because it involves manual picking of the pointer tip position on the image. And that is more accurate than automatic wire recognition near artifacts.
#### By Andras Lasso on 2014-09-15 08:31
With large imaging depth it may be challenging to go much below 1mm. Multi-N-wire calibration and pointer-based calibration has different advantages and disadvantages, so you may try pointer-based calibration, too.

You should never rotate the probe during calibration. Unlike single-wall and other calibration methods that require imaging a phantom from different orientations, with fCal phantom you can image from the ideal orientation: keeping the transducer orthogonal to the wires (and just translate it). The diagonal wire still always appears as a line (length depends on the beamwidth and line angle) but the algorithm picks the middle and so if the beamwidth is symmetric then the algorithm should still accurately pick the correct location.

You can add any number of N fiducials with any angles (angle can be different for each N) with the following conditions:
all N fiducials shall be all visible at the same time
planes of N fiducials shall be parallel
multiple N fiducials are not allowed on the same plane

The error that you finally get is accumulated from various different error sources, so to give you more specific advice some more information would be useful.
What tracker do you use? (with EM tracker you typically get a few tenth of a mm larger error compared to optical trackers)
How/where the tracker markers are mounted on the probe, stylus, and phantom? (if markers are not fixed rigidly, e.g., taped to the objects then it increases the error; the errors are higher if the markers mounted farther from the region of interest)
What is the imaging depth and approximate pixel size? (low image resolution increases the fiducial detection error)
Which fCal phantom do you use? (the N fiducials should cover about the same area - same size and location - as your region of interest in the image; so if you image large structures then you probably need fCal 3 phantom; however, fCal 3 is assembled from multiple pieces, and so it may be somewhat less accurate then the smaller, unibody fCal 2).
Can you attach a typical screenshot of the calibration image and detected fiducials? (image quality and imaging parameters may influence the fiducial detection accuracy)
#### By Erwinv on 2014-09-17 09:39
Thanks, without rotation the shape is not a problem. I have some problems/questions regarding the results, but I will post them in a new message, together with the info Andras asked.


## PlusServer dealing with Aurora/Polaris sensors which are out of view
#### Posted by Jasper Nijkamp on 2014-08-11 11:20

I am using the plusserver to read sensor positions from an NDI Aurora and an NDI Polaris system simultaneously, and broadcast them through OPENIGTLink. The system works fine, as long as all the sensors positions can be determined. As soon as one of the sensors gets out of view, the whole communication of sensorpositions stops, even for the sensors which are still in view.

I have changed my local implementation of PlusServer in PlusLib in such a way that a transformation is always broadcasted for every sensor, but when sensors are out of sight, the matrix will be an identity matrix. From the receiver point of view it is easy to check if a transform is identity, and should be skipped.

This code change has quite an impact, so please let me know how you guys think about this problem and possible sollutions.

Jasper

#### 6 Comments
#### By Tamas Ungi on 2014-08-11 11:58
I have also been thinking about a hybrid virtual tracker device. That uses on of the other is not available. But I'm not sure sending identity transforms is the right way of letting the user application know that the device is not available. E.g. in 3D Slicer that moves the model of the tracked tool to a distant location (origin), which resets the bounding box that has the anatomical orientations on it. That way the 3D view gets messy. Could this be fixed in a more explicit way? E.g. not update those transforms that are not available?
I feel there is a need for "HybridTracker" device that implements something explicit to handle these use cases when the same object is tracked by two trackers. There could be different modes of this device, e.g. to choose a preferred when both are available, or to fuse them somehow, or just send whatever is available...
#### By Andras Lasso on 2014-08-11 12:01
The SendValidTransformsOnly attribute controls the behavior (http://perk-software.cs.queensu.ca/plus/doc/nightly/user/ApplicationPlusServer.html#ApplicationPlusServerConfigSettings).

It is normal that none of the transforms are sent that depend on an invalid transform (e.g., if ReferenceToTracker is invalid then SylusToReference, ProbeToReference, SomethingToReference will all be invalid), but if you find that a transform is not sent that should have been possible to compute (e.g., StylusToTracker is invalid and ProbeToTracker is not sent) then it may be a bug. Let us know.
#### By Andras Lasso on 2014-08-11 12:06
PlusServer sends whatever is valid if SendValidTransformsOnly is TRUE (and the client should decide what to do if there is no update for a transform for a while; e.g., it can show the status of a transform as invalid if on updates are received for 0.5sec). PlusServer sends all the transforms if SendValidTransformsOnly is FALSE (matrix is set to identity for invalid transforms). We may add a third option, such as send an all-zero matrix to make the distinction between valid/invalid transforms more explicit.
#### By Jasper Nijkamp on 2014-09-09 06:56
I tested the out of view problems on the latest build of plusserver with SendValidTransformsOnly set to false.

I have a setup in which I track two different optical trackers using the NDI Polaris Hybrid system. At a certain time point during tracking I occlude one of the trackers to make sure it is not visible anymore on the camera. A short while later I make sure the tracker is visible again. In the case of the Polaris system, Plusserver stops providing transforms for both trackers as soon as one is occluded and functionality does not return when both sensors are visible again. So actually, as soon as one sensor is out of view, the system stops providing tracking data for all sensors.

Source: PluslogPolaris.txt (see attachment)
For Polaris Spectra at line 1784 we see that one of the optical sensors is out of view:
Line 1784: 090914_121438.203|DEBUG|022.565000| Polaris-SensorsToPolaris: vtkPlusBuffer: Cannot do data interpolation. The closest item to the requested time (time: 7222.545000, uid: 200) is invalid.|in ..\..\..\PlusLib\src\DataCollection\vtkPlusBuffer.cxx(1019)

After which plus tries to get the trackerbuffer at timestamp 14422.5 which is not available, even when the sensor is back in sight.

Line 1787: 090914_121438.223|TRACE|022.585000| vtkPlusDevice::GetTrackedFrameList(14422.5, 1)|in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(581)

Line 1790: 090914_121438.247|ERROR|022.609000| Failed to get tracker buffer item by timestamp 14422.5. Item not available yet.|in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(705)

I perform the exact same experiment with the NDI Aurora tabletop field generator. Here I track four 6DOF sensors. During tracking I move one of the sensors out of the magnetic field. Plusserver stops sending tracking information for all sensors as soon as one is out of view. As soon as all sensors are back within the EM field Plusserver behaves normally again, and provides actual tracking data.

Source: PluslogAurora.txt (see attachment)
For Aurora Tabletop Fieldgenerator at line 6193 one of the sensors is out of view. At line 6846 Plusserver function goes back to normal.

So in both systems tracking information stops when only one sensor/tracker is out of view. I have a working sollution in which I send a unity matrix for sensors which are out of view. It works fine for me, since it is easy to test if a matrix is unity. But given the
####  comments above better sollutions might be available. Please help.

Thanks, Jasper
PlusLog_Polaris.txt	379 KB
PlusLog_Aurora.txt	1.26 MB
#### By Jasper Nijkamp on 2014-09-16 06:44
Anyone able to help here?
#### By Andras Lasso on 2014-09-16 08:37
Due to some reason Assembla haven't sent a notification about your previous post. I've added a ticket to follow-up on this issue: #934 - let's continue the discussion there.


## Beginner -- Try to Connect with SonixTab - Ulterius
#### Posted by gdardenne on 2014-08-22 03:06

Hi,

Firstly, thanks for providing this SDK.
I would like to realize the calibration of an ultrasound probe with an Aurora Localizer.
We have a SonixTab with the probe 4DC7-3/40 from Ultrasonix.

For a first step, I would like to display US images with 3Dslicer installed on my computer.
For that, I use PlusServer. I have installed the PlusApp release (2.1.0.2971).

To make the connection, I use the config file (see PlusDeviceSet_Server_SonixTouch_L14-5.xml in attached file) coming from Plus SDK (svn).
However, I have a problem of video buffer size (see log file) even if I change the BufferSize.

Please, could you help ?

Thanks,
Guillaume DARDENNE
PlusDeviceSet_Server_SonixTouch_L14-5.xml	1.92 KB
082214_085136_PlusLog.txt	7.36 KB

#### 15 Comments
#### By Rsingla92 on 2014-08-22 19:05
Hi Guillaume,

Which version of the Ultrasonix software are you running? 6.0.1? 5.7.4? Please post.

I have experience an issue when the SDK version that PlusApp uses and the Ultrasonix software is are not the same.
#### By Gdardenne on 2014-08-25 03:05
Hi,

Thanks for your feedback,
The version of our Ultrasonix software is 6.0.7.
#### By Gdardenne on 2014-08-25 04:43
With this problem, I have tried to compile myself PlusApp from the svn repo.
However, I have some errors coming : PlusLib cannot be compiled.
BCAD.dll cannot be found (see in attached file).
Do you think this is a problem of ultrasonix sdk version ?

Thanks.
Guillaume
error.txt	5.34 KB
#### By Andras Lasso on 2014-08-25 12:04
Plus works with Ultrasonix SDK 6.0.2 or earlier.
Plus also should work with Ultrasonix SDK version 6.1.0 or later, but this has not been tested and you need to build Plus yourself.
See details in #491
#### By Gdardenne on 2014-08-25 12:13
Thanks for your answer.
I've tried to build Plus myself but it still doesn't work (see the result in attached file).
BCAD.dll cannot be found and PlusLib cannot be generated.
We use the last version of the Ultrasonix SDK for the ULTRASONIX tablet.
Do you have an idea ?
Thanks.
error.txt	5.34 KB
#### By Rsingla92 on 2014-08-25 13:31
Hi Guillaume,

It looks like you're missing a file (and perhaps more) from your Ultrasonix SDK. Try redownloading the SDK from the Ultrasonix Research forum and building Plus again. After you've built Plus, try debugging around where the SonixVideo device connects and communicates with the Ulterius SDK on the machine. When setting up your CMake to build Plus, double check the parameters for Ultrasonix too.

BufferSize in the XML file is not the same as the buffer size that's giving you the error. BufferSize in the XML is for Plus. What the error is saying is that it's calculating how big a single ultrasound image is, and creating a buffer for that size. This is done by communicating with the Ultrasonix tablet.

Are you able to connect to the tablet?
#### By Gdardenne on 2014-08-25 15:05
Hi,

I'm very sorry but I have downloaded the latest version of the ultrasonix SDK for SonixTablet (6.0.7) andt here is no BCAD.dll.
Could you please check this ?

I have therefore the same error when I want to build Plus.

Guillaume
#### By Gdardenne on 2014-08-28 03:36
Hi,

The problem is that our ultrasonix SDK version is not the same as yours and a lot of dll that you add in the CMakeList (in the directory PlusLib/src/DataCollection) were not found.
I solved the problem and Plus can be correctly built.
I try now to make the connexion with the tablet.

Guillaume
#### By Andras Lasso on 2014-08-28 10:30
Do not try to use Ultrasonix SDK-6.0.x. Even if you build it, it will crash due to DLL conflicts.
You can use:
Ultrasonix SDK 5.7.x (without any modification to Plus), up to Exam software version 6.0.2
Ultrasonix SDK 6.1.x (you need to adjust the list of DLLs in Plus and maybe a few include files, etc), with Exam software version 6.1.x (maybe also Exam software version 6.0.3 or later)
#### By Gdardenne on 2014-09-01 03:20
Hi,

I have installed Ultrasonix SDK 6.1.0 with Exam Software 6.1.0.
I have built the last version of Plus.
But, when I try to make the connection with Sonix Tablet, I have the following error (see attached file) : RF acquisition mode is not supported on Ultrasonix SDK 6.x and above.
To make the connection, I use the xml in attached file.
Guillaume
090114_091459_PlusLog.txt	3.57 KB
PlusDeviceSet_Server_SonixTouch_L14-5.xml	1.92 KB
#### By Andras Lasso on 2014-09-01 10:47
SDK 6.x and later does not have a specific RF acquisition mode, as it always acquires RF images only and all processing is done in software.

We have not yet updated PLUS to work with the new SDK (we may be able to start working on that next week), so you need to make some changes. Changes include ignoring this error. Does B-mode acquisition work?
#### By Gdardenne on 2014-09-03 10:23
Ok,

I have ignored this error and it works now perfectly.
Thanks for your feedacks and your time.

Guillaume
#### By Andras Lasso on 2014-09-03 10:30
Great! Did you have to make any changes to Plus to make it work?
#### By Gdardenne on 2014-09-04 09:38
I have ignored the errors by commenting the two code lines in vtkSonixVideoSource.cxx (internalConnect function).
#else
//LOG_ERROR("RF acquisition mode is not supported on Ultrasonix SDK 6.x and above");
//continue;
#endif
#### By Andras Lasso on 2014-09-04 17:21
OK, thanks for the info!


## Build error?
#### Posted by Tamas Ungi on 2014-08-22 18:10

I tried to build PLUS just now and got the following errors. I'm not sure I followed every step accurately from the build instructions. Has anybody else experienced this? (Debug, 64-bit, Windows, clean build just an hour ago)

Error 194 error C2660: 'vtkVolumeReconstructor::SetOutputExtentFromFrameList' : function does not take 2 arguments 22>..\..\..\..\PlusLib\src\VolumeReconstruction\Testing\VolumeReconstructor.cxx
Error 197 error PRJ0019: A tool returned an error code from "Performing build step for 'PlusLib'" PlusLib
Error 198 error C2660: 'vtkVolumeReconstructor::SetOutputExtentFromFrameList' : function does not take 2 arguments e:\Plus\Debug-64\PlusApp\fCal\Toolboxes\VolumeReconstructionToolbox.cxx 415
Error 199 error PRJ0019: A tool returned an error code from "Performing build step for 'PlusApp'" PlusApp

#### 1 Comments
#### By Andras Lasso on 2014-08-24 21:19
Thanks for reporting. The error has been fixed.


## CAD model for fCal_2.0
#### Posted by balterm on 2014-08-14 09:55

Hi, do you have the CAD model for fCal_2.0 that can be opened in SolidWorks or AutoCAD? We're trying to adapt this part to our system before printing, and we're hoping you could provide the CAD model. If you have the file in .prt, .dwg, .stp, or .igs form that would be great.

Thanks for your help,

Regards,

Max Balter

#### 1 Comments
#### By Andras Lasso on 2014-08-14 10:30
It is available in SolidEdge .par file format:
https://www.assembla.com/code/plus/subversion/nodes/3594/trunk/doc/specifications/fCalPhantom/fCal_2


## PLUS + NDI Aurora tracker + framegrabber with usb connector
#### Posted by Jason... on 2014-08-10 07:50

Hi,
I have some questions about using the PLUS + Aurora tracker + framegrabber.

1. I had summited a message about configuration error before, and with the help from Adam and Jasper, I enable the PLUS_USE_POLARIS option in CMAKE and it works in the project of plusBulid. And here is the problem, when I
take the project as plusAPP, it make error as 'unkown AuroraTracker' . Why is that?

2. As I would like to use the framegrabber, I download the ImagingControl Capture 2.3 and enable the PLUS_USE_ICCAPTURING_VIDEO option, but it can never been bulit successfully. The error shows like
"A tool returned an error code from performing update step (git fetch)." for PlusLib" or "A tool returned an error code from performing update step (git fetch)." for PlusApp". Refer to the troubleshooting, I have try so many times to
delete the file of PlusApp and PlusLib to rebulid. It failed. Any advice?

3. During the calibration, should I bind two sensors(5 DOF) to the ultrasound probe? And the phantom? Does there is some tutorial document about the PLUS with Aurora tracker ? PS: I have search in the Trunk\doc\tutorials,but it
doesn't mention that.


Thanks !

Jason.
CMakeCache.txt	66.7 KB

#### 8 Comments
#### By Andras Lasso on 2014-08-10 08:39
1. After you change a PlusBuild option you need to build the PlusBuild.sln project to propagate the changes to PlusLib and PlusApp

2. You need to set the ICCAPTURE SDK paths in CMake and rebuild PlusBuild.sln

3. You need a 6DOF sensor for the probe and reference. A 5DOF sensor is OK for the stylus.
#### By Jason... on 2014-08-10 21:18
Thanks for your reply, Andras.

1. I had built the plusbuild.sln project, and this project is OK for the 'AuroraTracker', but not the PlusApp.sln project.

2. I had set the paths for ICCAPTURE SDK in CMake, if not, it can not configure sucessfully in CMake.

3. Does there is any doc to show how to handle the sensor , probe and the reference?
#### By Adam Rankin on 2014-08-10 21:25
1. The reason Andras had you redo the PlusBuild (also called the super build) is to propagate the activation/selection of the Aurora tracker. I know it's frustrating, but could you delete the entire build folder and start from scratch?

2. Could you give us more specific information? When the super build reports those errors, it will contain more information in the previous lines. Could you copy and paste all related lines to the errors?
#### By Jason... on 2014-08-11 04:20
1. I have deleted the entire folder to build it again, and now the 'AuroraTracker' is OK for both plusbuild.sln project and plusapp.sln project.

2. I use the framegrabber device to get Image, and I download IC SDK from http://www.theimagingsource.com/en_US/support/downloads/details/icimagingcontrolcwrapper/ , enable PLUS_USE_ICCAPTURING_VIDEO and PLUS_USE_VFW_VIDEO in CMake. But it makes errors with: error PRJ0019: A tool returned an error code from "Performing update step (git fetch) for 'plusLib'. I think maybe this is caused by the path of ICCAPTURING setting. And I'm wondering what exactly should I choose for each path in ICCAPTURING setting.

Great thanks !
#### By Andras Lasso on 2014-08-11 07:19
Could you copy and paste all related lines to the errors?
Please also attach CMakeCache.txt file that is in the top-level binary directory (the directory that you specified in CMake).
#### By Jason... on 2014-08-11 07:48
As I'm trying to rebuild the project, I cannot copy that lines to errors right now.

I have attached the CMakeCache.txt.

And I think the problem maybe lay in line 177 to 196 in CMakeCache.txt, but I don't know how to modify it.
#### By Andras Lasso on 2014-08-11 10:02
There are two problems with IC paths:

1. Invalid character in several lines before UPMOST SDK/RELEASES/...

2. Some filenames are incorrect. An example of filenames to be set:
ICCAPTURING_INCLUDE_DIR:PATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/include
ICCAPTURING_TIS_DSHOWLIB09D_SHARED_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/debug/TIS_DShowLib09d.dll
ICCAPTURING_TIS_DSHOWLIB09_SHARED_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/release/TIS_DShowLib09.dll
ICCAPTURING_TIS_UDSHL09D_SHARED_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/debug/TIS_UDSHL09_vc9d.dll
ICCAPTURING_TIS_UDSHL09D_STATIC_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/debug/TIS_UDSHL09_vc9d.lib
ICCAPTURING_TIS_UDSHL09_SHARED_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/release/TIS_UDSHL09_vc9.dll
ICCAPTURING_TIS_UDSHL09_STATIC_LIB:FILEPATH=c:/Users/Andras/devel/PLTools/ImagingControl/ImagingControl-3.2/win32/release/TIS_UDSHL09_vc9.lib
#### By Jason... on 2014-08-13 22:27
I still don't know how to handle this problem.

I download the ImagingControl 3.3 , delete the entire build folder and bulid it again, and it cannot go through.

Here is the error shows:
10>CMake Error at CMakeLists.txt:13 (FIND_PACKAGE):
10> Could not find a configuration file for package PlusLib.
10> Set PlusLib_DIR to the directory containing a CMake configuration file for
10> PlusLib. The file will have one of the following names:
10> PlusLibConfig.cmake
10> pluslib-config.cmake
10>CMake Error at CMakeLists.txt:19 (MESSAGE):
10> This project requires PlusLib. One of these components is missing. Please
10> verify configuration
10>-- Configuring incomplete, errors occurred!
10>Project : error PRJ0019: A tool returned an error code from "Performing configure step for 'PlusApp'"
10>Build log was saved at "file://e:\PLUS\Plus-bin\PlusApp.dir\Debug\BuildLog.htm"
10>PlusApp - 1 error(s), 0 warning(s)

And here is the PATH for ICCAPTURING:
ICCAPTURING_INCLUDE_DIR:PATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/include
ICCAPTURING_TIS_DSHOWLIB09D_SHARED_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/debug/TIS_DShowLib10d.dll
ICCAPTURING_TIS_DSHOWLIB09_SHARED_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/release/TIS_DShowLib10.dll
ICCAPTURING_TIS_UDSHL09D_SHARED_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/debug/TIS_UDSHL10d.dll
ICCAPTURING_TIS_UDSHL09D_STATIC_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/debug/TIS_UDSHL10d.lib
ICCAPTURING_TIS_UDSHL09_SHARED_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/release/TIS_UDSHL10.dll
ICCAPTURING_TIS_UDSHL09_STATIC_LIB:FILEPATH=C:/Users/Administrator/Documents/IC Imaging Control 3.3/classlib/win32/release/TIS_UDSHL10.lib

I have attached new CMakeCache.txt file.
CMakeCache.txt	65.7 KB


## configure error
#### Posted by Jason... on 2014-08-05 07:09

Hi,
I'm trying to bulid up the system with NDI Aurora Tracker and capture device, but when I select my configuration file and click connect buttom , it makes errors with unkown device type: AuroraTracker.

And the series port that NDI controler to my computer is in COM 8, and the SIU to the controler is in port 1 and port 2.

The DeviceSet tag in my Device config file is:

~~~~
<Device
Id="TrackerDevice"
Type="AuroraTracker"
SerialPort="8"
BaudRate="115200"
AcquisitionRate="40"
LocalTimeOffsetSec="0.0">
<DataSources>
<DataSource Type="Tool" Id="Probe" PortName="0" BufferSize="500" AveragedItemsForFiltering="20"/>
<DataSource Type="Tool" Id="Reference" PortName="1" BufferSize="500" AveragedItemsForFiltering="20"/>
</DataSources>
<OutputChannels>
<OutputChannel Id="TrackerStream" >
<DataSource Id="Probe"/>
<DataSource Id="Reference"/>
</OutputChannel>
</OutputChannels>
</Device>
~~~~

I am not sure where that error located .Is that I miss some info in the config file ? Any idea ?


Thanks!

Cheers,
Jason.
config2.0.xml	6.93 KB

#### 9 Comments
#### By Jason... on 2014-08-05 07:30
I am very confused with this problem that when I replace the 'AuroraTracker' by 'FakeTracker' , and 'SonixVideo ' by 'NoiseVideo' , it can connect suceessfully. I don't kown why, does the rule is that I have to take it 'SonixVideo ' when I use the Polaris Tracker, and take 'NoiseVideo' when I use the Aurora Tracker ?
#### By Adam Rankin on 2014-08-05 08:31
Hi Jason,

Did you download PLUS from assembla or did you build it yourself?

Adam
#### By Jason... on 2014-08-06 00:47
Hi Adam, thanks for you reply.

I did download the PLUS from assembla and bulid it suceessfully. It can been connected when I take the sim config file, except the xml file with Type="AuroraTracker" .

I'm not sure whether if this is defined inside the PLUS or it can been defined by the user. If it's defined in the PLUS, where can I find its rules.


PS: when I take Type="AuroraTracker" , it will make error. And when I take Type="OpenIGTLinkTracker" or Type="FakeTracker", it can connect suceessfully.
#### By Andras Lasso on 2014-08-06 01:13
Please attach the complete log file that contains the error.
#### By Jasper Nijkamp on 2014-08-06 02:13
Hi Jason,

It sounds like you forgot to enable the PLUS_USE_POLARIS option in CMAKE before you build the project in visual studio.
This enables the use of both the Aurora and Polaris system form NDI.

Jasper
#### By Adam Rankin on 2014-08-06 10:29
Jasper, since he downloaded a built version from the website, it will be a different issue. It is up to us to enable/disable devices when we make the downloadable build.

That being said, I'm fairly confident the Aurora was enabled when the build was made. I can make a new build just in case though.
#### By Jasper Nijkamp on 2014-08-07 03:18
Adam, on the post of 2014-08-06 Jason wrote he downloaded PLUS from assembla and built it. So I still think this could be the issue.
#### By Jason... on 2014-08-07 04:25
Jasper, you are right. I have checked my cmake cache, and the PLUS_USE_POLARIS is disabled. I enable that to rebulid and it can been connected with Type="AuroraTracker" or PolarisTracker.

And I found that this 'Type' is defined by the PLUS,not by the users.

thanks for you guys' replies.
#### By Adam Rankin on 2014-08-07 13:45
Aaahh I had completely overlooked that! Good catch Jasper.

I'm glad you were able to get it working Jason.


## Generic Tracker Support
#### Posted by rsingla92 on 2014-07-17 18:17

Hi there,

Two questions for the PLUS team. The first one is a sanity check.

1. Does PLUS have support for the da Vinci surgical system? The da Vinci has transform information available through its own libraries, and we were wondering if someone had already integrate support (say adding OpenIGTLink to the da Vinci so it can communicate to PLUS or writing a customized device class)?

2. If no, is there a generic tracker class that exists? Or is there a step-by-step guide for creating a new tracker class for PLUS? I notice there are developer's guides for creating a new PLUS application but none similar for just adding support.Briefly looking at the repo, it seems one would inherit from vtkPlusDevice. What else would be needed?

Thanks.

Regards,
Ricky

#### 4 Comments
#### By Andras Lasso on 2014-07-17 19:05
da Vinci interface is implemented in the CISST toolkit, which can provide the data through OpenIGTLink.

If you prefer a full solution in Plus then you can implement an interface class in Plus. There is no step-by-step guide but you can have a look at any tracking device in Plus and the source code of CISST and we can also help as needed.
#### By Rsingla92 on 2014-07-17 19:06
Great thanks! I'll let you know if we choose to pursue a full solution in Plus.
#### By Rsingla92 on 2014-07-21 21:50
Pursuing a full solution.

A question for the PLUS team. Given that I have:
created an appropriate tracker class, implementing the interface and overriding the respective functions
changed the vtkPlusDeviceFactory to create the tracker I want when given the device type I've specified
changed the CMakeLists in \DataCollection\ to add the new source, header, includes and external libraries

Are there any other steps I should be aware of in supporting a new tracker? Perhaps another CMakeLists file to edit?

Thanks!
#### By Andras Lasso on 2014-07-21 22:13
I think the steps that you described should be enough.


## What is a good phantom calibration error?
#### Posted by erwinv on 2014-07-16 08:58

Hi all,

What is typical (good) error for phantom calibrations? After many tests I receive a calibration error of around 1 mm.

I'm using a precalibrated stylus and manually tested it on a special phantom to test the accuracy of the stylus, which 0.3 mm. I tested this accuracy phantom at the same heights as the calibration phantom.
The accuracy of the 3d printer is 0.3 mm. So I would also expect a lower error, but perhaps 1.0 is okay?

I also get a small visual translation offset in fcal of the blue points compared to the model (see attachment), but I'm not sure if this is the calibration or visualization error. The stylus tip is exactly in one of the holes. I also attached my config.

Thanks,
Erwin
PlusDeviceSet_Server_NDIAurora__20140716_141913.xml	7.04 KB
phantomcalib.png	403 KB

#### 6 Comments
#### By Adam Rankin on 2014-07-16 09:30
Hi Erwin,

For phantom calibration we typically aim for sub-millimeter. 1mm is not bad, but better can be achieved.

Sadly at the moment my best advice is to try a few more times and try to aim for the bottom of each hole (which you were probably already doing).

Adam
#### By Erwinv on 2014-07-16 09:42
Thanks Adam,

Yes, I already tried many times and each time it is around 0.9 - 1.1 mm. We have a NDI stylus with a sharp point and I'm pointing it at the center of the hole, touching the backside of the hole, and I'm not moving the stylus when recording the point.

Erwin
#### By Andras Lasso on 2014-07-16 09:46
1mm is slightly higher than average. With electromagnetic trackers we can usually go down to 0.6-0.7mm phantom registration error.

fCal 3 is put together from multiple pieces, so there could be differences depending on how accurately you can print and assemble it. You could try to measure the actual landmark point positions using an accurate caliper and adjust the positions in the <Landmarks> element in the config file accordingly. You can also check the expected and measured point positions in fCal: The blue points that are shown are the actual recorded landmark positions they should match the model, so if there is a mismatch then it means an actual error. The red point in the small window in the left panel during phantom registration show the expected landmark position.

For example, config file for a perfectly assembled phantom:
https://www.assembla.com/code/plus/subversion/nodes/3501/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTablet_C5-2_Ascension3DG_3.xml
Config file with adjustments:
https://www.assembla.com/code/plus/subversion/nodes/3501/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_3.0.xml

Electromagnetic tracking in a relatively large region as the fCal 3 phantom can have up to 0.5-1mm error, but if you try to keep all sensors in the field of view and away from any source of distortion then probably you can reduce this. The shape of the stylus tip also has an effect: it should be sharp enough to have an accurate pivot calibration and should match the shape&size of the landmark point as much as possible (although it is a bit difficult to achieve this in 3D printed phantoms).
#### By Erwinv on 2014-07-17 03:51
Thanks Andras!

For my first post I used the landmarks positions of the config file with adjustments you linked to. But the positions to be selected (red points) weren't quite right, which you can also see in the attachment. The same problem occured with the perfectly assembled phantom.

I adjusted the landmark positions so that the red points are now completely in the center of the holes, where the stylus tip and the blue points should also be. Now I get a phantom calibration error of 0.3 mm, which is much better :) I'm using the 3.1 model. Perhaps the landmark positions are not the same compared to the 3.0 model?

Thanks again,
Erwin
phantomcalib2.png	36.8 KB
phantomcalib3.png	27.1 KB
#### By Andras Lasso on 2014-07-17 10:23
Thanks for the update. Can you attach the config file that resulted in the 0.3mm phantom calibration error? Thanks!
#### By Erwinv on 2014-07-17 10:31
Hi Andras,

Attached is the config file with the landmarks I used.

Erwin
PlusDeviceSet_Server_NDIAurora__20140717_145436.xml	8.37 KB


## Why is spatial calibration disabled?
#### Posted by erwinv on 2014-07-07 08:55

Hi all,

In fCal I cannot perform a spatial calibration, because the Start button is disabled. All the previous calibration steps are completed. I can open the options pannel though, with the correct ultrasound stream, but after clicking Apply and Close, the button is still disabled. In the attachment is my saved configuration XML and a screenshot. When opening the Spatial Calibration tab, I receive the following warnings (after clicking on the tab), with device video selected:

|WARNING|167.339000| SelectedChannel object is invalid or the selected channel does not contain tracking data!|in ..\..\PlusApp\CommonWidgets\vtkVisualizationController.cxx(555)
Phantom registration is not available: transform between Probe and Reference coordinate frames is missing. Either phantom registration has not performed yet or the ProbeCoordinateFrame, ReferenceCoordinateFrame, or PhantomCoordinateFrame attributes in the device set configuration file are not set correctly.
Toolbox changed to Spatial calibration

With device tracker selected or virtualmixer (found it in another config):

|WARNING|567.278000| Cannot switch to image mode without enabled video in data collector!|in ..\..\PlusApp\CommonWidgets\vtkVisualizationController.cxx(224)
|WARNING|567.285000| Unable to switch to 2D visualization. Unable to use freehand calibration toolbox.|in ..\..\PlusApp\fCal\Toolboxes\SpatialCalibrationToolbox
.cxx(229)
ImageToProbe transform is absent, spatial calibration needs to be performed
Toolbox changed to Spatial calibration

I also have to switch devices to make the calibration result/error show itself in the GUI for the other calibrations. Is this normal? Which device do I have to select for spatial calibration? I have tried using version 2.1.1 and 2.1.2. With temporal calibration I have the settings Fixed: TrackerStream - ProbeToTracker and Moving: TrackedVideoStream - Video, is this correct?

Any ideas?

Thanks,
Erwin

Update: Please use PlusDeviceSet_Server_NDIAurora_20140708_141826, I could not remove the other XML after posting.
PlusDeviceSet_Server_NDIAurora_20140708_141826.xml	7.87 KB
printscreen_spatial_calib.png	75.3 KB

#### 5 Comments
#### By Andras Lasso on 2014-07-07 09:12
If tracking and video data comes from two different devices then you need to creates a combined tracked video channel from the output channel of the two devices. I would suggest to start from an fCal config file and just replace the tracking and video acquisition devices with your devices.
#### By Erwinv on 2014-07-07 09:18
Thanks Andras,

I think I did that with the VirtualMixer type. In the original post I added the current XML but it is removed again, but reattached it here. Can you have a look?

Thanks,
Erwin

Update: Perhaps I see the error now with a double TrackedVideoStream. I will test it again with the correct names.
PlusDeviceSet_Server_NDIAurora_20140708_141826.xml	7.87 KB
#### By Erwinv on 2014-07-07 10:00
Hi Andras,

It works now with the correct names :) Thanks for your help!

Erwin
#### By Andras Lasso on 2014-07-07 10:48
Thanks for letting us know. As a preventive action, we've added a check for duplicate output channel Ids in the device set config file (see #913).
#### By Erwinv on 2014-07-08 05:36
Great! Excellent that (even small) problems are immediatly fixed or additional checks in this case are added in the source.


## VolumeReconstruction Log Errors
#### Posted by rsingla92 on 2014-07-03 19:00

Hi there,

I'm trying to use the volume re-constructor application and running into some errors. The error log (attached) seems to indicate memory cannot be allocated for my dataset of 96 frames. It reads in the data just fine, and when the volume output extent is being set the memory issue arises.

The VolumeReconstruction tag in my Device config file is:
~~~~
<VolumeReconstruction
    ImageCoordinateFrame="Image" 
    ReferenceCoordinateFrame="EastNorthUp"
    Interpolation="LINEAR"
    Optimization="FULL" 
    Compounding="On" 
    NumberOfThreads="2"
    OutputOrigin="-50 -100 -56" 
    OutputExtent="0 200 0 160 0 224" 
    OutputSpacing="0.5 0.5 0.5"
    FillHoles="Off" >
</VolumeReconstruction>
~~~~

which to me seems that values of the extent should be small.

Visual inspection of the MetaImage file in Notepad++ seems fine, and the file opens just fine in MITK. Perhaps something with the transforms for each slice? Would the volume reconstructor create the entire volume first and then trim it down to the specified extents? Any ideas?

Thanks!

Cheers,
Ricky
070314_124407_PlusLog.txt	2.06 KB

#### 1 Comments
#### By Andras Lasso on 2014-07-03 22:02
There is no problem with allocating memory for the 96 frames. The issue is that you "Cannot allocate memory for output image extent: 241856x155219 x 688911" the extent is automatically computed from the size of the area that enclose all the tracked frames and the spacing. Spacing is reasonable, so the position of the frames must be extremely far from each other.

As I recommended earlier, if you use a MARG sensor for tracking, first fix the position and only use the orientation. If the volume reconstruction works well with orientation only then you can start experimenting with estimating the position (a small error in orientation estimation can lead to several meters of position error in a few seconds).


## Ethernet cable with Plus and Slicer
#### Posted by mariie.leconte on 2014-07-03 10:08

Hello,

I try to explain my problem. I would connect a Ultrasound philips machine with plus and look the images in streaming on Slicer with a ethernet cable and I would know if it is possible?
The US machine has its network status in connected but i don't see anything on Slicer.

Thanks for your future responses

#### 5 Comments
#### By Adam Rankin on 2014-07-03 10:11
Hi Marie,

Would you mind posting your configuration file that you are using for PLUS?

Have you confirmed that slicer is looking at the correct ip?
Adam
#### By Mariie.Leconte on 2014-07-03 11:50
I'm not exactly sure Slicer to the correct address, but anyway Plus unable to connect to the US machine.

And here is the file PLUS but I'm not sure it is correct for a machine connected by ethernet cable:
~~~~
<PlusConfiguration version="2.3">

<DataCollection StartupDelaySec="1.0" >
<DeviceSet
Name="EPIQ-7: Probe Calibration - Test 1"
Description="Probe calibration on EPIQ-7"

<Tracker
Type="Ascension3DG"
BufferSize="500"
AcquisitionRate="50"
LocalTimeOffsetSec="0.0"
AveragedItemsForFiltering="10"
>
<Tool Name="Probe" PortName="0" />
<Tool Name="Reference" PortName="1" />
</Tracker>

<ImageAcquisition
Type="SonixVideo"
BufferSize="50"
UsImageOrientation="UF"
AcquisitionRate="30"
AveragedItemsForFiltering="10"
LocalTimeOffsetSec="-0.03"
IP="169.254.56.30"
ImagingMode="BMode"
AcquisitionDataType="BPost"
Depth="-1" Sector="-1" Gain="-1" DynRange="-1"
Zoom="-1" Frequency="-1" Timeout="-1" CompressionStatus="0"
SoundVelocity="1490"
/>
/>

</DataCollection>


<PlusOpenIGTLinkServer
MaxNumberOfIgtlMessagesToSend="10" MaxTimeSpentWithProcessingMs="50" ListeningPort="18944" SendValidTransformsOnly="true" OutputChannelId="TrackedVideoStream">
<DefaultClientInfo>
<MessageTypes>
<Message Type="IMAGE" />
<Message Type="TRANSFORM" />
</MessageTypes>
<TransformNames>
<Transform Name="ImageToProbe" />
</TransformNames>
<ImageNames>
<Image Name="Image" EmbeddedTransformToFrame="Probe" />
</ImageNames>
</DefaultClientInfo>
</PlusOpenIGTLinkServer>

<CoordinateDefinitions>
<Transform From="Image" To="Probe"
Matrix="1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1"
Date="2011.12.06 17:57:00" Error="0.0"
/>
</CoordinateDefinitions>
</PlusConfiguration>
~~~~
#### By Adam Rankin on 2014-07-03 11:53
To clarify your setup:

You currently have plus running on the ultrasound machine and broadcasting to slicer using plus server?
#### By Mariie.Leconte on 2014-07-03 12:00
Sorry I don't speak and understand very well english.
I use Plus Server to link US machine at Slicer. So I use this script for Plus but i'm not sure it's correct
#### By Mariie.Leconte on 2014-07-03 12:38
I have an other question, what US device type is important? Because, I work on a philips US device.


## Fastest hole filling method for volume reconstuction
#### Posted by Mikael Brudfors on 2014-06-16 21:05

Hello,

When running volume reconstruction in Plus does anybody know which hole filling method is the fastest? I would prefer speed over reconstruction accuracy.

Thank you,

Mikael

#### 4 Comments
#### By Thomas Vaughan on 2014-06-19 22:03
How many voxels wide are your holes, typically?

Thomas
#### By Mikael Brudfors on 2014-06-23 11:59
Hello Thomas,

I have attached an image showing a slice from the reconstructed volume (axial plane).

In the axial plane, furthest away from the transducer, the holes are approximately 3 pixels wide. In the sagittal plane they are bigger, approximately 5 pixels. And in the coronal around 1-2 pixels.
hole-filling.PNG	55.4 KB
#### By Thomas Vaughan on 2014-06-27 14:06
I would recommend trying the sticks hole filling method with the following parameters:

~~~~
<VolumeReconstruction ... FillHoles="On" >
<HoleFilling>
<HoleFillingElement Type="STICK" StickLengthLimit="7" NumberOfSticksToUse="1" />
</HoleFilling>
</VolumeReconstruction>
~~~~

For each hole, the sticks hole filling method searches along a series of predefined directions for non-hole voxels.

Increasing "StickLengthLimit" will make it so that larger holes are filled

If "NumberOfSticksToUse" is increased, then more values from the surrounding area will be used to compute an interpolated value. We've found that setting this to 1 tends to work best in most cases. Increasing it beyond this seems to cause blurring.

I hope this helps!

Thomas
#### By Mikael Brudfors on 2014-07-02 14:44
Okay, thank you Thomas!


## Corrupted release files?
#### Posted by finetjul on 2014-06-24 12:12

Hi,

I attempted to download PlusApp-2.1.2.3392-Win64.exe [1]
However my browser (Chrome) tells me the file is malicious and encourages me to not open it. (Same problem with any other files).

If you confirm those files are safe, you might want to add some warning.

Thanks,
Julien.
[1]: https://www.assembla.com/spaces/plus/documents/axQ4GU8xGr44L3acwqEsg8/download/axQ4GU8xGr44L3acwqEsg8

#### 2 Comments
#### By Andras Lasso on 2014-06-24 12:49
Anything that we upload is flagged as malware. Sometimes the warning goes away after a while, but the heuristics that these filters use are not described anywhere. Many software projects have this problem, so we might have to sign the installer or upload to a different server.
#### By Andras Lasso on 2014-06-30 15:50
The warning is displayed because of the file type (.exe) and assembla's reputation at google. We'll probably upload the releases to another server. The issue is tracked here: #909


## PatternLocAlgo on image sequence not acquired using PLUS
#### Posted by Vikas Revanna Shivaprabhu on 2014-06-19 13:35

Hi,

I would like to use the PatternLocAlgo to get the fiducial coordinates of the N-wire on data recorded outside PLUS pipeline (does not have tracking data). Should I first convert the image sequence to trackedFrame format? Or is there a better method?

Thanks
Vikas

#### 5 Comments
#### By Andras Lasso on 2014-06-19 13:56
I think the simplest is to save the frames into an mha file (standard file format, should be no problem to create it in any environment) and then use PatternLocTest.exe to detect the points and write the coordinates to file.
#### By Vikas Revanna Shivaprabhu on 2014-06-19 14:02
Thanks for the quick response. So the mha file need not contain any additional header information that is usually added if acquired using PLUS ?
Also, is the coordinates that is written to file in Phantom coordinates space?
#### By Andras Lasso on 2014-06-19 14:11
You might need to add some items to the header if PatternLocAlgo complains (see the full list of fields here: https://www.assembla.com/spaces/plus/wiki/Sequence_metafile_format). You can easily add any field that might be missing by editing the file with a text editor.

You get the point coordinates in the 2D Image coordinate system (see for example UsTestSeqBaselineThomasShortened_baseline.xml).
#### By Vikas Revanna Shivaprabhu on 2014-06-26 19:58
Thanks. I am able to read mha file without having to add any additional header data.
#### By Andras Lasso on 2014-06-26 23:00
Very good. Thanks for letting us know.


## Is there a way to lower the framerate of SavedDataSource device?
#### Posted by Tamas Ungi on 2014-06-20 09:49

I would like to replay tracked ultrasound data, but at a slower frame rate than it was recorded at. Is there a way of doing that in PLUS?

#### 4 Comments
#### By Andras Lasso on 2014-06-20 09:50
Would you like to skip frames or replay all the frames but slower?
#### By Andras Lasso on 2014-06-20 09:58
In the SavedDataSource device set UseOriginalTimestamps="FALSE" and then you can control the replay speed by AcquisitionRate attribute.
#### By Tamas Ungi on 2014-06-20 11:52
Replay the same frames but slower. Thanks.
#### By Tamas Ungi on 2014-06-20 11:55
It worked. For the record, here is my device description in the config file:

~~~~
<Device
Id="TrackedVideoDevice"
Type="SavedDataSource"
SequenceMetafile="test.mha"
UseData="IMAGE_AND_TRANSFORM"
UseOriginalTimestamps="FALSE"
AcquisitionRate="5"
ToolReferenceFrame="Tracker"
RepeatEnabled="TRUE" >
<DataSources>
<DataSource Type="Video" Id="Video" BufferSize="100" />
</DataSources>
<OutputChannels>
<OutputChannel Id="TrackedVideoStream" VideoDataSourceId="Video" />
</OutputChannels>
</Device>
~~~~

## VirtualMixer device type
#### Posted by rsingla92 on 2014-06-16 18:35

Hi there,

A question about the VirtualMixer device type. As it combines two input channels into one output channel, does this then include the per-frame transform into the MetaImage file?

#### 1 Comments
#### By Andras Lasso on 2014-06-16 20:31
Yes, if you write the output of the mixer device to a metafile then for each image frame you will have the corresponding transforms (the transforms are interpolated as needed).


## OpenIGTLink protocol
#### Posted by erwinv on 2014-05-26 13:45

Hi all,

We are using an ultrasound machine with proprietary software and we communicate with it via MeVisLab (although the problem/protocol is MeVisLab unrelated). I'm trying to send the images to the Plus calibration software via a custom adapter module using OpenIGTLink. Fcalc is acting as a client and MeVisLab as the server. I can ´see´ in MeVisLab that the client can connect to the server as the server first receives a ClientInfoMessage, and then two messages with an empty/unknown header. Can anyone tell me what the exact protocol is for communicating with OpenIGTLinkVideo (or a link with more info)? After the first three messages I don't receive any further messages (which could indicate requests). Looking at the source code in svn (vtkOpenIGTLinkVideoSource.cxx), it seems that the server should continuously send the images to the client over the created socket, but I didn't get this to work. I also receive the following, possibly related errors/warnings in the console:

|WARNING|1221.521000| Unable to get lo timestamp for frame UID: 1|in f:\devel\plusexperimental-bin\pluslib\src\pluscommon\vtkTimestampedCircularBuffer.txx(427)
|ERROR|1221.600000| Couldn't get frame UID from time (0.000000) - item not available yet!|in ..\..\..\PlusLib\src\DataCollection\vtkPlusChannel.cxx(414)
|ERROR|1221.608000| Unable to get tracked frame from data collector|in ..\..\PlusApp\CommonWidgets\vtk3DObjectVisualizer.cxx(353)
|WARNING|1221.809000| Volume displayable object ID not defined in fCal. Unable to update volume object.|in ..\..\PlusApp\CommonWidgets\vtk3DObjectVisualizer.cxx(506)
|WARNING|1221.815000| Unable to read image orientation from configuration file (Rendering tag, DisplayedImageOrientation attribute). Defauting to MF.|in ..\..\PlusApp\CommonWidgets\vtkImageVisualizer.cxx(713)
|WARNING|1221.824000| No Segmentation element is found in the XML tree!|in ..\..\PlusApp\CommonWidgets\vtkImageVisualizer.cxx(722)
|WARNING|1221.914000| Unable to get lo timestamp for frame UID: 1|in f:\devel\plusexperimental-bin\pluslib\src\pluscommon\vtkTimestampedCircularBuffer.txx(427)
|WARNING|1223.668000| Volume displayable object ID not defined in fCal. Unable to update volume object.|in ..\..\PlusApp\CommonWidgets\vtk3DObjectVisualizer.cxx(506)

The errors with line 414 and 427 are generated several times per second. In the attachment is my configuration file. Hope that anybody can help?

Thanks!
Erwin

Edit: The above problem was solved by appending the timestamp data to the igtl message before sending it to fcal. This question can be considered answered. Thanks anyway!
config.xml	5.2 KB

#### 5 Comments
#### By Andras Lasso on 2014-05-27 15:12
OK, great! FYI, the ClientInfoMessage can be ignored, it only indicates what data streams the client is interested in (if the server can provide various data streams and the client is interested only in some of them then you can save some bandwidth by sending only the needed data).
#### By Rsingla92 on 2014-06-06 14:47
Just following up (I understand the original poster's problem was solved) - is there anywhere to find what the exact protocol for communicating is, whether it be OpenIGTLinkVideo or OpenIGTLinkTracker etc? Or a link?
#### By Andras Lasso on 2014-06-06 15:00
We follow the OpenIGTLink protocol, as described here: http://openigtlink.org/spec.html

The only addition to this is that the connecting client can send an optional custom CLIENTINFO message, which describes what data the server should send to it (by default the server sends the data that is defined in the config file in the DefaultClientInfo element.
We only write about this here: http://research.cs.queensu.ca/perklab/plus/docnightly/classvtkPlusOpenIGTLinkServer.html#details. I'll add some more documentation soon.
#### By Andras Lasso on 2014-06-06 15:10
Added more info:
https://www.assembla.com/code/plus/subversion/commit/3387
#### By Rsingla92 on 2014-06-09 13:38
Thanks!


## Units in all config file parameters?
#### Posted by Tamas Ungi on 2014-06-09 09:14

I was thinking about adding a ticket. I noticed that units are missing from all parameter names in volume reconstruction. E.g. do we want to have OutputSpacingPixelsPerMm (instead of OutputSpacing)? Do you want me to create a ticket for this?

#### 1 Comments
#### By Andras Lasso on 2014-06-09 09:56
Yes, please add a ticket.


## Qt version updated to Qt-4.8.5
#### Posted by Andras Lasso on 2014-06-05 15:17

Plus uses the same version of ITK, VTK, and Qt as 3D Slicer. As Slicer has been updated to use Qt-4.8.5, Plus has also moved to this Qt version. Add
####  comments to #898 if you have any questions or concerns.

Andras

#### 0 Comments


## MF origin
#### Posted by amit.shah on 2014-06-03 04:55

Where is the MF origin set? In the example ppt file it is shown at the left bottom corner where as in Plus application window it is always at the left top corner.

Thanks,
Amit

#### 2 Comments
#### By Tamas Ungi on 2014-06-03 07:41
Hi Amit,
You can show an MF ultrasound image in any direction on the screen. The M/U, N/F letters determine how the image data is stored (in memory or file). More specifically, when you store an image, where is the first pixel (origin) relative to the transducer and the marker on the transducer.
When you show an image on the screen, it is better not to make the orientation (on the screen) a function of origin, but a function of M and F. (And it would be important to have a marker on the screen at the MN corner.) Because the marker is used by sonographers to orient themselves.
Tamas
#### By Andras Lasso on 2014-06-03 08:15
#### By default the images are displayed in fCal with the MF origin in the top-left corner bur you can move it to any corner by clicking the 'XY axes' icon at the top and choosing a different axis orientation.


## How are fields in volume Metafile set?
#### Posted by amit.shah on 2014-06-02 10:43

Hi,

How are the following fields in reconstructed volume .mha file set?

- TransformMatrix
- Offset
- CenterOfRotation
- AnatomicalOrientation
- ElementSpacing (specified in config file)

Thanks,
Amit

#### 4 Comments
#### By Adam Rankin on 2014-06-02 10:49
AnatomicalOrientation is hardcoded to RAI.
There is a comment in the code:
  // By definition, LPS orientation in DICOM sense = RAI orientation in MetaIO. See details at:
  // http://www.itk.org/Wiki/Proposals:Orientation#Some_notes_on_the_DICOM_convention_and_current_ITK_usage


With regard to the others, I'm not sure. It uses the MetaImage class from the MetaIO library.
It would appear that certain things are set here.
#### By Andras Lasso on 2014-06-02 10:55
As there are multiple frames, each with different pose (TransformMatrix, Offset, CenterOfRotation, possibly ElementSpacing), these values are set to some default values to allow any MetaIO image reader to read the sequence as a regular volume. The values are not used by Plus.

AnatomicalOrientation field is useless on MetaIO image files, as according to the specification of the file format it is just a hint. ITK and VTK MetaIO image reader implementations ignore it. Therefore, you cannot rely on it and the best you can do is to ignore it and just set the default RAI value.
#### By Andras Lasso on 2014-06-02 11:31
Sorry, I just realize that you asked about the reconstructed volume. For the volumes:

TransformMatrix: orientation, aligned with the axes of the reference volume that you specified for the volume reconstructor
Offset (=origin): either you can specify it in the config file or computed automatically from the region that contains all the input frames
CenterOfRotation: hardcoded
AnatomicalOrientation: hardcoded (see rationale above)
ElementSpacing: yes, specified in config file
#### By Amit.Shah on 2014-06-03 04:52
Thanks for the answers.


## Landmarks for 3.1 model
#### Posted by erwinv on 2014-05-28 09:25

Hi all,

Recently we printed the calibration phantom based on the 3.1 stl, because it sounded the best for our US machine and transducers. However, I could not find the configuration file for this model with the wire patterns and landmarks. I read that this model is experimental, but only after it was already printed, as we assumed it was supported. I found one configuration here (url suggests it's for 2.0, but config is for 3.1): https://www.assembla.com/code/plus/subversion/nodes/3309/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_Sonix_Ascension_LegoPhantom2.0 . However, this one doesn't work for me, because the points are outside the model boundaries. I put File="fCal_3.1.stl" in the DisplayableObject in the XML. I think the top part of the 3.1 model is similar as the 2.0 model, but the landmarks are not there anymore.

Is there a configuration file for the 3.1 model with the correct landmark positions? Can we otherwise calculate that ourselfs? Otherwise we have to print the 2.0 model.

Thanks,
Erwin

#### 5 Comments
#### By Andras Lasso on 2014-05-28 10:29
You can change the wire coordinates in the config file that matches your arrangement. We'll check the config files and upload a readily usable today or tomorrow.
#### By GuillermoCarbajal on 2014-05-28 14:53
Hi Erwin,
Have you tried this config file.
https://www.assembla.com/code/plus/subversion/nodes/3309/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_3.0.xml

This config file is for fCal 3.0 but I think the landmarks positions are similar for fCal 3.1.
As Andras said you can also change the wiring configuration.

Cheers,
Guillermo
#### By Erwinv on 2014-05-28 15:02
Thanks Andras and Guillermo,

This afternoon I also tested another configuration file, and I think that was the one Guillermo mentioned. I can check it next week, as I am out of office for the upcoming days. A new config would be great!

During the phantom calibration, several red points have to be selected with the tracker. I assume that that are the landmarks in the config; am I correct or mistaken? How can I calculate the wire coordinates (and possible landmark coordinates)?

Thanks,
Erwin
#### By Marie Soehl on 2014-05-29 10:28
The origin (0.0,0.0,0.0) is on the side marked "Back" at point A6 on the marked grid. Every numerical increment is separated by 10.0 mm and increases in the negative z direction (Eg. A7 is (0.0,0.0,-10.0)) Every alphabetical increment is separated by 10.0 mm and increases in the positive x direction (Eg. B6 is (10.0, 0.0, 0.0)). The points on the side marked "Front" are separated by 40.0 mm in the positive y direction. (Eg. a6 is (0.0, 40.0, 0.0).

Note: Capitalization indicates the side of the phantom: "Front" has lowercase letters and "Back" has uppercase letters.

Each wire that crosses =the "Back" to the "Front" of the phantom must be defined. This is done in the config file under the PhantomDefinition in a line of code such as the following:
~~~~
<Wire Name="7:G6_g6" EndPointFront="60.0 0.0 0.0" EndPointBack="60.0 40.0 0.0" />
~~~~
The wire name "G6_g6" Refers to the threading point on the "Back", G6, and the coordinate location is input after "EndPointFront" in the config file and the threading point on the "Front", g6, and the coordinate location is input after "EndPointBack".

The landmark coordinates are in the config file under "Landmarks" of the "PhantomDefinition". The locations in the config file are measured in reference to the origin A6. They refer to the numbered points on the "Right" and "Left" sides of the phantom.

An updated config file that is compatible with the latest build of Plus can be found here:
https://www.assembla.com/code/plus/subversion/nodes/3342/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTablet_C5-2_Ascension3DG_3.xml
#### By Erwinv on 2014-06-02 10:13
Thanks a lot Marie for the explanation and the config file! With the new config I can see the red points correctly on the phantom in the application.

Erwin


## obtain uncompressed .mha files from volume reconstruction
#### Posted by mmscr on 2014-06-01 17:36

Hello,

I would like to have the files uncompressed but I have noticed that the .mha files resulted from volume reconstruction are compressed by default. I haven't set this action to be true anywhere in the config file. Is this the case? Is compression of the .mha file done by default? If yes, how can I deactivate it, in case I am not using the VirtualDiscCapture and VirtualBufferedDiscCapture devices?

Thank you.

#### 3 Comments
#### By Andras Lasso on 2014-06-01 20:45
In the VirtualDiscCapture element set EnableFileCompression="TRUE". If you have existing compressed files then you can uncompress them using EditSeqMetaFile tool (Diagnostic_and_test_tools).
For example:
EditSeqMetaFile.exe --source-seq-file=MyCompressedInputFile.mha --output-seq-file=MyUncompressedOutputFile.mha
#### By Mmscr on 2014-06-02 07:51
Wouldn't EnableFileCompression="TRUE" mean that I get them compressed? I would like to get them directly uncompressed. Further on, I am not using a VirtualDiscCapture device instance in the config file.
#### By Andras Lasso on 2014-06-02 07:55
Yes, if you need uncompressed set EnableCompression="FALSE". Works for all capture devices.


## Visual Studio build configuration in dashboard scripts
#### Posted by Matt McCormick on 2014-05-27 01:24

Hi,

In
https://www.assembla.com/code/bm1A8eCNSr4l2deJe5cbCb/bnyqsQCNSr4l2deJe5cbCb/commit/3331
r3331

I tried to add the Visual Studio build configuration to the BuildAndTest.bat script, but this does not appear to have fixed the tests that are not run on the dashboard. Are these scripts used for the dashboard submissions?

Thanks,
Matt

#### 2 Comments
#### By Matt McCormick on 2014-05-27 10:38
It seems to be fixed in the most recent dashboard builds:

http://crunch.cs.queensu.ca/CDash/buildSummary.php?buildid=25028

Maybe it took a couple of builds before the effect occurred?
#### By Andras Lasso on 2014-05-27 11:54
I think the nightlies failed that might have been started before you commited all your changes.


## Visual Studio build configuration in dashboard scripts
#### Posted by Matt McCormick on 2014-05-27 01:24

Hi,

In
https://www.assembla.com/code/bm1A8eCNSr4l2deJe5cbCb/bnyqsQCNSr4l2deJe5cbCb/commit/3331
r3331

I tried to add the Visual Studio build configuration to the BuildAndTest.bat script, but this does not appear to have fixed the tests that are not run on the dashboard. Are these scripts used for the dashboard submissions?

Thanks,
Matt

#### 0 Comments


## Interson Driver for 1.X SDK
#### Posted by Matt McCormick on 2014-05-09 16:31

Hi,

I am working on the Plus Interson Driver for their 1.X SDK.

I have the BMode driver set up here:

https://github.com/thewtex/Plus/compare/github...interson

with RF to go.

When I run the test without the --rendering-off flag, the populated window pops up with the ultrasound image, but the content does not update. Any ideas?

Any other thoughts or tips are appreciated!

Thanks,
Matt

#### 3 Comments
#### By Andras Lasso on 2014-05-09 17:02
Check if you update the modification time of the image when you update the pixels.
Is the image updated correctly when you use fCal and/or PlusServer?
#### By Adam Rankin on 2014-05-10 11:07
I've learned this lesson a few times!

Whenever you get the scalar pointer of a vtkImageData, remember to call Modified() on the image data afterwards!
#### By Matt McCormick on 2014-05-26 23:41
Yes, a missing Modified() call did the trick! Thanks!

I'm adding the 1.X SDK support in #892.


## correction MediaFoundationVideoCaptureApi
#### Posted by EvgenyPereguda on 2014-05-08 23:30

Hi,

I am Evgeny Pereguda. I found your project when I have decided to find the links on my project - "videoInputVS2012":
http://www.codeproject.com/Articles/559437/Capturing-video-from-web-camera-on-Windows-7-and-8.

I see that you use elements of my project and I am very glad that I have made contribution in that serious project. However, I can say that you use old version of code and I have corrected three mistakes in my project. You can find a new version of it and describing of them on site CodeProject (You have URL already :)).

I understand that your project is very serious and unstable working of one of the elements can lead to the huge problems. If you are interested to have more stable stable version of MediaFoundationVideoCaptureApi, I am ready to help you.

You can posted your answer on CodeProject: http://www.codeproject.com/Members/Evgeny-Pereguda

With best regard.

#### 4 Comments
#### By Andras Lasso on 2014-05-09 07:00
Thanks for sharing your library and letting us know about the more recent version. We've made some fixes in the code but maybe we have not found all the issues. Is your code available in a public revison control repository so that we can review the change history? Or, are the changes that you've made are described somewhere?
#### By EvgenyPereguda on 2014-05-23 11:09
Hi,
I am sorry for late answer. I just want say that I rewrite the code of "videoInput" project. I changed structure of it and added some new properties. I have published new article about it on "CodeProject". You can get Git repos on CodeProject by link: https://git.codeproject.com/evgeny-pereguda/videoinput OR ssh://git@git.codeproject.com/evgeny-pereguda/videoinput

With best regards.
#### By Andras Lasso on 2014-05-23 11:24
OK, thank you! (unfortunately, it seems that there is only one commit in the repository, so it's not easy to see what changes have been made compared to the first published version)
#### By EvgenyPereguda on 2014-05-23 21:30
Hi,
I can say I do not have much experience with Git version control and with the public repos. The describing this new project you can find by the next link new article about videoInput.


## Temporal Calibration for Rotational Tracker
#### Posted by rsingla92 on 2014-05-22 15:29

Hi there,

I understand that the temporal calibration in PLUS is done by moving the transducer up and down by hand and then the peak of the signals is used for calibration. This makes sense to me for trackers that track position. Would something similar (say rotating the probe 180 degrees and back in one axis) work for a rotational tracker?

Cheers,

#### 1 Comments
#### By Andras Lasso on 2014-05-22 15:43
The algorithm does not just uses the peaks (it would not be robust), but optimizes the correlation of the two position-time signals.

If you put a slanted plane in the field of view then rotation of the probe results in changes in line position. If you concatenate the rotation transform with a fixed translation, then you'll have a transform that has translation changing in time. So, this way you can get position-time signals for a rotational tracker without any code changes.

If you are willing to change the code then you can implement a rotational mode in vtkPrincipalMotionDetectionAlgo.

If you have a stepper with both the translation and rotation stage encoded then you may use translational motion for temporal calibration, as the translational/rotational stage likely to have the same time delay.


## PlusServer and Ultrasonix Propello
#### Posted by Mikael Brudfors on 2014-05-02 12:59

Hello,

I will be acquiring images using a motorized 3D probe (4DC7-3/40) on a Ultrasonix machine. To control the probe parameters I will be using Propello (part of the Ultrasonix SDK, http://www.ultrasonix.com/wikisonix/index.php/Propello#C.2B.2B). I would like to run Propello, set the parameters, do a scan and then send slices, from the Ultrasound machine to a client computer, in order to do processing and visualization in 3D Slicer. If I have the correct config-file, could I just run PlusServer while running the Propello GUI, and then connect with my client machine?

Thank you,

Mikael

#### 12 Comments
#### By Adam Rankin on 2014-05-02 13:28
I believe this should be fine. PLUS connects via the network to the ultrasonix machine. This should not coincide with anything to do with the motorized probe.
#### By Mikael Brudfors on 2014-05-02 13:34
I am not so sure. When I use the PlusDeviceSet_Server_SonixTouch_L14-15 config file, I can connect through the Plus Server app to Sonix RP. On the other hand when I run Propello, Plus Server says connection failed. Propello is derived from Porta so I was expecting it, maybe, to work but it seems it doesn't. Any advice?
#### By Tamas Ungi on 2014-05-02 13:39
The mentioned configuration file connects to Ulterius SDK, not the Porta SDK. Not many people (that I know of) have used Porta, so you may not find specific examples, but according to the documentation it is supported by PLUS: https://www.assembla.com/spaces/plus/wiki/Hardware_setup
search for "porta" on this page.
#### By Adam Rankin on 2014-05-02 13:46
Let me know if the SonixPortaVideo device type doesn't work, and I'll investigate.
#### By Andras Lasso on 2014-05-02 14:20
SonixVideoSource uses Ulterius interface, which is only available when the exam software is running.
SonixPortaVideoSource uses Porta interface, which is only available when the exam software is not running.

It should be possible to use the Propello GUI while collecting the data through Porta, but it would be even nicer to add motorized probe control to the SonixPortaVideoSource. We can help you with advice and some implementation work, but unfortunately our motorized Ultrasonix probe is broken, so we cannot test motor control here.
#### By Mikael Brudfors on 2014-05-05 10:21
Thanks for the feedback.

As you suggested, I tested just changing the type from SonixVideo to SonixPortaVideo. When I run PlusServer from the command line it just gives me three messages and then stops execution. The messages are:

--config-file=PlusDeviceSet_Server_SonixTouch_L14-5.xml
|INFO|000.001000| Software version: Plus-2.1.1.3163 - Win32
|INFO|000.029000| Selected US image orientation: UF
|INFO|000.031000| VideoDevice: Local time offset: 0ms

No error messages whatsoever.
#### By Andras Lasso on 2014-05-05 13:45
It's a good start, it's promising that there were no error messages. There hasn't been much interest so far in the Porta interface, so we haven't invested much effort into it. Probably you need to go through the PlusStatus vtkSonixPortaVideoSource::InternalConnect() and the PlusStatus vtkSonixPortaVideoSource::AddFrameToBuffer( void *param, int id ) methods step-by-step with a debugger and see if everything works well. I see that there are some hardcoded constants (e.g., the preset string) at least that has would have to be made configurable from the config file. Let us know if you stuck at any point or have specific questions. We can also test/improve this Porta interface with our SonixTouch here if needed.
#### By Mikael Brudfors on 2014-05-22 13:13
So, after after spending time with other things the last weeks I finally started looking at this again. This is what I have found out this far. When I run PlusServerLauncher in Debug mode from VS2010 (using the above mentioned config-file with SonixPortaVideo type and the exam s/w turned off) it crashes with the error message:

Unhandled exception at 0x0051d540 (msvcr100d.dll) in PlusServerLauncher.exe: 0xC0000005: Access violation reading location 0x00000000.

The ultrasound machine is running Win XP 32bit and I am using rev. 3163 of Plus. Has this something to do with me not using the correct version of Plus? Is rev. 3163 the same as PlusApp_2.1.1.3163-embedded.exe or do I need to build it in a special way for it to be compatible with XP? It runs fine with SonixVideo type and the exam software running though.
#### By Andras Lasso on 2014-05-22 13:49
Debug builds are not meant to be redistributed (copied) to other computers. Often a debug build that is created on a computer does not run or crashes on another. Have you built Plus on the Ultrasonix system?

Which Ultrasonix SDK version are you using?

Anyway, the problem most probably is simply in the SonixPortaVideo class. Run PlusServerLauncher (or PlusServer) from the debugger and then when it stops due to the access violation check the call stack to see what caused the reading attempt from address 0x0. If you are not sure what you are doing then I can help you by skype/remote desktop sharing.
#### By Mikael Brudfors on 2014-05-22 14:21
I think I have a fairly good idea what I am doing but I would appreciate any kind of help (maybe using TeamViewer?). I checked out rev. 3163 to the Ultrasonix system (version 5.7.3). Built it using VS2010 in debug mode on the Ultrasonix system with the Ultrasoinx stuff checked in CMake. Then I set PlusServerLauncher as startup project and ran it in Debug mode. When I pressed connect with the above config-file selected it crashed and displayed that error message. The call stack shows only one call:

msvcr100d.dll!strlen(unsigned char * buf) Line 81
#### By Andras Lasso on 2014-05-22 14:25
OK, if you have time now, we can do a remote debugging session now. Send me your skype name or a google hangout link to lasso@queensu.ca.
#### By Mikael Brudfors on 2014-05-22 14:29
Sent!


## Paper on PLUS published in IEEE-TBME
#### Posted by Andras Lasso on 2014-05-20 20:17

Hi all,

Our paper that provides an overview of the main concepts, features, performance measurements, and applications of Plus has been published in IEEE Transactions on Biomedical Engineering (electronic pre-print, http://dx.doi.org/10.1109/TBME.2014.2322864). If you don't have IEEE subscription, you can access the manuscript here:
http://perk.cs.queensu.ca/sites/perk.cs.queensu.ca/files/biblio/Lasso2014a.pdf

From now on please cite this paper when you refer to PLUS in your publications (as described on the Users_guide page).

Thanks!
Andras

#### 0 Comments


## OpenIGTLinkTracker Device Type - Server Address and Server Port
#### Posted by rsingla92 on 2014-05-08 17:05

Hi there,

Just a question about the OpenIGTLinkTracker Device Type (https://www.assembla.com/wiki/show/plus/Device_Types). There are two fields Server Address and Server Port. Are these meant to be the address and port of the device or the machine on which PlusServer is running?

Thank you.

Cheers,
Ricky

#### 11 Comments
#### By Andras Lasso on 2014-05-08 17:38
The OpenIGTLinkTracker receives transforms from an OpenIGTLink server (another PlusServer instance, BrainLab tracker, Slicer, Matlab, etc). You have to specify the address where the OpenIGTLink server is running.
#### By Rsingla92 on 2014-05-08 17:44
Great thanks!

In this case it'll be an OpenIGTLink server on a phone, and so it'd be the phone's address. Thanks Andras.
#### By Andras Lasso on 2014-05-08 17:51
This sounds interesting. What is the project about? What is the OS on the phone?
#### By Rsingla92 on 2014-05-08 19:10
For now, it's looking at making use of on-board phone sensors to do volume reconstruction, much like how one would use an EM tracker. The current idea is to simply transmit sensor readings to the US machine, sync them with US images (I'm open to suggestions on how to do this in Plus!), and then use PlusServer to transmit the tracked synced frames to some other PC for processing.
#### By Andras Lasso on 2014-05-08 19:39
Plus already supports two low-cost IMU / MARG sensors (accelerometer, gyroscope, magnetometer): Phidgets Spatial 3/3/3 and CHRobotics CHR-UM6, which are much smaller and less expensive than a phone (see details at Hardware_setup). Plus also includes a sensor fusion algorithm that can convert raw signal measurements to orientation values using different constraints, which are specifically developed for US probe tracking (especially for stepper-mounted probes).

I would recommend the Phidgets sensor, as it is smaller and can be directly connected to an USB port.

We would be interested in having an OpenIGTLink server implemented on a phone for demos. If you develop a usable solution for Android or Windows Phone then it would be great if you could make it available for us.
#### By Rsingla92 on 2014-05-08 19:47
Right - I understand that low-cost IMUs exist. However, there are more interesting things that can be done later on with the phone given modern-day processors and memory on them. The sensors are just one idea we're exploring. Thank you for your suggestion however.

From what I understand, there is an OpenIGTLink java implementation (OpenIGTLink4J). I plan on exploring this implementation and use as much of it as possible. I will let you know (in some time) what the results of that are.

Perhaps I should ask this here to get an idea if I'm on the right path. The approach I currently have planned is:
Have an OpenIGTLink client running on the phone
Have PlusServer make the requests to the phone for the messages
Perhaps make use of fCal for temporal calibration
Have PlusServer send tracked US images off to another PC

Does that seem reasonable? Should I even be using PlusServer in such a case?

EDIT: The discussion above refers to the application running on the phone as a server. I was thinking of the application as an OpenIGTLink client that sent data to PlusServer. Do I have this mixed up?
#### By Andras Lasso on 2014-05-09 09:57
The OpenIGTLinkTracker device in PlusServer is an OpenIGTLink client, so the phone should run an OpenIGTLink server. Conceptually, data sources (trackers, imaging devices, etc.) should be servers, which can broadcast their data to potentially multiple clients. However, if the implementation or resolving the phone's IP address is difficult then the reverse direction can be implemented, too (in this case the OpenIGTLinkTracker device should be changed to be able to act also as a server).

What is the US image source? Do you use a tablet/phone US system? Note that Plus already supports Interson USB probes that runs on a tablet (http://www.interson.com/products/seemore-153-usb-probes).
#### By Rsingla92 on 2014-05-09 20:27
I see - that makes a fair bit of sense. PlusServer uses a client to interact with the OpenIGTLinkTracker device`s server.

Thanks - I`ve seen the Interson USB probe used in Mobisante's mobile US system and other systems. We won't be using a tablet/phone US system.
#### By Adam Rankin on 2014-05-10 10:33
Just in case I read it wrong:

The PlusServer waits for any open igt link client (PlusLib has a device type that acts as a client, usable from fCal) to request data.

The most common usage model is for PlusServer to be running on a piece of hardware that does not support open igt link broadcasting, capture the data, and broadcast it.

Hope this helps,
Adam
#### By Rsingla92 on 2014-05-13 19:43
Thanks for the responses guys. Definitely helps clear up what to do.

When I get started on the OpenIGTLink work for a phone, would PLUS devs like me to start another message thread?
#### By Adam Rankin on 2014-05-14 10:14
Up to you! If you message here we receive notification emails, so it won't be missed.

Keep us up to date with how it goes!


## Calibration with f-cal in offline mode using a previously dumped dataset
#### Posted by Mohammad Najafi on 2014-04-24 20:07

Hi,
I want to run the calibration in f-cal on an offline dataset that I have previously obtained in f-cal after calibration. I have the following files:
BufferDump_Tracker_20140122_150735.mha
BufferDump_Video_20140122_150735.mha

I see fcal has an example of using a saved dataset in offline mode but these files don't look like that example. Could you please help me understand how to convert these two into the right format for this application?

#### 5 Comments
#### By Andras Lasso on 2014-04-24 20:11
If you saved the video and tracker data separately then use the temporal calibration test as an example.

https://www.assembla.com/code/plus/subversion/nodes/3287/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_Sim_TemporalCalibration.xml
#### By Mohammad Najafi on 2014-04-28 20:30
The data was automatically saved separately and for some reasons the video data is faulty. However, there is an xml file named "012214_145343.Calibration.results.xml" (attached) that has all the data required information for calibration (segmented points, transforms, etc). My objective is to do calibration using different number of calibration/validation frames on this previously captured dataset. It seems that I should run Calibrate() method but I need to read this xml file and make two vtkTrackedFrameList data structures for both calibration and validation.
My question is if there is a built-in method that will read this file and converts it to these data structuers? I appreciate any suggestions.
012214_145343.Calibration.results.xml	1.49 MB
#### By Andras Lasso on 2014-04-28 22:45
How did you record the data? If you combine the tracker and video data using a VirtualMixer device (e.g., https://www.assembla.com/code/plus/subversion/nodes/3299/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml) and you record the output of this mixer then it contains the video frames and the corresponding tracking data for each frame, all in one file. This is the recommended way of recording tracked ultrasound data.

How the video data is faulty? It cannot be loaded, contains artifacts, shifted, ...?

To calibrate using the xml file you need to modify vtkFreehandCalibrationTest.cxx. You can parse the xml file similarly to the way it is done in CompareCalibrationResultsWithBaseline method in vtkFreehandCalibrationTest.cxx. Then, you need to modify vtkProbeCalibrationAlgo::AddPositionsPerImage so that instead of trackedFrame->GetFiducialPointsCoordinatePx() it would use the already segmented wire positions (SegmentedPoints, read from the XML file). Of course you need to read those segmented point positions from the file and pass it to vtkProbeCalibrationAlgo::Calibrate and then to vtkProbeCalibrationAlgo::AddPositionsPerImage, so it's a bit a of a work. It is probably faster to just make sure that data acquisition works as expected and re-acquire the data.
#### By Mohammad Najafi on 2014-04-30 18:40
This is how I recorded the data: Ran calibration with f-cal and then clicked on the gear icon at the right top side of the sidebar. The icon turned into "dump buffers into files..." that I clicked and selected a folder to save them. The video files don't contain the dots and just have a white bar at the top.

Anyway, I found your suggestions very useful and was able to modify vtkFreehandCalibrationTest.cxx to solve my problem. Thanks for your help.
#### By Andras Lasso on 2014-05-01 19:34
This explains everything. The dumo buffers command just saves the contents of the circular buffers where the data is temporarily collected in memory. The buffer size is configurable in the config file but typically only the last few seconds of video data is kept in memory (to allow more memory space for data collection, volume reconstruction). Tracking data is very small, so typically the last few ten seconds are stored. I would suggest to record data using the tools on the Capture tab.


## PlusApp-2.1.1.3273-Win32.exe - compatible with Windows XP?
#### Posted by Mikael Brudfors on 2014-04-29 18:15

I am trying to run the latest version of PlusApp on our ultrasound machine running Windows XP. When I run the PlusApp I get a missing mf.dll error message, which seems to be a Windows 7 dll. Is this version of PlusServer not compatible with XP?

Thank you,

Mikael

#### 2 Comments
#### By Andras Lasso on 2014-04-29 18:20
Use the embedded version.

Details are described in the release notes:
"PlusApp_...-embedded.exe: for installation on Windows XP embedded systems, such as Ultrasonix US scanners. Unsupported devices include MicronTracker and MediaFoundation."
#### By Mikael Brudfors on 2014-04-29 18:28
Thank you Andras, I should have looked closer!


## Using OpenCV in ITK in PLUS
#### Posted by rsingla92 on 2014-04-23 18:12

Hi there,

OpenCV has some functionality that I am trying to use for ultrasound images. As ITK provides a bridge for OpenCV, I am trying to build that ITK module. I do not plan on committing these changes to PLUS. I am using Windows 7 with a recent (within the last week) revision of PLUS.

In External_ITK.cmake, I have added the following lines:

Line 35: Added a OPENCV_SRC_DIR variable that is points to OpenCVConfig.cmake (the directory in my case is "C:/opencv/opencv/build")
Line 60: Added two additional CMAKE_ARGS. These are:
-DOpenCV_DIR:String=${OPENCV_SRC_dIR}
-DModule_ITKVideoBridgeOpenCV:BOOL=ON

The configuration and generation steps using CMake are fine. However, upon building the generated solution, I run into linker errors galore. Brief research said that certain multithreaded DLLs were conflicting. However, before digging further, I wanted to ask if anyone's tried this before or if they have any guidelines as to how to proceed.

Thank you.

Regards,
Ricky

#### 3 Comments
#### By Andras Lasso on 2014-04-24 08:15
If you need a special ITK build then I would suggest to build ITK yourself with all the options that you need and test it to make sure there are no linker errors, etc. To use this ITK in Plus simply set ITK_DIR CMake variable to your ITK binary directory.

If you copy-paste here the exact error messages that you get then I may be able to help you finding out what causes the linking issues and how to fix them.
#### By Rsingla92 on 2014-04-24 15:02
Thanks for the reply! I'll try building ITK with OpenCV and see how that turns out as you suggested.

I've attached the modified External_ITK.cmake file, the entirety of the build log from Visual Studio, and the first BuildLog from the first project that errors.

It may or may not matter but I used the Windows installer for OpenCV found here which auto-extracts and installs OpenCV.

Thanks Andras!
External_ITK.cmake	2.55 KB
BuildLog.htm	127 KB
VSBuildLog.txt	806 KB
#### By Rsingla92 on 2014-04-28 16:13
Stopping the OpenCV effort (linker errors were due to conflicting DLLs). Found the functionality I needed in ITK modules as well. Currently building a customized ITK (for itkVtkGlue) and seeing how that goes.

Thanks again.


## Any plans for lossy compression for video recording?
#### Posted by Tamas Ungi on 2014-04-14 22:59

In some applications where PLUS records tracking data, we are also recording a camcorder video of the experiment. PLUS is almost ready to be able to record that video (so we wouldn't need a camcorder) using the MMF video input and a webcam. The only feature missing is real time lossy compression, like mpeg in the VirtualDiscCapture device. Is this feature planned any time in the near future?
I would use this feature a lot, and there are other potential applications, e.g. recording endoscopy video.

#### 3 Comments
#### By Andras Lasso on 2014-04-14 23:16
What is the main issue with the current non-compressed/lossless-compressed image data? Is the only issue the large storage space for archival? How would you like to replay/review the file? How accurate synchronization do you need with other recorded data (e.g., tracking)?

MetaIO only supports lossless zlib compression, so most likely we could only extend the file format in a non-standard way or use another format. MPEG is complex and there are also licensing concerns. MJPEG (basically a set of individually-compressed JPEG images) might be an option.
#### By Tamas Ungi on 2014-04-14 23:25
The only issue with the current lossless compression is data size. On my webcam it's around 300 MB/min. After ten minutes, it is hard to handle, and almost impossible to share/backup data from tens of experiments.
I don't need very accurate synchronization with tracking for my current applications. (It may become necessary with endoscopy though.)
MJPEG sounds good. If compression level could be set too, that would be awesome. I only want to replay the recorded videos with PLUS, so I don't need any standard video format.
#### By Andras Lasso on 2014-04-24 10:22
Right now recording long (for 30-60 minutes or longer), continuous, HD video would require quite significant developments (not just the lossy compression when stored in file but efficient random access, replay, streaming processing, etc.), which would not be useful for most of the current applications.
Having a multi-track data recorder that can store and replay multiple HD video and other data streams of a whole exam would be definitely useful and is planned to be developed by the NAMIC community (Steve Pieper et al.) and Plus could be a part of that (for recording tracking, US, and maybe some other data), but currently we don't plan to implement all these features in Plus.


## Example config file for fCal3.x phantom
#### Posted by amit.shah on 2014-04-14 11:29

Hi,

Can you please provide one example config file for fCal3.x phantom?

Thanks,
Amit

#### 2 Comments
#### By Adam Rankin on 2014-04-14 11:56
Hi Amit,

You can find an example in the Config files directory under the title:
PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_3.0.xml

You can extract the <PhantomDefinition> tag and contents to put in your configuration file.
#### By Amit.Shah on 2014-04-15 06:59
Thanks :-)


## Sending slices in simulation mode
#### Posted by Mikael Brudfors on 2014-04-06 19:26

I am new to PlusServer so I hope you excuse this very simple question. Anyway, what I want to do is just to send some ultrasound slices in simulation mode.

I have created a .mha image file from a .vtk file using ITK. Next I want to send the slices contained in this .mha file to 3D Slicer using PlusServer (no transforms, just the slices). I have found an example config file in the repository https://www.assembla.com/code/plus/subversion/nodes/573/trunk/PlusLib/data/ConfigFiles/USDataCollectionConfig_SavedDataset.xml and changed the SequenceMetafile to the path of my .mha file. But I get an error message once I run PlusServer, using this config-file, from the command prompt:

C:\Dev\Data\PlusServer-configs>PlusServer --config-file=USDataCollectionConfig_SavedDataset.xm
|INFO|000.000000| Editor application executable is not set - default 'notepad.exe' will be used
|ERROR|000.005000| Failed to open C:/Program Files (x86)/PlusApp_2.1.0.2971/bin/PlusConfig.xml for writing|in ..\..\..\PlusLib\src\PlusCommon\PlusCommon.cxx(386)
|INFO|000.011000| Application configuration file 'C:/Program Files (x86)/PlusApp_2.1.0.2971/bin/PlusConfig.xml' saved
|INFO|000.015000| Software version: Plus-2.1.0.2971
|ERROR|000.017000| Unable to find data collection element in XML tree!|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(73)
|ERROR|000.022000| Datacollector failed to read configuration!|in ..\..\..\..\PlusLib\src\PlusServer\Testing\PlusServer.cxx(87)

I am probably not doing this the right way. Any help would be greatly appreciated.

Thank you,

Mikael

#### 1 Comments
#### By Andras Lasso on 2014-04-06 20:32
First of all, download and use the latest available Plus version (2.1.1). Then try the replay sample configuration file in the package ("PlusServer: Replay fCal..."). Finally, modify the configuration file to point to your mha file and modify UseData attribute to UseData="IMAGE" to indicate that it should not look for tracking data.


## Front fire TRUS Probe calibration
#### Posted by amit.shah on 2014-04-01 15:19

Hi,

Is there a special phantom for front fire TRUS probe calibration?

We used fcal2.0 phantom as described in the userguide and also tried all the suggestion to reduce calibration errors, but we still get about 5mm error in spatial calibration.

Any input will be highly appreciated.

Thanks,
Amit

#### 5 Comments
#### By Andras Lasso on 2014-04-01 15:30
Have you checked the FAQ on this page? https://www.assembla.com/spaces/plus/wiki/System_calibration

What US system do you use? What tracker do you use?
#### By Amit.Shah on 2014-04-02 03:09
Yes, I checked the FAQs. We use fCal_2.0.stl phantom with 9 wires.

We use Hitachi Avius US system with Polaris Spectra tracking system. For the linear side fire probe we get good calibration, however we get large calib errors (~5mm) for curvilinear probe and front fire probe.
#### By Amit.Shah on 2014-04-02 04:38
After reading FAQs again, I found this line "Cal 3.x phantom is designed for deeper imaging (10-20cm) with curvilinear probes". Can I do calibration of curvilinear probe with fCal 2.0 phantom or do I need fCal 3.x phantom?

Where can I find CAD model of fCal 3.x phantom and an example xml config file file for curvilinear probe?

Many thanks.
#### By Amit.Shah on 2014-04-02 04:48
I found stl file for fCal 3.1 phantom. Looking for example xml config file file for curvilinear probe calibration.

.Thanks
#### By Siavash Khallaghi on 2014-04-02 17:02
Amit, I did phantom calibration for an end-firing 2D TRUS probe, i.e. EC9-5/10:

http://www.analogicultrasound.com/ultrasonix/transducers/ec9-510-endovaginal-microconvex

It took me about ~50 trials to get sub-millimeter accuracy. We observed that the calibration error decreased significantly when we used a probe with a built-in magnetic sensor.


## Volume reconstruction using motorized 3D-probe.
#### Posted by Mikael Brudfors on 2014-03-25 17:15

Hello,

I know I can use PlusServer to reconstruct a volume from a tracked 2D-probe. Is it also possible to use it to reconstruct a volume from slices acquired using a motorized 3D-probe, i.e., after each sweep of the probe, produce a reconstructed volume?

Thank you,

Mikael

#### 2 Comments
#### By Andras Lasso on 2014-03-27 18:50
If you know the pose of the wobbler inside the probe then of course you can reconstruct the volume using a motorized probe. What motorized probe would you use? Do you know how to access the wobbler pose?

As far as I remember, somebody wanted to reconstruct volume using a motorized probe, but it was not obvious how to get the wobbler position through the Ulterius or Porta API. If you know how to get it then we can help you with the rest.
#### By Mikael Brudfors on 2014-04-02 16:56
Thank you for your response. I figured out a way of avoiding the reconstruction though.

I have another question regarding the motorized 3D probe and I thought of asking it here instead of creating a new topic. I will acquire ultrasound images using a motorized 3D probe through PlusServer. I would like to keep track of which slices belongs to which sweep of the probe, i.e., which non-reconstructed volume. I know that Ultrasonix has a SDK called Propello that will give you a .vol file, with a header containing the slices per volume etc. Is this somehow incorporated in PlusServer?

Mikael


## Run time error PLUS rv #3192
#### Posted by Samira Sojoudi on 2014-03-28 12:33

Hello,

I built PLUS revision #3192 on two different computers, and I am getting run time errors for missing qt dlls or "entry point not found" for ITK or VTK on both. Any changes for qt version in latest revision or any idea?

Thanks,

Samira

#### 11 Comments
#### By Andras Lasso on 2014-03-28 12:37
Nothing has changed. You can double-check with depends.exe if all the DLLs are loaded from the local directory. To make sure you have up-to-date version of all libraries, update the PlusBuild directory and build Plus with all the libraries (by building PlusBuild.sln).
#### By Samira Sojoudi on 2014-03-28 13:09
I did a fresh build on the second computer. but I still get the run time errors!
#### By Andras Lasso on 2014-03-28 13:12
Do you try to run in debug or release mode? 32/64 bit?
Have you built QT yourself? If not, was QT built with the same compiler version that you are using? Debug/release? 32/64 bit?
#### By Samira Sojoudi on 2014-03-28 13:42
Debug and Release both have the problem. I am running it on 32bit VS2008 and I didn't build the Qt just got the v 4.7.4 from the address you mentioned on PLUS Wiki page to make sure it is the right version.
#### By Adam Rankin on 2014-03-28 13:43
What devices do you have enabled in the CMake config?
#### By Samira Sojoudi on 2014-03-28 13:51
Ascension, Brachy tracker and Ultrasonix .
#### By Andras Lasso on 2014-03-28 13:51
If you have time now then I can have a look at your computer, write me on skype with the details.
#### By Samira Sojoudi on 2014-03-28 14:20
sure, thanks Andras.
#### By Andras Lasso on 2014-03-28 14:39
It's caused by Ultrasonix SDK 6.0.x - see details at https://www.assembla.com/spaces/plus/tickets/491 . It should work with Ultrasonix SDK 6.1.x or later (not released yet).
#### By Tamas Ungi on 2014-03-28 14:42
When this happened to me, I asked Ultrasonix to send me an exam software version 6.0.2. It was easy to install, and PLUS works with it.
#### By Andras Lasso on 2014-03-28 14:45
Yes, right. Although currently Plus can only be built with Ultrasonix SDK 5.7.x it is compatible with Exam software 6.0.2 or earlier.


## Receive transforms in PlusServerRemoteControl client
#### Posted by mmscr on 2014-02-27 08:15

Hello,

I am trying to have access to live transforms that are sent from a PlusServer to its clients. I know that I can get live transforms in a 3D Slicer client, I have seen that it is possible to do this with scripts for real-time receiving of transforms in Matlab through OpenIGTLink but I would now like to receive these transforms in real-time by using the already implemented PlusServerRemoteControl client. I know that this client can receive messages of type STRING by looking at the
void* vtkPlusOpenIGTLinkClient::DataReceiverThread( vtkMultiThreader::ThreadInfo* data )

method of the vtkPlusOpenIGTLinkClient class.

Am I correct by saying that if I want to receive messages of some other type (in this case, TRANSFORM type) I should add modifications to the DataReceiverThread method?

Thank you.

#### 7 Comments
#### By Adam Rankin on 2014-02-27 09:13
Hi,

Yes, that is the place to add handling of other message types.

One thing to note is that the PlusServerRemoteClient is meant to be run as a single shot executable, and not continually communicating with a PlusServer. If you wanted to continually record incoming transforms, you would have to implement a looping client around a vtkPlusOpenIGTLinkClient. You could even take the PlusServer code and re-write it to use clients instead of vtkPlusOpenIGTLinkServer.

Hope this helps,
Adam
#### By Mmscr on 2014-02-27 10:26
Thank you. I managed to handle other message types. As for the looping client - that is my next goal.
#### By Adam Rankin on 2014-02-27 10:40
I highly recommend learning from the PlusServer. It already does 90% of what you'll need to do.
#### By Mmscr on 2014-02-27 12:13
Yes, I did that and it works nicely. The only thing that I had to take care of was the interrupt signal: if I set it to 'Q' or 'q', as it is in the PlusServer application, it interrupted the server as well.

Thank you for your help!
#### By Adam Rankin on 2014-02-27 12:29
No problem. If you wanted to throw it up under trunk/sandbox, we might be able to re-use it!
#### By Mmscr on 2014-02-28 06:11
Yes, no problem, I will. For now it is just looping in order to read the transforms. As soon as I implement it for continuous command execution, I will try to push it.
#### By Mmscr on 2014-03-18 11:21
I am trying to add and commit under trunk/sandbox the files that I modified for the purpose of this conversation, but I can't seem to be able to. I get the following error while trying to authenticate before the actual commit is supposed to happen:

svn: E170001: Commit failed (details follow):
svn: E170001: POST of '/svn/plus/!svn/me': authorization failed: Could not authenticate to server: rejected Basic challenge (https://subversion.assembla.com)


I am using my Assembla credentials.

Is there another authentication right that I need before committing?


## running Plus server with 3D probe
#### Posted by Samira Sojoudi on 2014-02-11 15:49

Hello,

we need to send the 3D probe images to the network and get it on another machine. I am wondering if it is possible to run the plusserver with the 3D probe?

Thanks,
Samira

#### 8 Comments
#### By Andras Lasso on 2014-02-11 16:29
Is the image from the 3D probe available through Ulterius?
#### By Samira Sojoudi on 2014-02-11 17:30
Yes it is.
#### By Andras Lasso on 2014-02-11 19:46
What is the model number of the probe?
How the 3D probe is any different from the other probes?
Does it provide a 3D volume on each new frame callback?
#### By Samira Sojoudi on 2014-02-12 13:41
it provides a set of 2D images, just like 2D probe. so, you mean we can change the config file and use the plusserver?
#### By Andras Lasso on 2014-02-12 14:04
If it's not any different from any other 2D probe then of course you can use PlusServer, fCal, etc. as usual.
#### By Samira Sojoudi on 2014-02-13 13:30
Thank you Andras.
#### By Samira Sojoudi on 2014-03-05 13:43
Hi Andras, I am trying to set up the plusserver using a 3D probe, when I send the START_ACQUISITION command I get this error: "No VirtualStreamCapture has been found" BTW I set the tracker node in config file to fake tracker. do you have any idea what's the problem? do I need to set the device parameter?

Thanks,
Samira
#### By Andras Lasso on 2014-03-05 13:53
Add a CaptureDevice to the config file, see any of the current config files (e.g., https://www.assembla.com/code/plus/subversion/nodes/3216/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_NDIPolaris.xml)


## Live streaming of volume reconstruction in 3D Slicer
#### Posted by mmscr on 2014-02-28 11:01

I am trying to stream the live reconstruction sent by a PlusServer to its 3D Slicer client. I managed to stream live the basic recording (i.e., in my case, ultrasound frames) but I cannot manage to stream the volume reconstruction. I should mention that I can receive the volume reconstruction once it is finished (either made offline or live) but I want to stream it as it is generated by the server.

Can this be done by using the commands for snapshot requests of the reconstructed volume?

I am aware that it might not have to do with PLUS because it is a Slicer related question, but I thought I will give it a try.

Thank you.

#### 5 Comments
#### By Adam Rankin on 2014-02-28 12:18
You know... I'm not sure.

@lassoan Do you recognize this use case?

If not, please feel free to submit a ticket and we will consider working it into the feature list.
#### By Andras Lasso on 2014-02-28 12:55
You can get the reconstructed volume anytime during live reconstruction using the GetVolumeReconstructionSnapshot command, just set the output device name (that'll be the volume name in Slicer) or filename (if you want to save the result in file). See more details and examples here: PlusServer_commands
#### By Mmscr on 2014-02-28 13:27
This is what I did: after starting the live reconstruction I kept capturing snapshots in a volume file in Slicer and enabled its visualization. However, I could not visualize it and my guess is because the volume reconstruction is corrupt due to my computer's specifications (it keeps skipping frames because of the delay in the image acquisition).

I will retry this as soon as I get hold of a more powerful CPU.

Thank you for creating and supporting this project and for your useful replies!
#### By Andras Lasso on 2014-02-28 13:38
Make sure you set the output volume origin, size, and extent properly when you start live reconstruction. This is done automatically when you reconstruct from file. You can also lower the output volume resolution (increase the spacing) and decrease acquisition frame rate, and pause the reconstruction for the time of snapshot requesting to resolve performance issues.
#### By Mmscr on 2014-02-28 13:47
I tried decreasing the acquisition rate but apparently in this case it does not suffice. I get those acquisition warnings and errors even when I do simple capturing, without reconstruction - in the case of server-client communication. If I use fCal for simple image capturing, lowering the frame rate suffices.

I will try all your suggestions, although I fear that the simple communication between the server and client bring my CPU usage to 100%, meaning that it cannot get better than that.


## Tracker + Image source via OpenIGTLink
#### Posted by MattClarkson on 2014-02-25 05:26

Hi there,

I am trying to send ultrasound images, and tracking matrices into fCal via OpenIGTLink. My application can successfully create an OpenIGTLink server socket on port 18944, and Slicer can connect to it as a client, and I can see the image and transform in Slicer. However, when I try and connect fCal in the same way, it does not seem to connect.

Log file attached.

Does anyone know what I am doing wrong?

Thanks

Matt
matt.log	480 KB

#### 3 Comments
#### By MattClarkson on 2014-02-25 08:49
And its Plus 2.1.1.3113 downloaded as a binary, running on Windows.
#### By Andras Lasso on 2014-02-25 12:18
I see a couple of things to fix:

1. The transform name in OpenIGTLink should be ProbeToTracker (tool name "To" ToolReferenceFrame), see an example for a working OpenIGTLink tracker configuration at
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_Server_SimulatedUltrasound_3DSlicer.xml and corresponding configuration file at https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/SimulatedUltrasound_Scene.mrb
(description is available at Ultrasound_simulation).

2. The DataSource ID in the OutputChannel element shall match one of the DataSource ID in the DataSources element (now there is mismatch: "Probe" != "TagTracking")

3. It would be better to use two separate ports for the image and tracking data, as currently theOpenIGTLinkTracker and OpenIGTLinkVideo creates two separate connections to the server (and so the server has to support multiple clients and send all data to both connections).

Let me know if it works.
#### By MattClarkson on 2014-02-25 15:14
Thanks for the response. Im at home now, so will try in the morning.


## Alternative Tracker - via OpenIGTLink maybe?
#### Posted by MattClarkson on 2014-02-08 15:59

Hi there,

Im just taking a look at PLUS. Thanks for the open-source transparency.

I see lots of configurations for trackers, scanner etc. But what if I have an unsupported tracker, and I want to calibrate an ultrasound probe with respect to the unsupported tracker. I do however have an ultrasonix MDP, and ulterius API. So, is it possible to use my tracker, record a tracking matrix, but send it Live into fCal, perhaps via OpenIGTLink?

Thanks

Matt

#### 4 Comments
#### By Andras Lasso on 2014-02-08 17:05
You either have to implement a class in Plus to communicate with the tracker (we would be happy to help you with that), or Plus can receive the transforms through OpenIGTLink.
#### By MattClarkson on 2014-02-09 01:42
Great thanks............ and final question, is it possible to just import a load of ultrasound images and corresponding tracking transforms, and have PLUS do all the image processing and calculations.

Thanks

Matt
#### By Andras Lasso on 2014-02-09 07:24
Yes, sure. Save all data in sequence metafiles (MetaIO image with some additional fields, see specification at Sequence_metafile_format), then use a SavedDataSource to replay it in any application (example: https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_Sim_SpatialCalibration_2.0.xml).

Feel free to ask any questions, we are happy if we can help.
#### By MattClarkson on 2014-02-09 12:25
Righto. I will try that in the first instance. Thanks again.


## fCal phantom
#### Posted by MattClarkson on 2014-02-08 09:34

Hi there,

Im interested in downloading the fCal_2 phantom as an stl file and printing it out. However, if I was using it with other software, I would need the definition of all the points that could be used for N-wire calibration. Is that available somewhere. Or do I work it out from the stl file?

Also, are the exact end points of each N defined? As it looks to me from the stl file that if you made an N, the diagonal would intersect the vertical lines, some way outside the phantom.

(i hope Im making sense, as Im new to this).

Thanks

Matt

#### 3 Comments
#### By Adam Rankin on 2014-02-08 14:24
Hi Matt, the description of the phantom 2.0 can be found in any config file in the plus lib repository that has the fcal 2.0 in the config description. There is a 99% chance that the file name matches the description for easy browsing.

All points are described relative to an arbitrary point on the phantom. You can analyze the visualization section of the config file to determine the point used. For most of our configs it is the inside point of a1 (maybe A1).

Hope this helps,
Adam
#### By MattClarkson on 2014-02-08 15:56
Thanks. Makes sense.
#### By Andras Lasso on 2014-02-08 23:05
Specification of the phantom coordinate system is available here: Coordinate_system_definitions

Some more pictures and info:
https://subversion.assembla.com/svn/plus/trunk/doc/tutorials/PlusTutorialBuildingfCalPhantom.pptx

Coordinates of the wires and landmark points are defined in the device set config file, for example:
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusDeviceSet_fCal_SonixTouch_L14-5_Ascension3DG_2.0.xml
~~~~
<PhantomDefinition>
<Description Name="fCAL" Type="Double-N" Version="2.0" WiringVersion="2.0" Institution="Queen's University PerkLab" />
<Geometry>
<Pattern Type="NWire">
<Wire Name="7:G1_g1" EndPointFront="30.0 0.0 20.0" EndPointBack="30.0 40.0 20.0" />
<Wire Name="8:L1_h1" EndPointFront="55.0 0.0 20.0" EndPointBack="35.0 40.0 20.0" />
<Wire Name="9:M1_m1" EndPointFront="60.0 0.0 20.0" EndPointBack="60.0 40.0 20.0" />
</Pattern>
<Pattern Type="NWire">
<Wire Name="4:G3_g3" EndPointFront="30.0 0.0 10.0" EndPointBack="30.0 40.0 10.0" />
<Wire Name="5:H3_l3" EndPointFront="35.0 0.0 10.0" EndPointBack="55.0 40.0 10.0" />
<Wire Name="6:M3_m3" EndPointFront="60.0 0.0 10.0" EndPointBack="60.0 40.0 10.0" />
</Pattern>
<Pattern Type="NWire">
<Wire Name="1:H5_h5" EndPointFront="35.0 0.0 0.0" EndPointBack="35.0 40.0 0.0" />
<Wire Name="2:L5_i5" EndPointFront="55.0 0.0 0.0" EndPointBack="40.0 40.0 0.0" />
<Wire Name="3:M5_m5" EndPointFront="60.0 0.0 0.0" EndPointBack="60.0 40.0 0.0" />
</Pattern>
<Landmarks>
<Landmark Name="#1" Position="104.3 5.0 20.0" />
<Landmark Name="#2" Position="104.3 45.0 20.0" />
<Landmark Name="#3" Position="104.3 45.0 0.0" />
<Landmark Name="#4" Position="104.3 -5.0 0.0" />
<Landmark Name="#5" Position="-34.3 45.0 15.0" />
<Landmark Name="#6" Position="-34.3 -5.0 20.0" />
<Landmark Name="#7" Position="-34.3 -5.0 0.0" />
<Landmark Name="#8" Position="-34.3 45.0 0.0" />
</Landmarks>
</Geometry>
</PhantomDefinition>
~~~~
The calibration algorithm computes the intersection points, so you can define the start/end points anywhere along the lines. You are correct, for the fCal-2.0 wiring 2.0 the (virtual) intersection points are somewhere in the phantom wall or outside the phantom.


## NDI Aurora not initialized
#### Posted by erwinv on 2014-01-24 05:43

Hi,

We have a NDI Aurora EM Field Generator and markers/trackers and I was trying Plus for the first time. Using fCal I can connect to the Aurora 'Hub'; the hub beeps and the lights on the hub for the connectors go orange. In the command prompt I get the error:

|INFO|000.007000| Software version: Plus-2.0.0.2873
|INFO|000.315000| Toolbox changed to Configuration
|INFO|400.106000| Device set configuration is read from file: D:/Mediate/plus/PlusConfiguration_NoVideo_NDIAurora.xml
|INFO|400.135000| Connect to devices
|INFO|401.295000| Device local time offset for TrackerDevice: 0ms
|ERROR|402.914000| System not initialized|in ..\..\..\PlusLib\src\DataCollection\PolarisTracking\vtkNDITracker.cxx(844)|ERROR|402.974000| Failed TSTART: System not initialized|in ..\..\..\PlusLib\src\DataCollection\PolarisTracking\vtkNDITracker.cxx(405)
|ERROR|403.074000| Cannot start recording, internal StartRecording failed|in ..\..\..\PlusLib\src\DataCollection\vtkPlusDevice.cxx(984)
|ERROR|403.102000| Failed to start data acquisition for device TrackerDevice.|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(240)
|ERROR|404.124000| Unable to start collecting data!|in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(191)

It looks like it is somehow not (correctly) initialized. Does anyone has experience with using the NDI Aurora and has a solution for the above problem? I am testing it on Windows x64, but with 32 bit Plus software (docs said it supports more devices), Plus version 2.0

Thanks,
Erwin

#### 5 Comments
#### By Andras Lasso on 2014-01-24 07:37
Could you try with the latest release (2.1.x)?
https://www.assembla.com/spaces/plus/milestones/completed?id=plus&milestone_sort_id=ddDESC
#### By Erwinv on 2014-01-27 05:16
Thanks Andres, the latest version works :) I see that device name has changed to PlusServer: NDI Aurora Tracker. Is this the same as the No Video Aurora Tracker? I removed the PlusOpenIGTLinkServer part in the configuration XML and added several parts I found in another configuration XML (e.g. Rendering, PhantomDefinition, vtkPivotCalibrationAlgo, vtkPhantomLandmarkRegistrationAlgo, vtkProbeCalibrationAlgo). I also have to plugin only the needle, instead of three components in the previous version (I thought needle, reference and stylus)?

I have another problem now (I get several warnings by the way). If i go to Stylus Calibration in the GUI I get the orange text " StylusTipToStylus transform is absent, calibration needs to be performed". When I go spatial calibration I get the orange text "Phantom registration is missing. It needs to be performed or imported", so some kind of circular dependency.
I also get the error "|ERROR|2278.422000| No transform found between stylus and reference!|in ..\..\PlusApp\fCal\Toolboxes\StylusCalibrationToolbox.cxx(105)" when clicking on the Stylus calibration tab in the GUI.

Am I missing something with the configuration?

Thanks,
Erwin
#### By Andras Lasso on 2014-01-27 07:36
What would you like to achieve? fCal is an application for performing various calibrations and the orange warnings just indicate that the particular calibration steps have not been performed yet.
#### By Adam Rankin on 2014-01-27 09:04
Hi Erwin,

Would you consider attaching your configuration file for me to examine?

Adam
#### By Erwinv on 2014-01-30 08:02
Hi,

Forgot to came back to you; it works now. I didn't had all the required connectors connected so the calibration options were grayed out. With the correct amount of connectors I can start the calibration.

Thanks,
Erwin


## fCal segmentation problem
#### Posted by Mohammad Najafi on 2014-01-16 18:50

Hi,
I'm trying to do N-wire calibration using fcal version 1.5.3.17. I get the following warning:
"Could not read InclinedLineAngleDegrees from configuration file."

I see the red dots in the right positions when I click on the adjust parameters menu. They never go green and when I click on start, it cannot find any correct frame (and I get the previously mentioned warning).

#### 11 Comments
#### By Andras Lasso on 2014-01-16 19:25
It's a very old software version. Would it be possible to use the latest Plus version instead?
#### By Mohammad Najafi on 2014-01-16 21:20
I'm using NDI Certus tracker and for some reasons the latest version doesn't work with it (says: Optotrak:invalid node version). I tried the segmentation algorithm by using a fake tracker in the latest version but still got the same warning (and with bunch of other warnings). Do you have any idea what the problem might be?
#### By Andras Lasso on 2014-01-16 22:00
Probably the warning is not related to the warning message. Try the tips described in the Spatial Calibration section at System_calibration.

If you still cannot get it to work then acquire a short sequence (a few frames that you think should work) and attach it here and I'll have a look at it.
#### By Mohammad Najafi on 2014-01-17 14:33
Could you please tell me what are the requirements for the pattern recognition (to turn the dots to green)? I have attached a screenshot of the segmentation parameter setting dialog (9 red dots) and my configuration file. I have no idea what I should do to make the dots go green.
#### By the way, when I click on start, no frames are acquired.

Thanks.
PlusConfiguration_SonixTouch_L14-5_NDICertus_fCal_1.0_EDIT.xml	7.05 KB
fcal_screenshot.PNG	134 KB
#### By Andras Lasso on 2014-01-17 14:39
The screenshot shows that you haven't set the approximate spacing value. Position the red and green lines on known distances and enter the corresponding mm distance values in the Spacing section.

It is described in detail on the page that I referred to:
"Check if initial spacing is correct. For giving a hint on image spacing to fCal, select the checkbox next to spacing. It will give you two rulers, a green (G) and a blue (B). You can manually enter two known distances that appear on the image, one horizontal and one vertical. Then set the visual rulers on the image to represent these distances. You can do this by dragging the end points of the ruler."
#### By Andras Lasso on 2014-01-17 14:42
See also slide 18 of the https://subversion.assembla.com/svn/plus/trunk/doc/tutorials/PlusTutorialfCalCalibrationProcess.pptx presentation. It is also explained in the tutorial video: http://www.youtube.com/watch?v=lx9GbPupBxA
#### By Mohammad Najafi on 2014-01-17 15:25
I set the approximate spacing value and it works now. I'm wondering how accurate this approximation should be? Does it affect the calibration results?
Thanks!
#### By Andras Lasso on 2014-01-17 17:05
The approximate spacing is only used for the pattern recognition, it has no effect on the calibration accuracy.
#### By Mohammad Najafi on 2014-01-17 18:01
ok thanks.
#### By Mohammad Najafi on 2014-01-21 20:28
I'm not sure if here is the right place to ask this but it is a quick question. I'm wondering if ImageToTransducerOriginPixel has any effect on the calibration or not?
#### By Andras Lasso on 2014-01-21 20:43
ImageToTransducerOriginPixel is only used for positioning the displayed 3D model of the transducer in the 3D view, see Coordinate_system_definitions. It does not affect the calibration.


## fCal Accuracy vs. Ultrasonix calibration
#### Posted by Siavash Khallaghi on 2014-01-08 19:27

Hello,

I am not sure if this question has been answered here before, I did a quick search and it did not come up. But anyway, here it goes:

My colleague asked me if the calibration matrix from fCal was more accurate than the calibration matrix found in /Exam/gps/probes.xml. Could you please comment on this?

Thank you,

Siavash

#### 1 Comments
#### By Andras Lasso on 2014-01-09 00:27
As I remember, we tried to compare them, but Ultrasonix defines the calibration matrix quite differently compared to Plus: it doesn't provide direct mapping of image pixels to tracker space, but just defines the transducer center and direction and you have to get information about the pixel spacing and the transducer center in the image and compute the image to probe matrix from them. This computation is not complex, but we had other things to do, so finally never tried it.

I don't know how Ultrasonix calibrates their probes, so I can only guess that the accuracy is comparable to fCal's multi-N-wire calibration.


## New Plus release: Plus-2.1.1
#### Posted by Andras Lasso on 2014-01-02 18:15

Dear Plus users,

We've prepared the Plus-2.1.1 release, with several new features and bugfixes.
The most visible change is the addition of a convenient graphical user interface for starting PlusServer from the Start menu.
Remote control through OpenIGTLink, temporal calibration, and ultrasound simulation are greatly improved and transform can now be streamed to Matlab as well.

We'll test this release thoroughly in the coming weeks and will release a stable version when we are done. It would help a lot if you could also give this release a test on your configuration and enter tickets if you find any issue.

Andras

New features:
• Usage of the install package has been simplified: a simple GUI application is added for launching PlusServer (https://www.assembla.com/spaces/plus/wiki/PlusServer)
• Ultrasound image simulation is improved: imaging of any number of objects is now supported (https://www.assembla.com/spaces/plus/wiki/Ultrasound_simulation)
• Temporal calibration can be performed between any two streams (between imaging/tracking, imaging/imaging, tracking/tracking devices)
• New virtual device is added for volume reconstruction that can be controlled remotely through OpenIGTLink
• Added support for Microsoft Media Foundation compatible imaging devices (framegrabbers, cameras, etc.) – known limitation: it may crash after disconnect (#843)
• Transforms can be updated and the changed device set configuration file can be saved remotely through OpenIGTLink (e.g., using the PlusRemote module in 3D Slicer)
• Outlier rejection is added to Stylus calibration algorithm to make it more robust
• Recording of signal quality value is now available for Ascension EM tracking devices
• Receiving of transforms from 3D Slicer through OpenIGTLink is supported. Useful for specifying transforms e.g., for US image simulation.
• Added script for receiving Plus-acquired transforms in Matlab through OpenIGTLink (native Matlab implementation, does not require any mex file compilation; see https://www.assembla.com/spaces/plus/wiki/Matlab_interface)

Bugfixes include:
• Fixed handling of transform concatenation if a tool is out of view
• Temporal calibration is applied also when offset is applied to tracking stream
• Clip rectangle is used in fully-optimized volume reconstruction

#### 0 Comments


## Wrong coordinate definitions
#### Posted by Bartłomiej Pyciński on 2013-11-28 15:32

Hi, there is a bug in Wiki page with default coordinate systems (https://www.assembla.com/spaces/plus/wiki/Coordinate_system_definitions). Units of TransducerOrigin and TransducerOriginPixel should be swapped.

Bart
P.S. By the way, if i would find other bug in Wiki in the future, should I create ticket, post a message here, post private mail, some other thing? Maybe you could add some info in Wiki page?

#### 2 Comments
#### By Andras Lasso on 2013-11-29 12:09
Good catch, thank you, I've updated the page!

Writing an assembla message is fine. If it's a bigger task then you can enter a ticket.
#### By Andras Lasso on 2013-11-29 12:13
I've also updated the How_to_report_an_error page with info about reporting documentation issues.


## OpenIGTLinkRemote
#### Posted by Samira Sojoudi on 2013-10-25 13:56

Hi guys,

I have problem using OpenIGTlinkRemote, the scenario is as below:
I start live volume reconstruction

#### 2 Comments
#### By Andras Lasso on 2013-10-25 19:52
your message seems to be truncated, could you please post the missing part?
#### By Samira Sojoudi on 2013-10-25 20:00
Hi Andaras,

The problem is resolved :) I hadn't sent the message, I just typed it. Thank you so much for the response.


## OpenIGTLinkRemote
#### Posted by Samira Sojoudi on 2013-10-25 13:56

Hi guys,

I have problem using OpenIGTlinkRemote, the scenario is as below:
I start live volume reconstruction

#### 1 Comments
#### By Andras Lasso on 2013-10-25 19:52
Seems to be a duplicate of https://www.assembla.com/spaces/plus/messages/3441473


## Windows/Linux build patch
#### Posted by Matt McCormick on 2013-10-23 16:43

Hi,

I'm not sure of the contribution process, but the following patch is needed to build on my linux box. "_WIN32" should be used instead of "WIN32" because the latter is not always defined.

Index: src/PlusCommon/vtkPlusConfig.cxx
~~~~
===================================================================
--- src/PlusCommon/vtkPlusConfig.cxx (revision 2975)
+++ src/PlusCommon/vtkPlusConfig.cxx (working copy)
@@ -18,6 +18,10 @@
#include "vtkDebugLeaksManager.h"
#include "vtkObjectFactory.h"

+#if defined(unix) || defined(__unix__) || defined(__unix)
+#include "unistd.h"
+#endif
+
static const char APPLICATION_CONFIGURATION_FILE_NAME[] = "PlusConfig.xml";

vtkCxxRevisionMacro(vtkPlusConfig, "$Revision: 1.1 $");
@@ -133,7 +137,7 @@
//-----------------------------------------------------------------------------
void vtkPlusConfig::SetProgramDirectory()
{
-#ifdef WIN32
+#ifdef _WIN32
char cProgramPath[2048]={'\0'};
GetModuleFileName ( NULL, cProgramPath, 2048 );
this->ProgramDirectory=vtksys::SystemTools::GetProgramPath(cProgramPath);
~~~~

Thanks,
Matt

#### 1 Comments
#### By Andras Lasso on 2013-10-24 12:15
Thank you very much for reporting this. The fix is committed to the trunk, see #816 for details.

#### By the way, did you have WIN32 or _WIN32 defined when you were compiling on your linux box?


## Odd looking temporal calibration plots
#### Posted by cathyal on 2013-08-14 15:40

Hello,

I attempted temporal calibration of my ultrasound probe (using the MicronTracker as the tracking device) and noticed that the results weren't very repeatable for me (I get wildly varying time offsets between trials). I looked at the calibration plots and noticed that they look quite different from the ones shown in the YouTube tutorial: one of the signals isn't smooth at all (it seems to have been clipped, see attachment). I wouldn't think these signals would correlate very accurately because of the large plateaux. Is there some parameter that I might have set incorrectly in my configuration file?

Cathy
temporal_calibration_plot.JPG	60.4 KB

#### 0 Comments


## Filtering image data in vtkTrackedFrameList
#### Posted by Siavash Khallaghi on 2013-08-13 17:27

Hello,

I was wondering if there was an easy way of changing the image data inside the frames in a vtkTrackedFrameList? Basically I would like to do the following:
~~~~
//Create a tracked frame list
vtkSmartPointer<vtkTrackedFrameList> trackedFrameList = vtkSmartPointer<vtkTrackedFrameList>::New();

//Read frames from disk
trackedFrameList->ReadFromSequenceMetafile( fileName.c_str() )

//Grab a frame from the tracked frame list
TrackedFrame* frame = smallTrackedFrameList->GetTrackedFrame( 0 );

//Pass this frame to a vtkShiftImageScaleFilter
vtkSmartPointer<vtkImageShiftScale> scaleFilter = vtkSmartPointer<vtkImageShiftScale>::New();
scaleFilter->SetInput( frame->GetImageData()->GetVtkImage() );
scaleFilter->SetShift( 0.0 );
scaleFilter->SetScale( 0.9 );
scaleFilter->Update();
~~~~
The part that I am not sure how to do is something like this:
~~~~
//Modify the image content in the frame
frame->SetVTKImage( scaleFilter->GetOutput() );
~~~~
I am using an older version of Plus (revision 2002), maybe there is an easy work around in the new version?

#### 2 Comments
#### By Andras Lasso on 2013-08-13 17:35
Something like this should work: frame->GetImageData()->DeepCopyFrom(scaleFilter->GetOutput());
#### By Siavash Khallaghi on 2013-08-13 18:10
Great it works! Thank you Andras. It blew my mind all day yesterday, I kept thinking this should have a simple solution.


## Problems using MicronTracker with Plus 2.0
#### Posted by cathyal on 2013-08-13 12:21

Hello,

I am new to Plus and just installed the stable release version 2.0. I wrote a configuration file to use the MicronTracker as a tracking device, following the instructions in the on-line documentation. When I try to connect to the device in fCal, I get an error message. Here are the contents of the log file:

time|level|timeoffset|message|location
081313_115806.303|INFO|000.001000| Software version: Plus-2.0.0.2873
081313_115806.425|INFO|000.123000| Toolbox changed to Configuration
081313_115811.126|INFO|004.824000| Device set configuration is read from file: C:/Program Files/PlusApp_2.0.0.2873/config/PlusConfiguration_CathyTestNoVideo.xml
081313_115811.131|INFO|004.828000| Connect to devices
081313_115811.233|ERROR|004.930000| Unknown device type: MicronTracker. Supported devices: 3dConnexion, Ascension3DG, AuroraTracker, BrachyTracker, CertusTracker, ChRobotics, Epiphan, FakeTracker, ICCapturing, NoiseVideo, OpenIGTLinkTracker, OpenIGTLinkVideo, PhidgetSpatial, PolarisTracker, SavedDataSource, SonixPortaVideo, SonixVideo, UsSimulator, VFWVideo, VirtualBufferedDiscCapture, VirtualDiscCapture, VirtualMixer, VirtualSwitcher|in ..\..\..\PlusLib\src\DataCollection\vtkPlusDeviceFactory.cxx(231)
081313_115811.246|ERROR|004.944000| Unable to create device: MicronTracker|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(113)
081313_115811.250|ERROR|004.948000| No devices created. Please verify configuration file and any error produced.|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(124)
081313_115811.254|ERROR|004.952000| Unable to start collecting data!|in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(191)

The MicronTracker does not appear in the list of supported devices. Is this issue unique to Plus 2.0 or I am likely to encounter the same problem in earlier versions of Plus?

Many thanks in advance,

Cathy

#### 4 Comments
#### By Andras Lasso on 2013-08-13 12:51
MicronTracker drivers are not supported on Windows XP embedded systems and therefore it is not included in regular releases ((MTC.dll cannot be loaded on some systems, see #348). Can you build Plus as described at https://www.assembla.com/spaces/plus/wiki/Windows_Build_Instructions? (if not, then we can build a Plus release for you with built-in MicronTracker support)
#### By Cathyal on 2013-08-13 17:11
Thanks Andras. I managed to build Plus and I am now able to connect to my MicronTracker device. I am now trying to understand how to use fCal properly. When I open the Capturing tab, there is a message saying that tracking is not enabled. What would I need to do to enable tracking?

Also, is there some sort of an install script with the build so that I can get a proper installation set up (with the same directory structure as in the release version)?

Cathy
#### By Andras Lasso on 2013-08-13 17:18
You need to create a suitable configuration file that describes your system. I would suggest to start from a recent fCal 2.x config file (such as this: https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal2.0.xml) and replace the TrackerDevice definition with the one that you find in the sample MicronTracker config file (https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/ConfigFiles/PlusConfiguration_SonixTouch_MicronTracker_3.2_L14_fCal1.xml).

Run run PlusApp-bin\CreatePackage.bat to create an installer package.
#### By Cathyal on 2013-08-13 17:49
Thank you Andras. That worked.

Cheers,

Cathy


## Changing scalar mode for volume reconstruction
#### Posted by custillo on 2013-08-02 04:16

Hello, I have a problem using the volume reconstruction module. I want to paste slices into a volume. The slices are encoded with unsigned char. Consequently, I use the function SetOutputScalarMode(VTK_UNSIGNED_CHAR). However, there is an error when I insert a slice into the volume : it is written that the out ScalarType is 11, which corresponds to VTK_DOUBLE, and the slice is not inserted.
Does somebody have a suggestion for me ?

Regards,

Guillaume

#### 0 Comments


## Building PLUS 2
#### Posted by Samira Sojoudi on 2013-07-15 19:17

Hello,

Today I built the latest version of PLUS and I got a bunch of errors. I attached a snapshot, do you guys have any suggestions?

Thanks
PLUS-err.jpg	278 KB

#### 3 Comments
#### By Bartłomiej Pyciński on 2013-07-16 07:08
Hello, please see discution at ticket 795 (www.assembla.com/spaces/plus/tickets/795).
#### By Andras Lasso on 2013-07-16 09:01
Thanks for reporting, it should work correctly now.
#### By Samira Sojoudi on 2013-07-16 13:06
Thanks, it worked.


## PLUS Server UDP Message
#### Posted by Laurent Chauvin on 2013-06-24 17:03

Hello,

I am trying to synchronize data acquired with a probe, with BrainLab (or other tracking device) and send them to slicer.
However, the probe is sending data through UDP.
Is PLUS handle UDP connection ?
Can it synchronize some data from UDP (probe) and tracking data (tracking device) ?

Thank you.

#### 3 Comments
#### By Andras Lasso on 2013-06-24 17:27
Plus uses OpenIGTLink for receiving/sending images and transforms through the network. If OpenIGTLink supports UDP then Plus can support it too (probably we just have to add a new configuration option to enable/disable this).
Would you like to use UDP with OpenIGTLink?
Have you used it already? Do you know how you can choose between TCP and UDP?
#### By Laurent Chauvin on 2013-06-27 06:01
It seems OpenIGTLink is supposed to be able to use UDP messages, from documentation here:

http://www.na-mic.org/Wiki/index.php/OpenIGTLink/ProtocolV2
" It is designed to work in the application layer of the TCP/IP stack, but not limited to it; developers can use this protocol with UDP/IP or other network protocol models."

However, my question was more on the synchronization. If I received a message from tracking device and data from a probe, can PLUS synchronize them ?

Thank you.
#### By Andras Lasso on 2013-06-27 08:01
Plus can compute the time offset between an ultrasound image and tracker stream and then apply this time offset when pairing the images with transforms.


## Outlier rejection in stylus calibration
#### Posted by Isaiah Norton on 2013-06-18 21:52

A small number of outliers (2 in the attached image) can cause a very large error in the stylus calibration. Is there any plan to add filtering at this step?
Thanks,
Isaiah
plus-no-outlier.png	106 KB
plus-outlier.png	120 KB

#### 1 Comments
#### By Andras Lasso on 2013-06-18 23:50
It's quite easy to add outlier rejection: compute the stdev of error, remove points where the error larger than stdev*2,.0 repeat until no more points to remove. I can implement this after the project week - please enter a ticket.

Do you know why we have the outliers? Are they reproducible? Can you provide stylus pivoting recordings with and without outliers for validation of the outlier rejection algorithm?


## Phantom for tight ultrasound image
#### Posted by Bartłomiej Pyciński on 2013-05-27 04:22

I need to calibrate a small linear ultrasound transducer, whose width of image is 25 mm, therefore "official" phantoms have too wide pattern. Would the callibration algorithm work fine, if I print the phantom with the wire patterns tighter and only adjust the Geometry tag of PhantomDefinition?

I assume that the final resolution of registration probably would extensively decrease, but for now it is not crucial.

#### 2 Comments
#### By Andras Lasso on 2013-05-27 08:37
Yes, you can just edit the PhantomDefinition and the calibration should work fine. Use the same whole for the endpoints if the middle and center wires and pay attention to adjust the imaging parameters to make the wires appear in the image as small bright dots.
#### By Bartłomiej Pyciński on 2013-05-28 05:38
OK, thank you for the answer, I will try this.


## Volume reconstruction of phasor data
#### Posted by jabeysekera on 2013-05-03 21:55

Hi,

I am trying to use the VolumeReconstructor project in Plus to reconstruct tracked frames of phasor displacement data used to create elasticity images. The project works fine for reconstructing B-mode images where the data type is unsigned char, but I am running into a problem when attempting to use float/single precision data. It appears that the floats are rounded to integer values.

I have attached an example, where a stack of image slices is scaled and translated. The expected output should be 64x50x64, with values increasing in increments of 0.6 in one direction, but the output is all integers. I execute the program by calling VolumeReconstructor.exe --transform="ImageToReference" --img-seq-file="test.mha" --config-file="test.xml" --output-volume-file="test.vtk" from the command line.

Does the VolumeReconstructor project handle float data? Am I just making a simple mistake?

Thanks,
Jeff
test.xml	469 Bytes
test.raw	800 KB
test.mha	10.4 KB

#### 4 Comments
#### By Andras Lasso on 2013-05-04 08:12
@thomasvaughan, could you have a look at this?
#### By Andras Lasso on 2013-05-05 21:39
Nice catch. There was a rounding in the output if the compounding mode is weighted average. The issue has now been fixed, see #752. The fix is available in the trunk and will be available in the next patch release (2.0.1).

Note that the sample data that you attached had two small issues: If the header and pixel data are in separate files then the ElementDataFile tag in the header shall contain the filename of the pixel data and the header file extension shall be mhd.
#### By Jabeysekera on 2013-05-08 16:58
The fix is working great. Thanks guys! Also, thanks for catching the mistake I made in the example.
#### By Andras Lasso on 2013-05-08 17:50
Great, thanks for the feedback!


## To me from Nic Heron
#### Posted by Adam Rankin on 2013-04-17 11:29

Hi,

I am new to the Plus library and have some basic configuration questions:

I am using a SonixTablet with Ascension 3D sensors.
I have downloaded Plus 1.8 on the SonixTablet and tried to run fCal.exe but none of the sonix configuration files work (connection failed error).
Could you help me get past my connection issues?
I noticed that the Sonix configuration files all have SonixVideo as the ImageAcquisition Type set to "SonixVideo" but the PlusVersion.exe does not list SonixVideo as a supported video capturing device.

Thank you very much
nick

#### 72 Comments
#### By Nic.Heron on 2013-04-17 11:33
Hi Adam,
Thanks for getting back to me so quickly. I downloaded the Plus 1.8 from:
https://www.assembla.com/spaces/milestones/completed/plus?milestone_sort_id=DESC
#### By Adam Rankin on 2013-04-17 11:48
No problem, I'm downloading it now.

One thing to correct is that in the configuration file you wish to use, you must assign a valid IP address for the Sonix device. If it is running on the same machine, simply set IP="-1" to IP="127.0.0.1"
#### By Nic.Heron on 2013-04-17 11:51
OK thanks. I had it set before to the actual IP address but still it would fail to connect. I am changing it now to 127.0.0.1
PlusConfiguration_SonixTablet_Ascension3DG_L14_fCal2.0.xml	6.03 KB
#### By Adam Rankin on 2013-04-17 11:56
Hi Nic,

Sure enough, the 1.8 build does not have Sonix enabled. I will re-do a build and ensure that it works.

Adam
#### By Nic.Heron on 2013-04-17 11:56
Here is the error I'm getting: "Unknown video source type: SonicVideo"
fCal-error-videosource.jpg	47.8 KB
#### By Nic.Heron on 2013-04-17 12:01
OK. How will I get the new build? Will you send me a link?

Thx
Nic
#### By Adam Rankin on 2013-04-17 12:20
I will overwrite the existing build in the 1.8 milestone. You can download it from the same spot after I upload a new build.
#### By Nic.Heron on 2013-04-17 12:23
ok thanks. When do you think it will be ready?
#### By Adam Rankin on 2013-04-17 12:35
Build is about 3/4 done. After that I'll run it just to make sure I can connect to the Sonix. Approx 1 hour.
#### By Adam Rankin on 2013-04-17 12:35
Oh, and if you know the IP of your Sonix system, set it to that!
#### By Nic.Heron on 2013-04-17 12:42
Do you mean it is better to use the actual local IP than 127.0.0.1?

Also, how will fCal know where to find the porta SDK DLLs?

Thanks
Nic
#### By Andras Lasso on 2013-04-17 13:02
Using 127.0.0.1 or the actual IP is equivalent. We mostly use the Ulterius SDK as we usually need image acquisition only. Do you need to use the Porta SDK?
#### By Nic.Heron on 2013-04-17 13:04
no Ulterius is fine too. I'm just wondering how does fCal.exe know where to find the Ulterius SDK?

Thx
Nic
#### By Nic.Heron on 2013-04-17 13:04
and which version of Ulterius SDK does Plus 1.8.0 support?
#### By Adam Rankin on 2013-04-17 13:13
We build against 5.7.1
#### By Nic.Heron on 2013-04-17 13:17
ok. Do you embed the Ulterius DLLs in the Plus installation or do I have to indicate a path to Ulterius in a configuration file somehow?

N
#### By Adam Rankin on 2013-04-17 13:19
I believe it is embedded. One second, I'll verify.
#### By Andras Lasso on 2013-04-17 13:21
All the necessary dlls are in the package.

Ultrasonix messed up their 6.x SDK: they supplied custom ITK, VTK, and QT dlls with their SDK, which of course does not work with any applications that use ITK, VTK, or QT. So, Plus can be linked to SDK up to 5.x. Fortunately, 5.x SDK can communicate with 6.x exam software through Ulterius.
#### By Nic.Heron on 2013-04-17 13:39
OK. So in order to use fCal.exe for calibration of my probe and stylus, I don't need anything other than the DLLs and Exe that come with the Plus package, right?
#### By Adam Rankin on 2013-04-17 13:53
Ok, Plus 1.8 has been rebuilt. Try re-downloading and trying again.

Yes, you can simply launch fCal and connect to the Sonix.
#### By Nic.Heron on 2013-04-17 13:56
1.8.0.2709.zip from https://www.assembla.com/spaces/milestones/completed/plus?milestone_sort_id=DESC, right?
#### By Nic.Heron on 2013-04-17 14:04
I get the following error when running fCal.exe: QtOpenGld4.dll is missing
Is this a debug build?...
#### By Adam Rankin on 2013-04-17 14:10
No, I had debug Qt built on my system. Sorry, doing another build.
#### By Nic.Heron on 2013-04-17 14:11
ok thank you :)
#### By Nic.Heron on 2013-04-17 14:18
While this is rebuilding, I have another question: can I use any ultrasound probe (as long as it works on the SonixTablet) with fCal?
#### By Adam Rankin on 2013-04-17 14:20
Yes! This is the great part about PLUS. It can handle any supported image source in conjunction with any tracker.

You will probably have to create your own config file, but there are lots of examples and I can help you with that.
#### By Nic.Heron on 2013-04-17 14:20
or would I need to create a custom stl file for the probe?
#### By Nic.Heron on 2013-04-17 14:20
great!!
#### By Adam Rankin on 2013-04-17 14:22
The .stl file is only for visualization in fCal. It's just a 3d model to give you a better sense of where your probe is. You can use the existing stl as it should be close enough to be clear.

You can use any .stl you want though, even that of a spaceship.
#### By Nic.Heron on 2013-04-17 14:28
:-)
#### By Adam Rankin on 2013-04-17 15:40
Ok, try again. Sorry about that.
#### By Nic.Heron on 2013-04-17 15:42
downloading...
#### By Nic.Heron on 2013-04-17 16:23
hmmm, I still get (after a while) this error: "Failed to connect to sonix video device..." see attached screen capture and log file.
sonixvideodeviceerror.jpg	207 KB
041713_161748_PlusLog-Copy.txt	3.5 KB
#### By Nic.Heron on 2013-04-17 16:24
Do I need to be running the Sonix Exam software? I tried both with and without it and still won't get past the error above.
#### By Nic.Heron on 2013-04-17 16:24
note: I am running Exam 6.0.3
#### By Adam Rankin on 2013-04-17 16:27
The exam software needs to be running.

Andras noted:
"Ulterius in the 5.7.x SDK is compatible with Exam software with client version up to 6.0.2. Exam software that are 6.0.3 or newer will not work with clients that are built with 5.7.x SDK."

It looks like you'll have to use exam software 6.0.2 or earlier.
#### By Nic.Heron on 2013-04-17 16:29
ok I'll try that. Thank you
#### By Nic.Heron on 2013-04-17 16:50
looks better! I'm able to connect but...I see these errors:

041713_163908.358|WARNING|027.063000| File not defined for Model. No visualization will occur until data is defined.|in ..\..\PlusApp\CommonWidgets\vtkDisplayableObject.cxx(467)
041713_163908.871|INFO|027.576000| Application configuration file 'C:/Workspace/PlusApp_1.8.0/bin/PlusConfig.xml' saved
041713_163946.904|ERROR|065.608000| Render window unavailable when trying to render 2D image.|in ..\..\PlusApp\CommonWidgets\vtkImageVisualizer.cxx(291)
fcal-log.txt	1.57 KB
#### By Nic.Heron on 2013-04-17 16:52
note: I'm now running with Exam 6.0.1
#### By Csaba Pinter on 2013-04-17 17:30
Don't forget to set the exam software to research mode.
#### By Nic.Heron on 2013-04-17 17:32
I get a stylus calibration precision of only 2 mm. Any suggestion to get a more accurate calibration?

thanks
nick
#### By Nic.Heron on 2013-04-17 17:33
yes, Exam is in research mode. thx
#### By Andras Lasso on 2013-04-17 17:39
>I get a stylus calibration precision of only 2 mm.
2mm seems high. In general the displayed error of the stylus calibration is between 0.5-1.0mm.
What tracker do you use? Can you describe your stylus (material, tip construction, distance of the sensor from the tooltip)?
#### By Andras Lasso on 2013-04-17 17:45
See System_calibration page, section "I get large (>1mm) stylus calibration error - what's wrong?" for some tips on how to improve stylus calibration results.
#### By Nic.Heron on 2013-04-17 22:38
Hi,
Is there a preferred material I should use with 3D printer to print the calibration phantom?
Is there a way to calibrate the probe manually without a calibration phantom using fCal and a needle tip in a water tank?

Thanks!
Nick
#### By Nic.Heron on 2013-04-18 10:19
Which phantom should I use, the FCal_1.2 or fCal_2.0 with Plus 1.8.0 ?
thx
nick
#### By Adam Rankin on 2013-04-18 10:21
I do not have much experience with the fCal 1.2, but I know the fCal 2.0 gives good results.

I'd say go with 2.0
#### By Andras Lasso on 2013-04-18 10:23
Which phantom: click on "How to build an fCal calibration phantom" on the System_calibration page
#### By Csaba Pinter on 2013-04-18 10:24
The choice of phantom is almost independent of the Plus version.
I recommend using fCal 2.0 as there were many important enhancements from 1.2. It is easier to wire correctly, and supports deeper wire patterns, more suitable for the 3 layer N-wire pattern, which is way superior to the 2 layer one in terms of calibration accuracy.
#### By Nic.Heron on 2013-04-18 10:31
thank you all. Since I'm really new to this, which material should be used for the 3D printing of the phantom?
#### By Andras Lasso on 2013-04-18 10:46
Use plastic. If the printing shop have options for different plastics then choose dense.
You can also calibrate using by only a calibrated stylus: the procedure is more complex and operator-dependent, described at https://github.com/SlicerIGT/SlicerIGT/wiki/Ultrasound-image-to-probe-calibration.
#### By Nic.Heron on 2013-04-18 13:39
Thanks Andras! I've followed the instructions on the link you've provided and got stuck at the point where I have to select the 'Volume Reslicing Driver' menu from the IGT menu in 3D slicer. I don't have this menu. The only menu under the IGT menu is OpenIGTLinkIF... What am I missing?
Thx
#### By Adam Rankin on 2013-04-18 14:39
This isn't my area of expertise, but have you installed the SlicerIGT extension?
#### By Nic.Heron on 2013-04-18 15:09
no but I can't find any information about how to add that extension... :(
#### By Adam Rankin on 2013-04-18 15:12
https://www.google.ca/search?q=install+slicerigt&ie=utf-8&oe=utf-8&aq=t&rls=org.mozilla:en-US:official&client=firefox-a

First hit is the SlicerIGT page which shows how to install it!
#### By Nic.Heron on 2013-04-18 15:16
thanks!
#### By Nic.Heron on 2013-04-18 15:21
that's what I had done...but this does not make the reslice driver menu visible somehow...
#### By Csaba Pinter on 2013-04-18 15:29
This is the list of modules in SlicerIGT:
https://github.com/SlicerIGT/SlicerIGT/wiki/List-of-Modules

If you need the volume reslice driver, then you should install that extension (http://snag.gy/YBRNT.jpg)

@ungi: Please confirm
#### By Nic.Heron on 2013-04-18 15:35
I have installed the Reslice driver extension, but the module is nowhere to be found even after I've restarted slicer.

The extension manager shows that Reslice Driver is installed though. So my question is: how do I get to the reslice driver module once it's installed, because it does not show up in the list of modules...

thx
#### By Nic.Heron on 2013-04-18 15:44
got it! even after reslice driver extension is added, you still have to customize slicer and add the path to the reslice driver modules in the custom module path... :-)
#### By Csaba Pinter on 2013-04-18 15:49
Strange, it should not be the case. The module should be there without this tinkering. Do you work with a built Slicer or an installed one? In either case which revision/nightly/stable?
#### By Nic.Heron on 2013-04-18 16:24
I am working with installed slicer: 4.2.2-1 r21513
#### By Nic.Heron on 2013-04-18 16:26
I am now running into another issue, this time with Plus-server.

at some point I get the following error on the server console: "failed to get oldest timestamp from buffer!"

I am attaching a screen capture.
Plus-server-error.jpg	40.6 KB
#### By Nic.Heron on 2013-04-18 16:50
@pinter: it looks like I also need the CollectFiducials module and that one is not listed in the extension manager... Any suggestion?

Thx
nick
#### By Csaba Pinter on 2013-04-18 17:05
Nick, unfortunately I don't know much about the IGT stuff, the best I can do is to google or to look in the existing documentation (slicerigt.org, its github page, slicer extension pages (http://www.slicer.org/slicerWiki/index.php/Documentation/Nightly#Cat_2) etc.)
Tamas (who is the owner of SlicerIGT) is on vacation starting today, so he cannot help.
If you cannot find the information doing the stuff I would do, then please wait until someone who actually knows these things has an answer for you (@lassoan maybe).
#### By Andras Lasso on 2013-04-18 17:14
VolumeResliceDriver and CollectFiduciuals modules are all part of the SlicerIGT extension. Install the latest 64-bit nightly build of Slicer, then install the SlicerIGT extension. After restarting Slicer all the module shall appear. No need for manual editing of module paths. The separate VolumeResliceDriver extension is obsolete, don't use that.
#### By Nic.Heron on 2013-04-18 20:10
Thanks Andras. I installed the latest 64-bit nightly build and sure enough, VolumeResliceDriver and CollectFiducials are there with the SlicerIGT extension. :-) Thank you!
nick
#### By Nic.Heron on 2013-04-18 20:47
now that I have PlusServer working with the Exam software, I would like to run it with the Porta SDK: I have a custom ultrasound application that uses the Porta SDK to produce ultrasound images and would like to know if I can use fCal with those images.
When I run fCal with a config file that has SonixPortaVideo it crashes...
I have attached the config file. The only difference between that file and the file that works with Exam is the ImageAcquisition type.
Thank you
n
PlusConfiguration_SonixTablet-3_Ascension3DG_L14_fCal2.0.xml	2.52 KB
#### By Andras Lasso on 2013-05-04 11:02
Sorry, for the late ansert, I haven't seen this question. Porta SDK version has to match exactly with the installed Ultrasonix software package. If it still does not work then most likely there is an error in the Porta SDK. I've entered a ticket to track this issue: #751. If you are ready to help us with some debugging and testing then let us know and we can work on this.
#### By Nic.Heron on 2013-05-08 12:28
Hi,
I've changed systems and on the new system I get an error when I go to the stylus configuration step. The start button is grayed out and the log shows:
050813_121858.670|ERROR|025.670000| Unable to find fCal element in XML tree!|in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(401)
050813_121858.690|ERROR|025.690000| Failed to read fCal configuration|in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(197)
050813_121858.703|ERROR|025.704000| Unable to find Rendering element in XML tree!|in ..\..\PlusApp\CommonWidgets\vtk3DObjectVisualizer.cxx(406)
050813_121858.710|ERROR|025.710000| Unable to configure perspective visualizer.|in ..\..\PlusApp\CommonWidgets\vtkVisualizationController.cxx(718)
050813_121907.686|ERROR|034.686000| Unable to find vtkPivotCalibrationAlgo element in XML tree!|in ..\..\..\PlusLib\src\CalibrationAlgo\vtkPivotCalibrationAlgo.cxx(290)
050813_121907.694|ERROR|034.694000| Reading pivot calibration algorithm configuration failed!|in ..\..\PlusApp\fCal\Toolboxes\StylusCalibrationToolbox.cxx(91)
050813_121907.707|ERROR|034.708000| Render window unavailable when trying to render 2D image.|in ..\..\PlusApp\CommonWidgets\vtkImageVisualizer.cxx(291)

Am I missing a library?

Thanks,
nic
#### By Andras Lasso on 2013-05-08 12:55
As you can see in the error log some required elements are missing from your config file. Please attach your config file.
#### By Nic.Heron on 2013-05-08 13:38
Thanks Andras, that was it!
Nic


## PLUSServer
#### Posted by Samira Sojoudi on 2013-04-12 20:14

Hello,

I tried to run latest version of Plusserver. I built the latest version of PLUS and changed my config files based on devices. When I run the Plusserver I am getting some errors, I attached a snapshot of the errors and my config file. I think I have something wrong in the config file. Can you please advise me on this?

Thanks,
Samira
plusserver.jpg	234 KB
C52_Calibration_7cm.xml	9.95 KB

#### 41 Comments
#### By Tamas Ungi on 2013-04-17 22:02
What I don't understand is why do you have the whole "OpenIGTLinkVideoSenderDevice" part in your config file?
PlusOpenIGTLinkServer already sends the images and the transforms to Slicers. Having OpenIGTLinkVideoSender is probably a misunderstanding, and you should delete it.
#### By Adam Rankin on 2013-04-17 22:21
Yes, the type "OpenIGTLinkVideo" is for receiving OpenIGT images.

It is not needed for sending images.
#### By Adam Rankin on 2013-04-17 22:32
If you are building the latest SVN of PLUS, you may remove OutputDeviceId from the PlusOpenIGTLinkServer tag.

The UsImageOrientation="UF" should be moved to the DataSource with Id="Video" tag and renamed to PortUsImageOrientation="UF"
#### By Andras Lasso on 2013-04-18 12:46
The "OpenIGTLinkVideoSenderDevice" device ID might have confused Tamas.

@rankin: Is there a reason for using "OpenIGTLinkVideoSenderDevice" as device ID instead of something like "OpenIGTLinkVideo" (as everywhere else) or maybe "OpenIGTLinkVideoReceiverDevice"?
#### By Adam Rankin on 2013-04-18 12:58
@lassoan No reason. Can be anything.
#### By Andras Lasso on 2013-04-18 13:27
I've checked the PlusConfiguration_OpenIGTLinkTest.xml config file again and actually everything is explained in a comment: <PlusServerTestClientsConfiguration>... <!-- This configuration section is used during PlusServer testing to configure OpenIGTLink clients -->

So, answering Tamas' question "What I don't understand is why do you have the whole "OpenIGTLinkVideoSenderDevice" part in your config file?": that section is for testing only, it used for setting up test clients that connect to the server during automatic testing.
#### By Samira Sojoudi on 2013-04-18 13:37
Thanks guys, I deleted "OpenIGTLinkVideoSenderDevice", removed OutputDeviceId from the PlusOpenIGTLinkServer tag and added PortUsImageOrientation = "UF" so, I don’t get the error any more. But in the slicer side I don’t see any image or transform. The OpenIGTLink is changing from “Wait” to “ON” but no image is coming.
I have these Devices in my config file: TrackerDevice, TrackedVideoDevice is it ok? do I need "CaptureDevice"?
I attached the latest config file.
C52_Calibration_7cm.xml	8.66 KB
#### By Tamas Ungi on 2013-04-18 23:57
Samira, have you checked in the data module of Slicer that there are really no new MRML nodes appearing in Slicer when it connects to PlusServer? Maybe the transforms and images are there, you just don't see them?
#### By Andras Lasso on 2013-04-19 00:26
The problem is that in the config file you haven't specified any input channels for the VirtualMixer device, so of course the device doesn't produce any output. Replace the current VirtualMixer device element with the one that you can find in the PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal2.0.xml example.

It is also recommended to specify the OutputChannelId="TrackedVideoStream" attribute in the PlusOpenIGTLinkServer element to indicate that the server should send out the tracked image data.

If you still have problems then run PlusServer with --verbose=4 and attach the created log file so that we can see what happens.
#### By Samira Sojoudi on 2013-04-19 16:00
Thanks, the problem is resolved. I added the input channels for the VirtualMixer device and OutputChannelId="TrackedVideoStream" OutputDeviceId="TrackedVideoDevice" attribute to the PlusOpenIGTLinkServer element. I attached my latest config file as a log.
C52_Calibration_7cm.xml	9.28 KB
#### By Andras Lasso on 2013-04-19 16:01
Great, thanks for the feedback.
#### By Samira Sojoudi on 2013-04-19 16:12
Andras, one more question. do I need to add any node to the config file when I want to use OpenIGTLinkRemote module in the slicer. do you have any advice on this?
#### By Andras Lasso on 2013-04-19 16:19
You just need to set up the OpenIGTLink connector node as usual then communicate by using the remote control module.
#### By Samira Sojoudi on 2013-04-19 16:25
When I am sending commands like START_ACQUISITION, START_RECONSTRUCTION I am getting this error : Failed to create command from string:...
#### By Tamas Ungi on 2013-04-19 17:21
Are you sending full XML strings? See examples here: https://github.com/SlicerIGT/OpenIGTLinkRemote/wiki/How-to-use-OpenIGTLinkRemote
There are no pre-written XML messages in OpenIGTLinkRemote. As it is supposed to be used by other modules through its logic, without opening the OpenIGTLinkRemote GUI. So your module is responsible for generating full XML syntax strings. The GUI is mainly for experimenting/testing.
#### By Samira Sojoudi on 2013-04-19 17:35
Thanks, Tamas. I didn't know that I have to send XML strings.it worked. Where can I find the examples on other commands?
#### By Andras Lasso on 2013-04-19 17:41
I've just fixed some issues with the volume reconstruction command. Update and build PlusLib.
See examples here: https://www.assembla.com/spaces/plus/wiki/PlusServer_commands
#### By Samira Sojoudi on 2013-04-19 17:45
Sure, Thanks Andras.
#### By Samira Sojoudi on 2013-04-19 19:10
Andras, I built the latest version of PLUS and when I am running plusserver it crashes. here is the snapshot of the error and my config file!
PlusserverError.JPG	62.6 KB
C52_Calibration_7cm.xml	9.24 KB
#### By Samira Sojoudi on 2013-04-22 17:31
Hi guys,
Any suggestion?
#### By Adam Rankin on 2013-04-22 17:36
Investigating.
#### By Andras Lasso on 2013-04-22 17:37
Set the verbose level to 5 and attach the log that is generated in the output folder. Thanks!
#### By Adam Rankin on 2013-04-22 17:39
GetVideoSourceByPortName crash. I'll fix it.
#### By Samira Sojoudi on 2013-04-22 17:42
I set the verbose level to 4 and added the image, but unfortunately we have a problem on our sonix touch machine so, I can't run it right now. I'll put the image as soon as I can.

Thanks,
#### By Samira Sojoudi on 2013-04-22 17:43
Thanks Adam, I'll give it a try.
#### By Adam Rankin on 2013-04-22 17:43
Should be fixed with ticket #740. If you are able to continue working, please mark the ticket as fixed.

Thanks,
Adam
#### By Andras Lasso on 2013-04-22 17:58
We had to change the config file structure in the trunk to allow simultaneous B-mode/RF-mode acquisition. The problem was that you attempted to connect with the old config file structure and PlusServer was not prepared for that.

Have a look at a current config file example, e.g., PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal1.1.xml for how a SonixVideo device should be specified now.
#### By Samira Sojoudi on 2013-04-22 18:52
Thanks, it worked.
#### By Samira Sojoudi on 2013-04-23 18:45
Hello :)
I need some more help, I attached two snapshot of what happened when I tried to send these command through Slicer (OpenIGTLinkRemote module) while the plusserver was running on the ultrasound machine :
1- <Command Name="StartRecording" OutputFilename="PlusServerRecording.mha"></Command> (the output file contains some header data with size 1k)

2- <Command Name="StartVolumeReconstruction" Id="101" InputSeqFilename="PlusServerRecording.mha" OutputVolFilename="PlusServerRecording.vtk" OutputVolDeviceName="recvol_reference" TrackedVideoDeviceId="TrackedVideoDevice"></Command>

do I need to add any node or attribute to my config file?
PlusserverError-volume-reconstruction.JPG	347 KB
PlusserverError-recording.JPG	316 KB
#### By Samira Sojoudi on 2013-04-24 15:40
Apparently, we need to add these attributes to VolumeReconstruction node, which we didn't have before:
ImageCoordinateFrame, ReferenceCoordinateFrame, OutputExtent , FanAngle, FanOrigin, FanDepth
#### By Andras Lasso on 2013-04-24 16:24
ImageCoordinateFrame, ReferenceCoordinateFrame: these parameters were always required. If you use the command-line volume reconstructor then you can choose to specify them in the config file or through command-line parameters.

OutputExtent: if you do batch-mode volume reconstruction then the extent can be computed from the list of frames (this was done by default if you didn't specify this parameter in the config file and used the command-line volume reconstructor). You can do a scout scan and reconstruct it in batch mode (with the ReconstructVolume command) or in live mode (with a large, low-resolution volume around the reference sensor, e.g., +/-500mm range, 10mm spacing) and get the extent from that. What may missing is that currently you cannot specify the extent as a command parameter, but you can easily add this (let me know if you need any help).

FanAngle, FanOrigin, FanDepth: are all optional parameters but recommended to set for curvilinear probes
#### By Samira Sojoudi on 2013-04-24 17:36
Actually I am using the plusserver + OPenIGTLink remote module in slicer, so I am not calling the volume reconstruction, the module do it. but when I didn't have the OutputExtent in the config file I was getting errors as I attached the snapshot before. Now I have the volume in the slicer but it's just a black frame. do you have any idea? my work flew is as below:

1- running the plusserver
2- starting the OpenIGTLink module
3- sending the start volume reconstruction command
4- sending the get snapshot command
5- sending stop reconstruction command
#### By Andras Lasso on 2013-04-24 17:50
As I wrote OutputExtent is not required if you do the reconstruction in batch mode ("ReconstructVolume" command). The server doesn't know what will be the total extent before receiving all the frames, so for continuous reconstruction (using the StartVolumeReconstruction/StopVolumeReconstruction commands) you need to pre-define the extent.

Empty volume: Make sure the slice viewer is aligned with the volume (click on the "Adjust slice viewer's field of view..." icon on the slice viewer). If the volume is really empty (you can double-check that in the Volumes module: the min/max of the scalar range should not be 0.00/0.00) then most likely the OutputExtent is not set properly. Do a batch-mode reconstruction to find out the extent automatically.
#### By Samira Sojoudi on 2013-04-24 19:09
Andras, Is it needed to set the OutputOrigin as well?
#### By Samira Sojoudi on 2013-04-24 19:22
The volume has dimension, spacing and origin but scalar range (min and max) is 0.00!
#### By Andras Lasso on 2013-04-24 20:31
The output origin has to be set as well. Do a batch mode reconstruction first (start and stop acq then reconstruct) and see if that works as expected. Then use the same origin, extent, and spacing for the continuous reconstruction.
#### By Samira Sojoudi on 2013-05-03 14:28
Hello!
I still have problem in continues reconstructing volume. what is your exam software version? is it 6.0.1?
#### By Andras Lasso on 2013-05-03 16:26
I've tested the example commands at PlusServer_commands and they worked after some minor changes (that I've committed to the trunk, see #749).
Please try if the commands work for you in simulation mode (Server setup, Example: volume reconstruction in batch mode, Example: live volume reconstruction with intermediate snapshots). If they do, then replace the simulated inputs with hardwar input devices and see if it works.
#### By Samira Sojoudi on 2013-05-03 17:17
Thanks Andras,
Do I need to build new PLUS with 6.0.1 Ultrasonix sdk?
#### By Andras Lasso on 2013-05-03 18:25
You don't need to build with ultrasonix support to test the remote controlling with simulated device as described in the examples.
#### By Samira Sojoudi on 2013-05-07 19:08
Andras, I updated the PLUS source and built it again. But when I want to run Plusserver or PlusserverRemote I am getting a Qt error, however all Qt paths are correct in the Cmake. it is looking for QtCore4.dll and can't find it.
pserver.png	19.7 KB


## To siavashk from Nic Heron
#### Posted by nic.heron on 2013-04-29 16:09

Hi Siavash,

We met at UBC on Friday with Bo. You helped us with the calibration of our probe.
I have a few questions for you about the "Image" To="Probe" matrices we obtained with fCal.

Let’s call S the probe sensor and (sx, sy, sz) its coordinates in the transmitter system (as provided by the ascension API) and u, v, w the sensor’s 3 orthogonal vectors.

T is the center of the transducer.

We need the coordinates of T in the transmitter system and its rotation matrix that defines the relationship between the transducer’s 3 orthogonal vectors and the transmitter’s vectors.

Let’s call M1 is the rotation matrix (3x3) of S as provided by the ascension API and M2 rotation part (3x3) of the “Image to Probe” matrix that we got from fCal.
M1 defines the relationship between vectors u, v, w and the transmitter’s vectors.

Finally Tu, Tv, Tw (as I understand it) is the translation defining T as a function of the sensor’s 3 vectors and is the last column of the “Image to Probe” matrix (which I’ve removed from M2 so that M2 is a 3x3 rotation only matrix just like M1).

Question1: is the rotation we’re looking for the product of M1 * M2 ?
Question 2: are the coordinates of T: M1 * (Tu, Tv, Tw)?

The results I’m getting when I do the above computations don’t make much sense on the screen so I must be missing something in the interpretation of the “Image to Probe” matrix.

Also, the 3 sets of values we got for the last column of the “Image to Probe” matrix (Tu, Tv, Tw) are:
7.9221
38.5849
-44.3739

11.0082
36.7215
-45.26

12.6945
39.6558
-46.9818

what are the units? I assume it's millimeter, but that does not make any sense as I know that our 3D sensor's distance from the center transducer is about 15 mm and the 3 sets of translation vectors above give respectively distances of 59.33, 59.31, and 62.77 which (if they are in mm) are completely off.

Can you help me understand what I am missing?

Thanks a lot!
Nic





Thanks!
nic

#### 11 Comments
#### By Nic.Heron on 2013-04-29 17:26
PS: it would be really cool if you could get back to me today. :)
#### By Andras Lasso on 2013-04-29 18:44
See the answer on these pages: Coordinate_system_definitions and Transformation_matrix_definition
#### By Thomas Kuiran Chen on 2013-04-29 21:57
Hi Nick,

Your results look reasonable to me (Bo has forwarded me your fCAL output files).

Note Plus outputs the Transform From="Image" To="Probe". The Image coordinate is the Plus' MF image coordinate system (defined in the links Andras pointed out). The probe coordinate system is defined by the sensor (embedded in your transducer).

If you look at your results: <Transform From="Image" To="TransducerOriginPixel", it shows up -410 pixels in Tx translation. Considering a scaling factor of around 0.14 mm/pixel (you can decompose the scale factors from the Transform From="Image" To="Probe"), this translates to about 57 mm from MF image origin to the center of transducer origin. Adding to the distance from the sensor to the center of transducer (15 mm), we are talking about roughly 55-65mm in 3D, which seems about right.

Subsequently, when you want to use the fCAL calibration matrix, you also need to first convert your own image coordinate system (user defined) to the Plus Image coordinating system using the matrix: <Transform From="Image" To="TransducerOriginPixel". You need to apply an inverse of the original matrix to get the pixel coordinates from the transducer space to Plus Image space.

I have passed the details to Bo, and he will contact you tonight or tomorrow.

Thomas Chen
Ultrasonix Medical at Analogic Ultrasound Group
#### By Siavash Khallaghi on 2013-04-30 01:21
Hi Nic,

I am sorry, I received the call from Bo and I explained the 410 pixel offset to him on the phone and I didn't check Plus messages until now. I see that Thomas has made an excellent explanation of the issue and you are in trusting hands. I will follow this thread more closely and I will try to contribute if I can. :)

Best of luck

Siavash
#### By Nic.Heron on 2013-04-30 09:01
Thanks Thomas
i understand there is a scale factor embedded in the fcal rotation matrix (image to probe).
how do I remove it? I'm interested in the rotation matrix that gives the 3 orthonormal vectors at the center of the transducer as functions of the sensor's 3 orthonormal vectors.
thank you
nic
#### By Andras Lasso on 2013-04-30 09:29
Use svd as in vtkProbeCalibrationOptimizerAlgo.cxx
#### By Thomas Kuiran Chen on 2013-04-30 12:54
Hi Nic,

The decomposition of the fCAL transformation matrix is straightforward (you can do it in either C/C++ or Matlab with a couple of lines of codes). The underneath mathematics is here (a truncated section from my past thesis):

https://dl.dropboxusercontent.com/u/5522174/TKChenPublicSite/ThomasChen_fCALMatrixDecomposition.pdf

Bo has my Matlab implementation of this.

Hope it helps,

Thomas
#### By Nic.Heron on 2013-04-30 12:57
Thanks Thomas!
#### By Thomas Kuiran Chen on 2013-04-30 13:44
Hi Andras,

Do you think it may be a good idea if we add two extra matrices into fCAL calibration results (Image to Probe): a normalized rotation/ translation 4x4 matrix and a scaling 4x4 matrix?

To some OEM customers that I recommended to use Plus, they sometimes ran into a similar situation as Nic did where the user needs to adjust zoom and imaging depth during operation. This would effectively change the scaling factors, while the rotation transform remains intact. With the two separated, the user can simply compute and update the scaling matrix and use the same rotation matrix without the need for a recalibration.

The user may of course do the decomposition themselves as outlined in the above, but many of them do not feel comfortable doing so.

Thanks,

Thomas
#### By Andras Lasso on 2013-04-30 14:27
If there is a point in the Probe coordinate system that always appear in the same position in the Image coordinate system (let's call it TransducerReferencePoint) then I agree that it can be useful to provide a TransducerReferenceToProbe transform (getting rotation, scaling, translation from the 4x4 matrix of the TransducerReferenceToProbe transform is trivial). The TransducerReferencePoint can be computed from calibration at two different depths (and if you do calibration at multiple depths then you can verify that actually there is a point that remains fixed at all depth settings. Probably this TransducerReferencePoint position can be computed as simply as mulitplying ImageAtDepthAToProbe by ImageAtDepthBToProbe and take the translation part. Then create an ImageAtDepthAToTransducerReference transform just by constructing a translation from the TransducerReferencePoint. I added a ticket to track this (#746), but have other priorities till mid next week, so the best would be if you could contribute.

Note that such a fixed TransducerReferencePoint may or may not exist. The image may be arbitrarily moved around when the imaging depth is changed (especially when you acquire the image through a framegrabber), so we recommend calibration at each imaging depth and use the multi-channel architecture of Plus to attach the appropriate calibration matrix at each imaging depth. We'll provide a sample for such a setup soon (see #582 and #651).
#### By Thomas Kuiran Chen on 2013-04-30 15:16
From the feedback we gathered in OEM customers, they simply want a breakdown of the "Transform Image to Probe" into rotation, scaling and translation (in addition to the original Image to Probe matrix), in the XML file. Something like:

Transform From="Image" To="Probe" - Rotation
Transform From="Image" To="Probe" - Scaling
Transform From="Image" To="Probe" - Translation

Thanks,

Thomas


## OpenIGTLinkRemote module and Plus
#### Posted by GuillermoCarbajal on 2013-04-12 18:42

Hi,
I would like to run fCal and also make a volume reconstruction from 3D Slicer.
I think that OpenIGTLinkRemote module is useful for that purpose.
Could you please tell me where can I find an example?
Many thanks,
Guillermo

#### 2 Comments
#### By Andras Lasso on 2013-04-13 10:45
For now the only example is PlusServerRemoteControl. Start PlusServer with the PlusConfiguration_OpenIGTLinkCommandsTest.xml and send commands to it by using the PlusServerRemoteControl. You can see the generated XML commands in the log. You can send the same commands using the OpenIGTLinkRemote client. I plan to do some testing of this mechanism early next week and after that I will describe some examples.
#### By Andras Lasso on 2013-04-20 10:54
See examples here:
PlusServer_commands


## Notice: Plus configuration file changes
#### Posted by Adam Rankin on 2013-04-16 20:42

Recent changes in the configuration structure have occurred.

Most importantly:
When defining a video data source, you must include the PortUsImageOrientation attribute. This is the orientation that the device is outputting data in. It is a descendent of the DeviceImageOrientation attribute of the old ImageAcquisition tag.

The Sonix device now supports dual mode acquisition. You must define a data source for each mode you want. Each data source must have the PortName attribute defined to either "B" or "Rf". The PortUsImageOrientation must also be defined.

The RegionOfInterest attribute from the Segmentation tag has been removed. It is replaced with ClipRectangleOrigin and ClipRectangleSize.

#### 0 Comments


## Relaxing the tolerance requirement for rotation orthogonality in ITK
#### Posted by Siavash Khallaghi on 2013-04-09 17:42

Hello,

Setting a rotation matrix, for example something like this:

Seq_Frame0000_CommonReferenceToVisualizationTransform = 0.998525 0.000893046 -0.0542859 -192.256 -0.00433848 0.99798 -0.0633837 -122.362 0.0541196 0.0635257 0.996512 -232.984 0 0 0 1

into an itk::Euler3DTransform
typedef itk::Euler3DTransform< double > EulerTransformType;
EulerTransformType::Pointer eulerTransform;
EulerTransformType::ParametersType _parameters( eulerTransform->GetNumberOfParameters() );

_parameters.fill( 0.0 );

eulerTransform->SetParameters( _parameters );
eulerTransform->SetRoatationMatrix( _matrix ); //_matrix is the rotation component of the above defined transformation

throws the following exception: "Attempting to set a non-orthogonal rotation matrix" in line 96 of ITKRigid3DTransform.txx (ITK-3.20).

I was able to work around this buy relaxing the orthogonality tolerance from 1e-10 to 1e-5. This doesn't feel like the right way though, do you guys have a better solution?

#### 1 Comments
#### By Andras Lasso on 2013-04-10 14:29
I would not recommend to change the orthogonality tolerance, but instead the problem should be fixed in the transformation computation.

Plus now contains an additional optimization step that guarantees strictly orthogonal ImageToProbe calibration matrix result. The method finds the orthogonal transform that leads to the smallest reprojection error, so it's better than a simple orthogonalization of the matrix with SVD. Details of the method are described in a CARS paper, which will be published soon.

To activate this method just specify OptimizationMethod="2D" in vtkProbeCalibrationAlgo. You can also constrain the ImageToProbe matrix to have isotropic pixel spacing (good idea if you use a curvilinear transducer) by specifying IsotropicPixelSpacing="TRUE".

Example:
~~~~
<vtkProbeCalibrationAlgo
ImageCoordinateFrame="Image"
ProbeCoordinateFrame="Probe"
PhantomCoordinateFrame="Phantom"
ReferenceCoordinateFrame="Reference"
OptimizationMethod="2D"
IsotropicPixelSpacing="TRUE"/>
~~~~


## How to use PLUS with BK Medical via OEM interface
#### Posted by ben.xkang on 2013-04-08 21:54

Hi All,

We are using the BK Medical flex Focus 700 and are streaming ultrasound images through the BK Ethernet OEM interface. Since PLUS does support the OEM interface, it seems that we have to modify the source code and use our data acquisition code to obtain ultrasound image from the machine. Could you kindly tell me where is the proper and efficient start point to do this?

Looking forwards to your invaluable suggestions!

Best,
Ben

#### 1 Comments
#### By Andras Lasso on 2013-04-08 23:13
Hi Ben,

There is a video source for acquiring US images from BK through the OEM interface, it's a work in progress, first tests showed some errors, see details in #542. To try it:
check out PLTools to get BK's SDK: GrabbieLib (in the same directory where you have the PlusBuild subdirectory)
build Plus with the PLUS_USE_BKPROFOCUS_VIDEO option enabled in CMake
connect using the vtkBkProFocusOemVideoSourceTest.exe test application or using fCal (with the PlusConfiguration_BkProFocusOem_TrackingNone.xml config file)

Please add your findings (worked/not worked) to #542.

Thanks!


## How to compute pivot calibration offline
#### Posted by Tamas Ungi on 2013-04-02 22:51

I have a recorded tracker data (recorded using fCal, data in .mha format) when the stylus was doing a pivoting motion. I would like to compute the StylusTipToStylus transform using the pivot calibration algorithm. Is there a way to do it without running fCal?
If not, how to load my data into fCal? I tried by creating the attached config file, but fCal crashes on Connect. I attach the debug level log file of the crash. My input file doesn't have image data. It starts like this:

ObjectType = Image
NDims = 3
AnatomicalOrientation = RAI
BinaryData = True
BinaryDataByteOrderMSB = False
CenterOfRotation = 0 0 0
CompressedData = False
DimSize = 0 0 328
ElementSpacing = 1 1 1
ElementType = MET_UCHAR
Offset = 0 0 0
TransformMatrix = 1 0 0 0 1 0 0 0 1
UltrasoundImageOrientation = XX
UltrasoundImageType = XX
Seq_Frame0000_ReferenceToTrackerTransform = -0.862104 -0.131301 0.489425 -211.82 0.0194471 -0.973708 -0.226968 25.17 0.506359 -0.186152 0.841991 -1644.33 0 0 0 1
Seq_Frame0000_ReferenceToTrackerTransformStatus = OK
Seq_Frame0000_StylusToTrackerTransform = 0.518008 0.172904 0.837718 -424.89 0.314234 -0.949344 0.0016359 17.07 0.795566 0.262392 -0.5461 -1535.87 0 0 0 1
Seq_Frame0000_StylusToTrackerTransformStatus = OK
Seq_Frame0000_Timestamp = 389.227590
Seq_Frame0000_ToolToTrackerTransform = 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1
Seq_Frame0000_ToolToTrackerTransformStatus = INVALID
Seq_Frame0000_ImageStatus = INVALID
Seq_Frame0001...
PlusConfiguration_File_PivotCal_2.0.xml	6.71 KB
040213_224521_PlusLog.txt	70.8 KB

#### 5 Comments
#### By Tamas Ungi on 2013-04-02 22:55
Actually, the input data (that holds the recorded Stylus motion) is not too big, so I attach that too. Along with the saved config file of the data recording.
Calibration1_config.xml	5.74 KB
Calibration1.mha	199 KB
#### By Andras Lasso on 2013-04-02 23:11
Use the vtkStylusCalibrationTest.exe test application. See the vtkStylusCalibrationTest on the dashboard (http://crunch.cs.queensu.ca/CDash/testDetails.php?test=274969&build=16264) for an example.
#### By Tamas Ungi on 2013-04-03 00:06
Still no luck. I think the problem is not with the PivotCalibrationAlgo. But how to read a file without video data. I cannot start vtkStylusCalibrationTest with this device config:

~~~~
<Device
Id="TrackerDevice"
Type="SavedDataSource"
SequenceMetafile="c:\Users\ungi\Dropbox\Projects\CPR\2013-03-28_Experiment\Calibration1.mha"
AcquisitionRate="50"
LocalTimeOffsetSec="0.0"
Mode="PivotCalibration" >
<DataSources>
<DataSource Type="Tool" Id="Reference" BufferSize="1000" AveragedItemsForFiltering="20" PortName="0" />
<DataSource Type="Tool" Id="Stylus" BufferSize="1000" AveragedItemsForFiltering="20" PortName="1" Model="Example" />
</DataSources>
<OutputChannels>
<OutputChannel Id="TrackerStream">
<DataSource Id="Reference" />
<DataSource Id="Stylus" />
</OutputChannel>
</OutputChannels>
</Device>
~~~~

The error message is:
|ERROR|000.190000| Unable to retrieve the video source in the SavedDataSource de
vice.|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.
cxx(900)
|ERROR|000.194000| Buffer not created for vtkSavedDataSource but it is required.
Check configuration.|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtk
SavedDataSource.cxx(747)
|WARNING|000.223000| Cannot determine image orientation automatically, unknown i
mage type 0, use the same orientation in memory as in the file|in ..\..\..\PlusL
ib\src\PlusCommon\vtkMetaImageSequenceIO.cxx(345)

...and later:
|WARNING|002.548000| There are no valid images in the tracked frame list.|in ..\
..\..\PlusLib\src\PlusCommon\vtkTrackedFrameList.cxx(503)
|ERROR|002.553000| Unable to retrieve the video source in the SavedDataSource de
vice.|in ..\..\..\PlusLib\src\DataCollection\SavedDataSource\vtkSavedDataSource.
cxx(900)

Not even if I add UseData="IMAGE_AND_TRANSFORM" to the config.
According to the wiki, there is no UseData="TRANSFORM" possibility. I tried to set it, but it didn't work.
#### By Andras Lasso on 2013-04-03 01:23
It works correctly if you specify UseData="TRANSFORM". I've made a few changes in the code to get rid of some warnings. See sample config file and more details in #714.
#### By Tamas Ungi on 2013-04-03 10:11
Thank you. It works now.

## How to verification the result of fCal calibration
#### Posted by avicenna2008 on 2013-03-31 23:07

Hi, everyone. I did the calibration by fCal app, I could see the result of stylus calibration and spatial calibration.

My question is : How can I verify the result of calibration? fCal will show an "Error" and model simulation, but I think it need to be verified before the result is used.

Does anyone know any information or idea of this verification method or verification tools ?

thank you

#### 2 Comments
#### By Andras Lasso on 2013-03-31 23:58
fCal computes the calibration data from half of the acquired frames and computes the reprojection error on the other half of the data. This is clearly not a fully independent evaluation of the actual calibration accuracy, but a higher error value typically indicates a calibration problem.

There are a couple of commonly used methods for properly evaluating the calibration result. Read the calibration evaluation sections of these papers for details:
Mercier2005: https://subversion.assembla.com/svn/plus/trunk/doc/references/Mercier2005.pdf
Hsu2007: https://subversion.assembla.com/svn/plus/trunk/doc/references/Hsu2007.pdf
#### By Avicenna2008 on 2013-04-01 00:05
thank you Andras, I will read them


## ICCapturing frame grabber
#### Posted by GuillermoCarbajal on 2013-03-26 15:12

Hi,
I want to work with an ICCapturing frame grabber but I can not connect it properly.
PLUS library stops in the vtkICCapturingSource::InternalConnect() method when trying to write the log error that is shown below.
The reason is that it can not access to the DeviceName because it is NULL.
Attached is the log file.
Thanks!
Guillermo

// Set the device name (e.g. DFG/USB2-lt)
if ( this->GetDeviceName() == NULL || !static_cast<DShowLib::Grabber*>(FrameGrabber)->openDev(this->GetDeviceName() ) )
{
LOG_ERROR("The IC capturing library could not be initialized - invalid device name: " << this->GetDeviceName() );
return PLUS_FAIL;
}
032613_154751_PlusLog.txt	22.8 KB

#### 3 Comments
#### By Siavash Khallaghi on 2013-03-26 15:16
Hi Guillermo,

Could you please provide us with the configuration file?

Siavash
#### By Siavash Khallaghi on 2013-03-26 15:25
I don't have experience with the frame grabber, but could it be as simple as a driver issue? I mean fCal does not recognize the USB port that the frame grabber is connected to it.

Maybe try re-installing the driver for the frame grabber.
#### By Andras Lasso on 2013-03-27 18:16
Probably you haven't specified the DeviceName="DFG/USB2-lt" in the config file. See PlusConfiguration_SonixMDPFrameGrabber_BlackTargetGuideStepper_iCal_1.0.xml for a complete example.


## fCal configuration file for acquiring B-mode and RF simultaneously
#### Posted by Amir Khojaste on 2013-03-27 17:42

Hello,

Can anyone help me out on how the configuration file in fCal will look like when we want to acquire both B-Mode and RF data simultaneously?

Thanks in advance
Amir

#### 2 Comments
#### By Siavash Khallaghi on 2013-03-27 17:53
Hi Amir,

An easy way is to look into the vtkSonixVideoSource->ReadConfiguration() method (depending on your Plus version). There should be a line with FindNestedElementWithName("ImageAcquisition"). If Plus supports BMode/RF acquisition, the values should be there.

Siavash
#### By Andras Lasso on 2013-03-27 18:13
Although Plus now supports simultaneous acquisition of multiple video streams, the current vtkSonixVideoSource implementation just provides one stream at a time (either RF or B-mode). As you can convert the RF data to B-mode anyway, you can just acquire RF data and to the rest with post-processing. If you need the simultaneous acquisition then we can help you implementing it.


## about PLUS used 3rd party library
#### Posted by akioolin on 2013-03-12 23:49

Dear Sirs:

In https://www.assembla.com/spaces/plus/wiki/Linux_Build_Instructions, plus use qt 4.7.x / mesa for gui and data render.

but for vtksys, could some one do me a favor to tell where to found this?
is vtksys is come from http://www.vtk.org, and I have to install vtk package in my linux box?

Thank you very much.

Best Regards,
Akio

#### 9 Comments
#### By Andras Lasso on 2013-03-13 00:07
The build system takes care of downloading and building the correct version of VTK. Please follow the build instructions and write us if anything is unclear or fails.
#### By Akioolin on 2013-03-13 00:10
Dear Andras:

Thank you very much.

Best Regards,
Akio
#### By Akioolin on 2013-03-19 23:19
Dear Sir:

While build plus in my slackware box, the following error message come out.
~~~~
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx: In member function 'void CaptureControlWidget::SaveButtonPressed()':
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:179:34: error: ambiguous overload for 'operator+=' in 'message += QString::toLatin1() const()'
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:179:34: note: candidates are:
In file included from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/string:54:0,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/locale_classes.h:42,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/ios_base.h:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/ios:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/backward/strstream:54,
from /work/plus/PlusBin/PlusLib-bin/src/PlusConfigure.h:39,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.h:10,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:7:
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:938:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(const _CharT*) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:947:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(_CharT) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:184:34: error: ambiguous overload for 'operator+=' in 'message += QString::toLatin1() const()'
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:184:34: note: candidates are:
In file included from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/string:54:0,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/locale_classes.h:42,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/ios_base.h:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/ios:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/backward/strstream:54,
from /work/plus/PlusBin/PlusLib-bin/src/PlusConfigure.h:39,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.h:10,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:7:
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:938:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(const _CharT*) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:947:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(_CharT) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx: In member function 'void CaptureControlWidget::SaveAsButtonPressed()':
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:226:34: error: ambiguous overload for 'operator+=' in 'message += QString::toLatin1() const()'
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:226:34: note: candidates are:
In file included from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/string:54:0,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/locale_classes.h:42,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/ios_base.h:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/ios:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/backward/strstream:54,
from /work/plus/PlusBin/PlusLib-bin/src/PlusConfigure.h:39,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.h:10,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:7:
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:938:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(const _CharT*) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:947:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(_CharT) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:231:34: error: ambiguous overload for 'operator+=' in 'message += QString::toLatin1() const()'
/work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:231:34: note: candidates are:
In file included from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/string:54:0,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/locale_classes.h:42,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/ios_base.h:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/ios:43,
from /usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/backward/strstream:54,
from /work/plus/PlusBin/PlusLib-bin/src/PlusConfigure.h:39,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.h:10,
from /work/plus/PlusBin/PlusApp/CommonWidgets/CaptureControlWidget.cxx:7:
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:938:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(const _CharT*) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
/usr/lib/gcc/i486-slackware-linux/4.7.1/../../../../include/c++/4.7.1/bits/basic_string.h:947:7: note: std::basic_string<_CharT, _Traits, _Alloc>& std::basic_string<_CharT, _Traits, _Alloc>::operator+=(_CharT) [with _CharT = char; _Traits = std::char_traits<char>; _Alloc = std::allocator<char>; std::basic_string<_CharT, _Traits, _Alloc> = std::basic_string<char>]
~~~~
Could any one do me a favor to show me how to fix this error?
it seems the std::string and QString append method problem.

Thank you very much.

Best Regards,
Akio
#### By Andras Lasso on 2013-03-19 23:57
As you see on the dashboard (http://crunch.cs.queensu.ca/CDash/index.php?project=PLUS), there are no build errors on linux if the build is set up correctly. You can choose between these options to resolve your problem:
Follow the build instructions exactly, which includes using the QT library version that is prescribed in the build instructions
Fix the problem (e.g., you can try replacing toLatin1() by toLatin1().constData(), search the web for similar errors and try the suggested solutions, etc.) and let us know once you found a solution that worked for you and we'll test and integrate that change into Plus
#### By Akioolin on 2013-03-21 03:39
Dear Andras:

I follow the step in my slackware box. there is no apt package like system in my slackware
box.
finally, I change the code from "fileName.toLatin1(); " to "message += fileName.toStdString();"
It now Ok to run the MetaSqeViewer on my slackware box.

Is this the acceptable solution?

Thank you very much.

Best Regards,
Akio
#### By Andras Lasso on 2013-03-21 16:42
We would rather not rely on the STL support of QT (sue to potential mismatch of STL implementation in QT and the rest of the application). Could you try which of the followings work for you?:
message += fileName.toLatin1.constData();
message += fileName.toLatin1.data();
message += std::string(fileName.toLatin1.data());
#### By Akioolin on 2013-03-22 03:47
I see. I will try it for you. ^^
#### By Akioolin on 2013-03-22 04:55
message += fileName.toLatin1().constData(); could pass compilation.
message += fileName.toLatin1().data(); could pass compilation.
message += std::string(fileName.toLatin1.data()); could pass compilation.
#### By Andras Lasso on 2013-03-22 10:07
Thanks for the information. We've integrated a fix that uses toLatin1.constData(), see https://www.assembla.com/spaces/plus/tickets/704


## Referring to an active ticket in each commit comment is now required
#### Posted by Andras Lasso on 2013-03-21 15:41

We enabled a pre-commit check of the commit comment in the repository. Referring to an active ticket in the commit comment is now required and if the comment doesn't have the correct format then the whole commit is rejected.

Example for a valid commit comment (See "Committing code changes" in https://www.assembla.com/spaces/plus/wiki/Modifying_Plus_files for more details):
re #123: Changed something to achieve something

#### 0 Comments


## Log viewer tool for PLUS
#### Posted by Andras Lasso on 2013-03-13 09:13

FYI, if you need to read Plus log files: The log file format is compatible with the nice (and free) LogExpert log viewer tool. See details and sample screenshots here: Plus_log_files

Andras

#### 0 Comments


## Question about metafile data and ultrasound transducer grab data
#### Posted by akioolin on 2013-03-06 20:57

Dear Sir:

Could any one do me a favor to tell me the data in metafile is the raw data which grabbed by ultrasound transducer or not?
Right now, I'm doing a study an dealing the output data of transducer grabbed data. for the Image reconstruction part, utilize
the plus project provided is enough. Am I wrong?

the whole idea is as below.

ultrasound transducer --> raw data --> stored in metafile --> reader --> Image reconstruct algorithm --> image.

what I want to do in on the raw data which grabbed by using ultrasound transducer probe.

Thanks in advance.

Best Regards,
Akio

#### 6 Comments
#### By Andras Lasso on 2013-03-07 00:25
Plus can do all these:
record both raw (RF) data or processed (B-mode) ultrasound data and store them in metafile
convert RF data to B-mode data
reconstruct volume from tracked B-mode data

What data do you have and what would you like to do with that?
#### By Akioolin on 2013-03-07 03:43
Dear Andras:

Right now, what I want to do is using some algorithm to reduce the
data rate which grabbed by the ultrasound transducer in real system. before that,
I have to build a simulation environment.
I'm very happy to find that PLUS is a thorough system for ultrasound application.
that why I wonder is there any point to insert algorithm into the PLUS to do
what I am think about.

Right now, the metafile view seems the best cut-in point. Could you do me a favor
to tell me where to find out the exact wave form format in .mha file ?? I want to know
the reading part source code and the wave form format.

Thank you very much.

Best Regards,
Akio
#### By Siavash Khallaghi on 2013-03-07 17:59
Hi Akio,

I am not sure what you mean by "exact wave form format ". Could you please elaborate?

Siavash
#### By Akioolin on 2013-03-07 21:20
Dear Siavashk:

what i need to know is the transducer received echoes and then pass into adc,
the adc converts the analog signal into digital domain. the data which come from adc
is what i call "wave form", and the storage format in meta file is the key point for me.

as i know, the image reconstruct using this data to reconstruct the snapshot of the
ultrasound returned echoes.

Thank you very much.

Best Regards,
Akio
#### By Andras Lasso on 2013-03-08 15:10
Plus supports 3 different RF data encoding format. See the UltrasoundImageType tag description at https://www.assembla.com/spaces/plus/wiki/Sequence_metafile_format.

Sample files:
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/TestImages/BkCurvilinearRfData.mhd
https://subversion.assembla.com/svn/plus/trunk/PlusLib/data/TestImages/UltrasonixCurvilinearRfData.mha

Definition of transducer geometry for RF to B-mode brightness and scan conversion:
https://www.assembla.com/spaces/plus/wiki/RF_to_B-mode_conversion
#### By Akioolin on 2013-03-11 22:14
Dear Andras:

Thank you very much. hope I can make the work done in a short time and demo the whole procedure on tablet.
Thank you very much.

Best Regards,
Akio


## Real-time volume reconstruction
#### Posted by Abtin Rasoulian on 2013-01-23 01:19

Hi,

We are trying to add the ability of real-time volume reconstruction as the user acquires the ultrasound images with fCal. Our data acquisition takes up to 45 seconds in some cases and we though it may be possible to include the volumeReconstruction in that and reduce the overall computation time. We really appreciate if you could give us a hint of how to start and what to manipulate. We want to use the same algorithm as PLUS, i.e. pasting each frame into the volume one-by-one.

Thanks,
Abtin

#### 10 Comments
#### By Tamas Ungi on 2013-01-23 08:14
Hi Abtin,

This could also be a nice feature in PlusServer. Andras recently implemented control by OpenIGTLink commands in PlusServer. So you can send "start data collection" and "stop data collection and save to file" commands to this background program. If you create a class with it's own frame buffer and volume reconstruction thread, it could be added to the PlusServer, so other programs (with GUI, e.g. Slicer) could use this real time vol rec.

I think a good way to start could be that you add a test program to PlusLib/VolumeReconstruction/Testing and implement this frame-by-frame addition of frames using the test program that reads a saved mha file and adds the frames to your new class one-by-one. When you are ready with that, this class could be used in other PLUS applications.

Tamas
#### By Abtin Rasoulian on 2013-01-24 21:08
Hi Tamas,

I have another question. The student who is developing this code is trying to do it on his laptop. Is there any config file that makes it possible to read a mhd file together with the transformation of the frames and the calibration matrix of the probe?

Thanks,
Abtin
#### By Tamas Ungi on 2013-01-24 21:40
The saved tracked ultrasound data (.mha file) can be read into a "tracked frame list" object using this class:
PlusLib\src\PlusCommon\vtkMetaImageSequenceIO.h
The calibration matrix of the probe (ImageToProbeTransform) is saved in a different file, the config file (.xml file). The TransformRepository reads and manages all the transforms read from a config XML file. Look at the ReadConfiguration function:
PlusLib\src\PlusCommon\vtkTransformRepository.h

Hth,
Tamas
#### By Andras Lasso on 2013-01-24 23:30
If you need a specific config file and corresponding sequence file for volume reconstruction, then check out the volume reconstruction tests on the dashboard:
http://crunch.cs.queensu.ca/CDash/viewTest.php?onlypassed&buildid=14071

e.g., this one: http://crunch.cs.queensu.ca/CDash/testDetails.php?test=227983&build=14071
uses PlusLib/data/ConfigFiles/Testing/PlusConfiguration_SpinePhantomFreehandReconstructionOnly.xml and PlusLib/data/TestImages/SpinePhantomFreehand.mha with the ImageToReference transform.
#### By Andras Lasso on 2013-01-25 11:59
Real-time volume reconstruction is now implemented in PlusServer. After the client (e.g., 3D Slicer) request volume reconstruction start all the collected frames are added to the volume. The client can request a snapshot of the current reconstructed volume at any time. The client can also temporarily suspend adding of the frames to the volume, then resume. Note that individual frames are not recorded, so the volume reconstruction does not consume increasing amount of memory or disk space.

The previous functionality of reconstructing volumes from recorded sequence still works.
#### By Tamas Ungi on 2013-01-25 12:09
Wow, that was quick.
Abtin, what you wanted is ready for you to try!
#### By Abtin Rasoulian on 2013-01-25 17:05
Thanks a lot Andras and Tamas,

Abtin
#### By Samira Sojoudi on 2013-03-07 21:18
Hi Andras,

As you mentioned the real-time volume reconstruction is developed in plus server. Actually I want to have the 3D slicer as a client and load the reconstructed volume in it. I am wondering if you have any example code of how to develop a plus server client in slicer and send the requests to the plus server.

Thanks a lot
Samira
#### By Tamas Ungi on 2013-03-08 09:23
Hi Samira,

The 3D Slicer module that sends commands to PlusServer is called OpenIGTLinkRemote. It is part of the SlicerIGT extension, you can install it from the Slicer Extension Manager. It is a recently developed module. Tests are working, but we haven't used it an an experiment. This is it's GitHub page: https://github.com/SlicerIGT/OpenIGTLinkRemote/wiki
Let me know what you need to know about OpenIGTLinkRemote, and I will update its Wiki page. Since you are the first external user of this module, I'm counting a lot on your feedback.
Through OpenIGTLinkRemote you can start/stop data collection, reconstruct volume, and have it sent to Slicer almost in real-time (around 1-2 update of the volume per second).

Thanks,
Tamas
#### By Samira Sojoudi on 2013-03-08 12:47
Thanks a lot, Tamas.


## The transform chain from image to reference in volume reconstruction
#### Posted by Siavash Khallaghi on 2013-02-25 18:49

Hello,

We are working on an alternative volume reconstruction method here at UBC. We have a number of tracked frames, captured using fCal, which we would like to use for validation. Here are my assumptions regarding coordinate representation and calculating the ImageToReferenceTransform. Could you please have a look at them and tell me if anyone of them is false?

1. The calibration matrix, i.e. ImageToProbeTransform, is defined in the xml configuration file under the CoordinateDefinitions node. It is the same matrix that is constructed in fCal during N-wire calibration. It is a 4x4 homogeneous transformation matrix, where the first three rows and three columns represent rotation and scaling (in mms/pixel) and the fourth column represents translation in mms/pixel.

2. The ImageToReferenceTransform is calculated using the following chain:

ImageToReferenceTransform = inv( ReferenceToTrackerTransform )x ProbeToTrackerTransform x ImageToProbeTransform

All the calculations are made using 4x4 homogeneous transformation matrices. The multiplications are all from the left side.

3. The resulting ImageToReferenceTransform is a 4x4 transformation matrix with units that are in mms/pixel.

4. To find the location of an image pixel, i.e. Pixel, in the reference frame, one must use the following transformation chain:

PixelToReference = ImageToReferenceTransform x ImageToTransducerOriginPixel x Pixel

where Pixel is a 4-by-1 vector in the format of transpose([Px Py 0 0]). ImageToTransducerOriginPixel is defined in the config file under the CoordinateDefinitions node and has units of pixels.

#### 1 Comments
#### By Andras Lasso on 2013-02-25 21:04
1. Yes. https://www.assembla.com/spaces/plus/wiki/Transformation_matrix_definition for details.

2. Yes, if ReferenceToTrackeTransform, ProbeToTrackerTransform, ImageToProbeTransform transforms are defined then the ImageToReference transform is computed as you described. Yes, multiplication is done from the left, see https://www.assembla.com/spaces/plus/wiki/Transformation_matrix_definition.

3. As the unit of Image is pixel and the unit of probe is mm (https://www.assembla.com/spaces/plus/wiki/Coordinate_system_definitions), in the R part the unit is mm/pixel, in the T part the unit is mm.

4. There are several issues here. In Plus there is no such coordinate system as "Pixel" (https://www.assembla.com/spaces/plus/wiki/Coordinate_system_definitions), but based on what you described the coordinate system that you call "Pixel" is actually the "Image" coordinate system. The transformation chain is wrong: you cannot multiply ImageToReferenceTransform and ImageToTransducerOriginPixel (when multiplying two matrices A*B: the "From" coordinate system name of A shall match the "To" coordinate system name of B).
To map a pixel from the Image coordinate system to the Reference coordinate system you have to simply use the ImageToReference transform. You can see that the ImageToReference transform is used to map pixels to the volume in all volume reconstruction examples (http://crunch.cs.queensu.ca/CDash/testDetails.php?test=249878&build=15130, http://crunch.cs.queensu.ca/CDash/testDetails.php?test=249879&build=15130, http://crunch.cs.queensu.ca/CDash/testDetails.php?test=249880&build=15130, etc.).


## Cannot connect NDI Polaris and Epiphan devices in fCal-2.0
#### Posted by Huoling on 2013-02-21 03:16

Hello everyone,

I've updated fCal from 1.8 to 2.0, and I followed the configuration file "PlusConfiguration_Epiphan_NDIPolaris.xml" in the folder "..\PlusLib\data\ConfigFiles\" to connect the devices. But when I connect the devices in fCal-2.0, the following errors occured:

|ERROR|531.505000| Command parameter out of range|in ..\..\..\PlusLib\src\DataCo
llection\PolarisTracking\vtkNDITracker.cxx(845)
|ERROR|531.587000| Command parameter out of range|in ..\..\..\PlusLib\src\DataCo
llection\PolarisTracking\vtkNDITracker.cxx(845)
|ERROR|531.621000| Command parameter out of range|in ..\..\..\PlusLib\src\DataCo
llection\PolarisTracking\vtkNDITracker.cxx(845)
......
|WARNING|535.243000| Cannot switch to image mode without enabled video in data c
ollector!|in ..\..\PlusApp\CommonWidgets\vtkVisualizationController.cxx(225)
|WARNING|535.274000| Unable to switch to 2D visualization. Unable to use capturi
ng toolbox.|in ..\..\PlusApp\fCal\Toolboxes\CapturingToolbox.cxx(119)

While the output messeages in the fCal indicate that the devices were connected successfully. The following information of my computer maybe useful:
win7 64 sp1, VS2008, PLUS 64bit(subversion code), NDI Polaris Spectra, Epiphan VGA2USB pro.

Thanks,

Huoling

#### 4 Comments
#### By Andras Lasso on 2013-02-21 10:10
Thanks for reporting this, we are investigating the issue. You can track the progress in #683.
#### By Huoling on 2013-02-21 21:28
Thank you Andras, I've update the PLUS-2.0 code, and the issue of NDI Polaris has fixed. But the Epiphan device still can not collect the data. Following is the output information:
|ERROR|403.188000| Error adding item to video source Video on channel VideoStrea
m|in ..\..\..\PlusLib\src\DataCollection\Epiphan\vtkEpiphanVideoSource.cxx(242)
|WARNING|453.225000| Cannot switch to image mode without enabled video in data c
ollector!|in ..\..\PlusApp\CommonWidgets\vtkVisualizationController.cxx(225)
|WARNING|453.242000| Unable to switch to 2D visualization. Unable to use capturi
ng toolbox.|in ..\..\PlusApp\fCal\Toolboxes\CapturingToolbox.cxx(119)

The configuration file I've used was:
~~~~
<PlusConfiguration version="2.1">

<DataCollection StartupDelaySec="1.0" >
<DeviceSet
Name="Epiphan framegrabber + FakeTracker"
Description="Epiphan framegrabber image acquisition + FakeTracker for tracking"
/>

<Device
Id="TrackerDevice"
Type="FakeTracker"
AcquisitionRate="50"
LocalTimeOffsetSec="0.0"
Mode="PivotCalibration" >
<DataSources>
<DataSource Type="Tool" Id="Reference" BufferSize="1000" AveragedItemsForFiltering="20" PortName="0" />
<DataSource Type="Tool" Id="Stylus" BufferSize="1000" AveragedItemsForFiltering="20" PortName="1" Model="Example" />
</DataSources>
<OutputChannels>
<OutputChannel Id="TrackerStream">
<DataSource Id="Reference" />
<DataSource Id="Stylus" />
</OutputChannel>
</OutputChannels>
</Device>

<Device
Id="VideoDevice"
Type="Epiphan"
AcquisitionRate="30"
UsImageOrientation="MF" >
<DataSources>
<DataSource Type="Video" Id="Video" BufferSize="100" AveragedItemsForFiltering="20" />
</DataSources>

<OutputChannels>
<OutputChannel Id="VideoStream" VideoDataSourceId="Video" />
</OutputChannels>
</Device>

<Device
Id="TrackedVideoDevice"
Type="VirtualStreamMixer" >
<InputChannels>
<InputChannel Id="TrackerStream" />
<InputChannel Id="VideoStream" />
</InputChannels>

<OutputChannels>
<OutputChannel Id="TrackedVideoStream"/>
</OutputChannels>
</Device>

</DataCollection>


<Rendering WorldCoordinateFrame="Tracker">
<DisplayableObject Type="Axes" ObjectCoordinateFrame="Reference"/>
<DisplayableObject Type="Axes" ObjectCoordinateFrame="Tracker" />
</Rendering>

<!-- and so on -->

</PlusConfiguration>
~~~~
Is anything wrong of the configuration file?

Regards,
Huoling
#### By Andras Lasso on 2013-02-21 21:37
It was Adam who fixed the Polaris tracking problem. Please attach the complete config file and we'll try to reproduce/fix the Epiphan problem.
#### By Huoling on 2013-02-21 21:51
Thank you!
PlusConfiguration_Epiphan_FakeTracker.xml	3.92 KB


## Issues about 3.0 phantom
#### Posted by Huoling on 2012-12-20 21:19

Hi PLUS developers,

I want to produce a 3.0 phantom. The 3.0 phantom will be produced by Computerized Numerical Control （CNC）, but the factory partner said that they can not make the triangles because their tool is circular. And 3D printing is much expensive than CNC. I want to ask will it affect the spatial calibration result if changing these triangles to circular? Thank you in advance!

Best regards,
Huoling
3.0phantomIssues.png	66 KB

#### 0 Comments


## Which version should be used in linux?
#### Posted by agomez@assembla on 2012-12-17 09:28

Hi,

Version in trunk is compiling but we have problems when trying to connect, maybe because of the changes in the configuration files. These are the messages:
|ERROR|220.480637| No devices created. Please verify configuration file and any error produced.|in /home/agomez/Software/Plus/PlusBin/PlusLib/src/DataCollection/vtkDataCollector.cxx(117)
|ERROR|220.480946| Unable to start collecting data!|in /home/agomez/Software/Plus/PlusBin/PlusApp/fCal/Toolboxes/ConfigurationToolbox.cxx(187)
|ERROR|220.482797| No selected device. Unable to determine if it has a tracker.|in /home/agomez/Software/Plus/PlusBin/PlusApp/fCal/Toolboxes/ConfigurationToolbox.cxx(227)

Version in branch 1.8 is suggested in:
https://www.assembla.com/spaces/plus/messages/2548293
but it is not compiling in linux.

Which version should we use?
Using the trunk version and "translating" the config files can be an alternative ? Is there a tool to do this?

Thanks,
Alvaro

#### 2 Comments
#### By Adam Rankin on 2012-12-17 11:07
Hi Alvaro, I will look into linux build issues in the 1.8 branch immediately.

In the trunk you can update the config files to match the new format. Unfortunately there is no tool at the moment and it must be done by hand.
You can use https://www.assembla.com/spaces/plus/wiki/Configuration_Structure_for_Plus_Version_2 as a guide.

Adam
#### By Adam Rankin on 2012-12-18 14:37
The linux build has been fixed in the trunk. You can now use either 1.8 or the trunk.

I recommend using 1.8 with the old style of config files. This should be stable for use.


## Best practice to orient reconstructed volume
#### Posted by Siavash Khallaghi on 2012-12-05 20:20

Hello,

I have magnetically tracked B-mode frames captured from a number of subjects. The application that I used to grab the data is built on top of Plus, so the format of the data is the same as data captured with fCal. The attached figure, shows an example stack of B-mode frames.

What I would like to do is to orient the volume such that the middle frame is normal to the one of the axes. I know that a possible solution is to resample the data using the itk::ResampleImageFilter. I was wondering if this was the best solution.

Thank you

Siavash
Frames.png	44 KB

#### 6 Comments
#### By Csaba Pinter on 2012-12-06 10:18
Hi Siavash,

What do you intend to do with the re-oriented image? What program do you want to load it in?

Why is it important to align the axes? You have a transformation that places your volume in space, so you know exactly the position of the voxels. Furthermore, the reconstructed volume is a 3D image, in which there are no frames any more, just voxels.

Sorry for the many questions but I have to understand your problem better before being able to answer.

csaba
#### By Siavash Khallaghi on 2012-12-06 18:33
I have data from 20 subjects and I would like to perform a leave-one-out study. In this study, I would like perform a leave-one-out deformable registration between the volumetric data from each subject to the rest of the subjects. Because of differences between individual subjects, the reconstructed volumes do not have a good initial alignment (see the attached figure). As a result, I would like to bring my data into a common coordinate frame. For anatomical reasons, it is important that the middle slice coincides across the population.
Frames2.png	100 KB
#### By Andras Lasso on 2012-12-06 23:27
You can choose which coordinate system you want to reconstruct your volume in by specifying the appropriate ImageToReferenceTransformName (--transform parameter in the VolumeReconstructor). The reconstructed volume axes will be parallel with the Reference coordinate system.

Note that if we simply define --transform=ImageToReference then the reconstructed volume will be correct, but its axes will be parallel with the patient-attached reference marker axes, which is correct, but not what you want.

Example 

Assumptions:
You have the following tools: Probe (marker attached to the US transducer), Reference (marker attached to the patient).
You determined the ImageToProbeTransform by spatial calibration.

Steps:
To reconstruct the volume in another coordinate system we have to define one. Let's call it ReconstructedVolumeReference. If we want a correct volume reconstruction (that is not sensitive to patient motion) then this reference frame should move together with the patient, i.e., with the Reference coordinate frame. Therefore, the ReconstructedVolumeReference has to be define by a constant ReconstructedVolumeReferenceToReference transform.
Determine the ReconstructedVolumeReferenceToReference transform matrix from the N-th frame: We would like to have ImageToReconstructedVolumeReference transform matrix to be identity for the N-th frame that we can formulate like this: ImageToReconstructedVolumeReference=identity. Therefore: ReferenceToReconstructedVolumeReference*ImageToReference=identity, So we can compute ReferenceToReconstructedVolumeReference=inv(ImageToReference).
Compute ImageToReference for the N-th frame, invert it, and save the matrix value as ReferenceToReconstructedVolumeReference into the CoordinateDefinitions section in the config file.
Call the VolumeReconstructor with --transform=ImageToReconstructedVolumeReference
#### By Siavash Khallaghi on 2012-12-11 20:06
Andras, I think you made a mistake. ImageToReferenceTransform has spacing information in it. As a result, a simple inversion would produce a spatially incorrect volume.

So, Step 2 has to be modified so that only the rotation and translation components of ImageToReferenceTransform are inverted. This is done using a Singular Value Decomposition (SVD) of ImageToReferenceTransform.
#### By Andras Lasso on 2012-12-11 20:41
You are right, ImageToReconstructedVolumeReference = identity provide axis alignment but also changes the volume spacing to pixel space, which in your case isn't desirable.
#### By Siavash Khallaghi on 2012-12-11 20:52
Now the results look like this, which is great!
P9_Screenshot.png	37.9 KB


## Where can I get the newest instruction of the config file?
#### Posted by Huoling on 2012-12-11 01:52

Where can I get the newest instruction of the configuration file for fCal application?
I've update the source code of PlusApp and PlusLib to the latest version, but the configuration file for previous can not work.
thank you!

#### 6 Comments
#### By Andras Lasso on 2012-12-11 09:05
We are working on adding support for connection to unlimited number of devices at the same time. This requires some changes in the configuration file structure. Until this feature is finalized you can still use the latest stable branch: https://subversion.assembla.com/svn/plus/branches/Plus-1.8
#### By Csaba Pinter on 2012-12-11 10:13
Sorry about that, Huoling!
Please watch ticket #628
#### By Huoling on 2012-12-11 10:20
Thank you for your reply. I've build Plus-1.8 successfully. I want use DFG/USB2pro as the image source and Polaris Spectra as the tracker. The configuration file I wrote as following (only list the DataCollection part):

<DataCollection StartupDelaySec="1.0">
<DeviceSet
Name="DFG/USB2Pro + NDI Polaris"
Description="DFG/USB2Pro framegrabber image acquisition + NDI Polaris for tracking"
/>

<Device
Type="ICCapturing"
Id="DeviceICCapturing"
AcquisitionRate="30"
UsImageOrientation="MN"
Selectable="true">
<OutputStream
Id="ICCapturingOutput"
BufferSize="100"
AveragedItemsForFiltering="20"
VideoNorm="PAL_B"
VideoFormat="Y800 (768x576)"
InputChannel="00 Video: Composite"
ICBufferSize="50"
ClipRectangleOrigin="0 0"
ClipRectangleSize="0 0" />
</Device>

<Device
Type="PolarisTracker"
Id="DevicePolarisTracker"
SerialPort="1"
BaudRate="115200"
AcquisitionRate="30"
LocalTimeOffsetSec="0.0" >
<Tool Name="Probe" PortName="4" RomFile="NDI_ROM_Files\8700339.rom" AveragedItemsForFiltering="20" BufferSize="2500"/>
<Tool Name="Stylus" PortName="5" RomFile="NDI_ROM_Files\8700340.rom" AveragedItemsForFiltering="20" BufferSize="2500"/>
<Tool Name="Reference" PortName="6" RomFile="NDI_ROM_Files\8700449.rom" AveragedItemsForFiltering="20" BufferSize="2500"/>
<OutputStream Id="TrackerOutput" AveragedItemsForFiltering="20">
<Tool Name="Probe"/>
<Tool Name="Stylus"/>
<Tool Name="Reference"/>
</OutputStream>
</Device>

<Device Id="FinalMixer" Type="VirtualStreamMixer" Selectable="True" AveragedItemsForFiltering="20">
<OutputStream Id="Final"/>
<InputStream Id="TrackerOutput" />
<InputStream Id="ICCapturingOutput" />
</Device>
</DataCollection>

I set this configuration file in fCal to connect DFG/USB2pro and Polaris Spectra, but it does not work. Is anything wrong with the above configuration structure?
Thank you!
#### By Andras Lasso on 2012-12-11 10:38
The config file above is for the new multi-stream version of Plus (Plus-2.x). Check out the PlusLib/data/ConfigFiles directory in your build tree for sample config files.

The DataCollection element in the config file should be something like this:
~~~~
<DataCollection StartupDelaySec="1.0">
<DeviceSet
Name="..."
Description="..."
/>

<Tracker Type="PolarisTracker" SerialPort="3" BaudRate="115200" BufferSize="2500" AcquisitionRate="50" AveragedItemsForFiltering="20" LocalTimeOffsetSec="0.0" >
<Tool Name="Tool" PortName="4" RomFile="NdiToolDefinitions\8700339.rom" />
<Tool Name="Stylus" PortName="5" RomFile="NdiToolDefinitions\8700340.rom" />
<Tool Name="Reference" PortName="6" RomFile="NdiToolDefinitions\8700449.rom" />
</Tracker>

<ImageAcquisition Type="ICCapturing"
BufferSize="100"
UsImageOrientation="MF"
AcquisitionRate="30"
AveragedItemsForFiltering="20"
LocalTimeOffsetSec="-0.13"
DeviceName="DFG/USB2-lt"
VideoNorm="NTSC_M"
VideoFormat="Y800 (640x480)"
InputChannel="01 Video: SVideo"
ICBufferSize="50"
/>

</DataCollection>
~~~~

#### By Huoling on 2012-12-11 10:57
Thank you Andras, the config structure you list seems for Plus-1.6 or previous version. I loaded this config file as you list above in Plus-1.8, and it still can not work, but working for Plus-1.6.
#### By Adam Rankin on 2012-12-11 11:14
Plus-1.8 is the current stable release. It uses the Tracker/ImageAcquisition style configuration file.

Please post your message log with the errors you have encountered.


## Compilation errors in linux - rev 2324
#### Posted by agomez@assembla on 2012-12-11 07:26

Reverting some files in PlusLib to revision 2299 brought back some compilation errors in linux such as:

.........../Plus/PlusBin/PlusLib/src/PatternLocAlgo/FidLabeling.cxx:288:80: instantiated from here
/usr/include/c++/4.6/bits/stl_algo.h:2233:4: error: invalid initialization of reference of type ‘std::vector<double>&’ from expression of type ‘const std::vector<double>’
/usr/include/c++/4.6/bits/stl_algo.h:2236:4: error: invalid initialization of reference of type ‘std::vector<double>&’ from expression of type ‘const std::vector<double>’

#### 1 Comments
#### By Andras Lasso on 2012-12-11 09:04
Thanks for reporting this. You can track the resolution here: #636


## fCal 2.0 wiring issues
#### Posted by Csaba Pinter on 2012-12-06 11:40

Guillermo found that the 2D errors in the X (lateral) direction were bigger than those in the Y (axial) direction.

We took a look at the wiring and found the issue illustrated in the attached image. Basically the parallel wires are not parallel to the phantom wall.
It would be better if the inclined holes were in a "/ \" manner instead of the current "/ /".

Thoughts?
fCal2.0_Wires.png	124 KB

#### 2 Comments
#### By Andras Lasso on 2012-12-06 23:45
It is not an issue if the first and last segment of the Z fiducial are not parallel to_the_phantom_wall (we might even have a phantom that have curved walls, etc.). The only important constraint is that the first and last segment of the Z fiducial must be parallel to each_other (and all segments must be in the same plane). Any translation of a wall compared to the other keeps the Z fiducial valid (first and last segments are parallel, all segments are in one plane).

Of course the position of the wire endpoints must be accurately described in the config file, in the Phantom coordinate frame. The Phantom coordinate frame has the origin at the inner end of the A4 hole, see the png files in doc\specifications\fCalPhantom.
#### By Csaba Pinter on 2012-12-07 10:26
As your're saying it, it's true. Shearing keeps the pattern valid in case of images where the image plane is parallel to the phantom's long walls (I'm not sure about the case where the plane isn't parallel to the wall).
Still, if we want to be precise, then either we have to incorporate this issue (the wire originates from the opposite sides of the holes) in the config files, or change the tilted holes to incline to the other direction along one wall of the phantom.


## fCal 2.0 Phantom, reduce width of N wires
#### Posted by Vikas Revanna Shivaprabhu on 2012-11-30 12:00

Hi,

I am using fCal2.0 phantom with 3N wires for spatial calibration. I just noticed that the width of the linear probe I am using is shorter than the width of the N wires. So all the wires are not visible in the ultrasound image. I would like to reduce the width of the N wires. Suppose I change the wire configuration, is it sufficient to change the "EndPointFront" and "EndPointBack" in the configuration file ?

For eg:

In place of
~~~~
<Pattern Type="NWire">
<Wire Name="7:G1_g1" EndPointFront="30.0 0.0 20.0" EndPointBack="30.0 40.0 20.0" />
<Wire Name="8:L1_h1" EndPointFront="55.0 0.0 20.0" EndPointBack="35.0 40.0 20.0" />
<Wire Name="9:M1_m1" EndPointFront="60.0 0.0 20.0" EndPointBack="60.0 40.0 20.0" />
</Pattern>
~~~~
Can I change it to
~~~~
<Pattern Type="NWire">
<Wire Name="7:I1_i1" EndPointFront="40.0 0.0 20.0" EndPointBack="40.0 40.0 20.0" />
<Wire Name="8:L1_j1" EndPointFront="55.0 0.0 20.0" EndPointBack="55.0 40.0 20.0" />
<Wire Name="9:M1_m1" EndPointFront="60.0 0.0 20.0" EndPointBack="60.0 40.0 20.0" />
</Pattern>
~~~~
and so on for the other two N's ?

Thanks

#### 2 Comments
#### By Csaba Pinter on 2012-11-30 14:23
Hi Vikas,
Yes, it is enough.
Do you plan to make the diagonal wire steeper or you want to put the parallel and diagonal wires in the same holes?
The second approach should give better results, but you have to pay extra attention to the wiring, to make sure both wires lie against the same side of the hole (and not stack on top of each other).
csaba
#### By Vikas Revanna Shivaprabhu on 2012-11-30 14:38
Great. I just moved the left side parallel wires and the left side of N's to the right by two holes (when looking at the front side of the phantom). Here is my new pattern:
~~~~
<Pattern Type="NWire">
<Wire Name="7:G1_g1" EndPointFront="30.0 0.0 20.0" EndPointBack="30.0 40.0 20.0" />
<Wire Name="8:J1_h1" EndPointFront="45.0 0.0 20.0" EndPointBack="35.0 40.0 20.0" />
<Wire Name="9:K1_k1" EndPointFront="50.0 0.0 20.0" EndPointBack="50.0 40.0 20.0" />
</Pattern>
<Pattern Type="NWire">
<Wire Name="4:G3_g3" EndPointFront="30.0 0.0 10.0" EndPointBack="30.0 40.0 10.0" />
<Wire Name="5:H3_j3" EndPointFront="35.0 0.0 10.0" EndPointBack="45.0 40.0 10.0" />
<Wire Name="6:K3_k3" EndPointFront="50.0 0.0 10.0" EndPointBack="50.0 40.0 10.0" />
</Pattern>
<Pattern Type="NWire">
<Wire Name="1:H5_h5" EndPointFront="35.0 0.0 0.0" EndPointBack="35.0 40.0 0.0" />
<Wire Name="2:J5_i5" EndPointFront="45.0 0.0 0.0" EndPointBack="40.0 40.0 0.0" />
<Wire Name="3:K5_k5" EndPointFront="50.0 0.0 0.0" EndPointBack="50.0 40.0 0.0" />
</Pattern>
~~~~
-Vikas


## problem with ascension tracker
#### Posted by Abtin Rasoulian on 2012-11-13 19:45

Hi Tamas,

I am trying to calibrate my 3D probe using magnetic tracker. I did the stylus and N-wire phantom calibration using fCal and then used Cubes (ascension software) to localize my 3D probe. I realized some incompatibility between transformation matrices in Cubes and fCal. I tracked my stylus and touch the origin of the N-wire phantom, saved the position of both in Cubes and used the calibration matrices from fCal. Following matrices are too off:

T_stylusToTracker * stylusTipToStylus
T_referenceToTracker*T_phantomToReference*[0 0 0]

Is the transformation matrix taken from Cube different from the one fCal takes?

Thanks,
Abtin

#### 8 Comments
#### By Tamas Ungi on 2012-11-13 19:59
Hi Abtin,

I never checked the coordinates in Cube, I don't know what coordinate system does it use.
I don't really understand what are you trying to do, could you please describe your workflow in a little more detail?

You have written two lines in your message. The first one yields the StylusTipToTracker transform matrix, and the other gives the origin of the phantom in the Tracker coordinate system. One is a matrix, the other is a vector. I'm not familiar with the Phantom coordinate system, so I don't know where is the origin in it. You shouldn't need that information for calibration.

Tamas
#### By Abtin Rasoulian on 2012-11-13 22:02
Thanks for your quick respond,

Actually, I want to calibrate the volume not the slices. I can't use fCal for that, since it only supports calibration of the 2D probes. My plan was to calibrate stylus and the phantom with fCal and be able to have the position of the N-wires in tracker coordinate system. Then capture tracked volumes with propello and reconstruct them. Tracking in this step is done by Cubes.

I assumed that the StylusTipToTracker transform is a vector showing the tip of the stylus in the stylus coordinate system. I found the origin from the "Landmark Name"s tag in the PhantomDefinition part of the configuration xml file.

Abtin
#### By Tamas Ungi on 2012-11-13 23:07
Your plan sounds good, except for using Cubes. I suggest using PlusServer and 3D Slicer to be able to display anything in any coordinate system. That makes think much clearer when you work.

Use the following convention please:
Transforms: Represented by 4x4 matrices and are used to transform points from one coordinate system to another.
Points: Represented by 4x1 vectors and their definition requires an explicitly named coordinate system where they describe a location.

Your assumption was wrong, the StylusTipToTracker transform is a matrix used to convert the stylus tip point from the StylusTip coordinate system to the Tracker coordinate system. The stylus tip point in the StylusTip coordinate system is (0,0,0,1) by definition.

For this experiment, I would suggest attaching a sensor to the fCal phantom, to avoid problems if the phantom moves during calibration. This also helps you to get additional data later, even after the experimental setup has been moved.

Start by sketching all the coordinate systems that play any role in your setup. You need a clear, explicit definition of your Image coordinate system for these 3D US volumes. Define the axes and units. See how it can be integrated in the current PLUS definition for Image coordinate system. When you have this, you need to load the 3D US image into Slicer in the Image coordinate system, and the fCal phantom in the Probe coordinate system. The next step is to manually pick points in the Image and the Probe coordinate system, e.g. endpoints of the wires, and register them using Fiducial Registration.

Hth,
Tamas
#### By Andras Lasso on 2012-11-14 00:10
Abtin, you should be able to acquire both the images and the corresponding wobbler angle using the vtkSonixPortaVideoSource class. As far as I remember you tried to do this some time ago, but maybe you couldn't complete that work. It shouldn't be very complicated (possibly doable within a few hours). Let us know if you need any help with that.

To calibrate a motorized probe you need to determine the ProbeToWobblerBaseTransform and WobblerToImageTransform (where WobblerBase is a coordinate system fixed to the rotation axis of the wobbler; Wobbler is simply rotated compared to WobblerBase by the wobbler angle). You can compute these transforms by performing fCal to get ProbeToImage in 2-3 different wobbler angles, compute the intersection line between different image planes to get ProbeToWobblerBaseTransform, then compute WobblerToImageTransform from one known ProbeToWobblerBaseTransform and the corresponding WobblerToWobblerBaseTransform. If you save ProbeToWobblerBaseTransform and WobblerToImageTransform in the transform repository and compute WobblerToWobblerBaseTransform in the vtkSonixPortaVideoSource class then you can do anything: acquire fully calibrated tracked sequences directly using Plus (fCal), visualize it correctly in 3DSlicer in real-time, etc.
#### By Abtin Rasoulian on 2012-11-14 00:24
Hi Tamas,

Problem solved. The transformation we see in the Cube should be read as follows:

[inv(R) T; 0 0 0 1]

R is built using those three angles, azimuth, elevation and roll. I attached the formula for generation of the rotation matrix.

Abtin
Matrix_output.pdf	289 KB
#### By Andras Lasso on 2012-11-14 00:28
Abtin, why do you consider using the Cube demo application?
#### By Abtin Rasoulian on 2012-11-15 22:09
Hi,

Tamas, thanks a lot for your
####  comments. Is there any tutorial on Plus Server?
#### By Abtin Rasoulian on 2012-11-15 22:24
Hi Andras,

Actually vtkSonixPortaVideoSource is working without any specific bug. We even grabbed some data with that during our clinical study. However, I realized that the angles acquired with vtkSonixPortaVideoSource have a delay time. Additionally, I don't think we can trust the way I wanted to calibrate the 3D probe. Before, I was calibrating the middle slice of the 3D probe, by using the fCal and ulterius and assumed that I can propagate the calibration result to the other slices. However, I didn't get very accurate results, since I am not sure if the probe goes to the zero angle (or even the same angle) every time I start Ulterius.

Anyway, I didn't know about Wobbler. It sounds like the correct way to do it, thanks for mentioning it.

Abtin


## question on probe orientation
#### Posted by lion2012 on 2012-11-12 09:59

Dear all:

May I ask a question regarding probe orientation? According to the wiki, "the marked side of the probe shall be close to the A1 point". I am not sure which side is the "marked side of the probe" if I am not using ultrasonix machine.

Here are some images of my setup with Terason machine and Ascension tracker. A smaller sensor was attached to the transducer. But I am not sure which side is the "marked side" of the probe. Is the marked side as displayed in picture transducer_1.jpg or in picture transducer_2.jpg?

Thanks a lot.

David
transducer_1.jpg	217 KB
setup.jpg	138 KB
transducer_2.jpg	136 KB

#### 0 Comments

## Segmentation parameter tuning
#### Posted by lion2012 on 2012-10-22 11:57

Hi,

May I ask for help on segmentation parameter tuning in spatial calibration?

In the snapshot of the image I got during spatial calibration, I got red dots on the wire intersections. However, it is hard to get green dots. Is there a sequence of steps to do parameter adjustment?

Thanks.

David
SegmentationParameterDialog_ExportedImage_20121022_221617_Config.xml	6.35 KB
SegmentationParameterDialog_ExportedImage_20121022_221617.mha	1000 KB

#### 5 Comments
#### By Siavash Khallaghi on 2012-10-24 17:42
Hi David,

Can you please post a jpeg version of the N-wire configuration in the segmentation dialog?
#### By Andras Lasso on 2012-10-24 21:54
There are multiple problems:
Main problem: you have 3 N-wires in the config file, but there are only 2 N-wires in the image
Region of interest is unnecessarily large
Probably the spacing is not set correctly (see System_calibration)
#### By Lion2012 on 2012-10-25 08:32
Thanks all. I will make sure the phantom matches the configuration file.
#### By Lion2012 on 2012-11-08 18:14
Hi,

Again I am asking for helps in the segmentation parameter tuning. Please see the attached screenshot. I have corrected the following error in my experiments:

1. Re-wire the phantom to match the configuration file. Now it is 3 N-wires.
2. Adjusted the ROI much smaller
3. I have manually adjusted the spacing (by drag the end points of the green line to 2 white points at the ends of the top lines.) The spacing I got is around 2.5 (not shown in the snapshot). Still I am not able to get any green dots.

It is easier to see changes when adjusting parameters in the Morphology group. However, I have no idea how to adjust parameters in the Tolerance group ( no effects in my trials).

Anything I may be able to do to get the segmentation correct? Maybe there is a sequence of steps I should do to identify the problem.

Siavashk: is the jpg version of the ultrasound image itself what you like to have? I don't know how to capture the jpg image from fCal. Screen capture may not work best I think. Maybe I could save one from the ultrasound machine itself. I will post it later today.

Thanks a lot

David
segparameter.png	545 KB
SegmentationParameterDialog_ExportedImage_20121108_224624.mha	1000 KB
Output.rar	118 KB
SegmentationParameterDialog_ExportedImage_20121108_224624_Config.xml	6.36 KB
#### By Lion2012 on 2012-11-12 09:49
Hi,

Here are 2 jpg images saved directly from ultrasound machine. Hope it might give hints on what I have done wrong.

Thanks.

Daivd
ABD002.jpg	194 KB
ABD003.jpg	185 KB


## Error building PLUS with MicronTracker
#### Posted by Vikas Revanna Shivaprabhu on 2012-11-02 16:23

I am trying to build PLUS with Micron Tracker turned ON. The latest version of MicronTracker 64-bit does not require us to install digiclops and triclops. So I commented out the following two lines from Tracking/CmakeLists.txt:

#${MICRONTRACKER_BINARY_DIR}/Windist/digiclops${CMAKE_SHARED_LIBRARY_SUFFIX}
#${MICRONTRACKER_BINARY_DIR}/Windist/triclops${CMAKE_SHARED_LIBRARY_SUFFIX}

I get the following error messages when I build. Please provide inputs to resolve this issue.

Thanks.

9>1>------ Build started: Project: vtkTracking, Configuration: Debug Win32 ------
9>1>Linking...
9>1> Creating library C:\Users\Vikas\Documents\Research\Libraries\PLUS\Bin\bin\Debug\vtkTracking.lib and object C:\Users\Vikas\Documents\Research\Libraries\PLUS\Bin\bin\Debug\vtkTracking.exp
9>1>MicronTrackerInterface.lib(MicronTrackerInterface.obj) : error LNK2019: unresolved external symbol _MTexit@0 referenced in function "public: void __thiscall MicronTrackerInterface::mtDetachCameras(void)" (?mtDetachCameras@MicronTrackerInterface@@QAEXXZ)

9>1>MicronTrackerInterface.lib(Cameras.obj) : error LNK2001: unresolved external symbol _MTexit@0

9>1>MicronTrackerInterface.lib(MicronTrackerInterface.obj) : error LNK2019: unresolved external symbol _Markers_LoadTemplates@4 referenced in function "public: int __thiscall MicronTrackerInterface::mtRefreshTemplates(class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > &,class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)" (?mtRefreshTemplates@MicronTrackerInterface@@QAEHAAV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@0ABV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@3@@Z)

9>1>MicronTrackerInterface.lib(MicronTrackerInterface.obj) : error LNK2019: unresolved external symbol _Xform3D_RotMatGet@8 referenced in function "public: void __thiscall MicronTrackerInterface::mtFindIdentifiedMarkers(void)" (?mtFindIdentifiedMarkers@MicronTrackerInterface@@QAEXXZ)

9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2001: unresolved external symbol _Xform3D_RotMatGet@8

9>1>MicronTrackerInterface.lib(MicronTrackerInterface.obj) : error LNK2019: unresolved external symbol _Markers_TemplateMatchToleranceMMDefaultGet@4 referenced in function "public: double __thiscall MicronTrackerInterface::mtGetTemplMatchToleranceDefault(void)" (?mtGetTemplMatchToleranceDefault@MicronTrackerInterface@@QAENXZ)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2001: unresolved external symbol _Markers_TemplateMatchToleranceMMDefaultGet@4

9>1>MicronTrackerInterface.lib(MicronTrackerInterface.obj) : error LNK2019: unresolved external symbol _Camera_LastFrameThermalHazard@4 referenced in function "public: int __thiscall MicronTrackerInterface::mtGetLatestFrameHazard(void)" (?mtGetLatestFrameHazard@MicronTrackerInterface@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2001: unresolved external symbol _Camera_LastFrameThermalHazard@4

9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_New@0 referenced in function "public: __thiscall Persistence::Persistence(void)" (??0Persistence@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_Free@4 referenced in function "public: __thiscall Persistence::~Persistence(void)" (??1Persistence@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_PathSet@8 referenced in function "public: int __thiscall Persistence::setPath(char const *)" (?setPath@Persistence@@QAEHPBD@Z)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_SectionSet@8 referenced in function "public: void __thiscall Persistence::setSection(char *)" (?setSection@Persistence@@QAEXPAD@Z)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_RetrieveInt@16 referenced in function "public: int __thiscall Persistence::retrieveInt(char *,int)" (?retrieveInt@Persistence@@QAEHPADH@Z)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_RetrieveDouble@20 referenced in function "public: double __thiscall Persistence::retrieveDouble(char *,double)" (?retrieveDouble@Persistence@@QAENPADN@Z)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_SaveInt@12 referenced in function "public: void __thiscall Persistence::saveInt(char *,int)" (?saveInt@Persistence@@QAEXPADH@Z)
9>1>MicronTrackerInterface.lib(Persistence.obj) : error LNK2019: unresolved external symbol _Persistence_SaveDouble@16 referenced in function "public: void __thiscall Persistence::saveDouble(char *,double)" (?saveDouble@Persistence@@QAEXPADN@Z)
9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Marker_RestoreTemplate@12 referenced in function "public: int __thiscall Markers::restoreTemplate(int,char *)" (?restoreTemplate@Markers@@QAEHHPAD@Z)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2001: unresolved external symbol _Marker_RestoreTemplate@12

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Marker_StoreTemplate@12 referenced in function "public: int __thiscall Markers::storeTemplate(int,int,char *)" (?storeTemplate@Markers@@QAEHHHPAD@Z)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2001: unresolved external symbol _Marker_StoreTemplate@12

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_TemplateItemGet@8 referenced in function "public: int __thiscall Markers::storeTemplate(int,int,char *)" (?storeTemplate@Markers@@QAEHHHPAD@Z)
9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_AddTemplate@4 referenced in function "public: int __thiscall Markers::addTemplate(int)" (?addTemplate@Markers@@QAEHH@Z)
9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_ClearTemplates@0 referenced in function "public: int __thiscall Markers::clearTemplates(void)" (?clearTemplates@Markers@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_IdentifiedMarkersGet@8 referenced in function "public: int __thiscall Markers::identifiedMarkers(class MCamera *)" (?identifiedMarkers@Markers@@QAEHPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Collection_New@0 referenced in function "public: int __thiscall Markers::identifiedMarkers(class MCamera *)" (?identifiedMarkers@Markers@@QAEHPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2001: unresolved external symbol _Collection_New@0

9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2001: unresolved external symbol _Collection_New@0

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_UnidentifiedVectorsGet@8 referenced in function "public: int __thiscall Markers::unidentifiedVectors(class MCamera *)" (?unidentifiedVectors@Markers@@QAEHPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_PredictiveFramesInterleaveGet@4 referenced in function "public: int __thiscall Markers::getPredictiveFramesInterleave(void)" (?getPredictiveFramesInterleave@Markers@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_PredictiveFramesInterleaveSet@4 referenced in function "public: int __thiscall Markers::setPredictiveFramesInterleave(int)" (?setPredictiveFramesInterleave@Markers@@QAEHH@Z)
9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_TemplateMatchToleranceMMGet@4 referenced in function "public: double __thiscall Markers::getTemplateMatchToleranceMM(void)" (?getTemplateMatchToleranceMM@Markers@@QAENXZ)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_TemplateMatchToleranceMMSet@8 referenced in function "public: int __thiscall Markers::setTemplateMatchToleranceMM(double)" (?setTemplateMatchToleranceMM@Markers@@QAEHN@Z)
9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_TemplatesCount@0 referenced in function "public: int __thiscall Markers::getTemplateCount(void)" (?getTemplateCount@Markers@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Marker_NameGet@16 referenced in function "public: char * __thiscall Markers::getTemplateItemName(int)" (?getTemplateItemName@Markers@@QAEPADH@Z)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2001: unresolved external symbol _Marker_NameGet@16

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Marker_NameSet@8 referenced in function "public: int __thiscall Markers::setTemplateItemName(int,char *)" (?setTemplateItemName@Markers@@QAEHHPAD@Z)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2001: unresolved external symbol _Marker_NameSet@8

9>1>MicronTrackerInterface.lib(Markers.obj) : error LNK2019: unresolved external symbol _Markers_ProcessFrame@4 referenced in function "public: int __thiscall Markers::processFrame(class MCamera *)" (?processFrame@Markers@@QAEHPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Cameras.obj) : error LNK2019: unresolved external symbol _Cameras_ItemGet@8 referenced in function "public: int __thiscall Cameras::AttachAvailableCameras(void)" (?AttachAvailableCameras@Cameras@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Cameras.obj) : error LNK2019: unresolved external symbol _Cameras_Count@0 referenced in function "public: int __thiscall Cameras::AttachAvailableCameras(void)" (?AttachAvailableCameras@Cameras@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Cameras.obj) : error LNK2019: unresolved external symbol _Cameras_AttachAvailableCameras@4 referenced in function "public: int __thiscall Cameras::AttachAvailableCameras(void)" (?AttachAvailableCameras@Cameras@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_New@8 referenced in function "public: __thiscall MCamera::MCamera(int)" (??0MCamera@@QAE@H@Z)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_Free@4 referenced in function "public: __thiscall MCamera::~MCamera(void)" (??1MCamera@@QAE@XZ)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ResolutionGet@12 referenced in function "public: int __thiscall MCamera::getXRes(void)" (?getXRes@MCamera@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_SerialNumberGet@8 referenced in function "public: int __thiscall MCamera::getSerialNum(void)" (?getSerialNum@MCamera@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_BitsPerPixelGet@8 referenced in function "public: int __thiscall MCamera::getBitsPerPixel(void)" (?getBitsPerPixel@MCamera@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsGet@8 referenced in function "public: double __thiscall MCamera::getShutterTime(void)" (?getShutterTime@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsSet@12 referenced in function "public: int __thiscall MCamera::setShutterTime(double)" (?setShutterTime@MCamera@@QAEHN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsMinGet@8 referenced in function "public: double __thiscall MCamera::getMinShutterTime(void)" (?getMinShutterTime@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsMaxGet@8 referenced in function "public: double __thiscall MCamera::getMaxShutterTime(void)" (?getMaxShutterTime@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsLimiterGet@8 referenced in function "public: double __thiscall MCamera::getShutterTimeLimit(void)" (?getShutterTimeLimit@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ShutterMsecsLimiterSet@12 referenced in function "public: double __thiscall MCamera::setShutterTimeLimit(double)" (?setShutterTimeLimit@MCamera@@QAENN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_FrameMTTimeSecsGet@8 referenced in function "public: double __thiscall MCamera::getFrameTime(void)" (?getFrameTime@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_FramesGrabbedGet@8 referenced in function "public: int __thiscall MCamera::getNumOfFramesGrabbed(void)" (?getNumOfFramesGrabbed@MCamera@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFGet@8 referenced in function "public: double __thiscall MCamera::getGain(void)" (?getGain@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFSet@12 referenced in function "public: int __thiscall MCamera::setGain(double)" (?setGain@MCamera@@QAEHN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFMinGet@8 referenced in function "public: double __thiscall MCamera::getMinGain(void)" (?getMinGain@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFMaxGet@8 referenced in function "public: double __thiscall MCamera::getMaxGain(void)" (?getMaxGain@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFLimiterGet@8 referenced in function "public: double __thiscall MCamera::getGainLimit(void)" (?getGainLimit@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainFLimiterSet@12 referenced in function "public: double __thiscall MCamera::setGainLimit(double)" (?setGainLimit@MCamera@@QAENN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GainDBGet@8 referenced in function "public: double __thiscall MCamera::getDBGain(void)" (?getDBGain@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ExposureGet@8 referenced in function "public: double __thiscall MCamera::getExposure(void)" (?getExposure@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ExposureSet@12 referenced in function "public: int __thiscall MCamera::setExposure(double)" (?setExposure@MCamera@@QAEHN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ExposureMinGet@8 referenced in function "public: double __thiscall MCamera::getMinExposure(void)" (?getMinExposure@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ExposureMaxGet@8 referenced in function "public: double __thiscall MCamera::getMaxExposure(void)" (?getMaxExposure@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_AutoExposureGet@8 referenced in function "public: int __thiscall MCamera::getAutoExposure(void)" (?getAutoExposure@MCamera@@QAEHXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_AutoExposureSet@8 referenced in function "public: int __thiscall MCamera::setAutoExposure(int)" (?setAutoExposure@MCamera@@QAEHH@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_LightCoolnessGet@8 referenced in function "public: double __thiscall MCamera::getLightCoolness(void)" (?getLightCoolness@MCamera@@QAENXZ)

9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_LightCoolnessSet@12 referenced in function "public: int __thiscall MCamera::setLightCoolness(double)" (?setLightCoolness@MCamera@@QAEHN@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_LightCoolnessAdjustFromColorVector@12 referenced in function "public: int __thiscall MCamera::AdjustCoolnessFromColorVector(int)" (?AdjustCoolnessFromColorVector@MCamera@@QAEHH@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_ImagesGet@12 referenced in function "public: bool __thiscall MCamera::getImages(unsigned char * * *,unsigned char * * *)" (?getImages@MCamera@@QAE_NPAPAPAE0@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_HalfSizeImagesGet@12 referenced in function "public: bool __thiscall MCamera::getHalfSizeImages(unsigned char * * *,unsigned char * * *,int,int)" (?getHalfSizeImages@MCamera@@QAE_NPAPAPAE0HH@Z)
9>1>MicronTrackerInterface.lib(MCamera.obj) : error LNK2019: unresolved external symbol _Camera_GrabFrame@4 referenced in function "public: bool __thiscall MCamera::grabFrame(void)" (?grabFrame@MCamera@@QAE_NXZ)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_New@0 referenced in function "public: __thiscall Marker::Marker(int)" (??0Marker@@QAE@H@Z)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_Free@4 referenced in function "public: __thiscall Marker::~Marker(void)" (??1Marker@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_IdentifiedFacetsGet@16 referenced in function "public: int __thiscall Marker::identifiedFacets(class MCamera *)" (?identifiedFacets@Marker@@QAEHPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_TemplateFacetsGet@8 referenced in function "public: int __thiscall Marker::getTemplateFacets(void)" (?getTemplateFacets@Marker@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_WasIdentifiedGet@12 referenced in function "public: bool __thiscall Marker::wasIdentified(class MCamera *)" (?wasIdentified@Marker@@QAE_NPAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_Marker2CameraXfGet@16 referenced in function "public: class Xform3D * __thiscall Marker::marker2CameraXf(int)" (?marker2CameraXf@Marker@@QAEPAVXform3D@@H@Z)
9>1>MicronTrackerInterface.lib(Marker.obj) : error LNK2019: unresolved external symbol _Marker_AddTemplateFacet@12 referenced in function "public: int __thiscall Marker::addTemplateFacet(class Facet *,class Xform3D *)" (?addTemplateFacet@Marker@@QAEHPAVFacet@@PAVXform3D@@@Z)

9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2019: unresolved external symbol _Collection_Free@4 referenced in function "public: __thiscall Collection::~Collection(void)" (??1Collection@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2019: unresolved external symbol _Collection_Add@16 referenced in function "public: void __thiscall Collection::add(int)" (?add@Collection@@QAEXH@Z)
9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2019: unresolved external symbol _Collection_Remove@8 referenced in function "public: void __thiscall Collection::remove(int)" (?remove@Collection@@QAEXH@Z)
9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2019: unresolved external symbol _Collection_Count@4 referenced in function "public: int __thiscall Collection::count(void)" (?count@Collection@@QAEHXZ)

9>1>MicronTrackerInterface.lib(Collection.obj) : error LNK2019: unresolved external symbol _Collection_Item@16 referenced in function "public: int __thiscall Collection::itemI(int)" (?itemI@Collection@@QAEHH@Z)
9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_New@0 referenced in function "public: __thiscall Xform3D::Xform3D(int)" (??0Xform3D@@QAE@H@Z)

9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_Free@4 referenced in function "public: __thiscall Xform3D::~Xform3D(void)" (??1Xform3D@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_Concatenate@12 referenced in function "public: class Xform3D * __thiscall Xform3D::concatenate(class Xform3D *)" (?concatenate@Xform3D@@QAEPAV1@PAV1@@Z)

9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_Inverse@8 referenced in function "public: class Xform3D * __thiscall Xform3D::inverse(void)" (?inverse@Xform3D@@QAEPAV1@XZ)
9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_InBetween@20 referenced in function "public: class Xform3D * __thiscall Xform3D::inBetween(class Xform3D *,double)" (?inBetween@Xform3D@@QAEPAV1@PAV1@N@Z)
9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_ShiftGet@8 referenced in function "public: double __thiscall Xform3D::getShift(int)" (?getShift@Xform3D@@QAENH@Z)
9>1>MicronTrackerInterface.lib(Xform3D.obj) : error LNK2019: unresolved external symbol _Xform3D_RotateLocation@16 referenced in function "public: void __thiscall Xform3D::getRotateVector(double *,double *,bool)" (?getRotateVector@Xform3D@@QAEXPAN0_N@Z)
9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_New@0 referenced in function "public: __thiscall Facet::Facet(int)" (??0Facet@@QAE@H@Z)

9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_Free@4 referenced in function "public: __thiscall Facet::~Facet(void)" (??1Facet@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_IdentifiedXPointsGet@12 referenced in function "public: int __thiscall Facet::getXpoints(class MCamera *,double *)" (?getXpoints@Facet@@QAEHPAVMCamera@@PAN@Z)
9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_TemplateVectorsGet@12 referenced in function "public: class std::vector<class Vector *,class std::allocator<class Vector *> > __thiscall Facet::TemplateVectors(void)" (?TemplateVectors@Facet@@QAE?AV?$vector@PAVVector@@V?$allocator@PAVVector@@@std@@@std@@XZ)

9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_IdentifiedVectorsGet@12 referenced in function "public: class std::vector<class Vector *,class std::allocator<class Vector *> > __thiscall Facet::IdentifiedVectors(void)" (?IdentifiedVectors@Facet@@QAE?AV?$vector@PAVVector@@V?$allocator@PAVVector@@@std@@@std@@XZ)

9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_SetTemplateVectorsFromSamples@16 referenced in function "public: bool __thiscall Facet::setVectorsFromSample(class std::vector<class Collection *,class std::allocator<class Collection *> > &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > &,double)" (?setVectorsFromSample@Facet@@QAE_NAAV?$vector@PAVCollection@@V?$allocator@PAVCollection@@@std@@@std@@AAV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@3@N@Z)

9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_Identify@20 referenced in function "public: bool __thiscall Facet::identify(class MCamera *,class std::vector<class Vector *,class std::allocator<class Vector *> >,double)" (?identify@Facet@@QAE_NPAVMCamera@@V?$vector@PAVVector@@V?$allocator@PAVVector@@@std@@@std@@N@Z)
9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_ValidateTemplateVectors@4 referenced in function "public: bool __thiscall Facet::validateTemplate(double,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >)" (?validateTemplate@Facet@@QAE_NNV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)

9>1>MicronTrackerInterface.lib(Facet.obj) : error LNK2019: unresolved external symbol _Facet_Facet2CameraXfGet@12 referenced in function "public: class Xform3D * __thiscall Facet::getFacet2CameraXf(class MCamera *)" (?getFacet2CameraXf@Facet@@QAEPAVXform3D@@PAVMCamera@@@Z)

9>1>MicronTrackerInterface.lib(Vector.obj) : error LNK2019: unresolved external symbol _Vector_New@0 referenced in function "public: __thiscall Vector::Vector(int)" (??0Vector@@QAE@H@Z)

9>1>MicronTrackerInterface.lib(Vector.obj) : error LNK2019: unresolved external symbol _Vector_Free@4 referenced in function "public: __thiscall Vector::~Vector(void)" (??1Vector@@QAE@XZ)
9>1>MicronTrackerInterface.lib(Vector.obj) : error LNK2019: unresolved external symbol _Vector_EndPosGet@8 referenced in function "public: int __thiscall Vector::getEndPos3x2(double *)" (?getEndPos3x2@Vector@@QAEHPAN@Z)
9>1>MicronTrackerInterface.lib(Vector.obj) : error LNK2019: unresolved external symbol _Vector_EndXPointsGet@8 referenced in function "public: int __thiscall Vector::getEndXPoints(double *)" (?getEndXPoints@Vector@@QAEHPAN@Z)
9>1>C:\Users\Vikas\Documents\Research\Libraries\PLUS\Bin\bin\Debug\vtkTracking.dll : fatal error LNK1120: 96 unresolved externals
9>1>Build log was saved at "file://c:\Users\Vikas\Documents\Research\Libraries\PLUS\Bin\PlusLib-bin\src\Tracking\vtkTracking.dir\Debug\BuildLog.htm"
9>1>vtkTracking - 107 error(s), 0 warning(s)

#### 3 Comments
#### By Andras Lasso on 2012-11-02 21:06
The linker cannot find the basic functions (MTexit, Markers_LoadTemplates, ...) that are normally defined in MTC.lib. Check if your MICRONTRACKER_LIBRARY CMake variable is set correctly (it should contain the full path of a MTC.lib file that matches the header files defined in MICRONTRACKER_INCLUDE_DIR).
#### By Vikas Revanna Shivaprabhu on 2012-11-06 13:07
The problem was that I had installed 64-bit version of the drivers for the Micron Tracker and the linker was unable to find the functions in MTC.lib. After installing 32-bit version of the driver, the build was successful.
#### By Andras Lasso on 2012-11-06 17:25
Great. Thanks for letting us know.


## Can not do spatial calibration in fCal
#### Posted by Huoling on 2012-11-06 04:08

Hi,
I use NDI Polaris Spectra + DFG/USB2pro as the data collection device, and I've printed fCalPhantom 2.0, use 3NWire pattern. But when doing spatial calibration in fCal, the buttons in the "Spatial calibration" toolbox are all disabled(see attachments). The configuration file is attached as well.
Another question: The US images I obtained have multiple reflections. According the message: https://www.assembla.com/spaces/plus/messages/1978963#comment_1979753
I push my phantom deeper in the water (the depth is about 15cm), but it seems no effect. Any helps?
Thanks in advance!
Regards!

Huoling
Untitled.png	487 KB
PlusConfiguration_DFG-USB2PRO_NDIPolaris_20121106_151826.xml	6.48 KB
SegmentationParameterDialog_ExportedImage_20121106_164544.mha	433 KB

#### 0 Comments

## one fCal3.0 phantom design file is lost
#### Posted by jiafucang on 2012-10-30 05:37

Hi,

I want to produce one fCal3.0 phantom by NC maching rather than 3D prototyping. When I open fCal3.0.asm
in Solid Edge ST4, it says that "Can not find: C:\PlusBuild-Experimental\PlusLib\docs\fCAL\CAD\fCal_3.0_spacer.par".
Would you like to check this?

BTW, I am wonder to know if the current fCal application support both fCal2.0 and fCal3.0 phantom.

Thank you very much!
Best,
Fucang

#### 7 Comments
#### By Csaba Pinter on 2012-10-30 08:10
Hi Fucang,

Solid edge works (at least ST3 definitely worked) with absolute paths when it comes to assemblies' included parts and sub-assemblies, so probably you can only open that if you create the path that is searched. Sorry about the inconvenience. It has been an annoyance to me too.
You can use the STL files instead if it suits you.

fCal supports every version of the fCal phantoms. What you need to do is to change the PhantomDefinition section in the configuration file and do the proper wiring for that version.

Cheers,
csaba
#### By Jiafucang on 2012-10-30 09:46
Hi Csaba,

I created the absolute path C:\PlusBuild-Experimental\PlusLib\docs\fCAL\CAD directory, but there is no fCal_3.0_spacer.par file in the CAD directory, only
fCal3.0_spacer.asm file. So Solid Edge can not show the correct view as fCal3.0.stl does.

Thanks!
Fucang
#### By Jiafucang on 2012-10-30 10:40
Hi Csaba,

I think there should be a fCal_3.0_spacer.par besides the fCal3.0_spacer.asm file in the PlusLib/docs/fCAL/CAD directory.
Because fCal3.0 phantom is somehow big, the price of 3D printing is much expensive than NC machining which can not
use STL format.

Best,
Fucang
#### By Csaba Pinter on 2012-10-30 10:42
I see.
I wrote to Guillermo who designed the phantom and so created these files, I think he can help you better.
#### By Andras Lasso on 2012-10-30 11:57
The missing CAD file has been uploaded. fCal 3.0 is intended for 10-20cm deep calibration and it is still in experimental phase (e.g., we haven't determined an optimal wiring configuration yet). If you need calibration up to 5-10cm depth then I would recommend the smaller and more thoroughly tested fCal_2.0_Wiring_2.0 phantom (https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/docs/fCAL/CAD/PhantomDefinition_fCal_2.0_Wiring_2.0.png).
#### By GuillermoCarbajal on 2012-10-30 13:20
Hi Fucang,
Sorry for not responding sooner. Could you open the file?
As Andras said, fCal3.0 is in experimental phase so probably is better (safer and cheaper) fCal2.0.
Cheers,
Guillermo
#### By Jiafucang on 2012-10-30 20:15
Hi Gullermo and Andras,

After update to svn head, I can open the file now, thank you for your hints, I will print one 2.0 phantom firstly.

Best,
Fucang


## fCal can not connect to NDI vicra?
#### Posted by Huoling on 2012-10-29 03:33

Hi guys,
I've used fCal to connect to NDI vicra, the configuration code snippet as following:

<DataCollection StartupDelaySec="1.0">
<DeviceSet
Name="No video + NDI Polaris"
Description="Configuration file for No video + NDI Polaris 1: Probe, 2: Reference, 3: Stylus, 4: Needle(optional)"
/>

<Tracker Type="PolarisTracker" SerialPort="5" BaudRate="115200" BufferSize="2500" AcquisitionRate="50" AveragedItemsForFiltering="20" LocalTimeOffsetSec="0.0" >
<Tool Name="Tool" PortName="4" RomFile="NDI_ROM_Files\8700339.rom" />
<Tool Name="Stylus" PortName="5" RomFile="NDI_ROM_Files\8700340.rom" />
<Tool Name="Reference" PortName="6" RomFile="NDI_ROM_Files\8700449.rom" />
</Tracker>

</DataCollection>


But when connect, printing the following errors:

|INFO|003.920000| Toolbox changed to Configuration
|INFO|007.926000| Device set configuration is read from file: F:/Plus/PlusConfig
uration/PlusConfiguration_NoVideo_NDIPolaris.xml
|INFO|007.982000| Connect to devices
|INFO|021.790000| Tools local time offset: 0ms
|ERROR|023.294000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(1188)
|ERROR|023.333000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(1188)
|ERROR|023.352000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(1188)
|ERROR|023.390000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(837)
|ERROR|023.409000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(837)
|ERROR|023.427000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(837)
|ERROR|046.514000| Command is invalid while in the current mode|in ..\..\..\Plus
Lib\src\Tracking\PolarisTracking\vtkNDITracker.cxx(394)
|ERROR|046.629000| Failed to start tracking!|in ..\..\..\PlusLib\src\Tracking\vt
kTracker.cxx(255)
|ERROR|046.663000| Failed to start tracking!|in ..\..\..\PlusLib\src\DataCollect
ion\vtkDataCollector.cxx(334)
|ERROR|046.679000| Unable to start collecting data!|in ..\..\PlusApp\fCal\Toolbo
xes\ConfigurationToolbox.cxx(188)

Anyone knows the reason? Thank you!

#### 1 Comments
#### By Huoling on 2012-10-29 03:51
I've changed another serial port, and it works. :-)


## How to edit configuration file for VFWVideo image acquisition devices
#### Posted by Huoling on 2012-10-23 03:48

Hi,

The site: https://www.assembla.com/spaces/plus/wiki/Hardware_setup gives an instruction to edit the configuration file. But for VFWVideo device set, the instruction is very simple, only list the device type. Anyone can tell me how to set other options?
The framegrabber I used is "Microview V110" (http://www.microview.com.cn/en/index.asp)

Best Regards!

#### 2 Comments
#### By Andras Lasso on 2012-10-23 10:18
We plan to improve the documentation of device set config files in the near future, see #619. Until then you can check out the sample config files and the code.
To answer your question: the VFW video source does not have any custom parameters, see a sample config file here: https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/data/ConfigFiles/Testing/PlusConfiguration_WebCam_FakeTracker.xml?rev=2197.
We are not aware of any serious use of the Video for Windows interface (we use ImagingControls and Epiphan framegrabbers for real work, and use VFW only for demos and testing with webcams), therefore we have not invested too much time into perfecting it. See the currently known limitations at ticket #454. If you have any specific problems or requests related to using this video source then enter as
####  comments for #454.
#### By Huoling on 2012-10-24 04:07
Thank you Andras, I've connected VFWVideo successfully by following your instruction.
But now I encounted another problem. I've attached two files: VFWVideo_Normal.png and VFWVideo_Abnormal.png. When connecting VFWVideo, I got the abnormal video by fCal, and the console print some error messages, like: " |ERROR|085.364000| Unable to convert Timestamp '-1.#IND00' to double|in ..\..\..\PlusLib\src\PlusCommon\TrackedFrame.cxx(283)". What's the cause of the abnormal video? Thank you!
VFWVideo_Abnormal.png	574 KB
VFWVideo_Normal.png	239 KB


## Errors when building fCal
#### Posted by Huoling on 2012-10-21 23:25

Hi,
I'm newer to PLUS. When Building fCal application, I encounted the following errors:

1>------ Build started: Project: fCal, Configuration: Debug Win32 ------
1>Compiling...
1>fCalMainWindow.cxx
1>Linking...
1> Creating library F:\Plus\PlusBuild\bin\Debug\fCal.lib and object F:\Plus\PlusBuild\bin\Debug\fCal.exp
1>fCalMainWindow.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: __thiscall QGridLayout::QGridLayout(class QWidget *,int,int,int,int,char const *)" (__imp_??0QGridLayout@@QAE@PAVQWidget@@HHHHPBD@Z) referenced in function "protected: void __thiscall fCalMainWindow::CreateToolboxes(void)" (?CreateToolboxes@fCalMainWindow@@IAEXXZ)

1>ConfigurationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: __thiscall QGridLayout::QGridLayout(class QWidget *,int,int,int,int,char const *)" (__imp_??0QGridLayout@@QAE@PAVQWidget@@HHHHPBD@Z)
1>TemporalCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: __thiscall QGridLayout::QGridLayout(class QWidget *,int,int,int,int,char const *)" (__imp_??0QGridLayout@@QAE@PAVQWidget@@HHHHPBD@Z)
1>CommonWidgets.lib(ToolStateDisplayWidget.obj) : error LNK2001: unresolved external symbol "__declspec(dllimport) public: __thiscall QGridLayout::QGridLayout(class QWidget *,int,int,int,int,char const *)" (__imp_??0QGridLayout@@QAE@PAVQWidget@@HHHHPBD@Z)
1>ConfigurationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setBackgroundColor(class QColor const &)" (__imp_?setBackgroundColor@QWidget@@QAEXABVQColor@@@Z) referenced in function "protected: void __thiscall ConfigurationToolbox::ConnectToDevicesByConfigFile(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >)" (?ConnectToDevicesByConfigFile@ConfigurationToolbox@@IAEXV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)

1>TemporalCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setBackgroundColor(class QColor const &)" (__imp_?setBackgroundColor@QWidget@@QAEXABVQColor@@@Z)

1>ConfigurationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setCaption(class QString const &)" (__imp_?setCaption@QWidget@@QAEXABVQString@@@Z) referenced in function "protected: void __thiscall ConfigurationToolbox::ConnectToDevicesByConfigFile(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >)" (?ConnectToDevicesByConfigFile@ConfigurationToolbox@@IAEXV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)

1>TemporalCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setCaption(class QString const &)" (__imp_?setCaption@QWidget@@QAEXABVQString@@@Z)

1>ConfigurationToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: char const * __thiscall QString::ascii(void)const " (__imp_?ascii@QString@@QBEPBDXZ) referenced in function "protected: void __thiscall ConfigurationToolbox::LogLevelChanged(int)" (?LogLevelChanged@ConfigurationToolbox@@IAEXH@Z)
1>CapturingToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: char const * __thiscall QString::ascii(void)const " (__imp_?ascii@QString@@QBEPBDXZ)

1>PhantomRegistrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z)

1>VolumeReconstructionToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z) referenced in function "public: virtual void __thiscall VolumeReconstructionToolbox::SetDisplayAccordingToState(void)" (?SetDisplayAccordingToState@VolumeReconstructionToolbox@@UAEXXZ)

1>CapturingToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z)

1>SpatialCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z)

1>TemporalCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z)

1>StylusCalibrationToolbox.obj : error LNK2001: unresolved external symbol "__declspec(dllimport) public: void __thiscall QWidget::setPaletteForegroundColor(class QColor const &)" (__imp_?setPaletteForegroundColor@QWidget@@QAEXABVQColor@@@Z)

1>CapturingToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: int __thiscall QAbstractSlider::maxValue(void)const " (__imp_?maxValue@QAbstractSlider@@QBEHXZ) referenced in function "protected: void __thiscall CapturingToolbox::SamplingRateChanged(int)" (?SamplingRateChanged@CapturingToolbox@@IAEXH@Z)
1>VolumeReconstructionToolbox.obj : error LNK2019: unresolved external symbol "__declspec(dllimport) public: __thiscall QString::operator char const *(void)const " (__imp_??BQString@@QBEPBDXZ) referenced in function "protected: enum PlusStatus __thiscall VolumeReconstructionToolbox::ReconstructVolumeFromInputImage(void)" (?ReconstructVolumeFromInputImage@VolumeReconstructionToolbox@@IAE?AW4PlusStatus@@XZ)

1>CommonWidgets.lib(ConfigFileSaverDialog.obj) : error LNK2001: unresolved external symbol "__declspec(dllimport) public: __thiscall QString::operator char const *(void)const " (__imp_??BQString@@QBEPBDXZ)

1>CommonWidgets.lib(StatusIcon.obj) : error LNK2019: unresolved external symbol "__declspec(dllimport) public: int __thiscall QString::find(class QChar,int,bool)const " (__imp_?find@QString@@QBEHVQChar@@H_N@Z) referenced in function "public: void __thiscall StatusIcon::AddMessage(class QString)" (?AddMessage@StatusIcon@@QAEXVQString@@@Z)

1>CommonWidgets.lib(ConfigFileSaverDialog.obj) : error LNK2019: unresolved external symbol "__declspec(dllimport) public: class QString __thiscall QTextEdit::text(void)const " (__imp_?text@QTextEdit@@QBE?AVQString@@XZ) referenced in function "protected: void __thiscall ConfigFileSaverDialog::SaveClicked(void)" (?SaveClicked@ConfigFileSaverDialog@@IAEXXZ)

1>CommonWidgets.lib(SegmentationParameterDialog.obj) : error LNK2019: unresolved external symbol "__declspec(dllimport) public: void __thiscall QLabel::setAlignment(enum Qt::AlignmentFlag)" (__imp_?setAlignment@QLabel@@QAEXW4AlignmentFlag@Qt@@@Z) referenced in function "public: void __thiscall Ui_SegmentationParameterDialog::setupUi(class QDialog *)" (?setupUi@Ui_SegmentationParameterDialog@@QAEXPAVQDialog@@@Z)

1>F:\Plus\PlusBuild\bin\Debug\fCal.exe : fatal error LNK1120: 10 unresolved externals
1>Build log was saved at "file://f:\Plus\PlusBuild\PlusApp-bin\fCal\fCal.dir\Debug\BuildLog.htm"
1>fCal - 23 error(s), 0 warning(s)
========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========

But I don't know how to solve these problem. Any help will be appreciated!

Best Regards!

Huoling
BuildLog.htm	40.8 KB

#### 3 Comments
#### By Huoling on 2012-10-22 22:09
Maybe the following information is useful:
Window7 32bit; VS2008 sp1; Qt 4.8.2;
PLUS set supperbuild.
#### By Andras Lasso on 2012-10-22 23:03
The recommended external library versions for Plus are the same as for 3D Slicer. Therefore, we currently use Plus with QT-4.7.4.
Anyway, I've tried today building Plus with QT-4.8.3 (http://releases.qt-project.org/qt4/source/qt-win-opensource-4.8.3-vs2008.exe) and it worked without any problems.
Double-check your QT version: the package should be complete and match your compiler version (VS2008) and bitness selected in CMake (32/64-bit).
#### By Huoling on 2012-10-23 02:44
Andras, thank you very much! According to you tips, I've build fCal success. It's the problem of the Qt version I've installed.


## Epiphan grabber hardware cropping setup
#### Posted by lion2012 on 2012-10-20 07:25

Hi,

May I know how to set up the hardware cropping setup for Epiphan grabber? I could use the GUI tool from Epiphan to do the hardware cropping. After I quit the Epiphan software and launched plus, the whole screen is captured. How do I setup the hardware cropping to be used in plus?

Thanks.

David

#### 4 Comments
#### By Andras Lasso on 2012-10-20 08:44
Use the ClipRectangleOrigin and ClipRectangleSize attributes, e.g.,
~~~~
<ImageAcquisition Type="Epiphan"
BufferSize="100"
AcquisitionRate="30"
UsImageOrientation="MF"
AveragedItemsForFiltering="20"
ClipRectangleOrigin="0 0" ClipRectangleSize="820 616"
/>
~~~~
#### By Lion2012 on 2012-10-21 07:51
Andras:

Thanks a lot.

One more question regarding documentation. I found the pluslib doc generated by doxgen. Other than this file and docs under PlusLib directory, is there other documentation related to the fCal software? I felt that I need more documentation for using the software, such as this configuration file, segmentation parameter, etc.

Thanks.

David
#### By Andras Lasso on 2012-10-21 15:59
I agree that the documentation of device set config files is not comprehensive. There is an overview on the Configuration_file_structure page and there are many example config files at https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/data/ConfigFiles. However, detailed information about the attributes is available by reading the code only. I've added #619 to track this issue.

The description of the calibration procedure using fCal is available here: https://www.assembla.com/spaces/plus/wiki/System_calibration. Let us know if you have any question that is not described there and then we add more details.
#### By Lion2012 on 2012-10-22 12:02
Thanks.

I do have issues with the clip. Here is the configuration file and saved snapshot in the capture window. Looks like the image are misaligned. I don't know why. Is there any requirement of the clip region parameter?

David
TrackedImageSequence_20121022_220314_clip_config.xml	6.35 KB
PlusConfiguration_Epiphan_Ascension3DG_L14_fCal2.0_20121020_083110_clip.xml	6.35 KB
TrackedImageSequence_20121022_220314_clip.mha	422 KB


## Falcon Frame Grabber
#### Posted by camilocortes on 2012-10-19 06:13

Hello

I would like to know if there are any plans to give support to Falcon frame grabbers (http://www.ids-imaging.com/frontend/accessories.php?group=47&group2=47), or if someone is already working on it. If not, I may undertake this task, but I will need some help.

Thansk

Camilo

#### 1 Comments
#### By Andras Lasso on 2012-10-19 07:00
We haven't planned to add support for these devices but we are open to that. Do they accessible through Video for Windows (vfw) interface? If yes, then we could just improve the existing vfw class to handle these framegrabbers.


## Qt 4.8.3 on Windows Embedded XP
#### Posted by Siavash Khallaghi on 2012-10-17 14:24

Hello everyone,

Just an observation that took us (Samira and I) 48 hours to make a conclusion on. We are working on a different site and we were using Qt 4.8.3 to build Plus and consecutively our own application.

Now, something very interesting happens when we try to run our own application. Everything is normal if we connect using a remote machine to Ulterius, but on the Sonix-Touch itself, our application either terminates on startup or, later on, our Qthreads terminate suddenly.

Interestingly, these issues were resolved once we reverted back to Qt 4.7.3.

Siavash

#### 2 Comments
#### By Andras Lasso on 2012-10-17 21:51
Which SDK version do you have on the SonixTouch? The Ulterius 6.x SDK uses Qt and may conflict with the Qt in your application.
#### By Siavash Khallaghi on 2012-10-18 21:54
It was SDK 5.7.3a. If I were to make a guess, I would say that Qt exceptions were not being handled properly, and this was causing the threads to terminate prematurely.

## Issues with building Plus on 64 bit machines (Windows 7)
#### Posted by Siavash Khallaghi on 2012-03-02 22:00

Hi guys,

When trying to build Plus on Windows 7, Visual studio 2008 professional SP 1, I get the following error while trying to build it in the x64 setting (i.e. by selecting Visual Studio 2008 X64 in CMake configuration):

------ Build started: Project: vtksys, Configuration: Debug x64 ------
"Generating vtksysProcessFwd9xEnc.c "
The application has failed to start because its side-by-side configuration is incorrect. Please see the application event log or use the command-line sxstrace.exe tool for more detail.

However everything is fine with x32 compiler.

#### 6 Comments
#### By Andras Lasso on 2012-03-02 22:39
Regardless of using a 32-bit or 64-bit Windows, by default you build 32-bit applications (you don't need to select 64-bit builds just because the OS is 64-bit).

If you specifically want to build a 64-bit exe, then read the general notes section in https://www.assembla.com/spaces/plus/wiki/Build_instructions. The builds should work with some changes, but this is not a supported or tested feature.

Have you built QT in 64-bit debug mode (the precompiled binary distribution is 32-bit only)?
You can debug side-by-side assembly loading problems by using sxstrace (http://blogs.msdn.com/b/junfeng/archive/2006/04/14/576314.aspx).
#### By Siavash Khallaghi on 2012-10-03 22:09
Hi Andras,

I am trying to build Qt from scratch because I am trying to build a 64-bit version of Plus for volume reconstruction. The problem that I have is that the compiler (?) complains that the side-by-side configuration is incorrect. This happens when I am trying to build Qt from source code.

Is it possible to put a step by step guide on how to compile a 64-bit version of Qt? Here is what I have done so far:

1. Download qt-everywhere-opensource-src-4.7.4.zip from Qt-website.
2. Extract the contents to C:\Qt\4.7.4
3. Open Visual Studio 2008 x64 Command Prompt and browse to C:\Qt\4.7.4
4. Run the following commands:
configure -debug-and-release -opensource -platform win32-msvc2008
qmake
nmake

The error happens during the configuration phase of Qt. I have tried substituting -platform win32-msvc2008 with win64-msvc2008, but it did not change anything. I am hesitant into trying msvc2010 because I know it is not fully supported by Plus as of yet.

Am I missing something? Do you have any ideas? I would really appreciate your insight.
#### By Csaba Pinter on 2012-10-03 22:16
Hi Siavash,

You can find the detailed instructions here:
http://www.slicer.org/slicerWiki/index.php/Documentation/4.1/Developers/Build_Instructions/Prerequisites/Qt#Windows_4

I think the thing you miss is that you have to run the commands from the Visual Studio 2008 x64 Win64 Command Prompt (which you can find in start menu)

csaba
#### By Andras Lasso on 2012-10-04 04:14
We have win64 continuous builds, which confirms that 64-bit builds are working fine. Check what Csaba suggested and also that you unselect all devices with 32-bit only driver when you configure the project. Open the application that complains about side-by-side issues in depends.exe to see if there are any obvious errors. If it doesn't help then use sxstrace.exe to debug the assembly loading. By the way, things mostly work with VS2010, see #162 for the list of limitations.
#### By Siavash Khallaghi on 2012-10-04 19:35
Thank you for the
####  comments. I checked the instructions in the Slicer wiki and it turns out that I forgot to install SP1 for Visual Studio 2008 (this is a new PC).
The debug build just finished right now, and I managed to launch fCal. The CMake flags for Ascension and SonixVideo are set to false in my current build.
I am building Plus in release mode right now.

#### By the way, all VTK projects build except for vtk__H5TN_init_interface, which depends on H5TN_init_interface. I don't know if this is related to a bad git checkout. Other than this everything works fine.
#### By Siavash Khallaghi on 2012-10-04 20:42
I did a clean debug build and the above issue is resolved. There are no errors.


## Out of Office AutoReply: #461: Change DataCollector design to stream based devices
#### Posted by Cristian Linte on 2012-09-28 13:48

I will be traveling until Oct. 11th, 2012 with sporadic email contact. I will reply to your message upon my return.

Regards,

CL 


#### 0 Comments


## help on phantom registration
#### Posted by lion2012 on 2012-09-23 23:22

Dear member:

May I ask help on phantom registration? I am using phantom version 2.0 and Ascension tracker. Here is the details.

The stylus calibration is ok, as seen in stylus_cal.png, error is 0.27mm. So I think the tracker is ok.

The phantom registration error is 13mm. From the snapshot phantom_reg.png, the wiring is clearly wrong. Something is wrong with my configuration file on the phantom? I did not see much difference between my configuration file from others.

Most likely I may made mistake on the configuration file. Could someone help?

I posted the configuration file, log and some snapshots here. Thanks.

David
092312_110546_PlusLog.txt	181 KB
PlusConfiguration_Epiphan_Ascension3DG_fCal2.0.xml	5.64 KB
phantom_reg.png	104 KB
stylus_cal.png	245 KB

#### 6 Comments
#### By Lion2012 on 2012-09-25 18:48
Anyone could help to take a look or give some hint? I think I may need help on the configuration file with asension tracker / fcal 2.0. If someone could confirm if the data in the configuration file is correct? Thanks.
#### By Bartłomiej Pyciński on 2012-09-26 03:33
I am not sure, but I think, that you have in your xml transformation matrix from phantom 1.2. In version 2.0 the geometry of model is different - try this (from file PlusConfiguration_File_fCal_2.0.xml):
~~~~
<DisplayableObject Id="PhantomModel" Type="Model" ObjectCoordinateFrame="Phantom"
Opacity="0.6"
File="FCal_2.0.stl"
ModelToObjectTransform="
1 0 0 -35.0
0 1 0 -10.0
0 0 1 -5.0
0 0 0 1"
/>
~~~~
#### By Csaba Pinter on 2012-09-26 08:54
Hi David,

First, please switch your Plus working copy to the 1.6 branch (https://subversion.assembla.com/svn/plus/branches/Plus-1.6), and do an update.
You will see that we made some changes in the example configuration files for the fCal 2.0 phantom, just to fix the issue you're having. The problem in your case is with the ModelToObjectTransform as Bartłomiej pointed out.

Still, the high phantom registration error has nothing to do with the wiring, as it comes in the picture with the spatial calibration step.
I'll look into your log file to see what could go wrong.
#### By Csaba Pinter on 2012-09-26 09:01
The first problem I found is that your configuration file contains PhantomDefintion of the fCal 1.2 phantom. Please replace the PhantomDefintion section with the one in PlusConfiguration_File_fCal_2.0.xml or other fCal 2.0 example.
#### By Csaba Pinter on 2012-09-26 09:03
Oh, and thank you for uploading everything we need to identify your problem! :)
The debug level log file and the screenshot are a great help!
#### By Lion2012 on 2012-09-27 05:34
Hi, Bartłomiej and Csaba:

Thanks so much for helping out quickly. I somehow picked up the wrong fCal 2.0 configuration. The two configuration files are different in a large extent. Thanks again.

David


## volume reconstruction sample xml missing
#### Posted by Elvis Chen on 2012-09-25 15:30

hi all,

in browsing the wiki page for volume reconstruction (https://www.assembla.com/spaces/plus/wiki/Volume_Reconstruction), the sample xml file seemed to be missing from the svn server:

https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/data/TestImages/NwirePhantomFreehandReconstructionOnly.xml

Can someone please fix the link (the xml is actually missing from the above svn directory) or post it here?

thanks,

#### 1 Comments
#### By Andras Lasso on 2012-09-26 04:47
I've updated the links. Note that there are several volume reconstruction examples in the nightly tests ( all the test cases starting with "vtkVolumeReconstructor").


## Failed to get video buffer
#### Posted by Bartłomiej Pyciński on 2012-09-21 09:04

I am trying to proceed whole callibration process, but there are some problems with acquiring the image. When I try to perform temporal calibration or when I try capture video at "Capturing" tab I get errors, that I can't figure, what do they mean.

092112_135834.593|ERROR|092.435000| Failed to get video buffer item UID from time: 80.260686|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollector.cxx(838)
092112_135834.613|ERROR|092.455000| Failed to get tracked frame list from data collector (last recorded timestamp: 76.474543|in ..\..\PlusApp\fCal\Toolboxes\TemporalCalibrationToolbox.cxx(549)

I can connect to the framegrabber without problem and I can see streaming, anyway.

I use ICC framegrabber, Polaris Spectra tracker, Win7, VS2010 32bit, PlusLib rev 2119.

Thanks for help for advance. Full logs and config file attached.
Bartłomiej Pyciński
PlusConfiguration.xml	6.54 KB
092112_141829_PlusLog.txt	1.81 MB
092112_135702_PlusLog.txt	3.27 MB

#### 2 Comments
#### By Andras Lasso on 2012-09-21 14:51
See #604. A related bug were found and fixed, update and rebuild. Also try the suggestions (increase buffer sizes, etc.) described in the ticket.
#### By Bartłomiej Pyciński on 2012-09-21 15:31
Than you very much for your feedback, I will test it on Monday and inform you of the results.


## Time synchronization in PLUS
#### Posted by Andinet Enquobahrie on 2012-09-20 13:25

Hi,

How is time synchronization done in PLUS? Are you using a pulse generator with a real time clock like the one in ITK ( http://www.itk.org/Doxygen/html/classitk_1_1RealTimeClock.html)

thanks,
Andinet

#### 2 Comments
#### By Csaba Pinter on 2012-09-20 13:37
You can find information about it here:
https://www.assembla.com/spaces/plus/wiki/Temporal_Calibration

(This page was not in the list as it was somehow moved to the archived list. Now I moved it back)
#### By Andras Lasso on 2012-09-20 14:06
As I see ITK (at least ITKv3) just queries the time using QueryPerformanceCounter. We use the same in Plus for getting the current time.

However, the challenging stuff is not having an accurate stopwatch, but having an accurate timer (delay).
We have a very accurate solution for that in Plus for Windows, which quite reliably provides 1ms accuracy, see vtkAccurateTimer.

If you were interested in the temporal calibration (video/tracking stream synchronization) method, it's described in the System_calibration page (the dedicated page is obsolete, now all the calibration process is described in one page). The stdev of repeated synchronization is typically just a few msec, even if no hardware timestamping is available.


## vtkDataCollectorTrackingTest?
#### Posted by Andinet Enquobahrie on 2012-09-19 17:09

Hi all,

I did a fresh build of PLUS but I couldn't find vtkDataCollectorTrackingTest

In..PlusLib

find . -name "vtkDataCollector*" -print
./src/DataCollection/Testing/vtkDataCollectorFileTest.cxx
./src/DataCollection/Testing/vtkDataCollectorTest1.cxx
./src/DataCollection/Testing/vtkDataCollectorTest2.cxx
./src/DataCollection/Testing/vtkDataCollectorVideoAcqTest.cxx
./src/DataCollection/vtkDataCollector.cxx
./src/DataCollection/vtkDataCollector.h
./src/DataCollection/vtkDataCollectorSynchronizer.cxx
./src/DataCollection/vtkDataCollectorSynchronizer.h

Has it been renamed?

Andinet

#### 2 Comments
#### By Csaba Pinter on 2012-09-19 17:19
Hi Andinet,

Yes, it has been renamed to TrackingTest and moved to DataCollection/Applications. See #477 for details.

csaba
#### By Andinet Enquobahrie on 2012-09-20 13:22
Got it. Thanks!!


## Tool to perform coordinate computations?
#### Posted by Tamas Ungi on 2012-09-13 11:21

Is EditSeqMetaFile.exe or any other example able to process a saved (mha) tracked frame list and add an extra Transform to the frame fields?
E.g. if the mha contains ProbeToTracker, and the config file contains ImageToProbe, can I generate an output mha file with ImageToTracker for every frame?

#### 3 Comments
#### By Csaba Pinter on 2012-09-13 11:31
There is an ADD_TRANSFORM operation of the EditSeqMetaFile application, which is (I think) just what you need.

I tried it and worked. My command line was:

C:\devel\Plus\Plus-bin\bin\Release>EditSeqMetaFile.exe --input-file-name=c:\devel\Plus\Plus-bin\PlusLib\data\TestImages\fCal_Test_Calibration_3NWires_fCal2.0.mha --operation=ADD_TRANSFORM --add-transform=ImageToTracker --output-file-name=d:\test.mha --device-set-configuration-file-name=c:\devel\Plus\Plusbin\PlusLib\data\ConfigFiles\PlusConfiguration_File_fCal_2.0_20120913_112754.xml
#### By Csaba Pinter on 2012-09-13 11:33
You may want to compress the output file (reduces the size by more than 95%) with adding --use-compression
#### By Tamas Ungi on 2012-09-13 11:33
Thank you Csaba.
And Andinet (from Kitware) thanks too :-)


## How to build plus package using offline files (downloaded through svn)
#### Posted by lion2012 on 2012-09-11 21:48

Hi,

I have a build issue related to plus package.

I have download and build itk/vtk/plus (trunk). And I have configured plus using CMake. During the build process in vc 2008, the build script automatically re-download itk vtk (into plusbuild/vtk and plusbuild/itk directories respectively) and rebuild both. However, the file vtkYoungsMaterialInterface.cxx in plusbuild/vtk/Graphics directory does not pass the build and caused the failure. I have manually copy the same file from vtk 5.6.1 to overwrite it.

Is there a way to build plus package using all files local (such vtk, itk, pluslib, plus app). I have downloaded all plus packages through svn, there is no need to re-download them again during the building process (took a lot of time).

FYI, the cmake source directory I put in CMake is the svn /trunk/PlusBuild directory.

Thanks.

-David

#### 1 Comments
#### By Andras Lasso on 2012-09-12 02:02
It is recommended to let Plus download and build ITK and VTK, as it ensures that the correct version and build options are used. Anyway, a new feature is added in #588 so now you can specify ITK_DIR, VTK_DIR in PlusBuild if you have an existing ITK_DIR and VTK_DIR that you want to reuse.

The vtkYoungsMaterialInterface.cxx file in VTK has some high code characters, which breaks the build on Chinese computers. We'll update Plus to use VTK-5.10 soon to resolve this. See more details in #331.


## PlusApp-bin\BuildAndTest.bat can fail even though generated code is likely fine
#### Posted by Andrei State on 2012-08-31 02:39

The above batch file is normally run from a command window. On a system with more than one display monitor, if that command window is located on a non-primary monitor, tests 1, 3, and 4 fail, possibly because the program windows open on the same non-primary monitor the command window is on.

Second issue; independently of the number of monitors (so even with a single monitor), if one uses a non-Wndows-7 desktop theme (such as Windows Classic), at a minimum tests 1 and 4 will fail.

This should help reproduce the above behavior:

C:\Users\andrei\devel\PlusExperimental-bin\bin\Release>PlusVersion.exe
|INFO|000.000000| PlusLib version: 1.5.3
|INFO|000.000000| Plus SVN revision: 2033
|INFO|000.018000| Build mode: Win32
|INFO|000.058000| Supported tracker devices:
- ChRobotics (ver: Plus-1.5.3)
- FakeTracker (ver: Plus-1.5.3)
- OpenIGTLinkTracker (ver: OpenIGTLink v@PLUS_OPENIGTLINK_VERSION)

- SavedDataset (ver: Plus-1.5.3)

|INFO|000.259000| Supported video capturing devices:
- Epiphan (ver: Plus-1.5.3)
- NoiseVideo (ver: Plus-1.5.3)
- OpenIGTLinkVideo (ver: OpenIGTLink v@PLUS_OPENIGTLINK_VERSION)

- SavedDataset (ver: Plus-1.5.3)
- UsSimulator (ver: Plus-1.5.3)

#### 5 Comments
#### By Andras Lasso on 2012-08-31 08:37
Thank you for reporting this, I've added #581 to tack the resolution.
#### By Csaba Pinter on 2012-08-31 09:56
Unfortunately we have lots of issues with the GUI tests and it is very unreliable. I applied many fixes (mostly workarounds for problems they claimed to fix), but they only partially help apparently.
Although the project owner keeps telling me (in the answers to my emails) that the Sikuli project is still alive, the website and the environment has not been touched since last September.
Maybe it is time to discuss whether we should continue using Sikuli.
#### By Andras Lasso on 2012-08-31 10:11
@pinter: Can you drop an email to the Sikuli guys, asking about solutions for the specific problems we have?
The lack of robustness in text recognition seems to be a Sikuli issue that we could report.
Are the multi-screen issues caused by a Sikuli bug that we should report (or could be an enhancement request for a multi-screen Find function)?
Can we report the theming related problem to Sikuli or we should implement it differently (using OCR instead of finding graphics, adding alternative graphics, increase the tolerance...)?
#### By Andras Lasso on 2012-08-31 10:14
post further updates/discussion at #581
#### By Csaba Pinter on 2012-08-31 10:15
Sure. I'll also ask about the locked screen issue. I think it is the biggest drawback right now (that Sikuli cannot perform when the screen is locked on Windows. They could solve it on other OSes...)


## Is support for NDI Optotrak Polaris and Aurora fully functional?
#### Posted by Andrei State on 2012-08-31 02:19

Hello, I plan to use PLUS for a project and would like to know whether Polaris and Aurora support is fully functional now. I don't have the trackers available yet, otherwise I could test it myself. The messages at https://www.assembla.com/spaces/plus/messages/1605943#comment_1606073 seem to imply that support is complete, but there are still non-fixed tickets #336 and #467 about the Polaris.

#### 1 Comments
#### By Andras Lasso on 2012-08-31 08:33
Tracking with both Polaris and Aurora works well. I'll do some more testing with Polaris and Aurora for the 1.5.4 release, which is due within a few days and update #336 accordingly (#467 is a duplicate ticket, already closed).


## Volume Reconstructor in fCal
#### Posted by Vikas Revanna Shivaprabhu on 2012-08-08 16:10

Hi,

Can the volume reconstruction interface in fCal be used for reconstruction ?
I get the following error when i run the reconstruction within fCal:

|ERROR|3165.214000| Failed to add tracked frame to volume with frame #1321|in ..
\..\PlusApp\fCal\Toolboxes\VolumeReconstructionToolbox.cxx(368)
|ERROR|3165.221000| Transform name is invalid|in ..\..\..\PlusLib\src\PlusCommon
\vtkTransformRepository.cxx(250)
|ERROR|3165.228000| Failed to get transform name - 'From' transform name is empt
y|in ..\..\..\PlusLib\src\PlusCommon\PlusCommon.cxx(95)
|ERROR|3165.234000| Failed to get transform '' from transform repository!|in ..\
..\..\PlusLib\src\VolumeReconstruction\vtkVolumeReconstructor.cxx(570)

I am able to run the volume reconstruction with the same config file and input volume using command line interface.
I think the error is because "input-transform-name=ImageToReference" is absent. Is there a way to specify this in the config file ?

Thanks
Vikas

#### 8 Comments
#### By Tamas Ungi on 2012-08-08 16:28
Hi Vikas. Indeed, it looks like you are missing a transform from your config file. Could you attach your config file please?
#### By Vikas Revanna Shivaprabhu on 2012-08-08 17:46
Please find attached the config file.
PlusConfiguration_EpiphanLRNew_MicronTracker_20120717_112920.xml	11.8 KB
#### By Tamas Ungi on 2012-08-08 18:21
I suspect that something is missing from the input file. (The transform chain is complete in your config file.) Could you save the collected tracked frame list and check the header of the file, especially around frame #1321?
#### By Vikas Revanna Shivaprabhu on 2012-08-08 18:56
I am able to obtain a 3D reconstructed volume when I run the VolumeReconstructor.exe from the command line using the same config file and input file. But I get these errors when I run the volume reconstruction algorithm using fCal's GUI.
I have only pasted part of the error here. I get the same set of errors for all the frames starting from frame 1.
#### By Andras Lasso on 2012-08-08 19:11
I've tested with the latest trunk version and the attached config file (same as yours only replaced the tracker and video source with saved data) and volume reconstruction in fCal worked well. Update your Plus version to the latest trunk and let us know if you still have problems.
PlusConfiguration_VR_test.xml	7.37 KB
#### By Vikas Revanna Shivaprabhu on 2012-08-09 18:18
Updating to the latest version solved the reconstruction problem. But now I am having another problem.

The tool state goes in and out of view rapidly. The status message flickers between 'Ok' and 'Missing'. I am confident that the markers are being tracked without the jitter. I tested with the previous version of fCal (the one I had before updating to the latest version) and this issue does not occur.

I tried changing the Image Acquisition 'Buffer Size' and fCal 'RecordingIntervalMs' and 'MaxTimeSpentWithProcessingMs' parameters.
#### By Tamas Ungi on 2012-08-09 19:16
I'm glad the reconstruction works now!

Please report the tracker problem in a separate thread. Maybe create an Issue directly. You use Micron Tracker if I remember well, right? We don't yet have one of those in our lab (although we have recently ordered one), so we had very limited chance to test that code in PLUS.
#### By Vikas Revanna Shivaprabhu on 2012-08-10 10:22
Yes, I am using Micron Tracker. I will create an issue directly.

Thanks


## FrameSize gone in Configuration file?
#### Posted by Elvis Chen on 2012-08-02 16:38

hi,

I just did a svn checkout of the latest PLUS source. Compared to my June build, I noticed the configuration file format has changed slightly. In particular, the FrameSize parameter is gone in the ImageAcquisition section.

How do I find out that the frame size?

any help is very much appreciated,

#### 11 Comments
#### By Andras Lasso on 2012-08-03 07:56
FrameSize is not an input to video sources any more but the recorded frame size is whatever the hardware provides. I think the frame size is shown in the log at debug level. You can also just grab a frame, save it to file, and have a look at the file header. From your own programs there is a get method to obtain the frame size. Some video sources allow cropping of the frames.

What would you need the frame size for? Show it to the user? Use it in your Plus-based application?
#### By Elvis Chen on 2012-08-03 09:57
I performed US calibration on our Ultrasonix linear probe (L14-5) and noticed that the calibration matrices were dramatically different between two versions of PLUS. One was compiled in June, the other compiled in July (30th, or so). It is not just slight offset, it would appear that the scaling was different (probably due to the frame size of the image acquired).

I'm using basically the same configuration file. The configuration file I used for the June-version of PLUS was what I contributed back to the repository (PlusConfiguration_SonixTouch_L14-5_NDIAurora_fCal_1.0_4cm.xml). I based this XML on PlusConfiguration_SonixTouch_L14-5_NDICertus_fCal_1.0.xml that was already in the repository and modified it for Aurora tracker. In the NDICertus version, the FrameSize set for SonixVideo was 820x616. An example of the calibration matrice for L14-5 at 4cm depth are:

TransducerOriginPixelToTransducerOrigin =
[0.050278306425827, 0, 0, 0,
0, 0.048755387704088, 0, 0,
0, 0, 0.047231299242459, 0,
0,0,0,1]

and ImageToProbe =
[-0.058278728700449, -0.005035635419992, 0.034517631200876, 11.3136,
0.037399631163945, 0.00119768298313, 0.054010458853676, -24.5595,
-0.005080577685566, 0.06657969885147, 0.001639100216609, 49.7608,
0, 0, 0, 1.0]



The configuration file for July-version of the PLUS was what was in the repository (ConfigFiles/Robarts/PlusConfiguration_SonixTouch_L14-5_NDIAurora_fCal_1.0_4cm.xml). I believe some of you cleaned up the xml file and updated it. The FrameSize was no longer in the SonixVideo, and the calibration matrices I got were:

TransducerOriginPixelToTransducerOrigin =
[0.069758410384294, 0, 0, 0,
0, 0.067698640741075, 0, 0,
0, 0, 0.065597789854349, 0,
0, 0, 0, 1]

ImageToProbe =
[-0.0506726 -0.00971093 0.0452955 13.6765
0.0464114 0.00218213 0.050061 -26.7573
-0.00559571 0.0657054 0.00503189 48.7957
0 0 0 1]

I suspect the change in scale was due to the image size. The default for SonixTouch should be 640x480; hence my question.

thanks,
#### By Andras Lasso on 2012-08-03 10:22
On Ultrasonix devices the frame size you get through the Ulterius interface is determined by the settings in the Exam software. As I remember the two available sizes are 640x480 and 820x616. You probably changed the settings in your Exam software since the last calibration.
#### By Tamas Ungi on 2012-08-03 11:48
If the image size can be set through Ulterius, would it be wise to put it in the config file as an option? Now that I regularly use SoundVelocity and Depth settings, I avoid a lot of setting mistakes that would make my calibration invalid.
We set the exam software to "full" (820x616) now manually before data collection. But what if somebody forgets?
Probably the size is not arbitrary, but something like DisplaySize="Normal" / DisplaySize="Full" in the config file?
#### By Elvis Chen on 2012-08-03 13:27
sorry, but where can you set the frame size in the exam software? I'm using 5.7.3 if it matters.

thanks,
#### By Elvis Chen on 2012-08-03 13:32
I just did another calibration and captures a frame inside fCal. The header file suggested that the image was indeed 820x616, and yet the scale seems different than my previous calibration (Using June build of PLUS, where "FrameSize= 820 616" was present in the configuration file.
#### By Csaba Pinter on 2012-08-03 13:51
Could you capture a calibration process? Just scan the phantom just as you would do it when calibrating, but use the Capturing tab instead of the Spatial calibration, and save the metafile from there.
It will save an mha and an xml, please send both.
Thanks!

PS: And double check the depth you're using just to be 100% sure.
#### By Andras Lasso on 2012-08-03 16:53
The ImageToProbe matrices are quite similar, so these differences may be normal.
#### By Andras Lasso on 2012-08-03 16:56
Tamas, controlling the image size through Ulterius is a good idea. Could you please check if it's among the parameters that we can control? Could you enter a ticket to track this? Thanks.
#### By Tamas Ungi on 2012-08-03 17:09
I've created the ticket: https://www.assembla.com/spaces/plus/tickets/567
#567
#### By Tamas Ungi on 2012-08-03 20:59
Elvis, there may be other ways to set the frame size. What I do is Menu/Administrator/Display/Screen. Full is the larger, Normal is the smaller.


## Plus with Slicer 4.1
#### Posted by GuillermoCarbajal on 2012-07-30 15:21

Hi,
I installed Slicer 4.1 for Developers and I would like to use PLUS with Slicer.
I can configurate the project with CMake but I have errors while compiling PlusLib. The first error is in the vtkPlusCommon project in the WindowsAccurateTimer.h file.
Error 1 error C2039: 'ostrstream' : is not a member of 'std'
It can be fixed by adding:
#include <strstream>
but then I have other errors. I attach you the build error.

If I install Plus without using Slicer I have no problems.
Thank in advance,
Guillermo
BuildLog.htm	69.8 KB

#### 0 Comments


## calibration matrix not orthogonal
#### Posted by Elvis Chen on 2012-07-11 10:05

hi,

I used fcal to calibrate an ultrasonix probe and noticed that the calibration matrix (Image to Probe) is not orthogonal. The matrix I got was:

m = [ -0.0581284, -0.00420584, 0.0359503, 11.3136;
0.0373263, 0.000742847, 0.0562522, -24.5595;
-0.00582967, 0.0640925, 0.00170713, 49.7608;
0, 0, 0, 1 ];

Notice the scaling.

let's define x,y,z and normalize them:

x = m(1:3,1)./norm(m(1:3,1))
y = m(1:3,2)./norm(m(1:3,2))
z = m(1:3,3)./norm(m(1:3,3))

then:
dot(x,y)=-0.022777

which is NOT insignificant. If one draws the resulting vtkImageActor and look closely, the vtkImageActor is NOT rectangular but parallelogram.


Is there a particular reason why PLUS return a non-orthogonal (rotation) calibration matrix? There is a simple fix: to refactor the rotational component using SVD. Or am I missing something?

#### 6 Comments
#### By Csaba Pinter on 2012-07-11 10:09
Elvis,
You are right.
We are aware of the issue and you can follow up in this ticket: https://www.assembla.com/spaces/plus/tickets/507
csaba
#### By Elvis Chen on 2012-07-11 10:23
One easy fix is:

[U,S,V] = svd(m(1:3,1:3));
R = U*V';

Now the R is the proper orthonormal matrix. In fact, the S is the scaling matrix (which is different from what PLUS calculates). If one wishes to put the anisotropic scaling back to R, I would do:

sx,sy,sz; // anisotropic scaling from, say, PLUS calibration
R(1:3,1) = R(1:3,1)*sx;
R(1:3,2) = R(1:3,2)*sy;
R(1:3,3) = R(1:3,3)*sz;

then:

m(1:3,1:3) = R;
#### By Csaba Pinter on 2012-07-11 10:25
Thanks, I added your comment to the ticket for future reference.
#### By Elvis Chen on 2012-07-11 10:25
I should note that this is a pure algebraic solution to obtain orthogonal rotation; doesn't mean this will result in a better calibration (i.e. lower FRE). But for visualization purpose, this may be a suitable fix.
#### By Andras Lasso on 2012-07-11 12:10
As Elvis noted, by post-processing the calibration matrix to make it orthogonal will not improve the actual calibration results.

There are two approaches to make the calibration results more accurate and valid:

1. Improve calibration input data. Non-orthogonal calibration matrix is mostly caused by inconsistent input data for the calibration (temporal shift, inaccurate segmented wire positions, etc.). A few tips for resolving the problem can be found here: https://www.assembla.com/spaces/plus/wiki/System_calibration ("The axes of the ImageToProbeTransform (calibration matrix) are not orthogonal").

2. Impose orthogonality constraint during calibration. The goal of the #507 ticket to constrain the calibration algorithm to always returns an orthogonal calibration matrix (even if a non-orthogonal matrix would provide smaller FRE).
#### By Tamas Ungi on 2012-07-11 19:48
I have been using the calculations Elvis described. They are implemented in VTK in the vtkTransform class. If you set the calibration matrix in a transform, you can get the parameters using GetOrientation(), GetPosition(), and GetScale(). Then set these in a new transform which will be orthogonal.
They may not improve the results from a mathematical point of view, but our work is usually not judged by mathematical metrics either :-)


## possible bug in calibration matrices: scaling in y/z may be flipped
#### Posted by Elvis Chen on 2012-07-11 10:59

Can someone please confirm. I believe the scaling factor obtained from fcal is flipped between the y and the z axis.

Using the PlusConfiguration_SonixTouch_L14-5_NDIAurora_fCal_1.0_4cm.xml I uploaded earlier as example:

<Transform From="Image" To="Probe" Matrix="-0.0581284 -0.00420584 0.0359503 11.3136 0.0373263 0.000742847 0.0562522 -24.5595 -0.00582967 0.0640925 0.00170713 49.7608 0 0 0 1" Error="0.969791" Date="060612_151300">
</Transform>
<Transform From="TransducerOriginPixel" To="TransducerOrigin" Matrix="0.0694331 0 0 0 0 0.0641193 0 0 0 0 0.0667806 0 0 0 0 1" Date="060612_151301">
</Transform>

define:

m = reshape( [-0.0581284 -0.00420584 0.0359503 11.3136 0.0373263 0.000742847 0.0562522 -24.5595 -0.00582967 0.0640925 0.00170713 49.7608 0 0 0 1],[4,4])'

and:

s = reshape([0.0694331 0 0 0 0 0.0641193 0 0 0 0 0.0667806 0 0 0 0 1],[4,4])'

Perform the refector of the rotational component of m:

[U,S,V] = svd(m(1:3,1:3))

S should be the scaling factor of m. But compare S and s one will notice that y and z are slipped.

I have seen this on all the calibration I've done here. Can someone please verify if the scaling factors are indeed flipped in the y/z axis or not? Or is TransducerOriginPixel to TransducerOrigin flip the axis on purpose?

#### 3 Comments
#### By Csaba Pinter on 2012-07-11 11:07
There should not be any flips, only rotations.
The TransducerOriginPixel to TransducerOrigin transform you wrote does not have any flip, nor rotation, only scaling (all the non-diagonal values are 0, and the diagonals are all positive).
#### By Elvis Chen on 2012-07-11 11:21
sorry, I should be more careful on my wording:

I meant the numerical value of the scaling factors are swapped between the y and the z axis. Using my example, the scaling factors reported by fcal is:

s =

0.0694331 0 0 0
0 0.0641193 0 0
0 0 0.0667806 0
0 0 0 1.0

but using the SVD refactorization on the rotational component of Image to Probe matrix, we get:
[U,S,V] = svd(m(1:3,1:3));
S =

0.0694331 0 0
0 0.0667806 0
0 0 0.0641193

comparing the matrix s and S, you'll notice that the scaling for y and z-axis are swapped:

s(2,2) ~= S(3,3)
s(3,3) ~= S(2,2)

and scaling for x-axis agrees with each other:

s(1,1) ~= S(1,1)
#### By Andras Lasso on 2012-07-11 13:40
Elvis, I think you are right, the computation of the TransducerOriginPixelToTransducerOrigin transform in FreehandCalibrationToolbox::SetAndSaveResults does not correspond to the coordinate system definition in Coordinate_system_definitions.

Note that the TransducerOriginPixelToTransducerOrigin transform is only used for some approximate visualization in fCal, but nevertheless we should resolve this inconsistency.

In FreehandCalibrationToolbox::SetAndSaveResults:
double* imageToProbeScale = imageToProbeTransform->GetScale();
vtkSmartPointer<vtkTransform> transducerOriginPixelToTransducerOriginTransform = vtkSmartPointer<vtkTransform>::New();
transducerOriginPixelToTransducerOriginTransform->Identity();
transducerOriginPixelToTransducerOriginTransform->Scale(imageToProbeScale);

The problem is that the Image and Probe coordinate systems can have an arbitrary relative orientation, so the imageToProbeScale is not the same as the imageToImageMmScale. We should apply the imageToImageMmScale to compute the transducerOriginPixelToTransducerOriginTransform.

Elvis, it would be great if you could fix this.
I've added #545 to track the resolution.


## framegrabber recommendation
#### Posted by lion2012 on 2012-07-09 05:17

Hi,

Don't know why I could not continue the previous topic. Have to start a new one here.

I am also very interested in the question of frame grabber choice. I am in the process in buying a video grabber. The ultrasound machine I have at hand is a Terason T3000, which has screen resolution of 1440x900. Could I still use the Imaging Control's video grabber, expecting downgraded video quality? Or shall I go with the Epiphan VGA2USB LR, which supports a higher resolution?

For video capture performance, shall I go with Epiphan's VGA2PCIe (up to 1920×1200 @ 35-85 fps)? The VGA2USB LR only has 10-35 FPS @1280 x 1024.

Thanks,

David

#### 1 Comments
#### By Andras Lasso on 2012-07-09 09:00
You may consider using Terason's research interface. It gives you direct access to the image and other data.

If you choose to use a framegrabber then consider the followings (starting with the highest priority):
match the scanner's hardware interface (S-video, VGA, DVI)
match the scanner's screen resolution (note that on some systems you can change the screen resolution)
suitable framegrabber hardware interface: USB is very flexible; it's quite probably that you'll have to use/test/demo your system with a laptop, so a PCIe interface may be problematic
frame rate: if you acquire images at very high frame rate (>30fps) then there is a high chance that you won't be able to process and display all of them in real-time. It's much easier to work with a lower frame rate (10-20 fps) image stream and do performance optimization once your system is functionally complete and works perfectly. Hardware-based cropping is a useful feature (you specify the cropping rectangle and the framegrabber only acquires image from that region). In case of the Epiphan framegrabbers the actual frame rate also depends on the image contents. Based on our exerience the actual frame rate on the VGA2USB LR tends to be about 30 fps (we use hardware cropping and the variation in the image contents is not too high).


## Calculating Fan Angle
#### Posted by Vikas Revanna Shivaprabhu on 2012-07-06 13:50

Hi,

I need help in calculating the fan angle. Please find attached a screenshot of the US image I am looking at.
I looked at the "UltrasoundImageOrientation" tutorial. But I am not able to figure out where to draw the lines extending to the left and right of fan origin in order to calculate the fan angle.

Thanks
Vikas
USImage.jpg	91.2 KB

#### 1 Comments
#### By Andras Lasso on 2012-07-06 16:14
According to UltrasoundImageOrientation.pptx (https://www.assembla.com/spaces/plus/documents/cQWtIUFbWr4lK8eJe5cbLr/download/cQWtIUFbWr4lK8eJe5cbLr) and drawing the fan start/end lines on the image (see attached):

Original image size: 658x556
Fan origin position in the image: (329, 711)
Fan origin position in the MF coordinate system: (329, 556-711) = (329, 556-711) = (329, -155)

Fan depth: "origin position Y" - "fan top position Y" = 711 - 43 = 668

Fan angles: approximately 30 deg

So, the fan defintion is something like this: FanAngles="-30 30" FanOrigin="320 465" FanDepth="668"
USImageExtended.jpg	62.7 KB


## Problems with Stylus Calibration
#### Posted by Brennecke on 2012-06-29 11:13

I tried to calibrate my NDI Pointer (8700340), but could not collect any points. I can start the calibration. When I try to stop it, the program crashes with this stacktrace (caught in debug mode):
~~~~
>	vtkCommon.dll!vtkDataArrayTemplate<double>::GetTuple(int i=0, double * tuple=0x014cc2e8)  Line 615 + 0xc bytes	C++
 	fCal.exe!vtkPivotCalibrationAlgo::DoPivotCalibration(vtkTransformRepository * aTransformRepository=0x06647e80)  Line 217 + 0x21 bytes	C++
 	fCal.exe!StylusCalibrationToolbox::Stop()  Line 353 + 0x39 bytes	C++
 	fCal.exe!StylusCalibrationToolbox::qt_metacall(QMetaObject::Call _c=InvokeMetaMethod, int _id=1, void * * _a=0x014cc9c0)  Line 81 + 0x8 bytes	C++
 	QtCored4.dll!671d8661() 	
 	[Frames below may be incorrect and/or missing, no symbols loaded for QtCored4.dll]	
 	QtCored4.dll!671f0186() 	
 	QtCored4.dll!6703c9cd() 	
 	QtCored4.dll!6703c98f() 	
 	QtCored4.dll!671f03b2() 	
 	QtCored4.dll!671ced95() 	
 	QtCored4.dll!6706ca61() 	
 	QtCored4.dll!671ceb81() 	
 	QtCored4.dll!6707459d() 	
 	QtCored4.dll!67036203() 	
 	QtCored4.dll!67212bdc() 	
 	user32.dll!766162fa() 	
 	user32.dll!76616d3a() 	
 	user32.dll!76616ce9() 	
 	user32.dll!766177c4() 	
 	user32.dll!7661788a() 	
 	QtCored4.dll!672139f6() 	
 	ole32.dll!76206269() 	
 	vtkCommon.dll!vtkGarbageCollectorImpl::Report(vtkObjectBase * obj=0x0806c030, void * ptr=0x6388813d, const char * desc=0x014ce5ab)  Line 624 + 0xf bytes	C++
 	06040002()	
 	QtGuid4.dll!02060427() 	
 	QtGuid4.dll!01a087c7() 	
 	QtGuid4.dll!01a09a9b() 	
 	QtGuid4.dll!0226b1fd()
~~~~

Additionally I get this message on the output.
First-chance exception at 0x63837e7e (vtkCommon.dll) in fCal.exe: 0xC0000005: Access violation reading location 0x00000000.
Unhandled exception at 0x63837e7e (vtkCommon.dll) in fCal.exe: 0xC0000005: Access violation reading location 0x00000000.


I added the log file. Do you have any pointers where the problem could be?

[edit]
The strange thing is, that the calibration works with the NDI Toolviewer. Also fCal shows that the marker can be seen (state ok for the marker in Tool State Display).

[edit 2]
Thanks for your help. Now I add the manual calculated transformation to the config file.
070212_160135_PlusLog.txt	271 KB
PlusConfiguration_OpenIGTLink_ImageMessage_NDIPolaris.xml	5.62 KB
062912_155527_PlusLog.txt	225 KB

#### 2 Comments
#### By Andras Lasso on 2012-06-29 12:28
The problem is that the tracking data is invalid (vtkTrackerBuffer: Cannot do tracker data interpolation. The closest item to the requested time ... is invalid), which usually happens when a tool is out of view. Make sure that both the stylus and the reference sensors are visible.

I've fixed the crash, fCal now nicely fails if there are no calibration points available (https://www.assembla.com/code/plus/subversion/changesets/1852).
#### By Andras Lasso on 2012-07-02 10:55
If you've already calibrated the stylus with the NDI toolviewer (and saved the offset in the flash memory in the tool) then when you rotate the tool then the tooltip position doesn't change. The pivot calibration algorithm collects unique points only (that have a minimum distance from each other), therefore you won't be able to collect points with an already calibrated tool.

So, if you do the calibration outside PLUS then just add the following calibration matrix to the CoordinateDefinitions element in the device set configuration file:
~~~~
<Transform From="StylusTip" To="Stylus"
Matrix="1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1"
Date="2012.07.02 10:00:00"
/>
~~~~
then in fCal simply skip the stylus calibration step.


## Problems with OpenIGTLink image source and Polaris tracker
#### Posted by Brennecke on 2012-06-18 11:24

I have some problems to get fCal working with OpenIGTLink image message and a Polaris tracker. I receive a strange error message, which I cannot interpret.

[..]
061812_165220.734|ERROR|011.935000| Failed to get video buffer item UID from time: 11.876214|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollectorHardwareDevice.cxx(548)
061812_165220.746|ERROR|011.946000| Failed to get most recent timestamp from the buffer!|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollectorHardwareDevice.cxx(919)
061812_165221.256|ERROR|012.457000| Unable to get tracked frame from data collector|in ..\..\PlusApp\CommonWidgets\vtkObjectVisualizer.cxx(961)
061812_165221.263|ERROR|012.464000| Unable to start collecting data!|in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(181)


You'll find my configuration file as an attachment. It would be great if you can give me a few pointers.

Thanks!
Thorsten

[edit 1]
Log on TRACE level added

[edit 2]
Unfortunately I cannot post
####  comments so I edit my original message.

I now ran the diagnosis. Obviously there is some problem with the video timestamps.

|in ..\..\..\PlusLib\src\PlusCommon\vtkGnuplotExecuter.cxx(206)
061912_171330.049|DEBUG|074.446000| Deleting process ...|in ..\..\..\PlusLib\src\PlusCommon\vtkGnuplotExecuter.cxx(241)
061912_171330.061|TRACE|074.457000| vtkHTMLGenerator::AddImage|in ..\..\..\PlusLib\src\PlusCommon\vtkHTMLGenerator.cxx(50)
061912_171330.069|TRACE|074.466000| vtkHTMLGenerator::AddHorizontalLine|in ..\..\..\PlusLib\src\PlusCommon\vtkHTMLGenerator.cxx(43)
061912_171330.082|TRACE|074.478000| vtkPlusVideoSource::GenerateVideoDataAcquisitionReport|in ..\..\..\PlusLib\src\ImageAcquisition\vtkPlusVideoSource.cxx(578)
061912_171330.096|ERROR|074.493000| Failed to get timestamp report table from buffer - table is NULL!|in c:\devel\plusexperimental-build\pluslib\src\pluscommon\vtkTimestampedCircularBuffer.txx(705)
061912_171330.111|ERROR|074.507000| Failed to get timestamp report table from video buffer!|in ..\..\..\PlusLib\src\ImageAcquisition\vtkPlusVideoSource.cxx(589)


[edit 3]
ok, I added both meta files.

[edit 4]
First of all thanks for your fast help!
I use the Fraunhofer Diphas Ultrasound Research Platform as image source, which provides an API in C#. This makes it difficult to use it with other tools and libs written in C++. In order to stream the images to any plattform, I implemented the OpenIGTLink image message in C#. Following the specification, the timestamps are generated relative to January 1, 1970 (http://www.na-mic.org/Wiki/index.php/OpenIGTLink/Timestamp). I now change the timestamp generation.
VideoBufferMetafile.zip	35.4 MB
TrackerBufferMetafile.mha	194 KB
trace_061912_095243_PlusLog.txt	83.9 KB
061912_171409_PlusLog.txt	514 KB
061912_171409.TrackerBufferTimestamps.txt	8.98 KB
TrackerBufferTimestamps.jpg	45.1 KB
PlotSpacingCalculationErrorHistogram.jpg	70.4 KB
061812_165209_PlusLog.txt	4.02 KB
PlusConfiguration_OpenIGTLink_ImageMessage_NDIPolaris.xml	5.96 KB

#### 8 Comments
#### By Andras Lasso on 2012-06-18 13:42
There seem to be a problem with the image acquisition. Could you change the log level to TRACE and send the log?
#### By Tamas Heffter on 2012-06-19 10:29
I'm not sure it's related to either the Polaris or the OpenIGTLink connection, both of them were connected successfully.
I have a feeling that when we want to get the video buffer item from fCal, it uses the exact timestamp, instead of the closest (if you check the trace it clearly shows that we have frames around the time requested).

061912_095258.026|ERROR|014.232000| Failed to get video buffer item UID from time: 13.999343|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollectorHardwareDevice.cxx(548)
061912_095258.026|TRACE|014.232000| timestamps = [14.152000 13.102000 13.152000 13.202000 13.252000 13.313000 13.352000 13.402000 13.463000 13.503000 13.552000 13.598000 13.652000 13.702000 13.746000 13.802000 13.852000 13.896000 13.952000 14.002000];|in c:\devel\plusexperimental-build\pluslib\src\pluscommon\vtkTimestampedCircularBuffer.txx(673)
061912_095258.038|ERROR|014.243000| Failed to get most recent timestamp from the buffer!|in ..\..\..\PlusLib\src\DataCollection\vtkDataCollectorHardwareDevice.cxx(919)

Could you also try to run
DiagDataCollection --input-config-file-name=PlusConfiguration_OpenIGTLink_ImageMessage_NDIPolaris.xml --verbose=4
to make sure we have no problem with the data collection.
#### By Tamas Heffter on 2012-06-19 12:11
Thorsten, what about the generated metafile for the image buffer? Can you open it? Can you see the image frames there? If it's not too big, could you attach to assembla?
#### By Tamas Heffter on 2012-06-19 16:16
The problem is with the timestamp, it looks like the image timestamp is differ what we expect (starting from a huge number) while the tracker timestamp is from 0 as we expected.

Video timestamps:
Seq_Frame0000_Timestamp = 1340118859.305460

Tracker timestamps:
Seq_Frame0004_Timestamp = 3.947000

The OpenIGTLink video source is getting the timestamp from the IGTL message. What kind of software/imaging device are you using for sending image messages to Plus?

Your device uses a different timestamping approach, so either we have to generate our own timestamp and create it when we receive a new frame (we lose the timestamped package information), or we could use relative timestamps to generate our timestamps (for that we need a frame number and the timestamp). This is basically just a calibration issue, so if you calibrate your system it should work (this is a constant time difference between the two streams, but Plus always start from 0 timestamp on application start, your device seems to use the time elapsed since 1970 or something).
Guys, what do you think, how should we handle this?
#### By Andras Lasso on 2012-06-19 16:59
I would compute an offset between the relative time and the absolute time similarly as it is done in vtkSavedDataTracker.cxx. Maybe it could be an option in the image source to enable/disable conversion to relative time. Tomi, would this make sense for you? Could you implement it?
#### By Tamas Heffter on 2012-06-20 09:12
Actually it needs to be a time synchronization only, and could be automated: When we get the first timestamp we just need to check if it's significantly different than our current timestamp (like diff > mMaxTimeDiff) and if so we can synchronize it with computing the relative time ( mTimeOffset = timestamp - GetCurrentTime(); and then ts = timestamp - mTimeOffset ). Unfortunately this (and probably all approaches) will change the temporal calibration, so after every start we need to re-calibrate the system.
See ticket: #532
#### By Andras Lasso on 2012-06-20 09:17
OK, let's continue the discussion at ticket #532
#### By Tamas Heffter on 2012-06-20 13:05
Thorsten, could you update your source and try it again with your original UTC timestamping? Thanks for pointing out this issue!


## Specifying hole filling parameters in config file
#### Posted by Vikas Revanna Shivaprabhu on 2012-06-13 11:45

Hi,

I am trying to turn on hole filling but I keep getting the following error message.
|ERROR|000.015000| Couldn't locate hole filling parameters for hole filling!|in ..\..\..\P
lusLib\src\VolumeReconstruction\vtkVolumeReconstructor.cxx(222)
|ERROR|000.024000| Failed to read configuration from C:\Users\Kitware\Documents\Toolkits\P
LUS\Bin\PlusLib\data\ConfigFiles\PlusConfiguration_Epiphan_MicronTracker.xml|in ..\..\..\.
.\PlusLib\src\VolumeReconstruction\Testing\VolumeReconstructor.cxx(78)

I have the following tags in my config file:

<VolumeReconstruction
ImageCoordinateFrame="Image"
ReferenceCoordinateFrame="Reference"
OutputSpacing="1 1 1"
Calculation ="WEIGHTED_AVERAGE"
Interpolation="LINEAR" Optimization="FULL" Compounding="On" FillHoles="On"
/>

<HoleFilling>
<HoleFillingElement Type="GAUSSIAN" Size="5" Stdev="0.6667" MinimumKnownVoxelsRatio="0.50001" />
<HoleFillingElement Type="STICK" StickLengthLimit="9" NumberOfSticksToUse="1" />
</HoleFilling>

Should I be defining the tags some other way?

Thanks
Vikas

#### 3 Comments
#### By Andras Lasso on 2012-06-13 12:37
I've added some clarifications on the wiki (https://www.assembla.com/spaces/plus/wiki/Volume_Reconstruction)
#### By Thomas Vaughan on 2012-06-13 13:28
Andras is right, the volume reconstruction tag should end after the hole filling elements are defined:
~~~~
<VolumeReconstruction [parameters]>
<HoleFilling>
[elements defined here]
</HoleFilling>
</VolumeReconstruction>
~~~~

#### By Vikas Revanna Shivaprabhu on 2012-06-13 13:41
Thanks. Your suggestions helped a lot.


## Multiple reflections of the phantom under water
#### Posted by Vikas Revanna Shivaprabhu on 2012-06-11 12:30

Hi,

I am getting multiple copies of the calibration phantom wires in the US image when imaged under water (screenshot attached). We believe it is because of reflections from the bottom and the water surface. We wanted to know if this effect is truly because of reflections. We would like to hear some thoughts/comments on this from those more familiar on the topic.

Thanks
Vikas
NWireMultipleReflections.png	155 KB

#### 5 Comments
#### By Siavash Khallaghi on 2012-06-11 14:01
Hi Vikas,

I have never had a reflection this bad. I suppose you could try putting a layer of absorbent at the bottom of your water bath.
#### By Elvis Chen on 2012-06-11 14:25
could be the reflection of the side lobes. Some machines such as Ultrasonix allow you to adjust for the # of focal zone, try to set it to 1.
#### By Tamas Ungi on 2012-06-11 16:17
1. You can try to lower the power (gain) on the ultrasound settings, push your phantom deeper in the water, and set the search region in the wire segmentation settings dialogue box so that the unnecessary regions are not included.

2. This is a problem we've already talked about is that US probes have so different scales. We might need to design a larger phantom later, when the user community demands that. There don't seem to be a way to calibrate the smallest and the largest probe with the same phantom at a satisfactory accuracy.
#### By Tamas Ungi on 2012-06-11 16:19
Do you know how to do ImageToProbe calibration with just a tracked needle and water? Because even if you do calibration with the fCal phantom, you need to verify that. Because you are working with a scale at which fCal has never been tested.
#### By Vikas Revanna Shivaprabhu on 2012-06-11 17:55
The reflections disappear by increasing the depth of water and imaging very close to the surface. I was able to run spatial calibration in fcal with calibration error of 2.5 mm.
I know manual calibration can be done with tracked needle using LiveUltrasound module in Slicer. I haven't tried it out. As you suggested, may be I will try it for verification.


## Epiphan frame grabber - Info message
#### Posted by Vikas Revanna Shivaprabhu on 2012-06-02 22:45

Hi,

When I connect to Epiphan frame grabber from fcal, I get this message a lot . Approximately 10 every 30 index. Is it normal or shoud I be concerned ?

|INFO|210.883000| Filtered timestamp is probably invalid for video buffer item with item i
ndex=672, time=210.883. The item may have been tagged with an inaccurate timestamp, theref
ore it will not be recorded.

Thanks
Vikas

#### 10 Comments
#### By Andras Lasso on 2012-06-03 08:11
It means that the image frames do not arrive at regular intervals. Perform the temporal calibration and have a look at the plot to see how much irregularity you have.

You may try to decrease the frame rate, use a faster computer, run the program in release mode to resolve this. You may also try to find some functions in the Epiphan SDK that provides accurate, reliable timestamp for the acquired frame.

Which framegrabber model do you use? 
What is the CPU load while you are acquiring? 
Do you have the problem in release mode as well?

From: Vikas Revanna Shivaprabhu 
Sent: 2012-06-02 10:46 PM

#### By Vikas Revanna Shivaprabhu on 2012-06-03 15:06
Framegrabber model - Epiphan VGA2USB
CPU load while acquiring - ~6%
I ran fCal in Release mode and reduced to frame rate to as low as 3. But the INFO message persists.
#### By Elvis Chen on 2012-06-04 14:44
The original VTK/C++ version of the epiphan video source class Chris implemented works at >30FPS@1600x1280 on a modest machine without any time-stamping issue. Does PLUS use a different time stamping mechanism than VTK?
#### By Andras Lasso on 2012-06-04 14:53
Plus uses a more accurate and more reliable timestamping mechanism than the basic VTK video source and there are multiple checks to find out potential timing issues. The old code does not contain any checks so obviously it doesn't show any warnings.
We have a VGA2USB LR and it doesn't have this problem (it seems to be able acquire images at 60fps without problems), so the problem might be specific to the basic VGA2USB converter (which provides interlaced images, so not suitable for any serious imaging anyway). I currently investigating the problem and will report the results here.
#### By Elvis Chen on 2012-06-04 15:03
vtkVideoSource had a check method to see if it was dropping frames. It is not the best implementation however since if it falls behind and/or can’t catch up it just keeps telling you frames have dropped instead of just continuing from where it left off. It should spit out a vtkWarning message from the record thread. (doesn’t work if you just have your own timer and use the grab function).

Have you tried just using the software from Epiphan and see if the video drops then as well and what the frame rate is?
#### By Vikas Revanna Shivaprabhu on 2012-06-04 16:05
The frame rate remain constant at 3.5 fps when I use the software from Epiphan. When I run fcal, the frame rate drops to ~1.5 and keeps changing between 1.2 and 2.5 fps.
#### By Vikas Revanna Shivaprabhu on 2012-06-04 16:15
The frame rate I am getting matches the product specification. According to Epiphan's website, the VGA2USB model should work at around 3.5fps for resolution 1400x1050.
#### By Elvis Chen on 2012-06-04 16:59
sorry, the frame-rate I was quoting refers to the use of the dvi2usb.
#### By Andras Lasso on 2012-06-04 19:37
The 3.5 fps is extremely low. You may try to lower the resolution to increase the frame rate or buy the VGA2USB LR (it also provides better image quality). Our VGA2USB LR works quite well, it consistently provides 60fps at 1024x768 resolution.

You can get more information about the dropped frame if you set the log level to DEBUG. You can also do advanced diagnostics using the DiagDataCollection tool (see Diagnostic_and_test_tools). You get the warning and the frame is dropped if the time difference between the expected (filtered) and actual (unfiltered) timestamp is more than 0.5sec.
#### By Vikas Revanna Shivaprabhu on 2012-06-11 12:35
After spending more time with the Epiphan VGA2USB frame grabber, I found out that the frame rate is very unpredictable even when running Epiphan's software. Sometimes, the frame acquisition stops all of a sudden. We have ordered the VGA2USB LR. Hopefully, this will give better results.


## Stylus distance not quite correct?
#### Posted by VaultLab on 2012-06-08 23:59

As part of our troubleshooting efforts, we calibrated our stylus (error ~0.2 mm) and then touched it to two points on a ruler and recorded the "stylus tip location" coordinates from fCal.

We got 20.7, 93.3, 24.4 [mm] when touching the stylus tip to the 1cm mark on the ruler, and then 21.1, 94, 15.6 [mm] when touching the stylus tip to the 2cm mark on the ruler. We kept the phantom (ref sensor) and ruler still during this time.

Euclidean distance between the two points is: 8.837 mm, where we would expect it to be 10 mm. We also took the position of the 3cm mark which was at 21.2, 93.4, 6.9 [mm]. The euclidean distance between the 2cm mark and the 3cm mark data is 8.7212 mm, again less than 10 mm.

We repeated the same test with a second stylus calibration (this time 0.5 mm error). A distance of 10 mm on the ruler resulted in a stylus-measured distance of 8.9 mm. A distance of 120 mm (the length of our phantom) resulted in a distance of 117 mm.

What are your thoughts on this?

Thanks,

Tom.

#### 2 Comments
#### By Tamas Ungi on 2012-06-09 06:42
Hi Tom,

What type of tracker do you use? Can you verify that you can measure distances correctly with those styluses using the own software (example application) of the tracker?

Thanks,
Tamas
#### By Andras Lasso on 2012-06-09 09:33
8.837mm vs. 10mm = 1.2mm error, 8.9mm vs. 10mm = 1.1m error => these are within specifications for many electromagnetic trackers.

120mm vs. 117mm = 3mm error => This is a bit too high. To minimize the tracking error follow the manufacturer's instructions for setting up your tracker. If it's an electromagnetic tracker then make sure it's far from metallic objects and EM noise sources, work not too far and not too near to the field generator, use as large sensor as possible (smaller sensors are typically less accurate), use a shorter stylus (to reduce the effect of angular errors), etc.


## Landmark locations and phantom size
#### Posted by VaultLab on 2012-06-08 23:41

Hi there, I've measured our phantom to make sure it was printed at correct size. It's 120 mm long, 25 mm deep and 50 mm wide. Does that match up with your phantoms?

Also, the locations of the landmarks are given in the configuration file - where on the phantom are the landmarks measured from? I.e. where is the origin of the phantom coordinate system? And are the locations of the landmarks in the configuration file given in mm?

Still trying to figure out why we get such a large phantom registration error :S we're getting a stylus calibration error of about 0.2 mm now!

Thanks,
Tom.

#### 1 Comments
#### By Andras Lasso on 2012-06-09 08:52
The "Phantom" coordinate system definition that is used in the example configuration files is illustrated here:
https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/docs/fCAL/CAD/PhantomDefinition_fCal_1.2_Wiring_1.1.png?rev=1754
The origin is at the inner end of the A4 hole. Everything is in mm. The phantom size that you described is correct.


## Aurora and Ultrasonix L14 is a bad combination
#### Posted by Elvis Chen on 2012-02-29 11:00

hi all,

just an observation to report. We have known for a long time that Aurora/NDI is sensitive to the presence of aluminium but is generally ok with other metals. Assenssion, on the other hand, is generally worse in the presence of all types of metal EXCEPT aluminium.

We are just testing the tracking performance of Aurora/Ultrasonix L14 linear probe. If the L14 probe is stationary, we can get consistent readings, but if the probe is moving, the tracking is not stable at all.

We know there is a big piece of aluminium inside L14.

Thus I would advise not to use Aurora with Ultrasonix probe at this time.

#### 10 Comments
#### By Andras Lasso on 2012-02-29 11:36
Thanks for the information, I've added it to the Troubleshooting page (https://www.assembla.com/spaces/plus/wiki/Troubleshooting_for_Plus_users). Interestingly, we've found that the Ascension trackers are not sensitive to the presence of any metals (we can use them on regular office tables with metallic legs, etc.), while Aurora with the regular field generator seems to be sensitive to the presence of any metals (and therefore we can use it only on plastic carts).
#### By Elvis Chen on 2012-02-29 11:48
One possible cause is that the Ascension system is on, which causes interference with Aurora. I'll see if I can physically turn off the Ascension system and report back.
#### By Tamas Ungi on 2012-02-29 16:56
Ascension should be resistant to all kinds of non-ferromagnetic metals. That's what we experience. And it's shown in this video too:
http://www.youtube.com/watch?v=BG80pCf25BE&feature=youtu.be
They put huge pieces of different metals near the Ascension sensors, and the reading stays the same within a submillimeter accuracy.
#### By Elvis Chen on 2012-03-02 14:57
We tested it again with Ascension FG disconnected from the drivebay. We still experience bad tracking with Aurora. With a stationary stylus, if the probe is moved around, the reading of the stationary stylus would fluctuate, by around 1-2mm. Once a while, the reading would be completely off.

I'll write a small software to see if this behavior still exist outside of the PLUS environment.
#### By Tamas Ungi on 2012-03-02 15:58
What is the point in checking it outside PLUS? PLUS doesn't introduce any error into the tracking data.
#### By Andras Lasso on 2012-03-02 17:54
I agree that is very unlikely that the small 1-2mm random error is introduced by Plus, but of course it could be interesting to verify it in a different environment. Probably you can just use the standard NDI applications or samples in the SDK.
#### By Elvis Chen on 2012-03-09 14:30
Just tried it using NDI's flat-bed field generator. Works wonderfully.
#### By Elvis Chen on 2012-06-07 10:43
sorry to bring up an old post.

I have recently calibrated Ultrasonix L14 probe using NDI Aurora (both the cube and flatbed FG). It would appear the problem I previously reported with L14 was related to Ticket #515 (https://www.assembla.com/spaces/plus/tickets/515) where the tracking in PLUS was unstable. After the fix, I was able to calibrate our L14 probe successfully. A typical stylus tool-tip calibration would have an RMS error of < 0.3mm; phantom registration error of < 0.5mm, and 2-N-wire calibration of < 1mm (for 3D reconstruction) error with the flat-bed FG. With the cube FG, the error is slightly worse but not significant (tip-calibration < 0.5mm, phantom registration < 0.8mm, 2-N-wire calibration < 2mm).
#### By Andras Lasso on 2012-06-07 10:47
This is great, thanks a lot for sharing the results!
#### By Csaba Pinter on 2012-06-07 10:48
Thanks for the update, we always like to hear good news :)


## Re: Re: Large phantom calibration error
#### Posted by VaultLab on 2012-06-06 21:34

Hi guys, sorry again to create a new message but I can't reply to the other threads. I thought maybe it was firefox so I tried IE as well, but no joy.

I checked that the sensors are working correctly in the cubes.exe demo, and they're good - both location and orientation match up. And I've got the sensors connected to the ports in the correct order.

I've gone back to the fCal-1.1.stl model so that the orientation matches up. I've attached some screenshots showing what happens when I try to register the phantom. The stylus calibration error in this instance was only 0.5 mm. The lower right image shows how the stylus appears on screen when I touch the stylus to landmark #1 on the phantom.

You can see that the dots form roughly the correct landmark pattern... just in the wrong location :(

I've also attached the log file (I set it to debug level).

Tom.
060712_110258_PlusLog.txt	66.5 KB
phantomRegError.PNG	138 KB

#### 0 Comments


## New fCal phantom design
#### Posted by Tamas Ungi on 2012-06-06 10:56

I'm planning to design a new fCal phantom. The geometry will change, so this is good time to incorporate new ideas.
Check out the ticket and add your
####  comments please. I will start drawing it in a few days:
https://www.assembla.com/spaces/plus/tickets/518

#### 0 Comments


## Re: Large phantom registration error
#### Posted by VaultLab on 2012-06-05 22:37

Hi Pinter and Andras,

Sorry to create a new message, but the system won't let me comment on the previous one. Thanks for your fast replies.

I've updated the software and now get a better stylus error - around 0.5-0.7 mm as you mentioned.

The phantom we are using was printed from the file downloaded from the plus repository - fCal_1.2.stl. We printed this with units of mm.

I have added the v1.2 config file to the config directory, and altered the config file so that it uses this model: e.g. file="fCal_1.2.stl". A matching phantom model is now shown in fCal.

When I register the phantom I still get an error of 6-8 mm. Now I have changed the model, the orientation is off by 90 degrees (see attached image). I have attached my configuration file also.

Are the locations of the land marks correct?

We're using the Ascension TrakSTAR system with Model 800 sensors (the large rectangular ones). Andras, when we touch the landmarks on the phantom with the stylus, the on-screen stylus does not touch the landmarks on the model displayed. The stylus seems to be working well though.

Thanks again for your help.

Tom.
phantomReg.PNG	25.9 KB
PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal1.1.xml	5.85 KB

#### 4 Comments
#### By Siavash Khallaghi on 2012-06-06 05:11
Hi Tom,

I had the same issue when I was calibrating a C5-2 probe with the Ascension tracker. In my case the reference sensor was defected. Can you try running Cubes and see if the reference sensor behaves as expected?
#### By Siavash Khallaghi on 2012-06-06 05:25
Also, are you sure that you have attached the ports correctly? On the Ascension tracker, it should be the following from left to right: probe, reference and stylus.
#### By Csaba Pinter on 2012-06-06 08:48
I tried using the fCal_1.2.stl model and with the same ModelToObjectTransform it is 90 degrees rotated in my case too. I don't have the good transform right now, so I suggest changing back to fCal_1.0.stl (it is only an illustration, so not important regarding the calibration process).

After confirming the good phantom model orientation, please change the Log level to "Debug" in the Configuration tab, that way we could see the acquired points and the landmarks in the log file. It could also help if you took another screenshot with the good orientation.

Thanks!
#### By Andras Lasso on 2012-06-06 09:32
All the fCal-1.x phantoms have the same geometry, the only difference is in the position and size of text labels and marker holder slots. Anyway, if you prefer to show the fCal-1.2 model then you have to use the following transform:
~~~~
<DisplayableObject Type="Model" ObjectCoordinateFrame="Phantom"
Opacity="0.6"
File="FCal_1.2.stl"
ModelToObjectTransform="
1 0 0 -25.0
0 0 -1 45.0
0 1 0 -5.0
0 0 0 1"
/>
~~~~
But as Csaba wrote, it is just for display - the calibration results are not affected by what surface models are displayed and where.


## Large phantom calibration error
#### Posted by VaultLab on 2012-06-04 22:13

Hi there,

We're getting quite large phantom calibration error. The stylus calibration error is about 0.9 to 1.5 mm, and the phantom calibration error is about 8 mm.

We're using Plus version 1.4.1.1391.

The phantom we're using doesn't quite match the one on screen - ours has a square hole in each corner (one of them to fit an ascension tracker) and one circular hole all the way through in the other corner. The one on screen has the same but with an additional hole in the middle of each end, from birds-eye-view.

Is this why we are seeing a large calibration error, because we're using a different phantom version?

Could our results be affected by this issue: https://www.assembla.com/spaces/plus/tickets/515 ?

Thanks,
Tom.

#### 2 Comments
#### By Csaba Pinter on 2012-06-05 08:23
Hi Tom,

The pivot calibration error you got is still in the acceptable zone, but a little high indeed. It should be around 0.5-0.7 to have no doubts about the success of rest of the calibration. I suggest to use a slightly rough surface to rest the stylus tip on, for example a kitchen towel, or the phantom itself. Also, the pointier the tip, the better.

The success of the phantom registration depends on the stylus calibration and the correctness of the landmark definitions in the configuration file. If the phantom you use also has different dimensions (no matter how slight the difference), then you must change the landmark definitions accordingly. Is it a phantom model you downloaded from our repository, or you designed it yourselves? If it's a custom phantom, please attach the STL model.
It would also help if you attached your configuration file.

I recommend using the latest stable Plus (1.5.3.1707 from the completed milestones page)
#### By Andras Lasso on 2012-06-05 10:30
8mm phantom calibration error is too high.

What tracking device do you use?
When you touch points on the calibration phantom with the stylus do you see the stylus appear at about the same position in fCal?


## Error when finalizing reconstructed volume
#### Posted by Simrin Nagpal on 2012-06-04 16:10

The number of frames added to the volume during volume reconstruction works. However, when the reconstructed volume is being finalized, the error seen in the attached image occurs. There are 2180 frames that need to be reconstructed, which seems to be the issue. Let me know if you need more information.
error_image.png	88.5 KB

#### 2 Comments
#### By Siavash Khallaghi on 2012-06-04 17:31
Hi Simrin,

In my experience, two issues may cause this:

1. You just have too many frames, try decreasing the number of frames for volume reconstruction. Try the following:
TrackedFrame* frame = trackedFrameList->GetTrackedFrame( frameIndex ); //Frame index is a down-sampled index, e.g. every five frames
reconstructor->AddTrackedFrame(frame, transformRepository, imageToReferenceTransformName, &insertedIntoVolume ) ; //Insert the frame into volume

2. Make sure that the frames locations are correct. This means that if you create slice models and watch them in Paraview, they will show a pattern similar to your sweep.
#### By Tamas Heffter on 2012-06-04 18:33
Hi Simrin,

You're out of memory, if you need to reconstruct this amount of frames, I would compile the 64bit version of plus (https://www.assembla.com/spaces/plus/wiki/Build_instructions).


## unable to update/compile PLUS today
#### Posted by Elvis Chen on 2012-06-04 15:37

hi all,

in the process of updating/compiling PLUS today and ran into the following issue. Does anyone else encountering this?


9>1>------ Build started: Project: vtkImageAcquisition, Configuration: Release Win32 ------
9>1>Compiling...
9>1>ICCapturingListener.cxx
9>1>c:\chene\winbin32\plus\pluslib\src\imageacquisition\iccapturing\ICCapturingListener.h(10) : fatal error C1083: Cannot open include file: 'tisudshl.h': No such file or directory
9>1>vtkICCapturingSource.cxx
9>1>c:\chene\winbin32\plus\pluslib\src\imageacquisition\iccapturing\ICCapturingListener.h(10) : fatal error C1083: Cannot open include file: 'tisudshl.h': No such file or directory

#### 1 Comments
#### By Andras Lasso on 2012-06-04 15:50
If you don't need support for ImagingControl framegrabbers then just disable the option and it should build fine.

If you do need to use these framegrabbers then make sure that PLTools is up-to-date. If you still have problem then you may have to clean up the PlusLib build directory because some time ago there were changes in the ImagingControl build options that required clean configure and build of PlusLib.


## PivotCalibration + VFW
#### Posted by GuillermoCarbajal on 2012-06-01 12:55

Hi all,
I was doing pivot calibration with an xml configuration file and result was excellent (Calibration error: 0.41 mm). Then I replaced the following line

<ImageAcquisition Type="None" />

#### by

<ImageAcquisition Type="VFWVideo" BufferSize="100" FrameSize="640 480" UsImageOrientation="MF" AveragedItemsForFiltering="20"> </ImageAcquisition>

and I did the pivot calibration again. To my surprise, the calibration error was 43.5mm! I do not realize why image adquisition could have changed the result. This is very strange!

If I roll back my configuration file to have <ImageAcquisition Type="None"/> then I get a small error !


Best regards,
Guillermo

I use a Polaris Spectra with passive markers.

#### 4 Comments
#### By Csaba Pinter on 2012-06-01 12:58
If you roll back your configuration file to have <ImageAcquisition Type="None"/> then do you get the same big error for pivot calibration?

I'm asking because theoretically it should not affect it at all, so I suspect some other change caused this.
#### By Csaba Pinter on 2012-06-01 13:59
We could reproduce the issue, and I created a ticket for it:
https://www.assembla.com/spaces/plus/tickets/515

I'm already on the case. I'll let you know when progress is made
#### By Csaba Pinter on 2012-06-01 15:34
What kind of tracker do you use?
#### By Andras Lasso on 2012-06-01 16:50
The problem has been fixed. See more details in https://www.assembla.com/spaces/plus/tickets/515. Thanks for reporting the issue.


## Volume Reconstruction
#### Posted by Vikas Revanna Shivaprabhu on 2012-05-29 16:22

Hi,

I am trying the 3D volume reconstruction. I would like to test the volume reconstruction without calibration. Hence I have a identity matrix for the Image to Probe transform. I have attached the configuration file I am using. I am encountering the following problems:
Using fcal:
I get the following error message after the reconstruction:
|ERROR|5424.788000| VTK log: ERROR: In ..\..\vtk\Graphics\vtkMarchingContourFilter.cxx, line 116|vtkMarchingContourFilter (15EB6660): No data to contour||| in..\..\..\PlusLib\src\PlusCommon\vtkPlusLogger.cxx(63)
|ERROR|5424.800000| Last error: 0|in ..\..\..\PlusLib\src\PlusCommon\vtkPlusLogg
er.cxx(66)
But I get a message saying "Volume Reconstruction performed successfully

The output generated is empty. When I save the reconstructed volume as either a vtk file or a .mha file, it does not open in the viewer (3D Slicer). When I opened it in notepad, the contents are empty other than origin and spacing information.

Using cmdline:
I get the following error:
|ERROR|000.176000| Unable to parse transform name, there are 0 matching 'To' phrases in the transform name '', while exactly one allowed.|in ..\..\..\PlusLib\src\PlusCommon\PlusCom
mon.cxx(71)
|ERROR|000.187000| Invalid image to reference transform name: |in ..\..\..\..\PlusLib\src\VolumeReconstruction\Testing\VolumeReconstructor.cxx(103)

Any help or suggestions is appreciated.

Thanks
Vikas
Test_PlusConfiguration_VolumeReconstructionOnly_Epiphan_MicronTracker.xml	1.07 KB

#### 15 Comments
#### By Tamas Ungi on 2012-05-29 16:30
Volume reconstruction without an ImageToProbe calibration can result in weird outputs. E.g. because without pixel to mm spacing conversion, the program tries to allocate a giant piece of memory that is not available in your PC.

As long as you don't have a proper calibration method, you could do a rough manual calibration. The LiveUltrasound Slicer module shows the tracked US image. You could use a tracked stylus to align that image with something. And you just manually adjust the rotation and translation parameters of the calibration matrix (ImageToProbe) in Slicer until it doesn't line up roughly with the stylus.

You just need a bucket of water and a tracked stylus for this. And another hint, if you choose to do this, start from an initial ImageToProbe matrix, that at least has a roughly good spacing. E.g. 0.1 in all directions. Otherwise you will see an enormous large US image in Slicer that is hard to handle.

I know this procedure takes some time and experimenting, but it's also a good way to familiarize yourself with the math behind the system.
#### By Andras Lasso on 2012-05-29 16:32
Currently you should specify the image to reference transform name in the command-line, because the ReferenceCoordinateFrame="Probe" and ImageCoordinateFrame="Image" attributes are ignored. I'll fix modify the volume reconstructor to use the ReferenceCoordinateFrame and ImageCoordinateFrame attributes, but till then you can just specify the transform using the --input-transform-name=ImageToReference command-line parameter.
#### By Andras Lasso on 2012-05-29 16:53
I've committed the change, now you can specify the transform in the config XML file as well (it will be used if you don't specify the transform at the command-line):
https://www.assembla.com/code/plus/subversion/changesets/1718
#### By Andras Lasso on 2012-05-29 17:14
' No data to contour' may happen because the voxels in the volume are too dark and the contouring threshold is hardcoded in fCal (see https://www.assembla.com/spaces/plus/tickets/174). You can try to increase the brightness of the US image or just visualize the volume in another application (e.g., 3D Slicer).
#### By Andras Lasso on 2012-05-29 17:24
Also, fCal may use a calibration matrix, only if a non-empty Date attribute is specified. See https://www.assembla.com/spaces/plus/tickets/511. So, if you manually add a calibration matrix then you may have to add a non-empty Date (and maybe also Error) attribute as well. Anyway, the command-line interface is recommended for volume reconstruction - the user interface in fCal is just for quick tests.
#### By Siavash Khallaghi on 2012-05-29 20:10
Hi Vikas,

Even with the fix that Andras has made, i.e. using the probe to reference transform, you may not be able to reconstruct a volume. It could very well happen that using an invalid calibration matrix, e.g. an identity matrix, the frames may lie on the same plane. Running the volume reconstruction algorithm in this case may not produce anything at all.
#### By Vikas Revanna Shivaprabhu on 2012-05-31 16:59
After providing a rough ImageToProbe transform obtained from LiveUltrasound module in Slicer, I am able to reconstruct a 3D volume.
Voxels in the generated volume either have an intensity value of 16 or 0. Why am I getting a binary output ?
ReferenceToRAS transform needs to be added. I tried adding the transform in the config file of VolumeReconstruction, but the output did not change. How do I enforce this transform?
#### By Tamas Ungi on 2012-05-31 17:03
I don't know why are you getting a binary output.

Why do you think ReferenceToRAS transform needs to be applied? I think it's fine that the VolumeReconstructor reconstructs in Reference coordinate system. After all, it doesn't know that Slicer exists at all. (RAS is only for Slicer.) You can always drag and drop your reconstructed volume on top of the ReferenceToRAS if you'd like to apply it inside Slicer.
#### By Vikas Revanna Shivaprabhu on 2012-05-31 17:21
Before applying the RAS transform, I get the output (attached) whose orientation matches the orientation of the image relative to RAS when viewed in Slicer.
After posting the question, I defined a ReferenceToRAS transform in the config file of VolumeReconstruction and set --input-transform-name=ImageToRAS. I now get the following output(attached).

Although the output does not make sense, I feel the orientation is now just about right. I may be wrong....
BeforeRASTransform.png	21.3 KB
AfterRASTransform.png	15.2 KB
#### By Andras Lasso on 2012-05-31 17:38
> Voxels in the generated volume either have an intensity value of 16 or 0. Why am I getting a binary output ?
Load the original images (in the mha file) into Slicer or ImageJ. Do they contain other intensity values?

As far as I remember Slicer assumes .vtk volumes are in LPS coordinate system and inverts the x and y axis when the volume is loaded, so you may need to apply a [-1 0 0 0 0 -1 0 0 0 0 1 0 0 0 0 1] transform when you load the image to Slicer.

If you share the xml and mha files with us then we can give you more specific help.
#### By Vikas Revanna Shivaprabhu on 2012-05-31 21:57
When I view the original .mha file in ITK-SNAP, I can see the recorded frames clearly.
I have attached the .mha file and the xml. Any help/suggestion is greatly appreciated. Thanks.
Phantom_fCal_Test7.mha	56.8 MB
Test_PlusConfiguration_VolumeReconstructionOnly_Epiphan_MicronTracker.xml	890 Bytes
#### By Andras Lasso on 2012-06-01 10:36
Thanks for the files. I've noticed two problems:
The clipping rectangle is not specified in the VolumeReconstruction element. For example, add these attributes to fix the problem ClipRectangleOrigin="114 0" ClipRectangleSize="400 500" attributes. To prevent this error occurring again, I've committed a change so that if no clipping rectangle is specified then we use the full image.
I've generated a model showing the slice positions (CreateSliceModels.exe --input-configfile=Test_PlusConfiguration_VolumeReconstructionOnly_Epiphan_MicronTracker.xml --input-metafile=Phantom_fCal_Test7.mha --output-modelfile=ReconstructedVolumeSlices.vtk --image-to-reference-transform-name=ImageToReference) and it seems there are a few outlier slices. Maybe you actually moved the transducer like this or there might have been some tracking errors.
#### By Vikas Revanna Shivaprabhu on 2012-06-01 11:00
Thanks. Specifying the ClipRectangleSize fixed the problem. May be a note about the ClipRectangle can be added to the Volume Reconstruction wiki
#### By Vikas Revanna Shivaprabhu on 2012-06-01 11:12
Yes, the probe was moved to a different position during which it might have been out view. Hence the missing slices.
#### By Andras Lasso on 2012-06-01 11:29
I've added more info on the clipping rectangle to the volume reconstruction wiki page.


## Make VolumeReconstructor user guide more clear on parameters
#### Posted by Tamas Ungi on 2012-05-31 10:12

I don't use VolumeReconstructor, but I have a feeling that the parameter " --input-transform-name=" is optional. If it is so, could somebody make it clear on the wiki? Maybe also add a section on what is the recommended way using transforms in volume reconstruction. E.g. provide ImageToProbe in the config file as a static calibration transform, and record ProbeToTracker and TrackerToReference when data is captured. And provide and example command line that can be used in this standard case. I think then --input-transform-name is not needed.

Thanks!

#### 1 Comments
#### By Andras Lasso on 2012-05-31 17:23
I've updated the https://www.assembla.com/spaces/plus/wiki/Volume_Reconstruction page, hopefully it is more clear now. Let me know if you think that more improvements are needed.


## reference tool in vtkNDITracker class
#### Posted by GuillermoCarbajal on 2012-05-31 11:14

Hi all,
It seems that Plus is not working as it is expected when using PolarisSpectra with Passive Markers.
In constructor of vtkNDITracker class, it is set: this->ReferenceTool = 0.
As I'm working with passive markers I changed this value to a number higher than 4 (5) that I have asociated with the reference in xml configuration file.
I happen that coordinates in Tracker reference frame are with respect to the reference and not with respect to the tracker. As a consequence of this, reference tool must always be visible .
It seems that the reference tool in vtkNDITracker class is deprecated but I don't know how to work without it.
I appreciate any help you can give me.
Thanks!
Guillermo

#### 1 Comments
#### By Andras Lasso on 2012-05-31 12:10
In the tracker classes all tools are equal, there is no distinguished "reference" tool. Instead, all transforms between any coordinate frames are computed automatically by the transform repository. This gives much more flexibility and simplifies the interpretation of the tracking data. The ReferenceTool member in vtkNDITracker remained there from an old implementation but recently it has been completely removed.

If you want to use a tool as "Reference" then just set the Tool name to "Reference":

~~~~
<Tracker Type="PolarisTracker" SerialPort="3" BaudRate="115200" ...  >
  <Tool Name="Tool" PortName="4" RomFile="NdiToolDefinitions\8700339.rom" />
  <Tool Name="Stylus" PortName="5" RomFile="NdiToolDefinitions\8700340.rom" />
  <Tool Name="Reference" PortName="6" RomFile="NdiToolDefinitions\8700449.rom" />
</Tracker>
~~~~


Alternatively, you can use any tool name (e.g., MyToolName) and make it equal to the "Reference" coordinate frame by adding an identity transform to the CoordinateDefinitions:

~~~~
<CoordinateDefinitions>
  <Transform From="MyToolName" To="Reference"
    Matrix="1 0 0 0
      0 1 0 0
      0 0 1 0
      0 0 0 1"  />    
...
</CoordinateDefinitions>
~~~~


## phantom
#### Posted by lion2012 on 2012-05-30 23:36

Dear Plus team:

This is David. I am working on a project on ultrasound calibration. I am using the single wall phantom. However, my result is not good.

I was told the Plus project is very good at ultrasound calibration. I am studying the plus project right now. May I ask for help on the phantom? I am really not sure I could make the plus phantom correct. Is it possible that you could send me a phantom to start with?

Thanks so much.

David

#### 1 Comments
#### By Tamas Ungi on 2012-05-31 09:20
Hi David,

Most probably we can provide you an fCal calibration phantom. Let's have a short meeting to talk about your project and the phantom requirements (size, sensor holder interface, etc.). Send me how can I contact you please: ungi [at] cs.queensu.ca

Thanks,
Tamas


## Added support for Epiphan framegrabbers
#### Posted by Andras Lasso on 2012-05-30 16:21

Plus now can acquire images from Epiphan framegrabbers. Thanks to the nice work of Vikas Revanna Shivaprabhu at Kitware and assistance of Chris Wedlake at Robarts Research Institute.

Several Epiphan framegrabber models are available: with USB, PCI, or network connection; VGA or DVI interface; with various options in maximum resolution, frame rate, image quality, and cost. See more information at https://www.assembla.com/spaces/plus/wiki/Hardware_setup and http://www.epiphan.com/.

Andras

#### 0 Comments


## Stylus
#### Posted by VaultLab on 2012-05-27 19:40

Hi,

We're just about to start calibration. Happy to report that fCal connects easily with the Ascension TrakSTAR using the 3DG driver. No need to rebuild fCal.

Are there any specifications for the stylus? Is this something that we need to buy, or can we make one from our existing tracker sensors? Should the tip of the tracker sensor be at the tip of the stylus?

Thanks for your help!

PS we love PLUS, it's so well made!

#### 2 Comments
#### By Andras Lasso on 2012-05-27 21:26
I'm glad that you find Plus useful.

You can create a tracked stylus by attaching a sensor to an object with a sharp tip. You can use fCal to compute the transform between the sensor and the stylus tip as described in the system calibration tutorial:
https://www.assembla.com/spaces/plus/wiki/System_calibration
https://www.assembla.com/spaces/plus/documents/a0YRX6_1Sr4islacwqjQWU/download?filename=PlusTutorialfCalCalibrationProcess.pptx

Note that currently only the tip position is computed, so the displayed stylus orientation may differ from its actual orientation.

Andras
#### By Csaba Pinter on 2012-05-28 11:18
This is our fabulous stylus for the EM tracker. As you can see it's just a sharpened wooden stick with the sensor attached to its blunt end. It is at the end, because the further it is from the tip, the more accurate the calibration.
2012-05-2809.46.11.jpg	423 KB


## Framegrabber recommendation
#### Posted by Andinet Enquobahrie on 2012-05-21 10:44

Hi:

We have been looking into developing TeleMedVideoSource class that will interface with TeleMed ultrasound scanner for image acquisition. Unfortunately, we are running into some issues with the SDK that is provided by the manufacturer.

As a backup plan, we would like to purchase a framegrabber to use the frame grabber acquisition capability in PLUS.

Could you please let us know which types of framegrabbers you would recommend? i.e frame grabbers that are currently supported very well by PLUS.

Our target platform is 32-bit windows machine

thanks,
Andinet

#### 1 Comments
#### By Andras Lasso on 2012-05-21 12:40
We use analog framegrabbers with USB interface produced by Imaging Controls. They are inexpensive and we didn't have any issues with them.

Andras

From: Andinet Enquobahrie 
Sent: 2012-05-21 10:44 AM


## We would like to help in testing and improving the MicronTracker code in PLUS.
#### Posted by Andinet Enquobahrie on 2012-05-15 11:46

Hi all:

We would like to help in testing and improving the MicronTracker code in PLUS. We do have a MicronTracker here at Kitware.

1) Is there a particular git branch we should start off for testing and modification? In that way, the merge will go seamless later on if you decide to merge with your release version.

2) Are there any unit tests for the MicronTracker? i.e simple tests we can run to interface with the tracker and gather data

3) Are there any special cmake configurations for building the MicronTracker support other than turning on the MicronTracker option at upper level.

thanks,
Andinet

#### 10 Comments
#### By Andras Lasso on 2012-05-15 23:40
Hi Andinet,

1 => We use SVN, without a designated integrator it is simpler and safer to use than git. We rarely need branches, you can work on the trunk in this case, too (just make sure that all the test pass before you commit and refer to the ticket number in each commit comment, see some more info on this here: https://www.assembla.com/spaces/plus/wiki/Modifying_Plus_files).

2 => You can use the vtkDataCollectorTrackingTest for basic testing of any tracking device. For testing the timestamping accuracy: run temporal calibration and inspect the plots (you can use fCal for this).

3 => Just enable the MicronTracker support in CMake and select the correct SDK directories and it should work.

Andras
#### By Vikas Revanna Shivaprabhu on 2012-05-16 14:47
Hi Andras,

The vtkDataCollectorTrackingTest takes in a configuration file as input. In order to write one for the MicronTracker, I looked at the example configuration files in the PlusLib/data/ConfigFiles. I found one which had the MicronTracker (PlusConfiguration_SonixTouch_MicronTracker_3.2_L14_fCal1). I copied the "Tracker" information to a new file and gave it as input to vtkDataCollectorTrackingTest. I get an error saying "Unable to read configuration file". I have attached the configuration file I used.

I was not able to find information on how to write the configuration files or explanation on what needs to be provided in these files. Can you please help me with this ?

Also, should the configuration file include the marker information ? If yes, then how do we specify them.

Thanks,
Vikas
MicronTrackerConfigurationFile.xml	429 Bytes
#### By Csaba Pinter on 2012-05-16 16:36
First problem I see is that you didn't add a closing tag for the root node, so the XML is syntactically faulty.
There may be other issues later, but let's see first what happens when the XML reader can parse the configuration file.

We have had a wiki page describing the configuration file structure, but I can't find it. Does anyone know what happened to it?
The search function is temporarily offline, but I'll do my best :)
#### By Csaba Pinter on 2012-05-16 16:40
Here it is, somehow it became private:
https://www.assembla.com/spaces/plus/wiki/Configuration_file_structure
#### By Vikas Revanna Shivaprabhu on 2012-05-16 18:15
Thank you for the response. The configuration file got parsed after adding the closing tag. I now need to figure out how to specify the marker templates that the tracker should look for. Currently the openGL window runs but no markers are identified.

The "tool" argument in the configuration file requires the PortName. But in the case of MicronTracker, the tools are not connected to any port but are identified using markers/fiducials. Should the PortName be "None" and is there a specific way to specify the markers in the configuration file? The wiki page does not have this information.

Thanks
Vikas
#### By Andras Lasso on 2012-05-16 18:30
The MicronTracker driver has been made functional, but has not been cleaned up or documented properly.

If you have a look at vtkMicronTracker.cxx you can see that the port name is used to identify the template name. So, instead of "None" use the actual template name there.

Probably Hussam (by https://www.assembla.com/user/popup_profile/hussam.ashab), who worked on this class will also reply if you have any questions that Csaba or I cannot answer.

Andras
#### By Vikas Revanna Shivaprabhu on 2012-05-17 17:47
vtkMicronTracker looks for the markers in PlusLib-bin\src\DataCollection\Testing\Markers. The markers folder with the templates should be added to this path manually. Once this is done, the desired marker is tracked flawlessly.

We should probably make a note of this somewhere for future users.

When vtkMicronTracker::RefreshMarkerTemplates() tries to load the templates, it checks for callResult returned from MT->mtRefreshTemplates(vTemplatesName, vTemplatesError) and throws an error only if callResult == -1. But in the case where "Markers" folder does not exist, callResult is equal to 16. Addition validation needs to be added to handle this case.

Vikas
#### By Andras Lasso on 2012-05-18 09:33
Thanks for the testing, Vikas. I've added two configuration options to specify the ini file name and marker directory (relative to the configuration directory):
<Tracker Type="MicronTracker" ... TemplateDirectory="Markers" IniFile="MicronTracker.ini">

I've also cleaned up the MicronTracker C++ wrapper classes and added some more consistent error reporting. I could not test any of the changes without the hardware device. It would be great if you could check if everything works well.

Andras
#### By Vikas Revanna Shivaprabhu on 2012-05-18 12:05
The changes you made works. It would be useful if the user could specify a custom Template path. Right now it looks for the markers directory only in PlusLib\data\ConfigFiles\

Vikas
#### By Andras Lasso on 2012-05-18 12:17
Thanks for the testing. The paths are relative to the DeviceSetConfigurationDirectory. The DeviceSetConfigurationDirectory location is defined in PlusConfig.xml. By modifying the DeviceSetConfigurationDirectory location you can place your markers into any directory. Let me know if you need more customization of the directory location.

Andras


## Calibration algorithm in Plus
#### Posted by Siavash Khallaghi on 2012-05-16 21:27

Hi guys,

I am writing up my thesis proposal and I want to know what algorithm is used in Plus for temporal and spatial calibration. Could you please add references for the calibration to the wiki?

Thank you

#### 1 Comments
#### By Tamas Ungi on 2012-05-16 22:50
There is a "How to cite" section on the User guide page. It will hopefully contain more publications in the future. When I use PLUS, I also add a link to this assembla space in a footnote, when I first mention PLUS in a paper. This latter is more useful for reproducibility, because the algorithms constantly improve (i.e. change), so it would actually be misleading to point to a frozen state.


## OpenIGTLink GIT repository
#### Posted by Tamas Heffter on 2012-04-27 11:43

We're planning to switch the OpenIGTLink repository in the trunk from SVN to GIT repository master branch (which is the main source of the development) by next Friday, May 4, 2012.
The main reason is that they use SVN repository for Slicer releases and they don't merge the modifications really often.
If this modification is not convenient for you by any sense, please let us know before due date.
We will post further instructions about the change by next week.

#### 1 Comments
#### By Tamas Heffter on 2012-05-04 17:15
We've changed the OpenIGTLink repository in the trunk from SVN to GIT, so please follow the following instructions for the modifications take effect:
- Update Plus build folder
- Delete OpenIGTLink folder under Plus bin directory
- Compile PlusBuild solution

Those who have nightly builds, please don't forget to do the same thing.


## Post-proccessing of the tracking data
#### Posted by Abtin Rasoulian on 2012-05-04 14:52

Hi,

I have a question regarding the transformations (e.g. ProbeToTracker) saved using fCal and if there is any post-processing performed on the raw data acquired from the tracker.

This is the story. I was trying to track my 3D probe using the ascension tracker. First I run Cube together with Propello (the motor of the 3D probe was running). I could easily detect a vibration of 2-3 mm in the translation part. Then I did the same experiment with fCal and found that the ProbeToTracker transformation remains almost the same. It seems it is kind of an average over neighboring data. I was wondering if it is a correct observation.

Thanks,
Abtin

#### 1 Comments
#### By Andras Lasso on 2012-05-04 16:14
If you acquire the raw tracker data then there is no interpolation or processing. If you acquire tracked image data then you have to find the pose data corresponding to the image acquisition time. Of course the image and tracker data acquisition times never match exactly, so for each image frame you have to interpolate between the two closest tracker data. The interpolation in Plus is very simple: linear interpolation for the translation, SLERP interpolation for the rotation component.

Also check if you use exactly the same tracker settings in Cube and in Plus (frame rate, etc.).


## Mirrored Image in fCal compared to exam software
#### Posted by Simrin Nagpal on 2012-05-02 16:50

In what orientation does fCal display the image? Currently, the image in fcal mirrors the image in the exam software.

Thanks,
Simrin

#### 15 Comments
#### By Csaba Pinter on 2012-05-02 17:20
You can find all information about it here:
https://www.assembla.com/spaces/plus/wiki/Ultrasound_image_orientation

If the image you're getting is not consistent with the description (basically that whatever the original image orientation is, Plus stores and displays it in MF orientation), then it may be a bug. Please check and let me know.
#### By Simrin Nagpal on 2012-05-02 17:49
Thanks for the info Csaba. We've fixed it - there is no bug in the software.
#### By Siavash Khallaghi on 2012-05-02 17:57
Hi Csaba,

For my own EC9 probe, I followed the instructions in the link that you above to the letter, i.e. How to check that the UsImageOrientation is attribute set correctly. The result of the test was that the image orientation was UF, also in \PlusLib\data\ConfigFiles\PlusConfiguration_SonixTouch_Ascension3DG_EC9_fCal1.0.xml, the example orientation is UF.

Now when I display the image in my own application, which uses Plus libraries and is written just like fCal, I see that the Bmode image is mirrored.

If we change the image orientation to MF, this issue is resolved. The question is if we need to re-calibrate the probe? (We don't really want to do that because we have a very low error and it took us a long time to get there).
#### By Csaba Pinter on 2012-05-02 18:30
It's fine if the image is mirrored compared to what you see in the exam software. Using MF orientation internally is to avoid ambiguity and the need for preparing all the algorithms to handle various orientations.
If you check the images in the exam software and your Plus-based application according to the images in the tutorial above, then you can know for sure. If the marked side is towards the left of the image and the far side is downwards, then the UF setting is fine. But it is still important to set the original orientation correctly. You can do it by running the SegmentationParameterDialogTest application or the segmentation parameter editor in fCal (as described in the tutorial). If you see the image in MF orientation in those Plus applications, then you're fine.

It is still interesting how come it is so difficult to calibrate your probe? It would be very helpful to find out, maybe something is missing from our tutorials.
Make sure you have
no bubbles (stale water)
correct temporal calibration
good segmentation parameters (green dots appear during calibration)
correct holding of the probe (it is very important which side of the phantom faces the marked side of the probe, but if you get very high errors with good segmentation, then you're probably holding it the wrong way)
move it relatively slowly
scan as big part of the phantom as you can from various angles (don't worry about non-segmentable images, they are omitted)
#### By Siavash Khallaghi on 2012-05-02 18:39
Csaba is it possible to chat for a couple of minutes on Skype?
#### By Csaba Pinter on 2012-05-02 18:44
It's almost 1AM here, and I am on vacation...can we postpone it? :)
#### By Csaba Pinter on 2012-05-02 18:45
Please try to make sure that all the possible problems I wrote are not present.
#### By Andras Lasso on 2012-05-02 18:49
The orientation in the XML configuration file (ImageAcquisition element's UsImageOrientation attribute) describes the orientation of the image that the image source provides. So, it must be set based on how you acquire the image, and not how you want to later display the image.

I can confirm that if you acquire images using the EC9 probe using Ulterius then you'll receive the B-mode images in UF orientation, so the ImageAcquisition element's UsImageOrientation attribute must be UF in the configuration file. If you calibrated with UF orientation then you are good, you don't have to re-calibrate the probe. If you had incorrect orientation (MF) in the xml file at the time of calibration then you could try to manually modify the ProbeToImage matrix, but probably it's simpler to repeat the calibration instead.

If you display your image with VTK and need a different image orientation on your screen then change your renderer camera pose - do not flip the pixels or change the spacing of the image! If you display your image in a 2D image window (not VTK, VTK is always 3D) then specify the bitmap orientation in the drawing function (I don't know about APIs that do not support this).
#### By Siavash Khallaghi on 2012-05-02 18:52
I see. Have a nice trip and I appreciate the fact you are answering questions while you are on vacation.

The only issue that I want to make sure, and is a common question here at UBC, is this:

If the probe is calibrated with a specific orientation, is the calibration matrix still valid for tracking and volume reconstruction if we change the orientation?

I don't have problems calibrating the probe at the moment, so this is not the issue.
#### By Andras Lasso on 2012-05-02 19:02
> If the probe is calibrated with a specific orientation, is the calibration matrix still valid for tracking and volume reconstruction if we change the orientation?

No, it is not. The images are always converted to MF orientation right after they are acquired. If you change the orientation setting in the configuration file then Plus will reorder the pixels accordingly (if the received image is already MF then no reordering will be done; if the received image is UF then the rows are reordered; ...), so the same object will appear in a different position, which leads to a different ImageToProbe transformation.

If you set the image orientation incorrectly and calibrate then in the resulting ImageToProbe transformation matrix:
one coordinate axis will be inverted and
there will be a different translation along the inverted axis.
This change in the ImageToProbe transformation matrix may be reverted manually, but it's simpler to just repeat the calibration with the correct orientation setting.
#### By Siavash Khallaghi on 2012-05-02 19:10
Andras thank you for commenting on this. For the record, I calibrated the probe with UF setting . The three of us, Simrin, Saman and I are a little confused here, and I think I am more confused than the other two.

I have a question, does the image orientation attribute depend on the preset on the US machine? This is a snapshot of the prostate preset on the exam software.
Half_Sector_Biopsy.PNG	410 KB
#### By Andras Lasso on 2012-05-02 19:15
No matter what orientation you selected in the Exam software for display, through the Ulterius interface you always get the B-mode image from an EC9 probe in UF orientation.
#### By Simrin Nagpal on 2012-05-04 13:55
We re-did our calibration with a UF orientation for the probe and within the config file. The calibration result was pretty nice (0.64mm) and all plane wire segmentation visualization worked properly.

We then double checked the UF/MF definition for the probe. Using UF orientation, in segmentation dialog finger touching marked side appears in right side. But using MF value in config file that appears in left side which indicates that the orientation is not valid.

So, UF is correct, segmentation params are valid and calibration matrix is also correct.

When we then go into fCal to do our data collection using the config file from calibration, fCal displays the original image in a wrong way (appears mirrored).

Let me know if there is another test you want us to try.
#### By Tamas Heffter on 2012-05-04 14:13
Guys, maybe we should consider to add a feature to fCal where the user could change the camera position (aka image orientation) as they wish, because it turns out that is hard to follow our thinking about image orientation and they just want to see the same thing that they see on the US system.
#### By Simrin Nagpal on 2012-05-04 14:39
Tomi this would be great because our sonographer did not like that the image was flipped


## Connecting via Ulterius
#### Posted by VaultLab on 2012-04-27 18:08

Hi there,

Just wondering if fCal can connect to the SonixRP via the Ulterius API? Or do I have to run fCal.exe directly on the Sonix RP computer?

Loving the software, by the way. Looks like a really good product.

Tom.

#### 2 Comments
#### By Andras Lasso on 2012-04-27 20:52
Yes, fCal can connect to SonixRP through Ulterius from another computer, so you do not have to run fCal on SonixRP.
#### By Csaba Pinter on 2012-04-29 06:11
When you build fCal, make sure that the Ultrasonix version on your SonixRP machine matches the one you build Plus with.
You can check the available supported Ulterius versions in the PLTools/Ultrasonix directory.
You can specify the used version by entering the version number in CMake in the fields PLUS_ULTRASONIX_SDK_..._VERSION
If you can't find a matching version, consider updating the software on the ultrasound machine


## PlusServer exchange
#### Posted by Tamas Ungi on 2012-04-26 17:02

The new PLUS OpenIGTLink server functionality works fine. It is now available in the vtkPlusOpenIGTLinkServerTest program in PlusLib. Since it's a practical usable application, I think it should be moved to PlusApp as an application. I will delete the current PlusServer to avoid confusion. The current PlusServer was an attempt last year, but I didn't have time to implement anything useful in that. So it is better deleted.
The vtkPlusOpenIGTLinkServerTest can be named as PlusServer in PlusApp, because it fulfills the functionality I originally planned for PlusServer.

#### 9 Comments
#### By Tamas Heffter on 2012-04-26 17:30
The reason I've put it into PlusLib is it's basically just an example how to use the vtkPlusOpenIGTLinkServer class (and for testing purposes), the whole server is just a few lines of code as usual:
~~~~
vtkSmartPointer< vtkPlusOpenIGTLinkServer > server = vtkSmartPointer< vtkPlusOpenIGTLinkServer >::New();
  server->SetDataCollector( dataCollector );
  if ( server->ReadConfiguration(configRootElement) != PLUS_SUCCESS )
  {
    LOG_ERROR("Failed to read PlusOpenIGTLinkServer configuration!"); 
    exit(EXIT_FAILURE);
  }

  server->SetTransformRepository( transformRepository ); 
  server->Start();
~~~~

I'm planning to make a PlusServer GUI application with configuration file selector which will be in the PlusApp and it will display the connected clients, make more user friendly the message type editing (currently either the client should send a request with preferred message type or the server will send the default message types defined in the configuration file).
Also we can add this feature to fCal to act as an OpenIGTLink server (we just need to add the above mentioned few lines as a minimum) if we need it.
So, it can be either way, just let me know what is more convenient for everybody:
- test app in the PlusLib (vtkPlusOpenIGTLinkServer ) + command line app in the PlusApp (PlusServer) + GUI app in the PlusApp, command line app (PlusServer) added to the package
- command line app in the PlusLib (renamed to PlusServer) + GUI app in the PlusApp, command line app added to the package (PlusServer).

The main drawback would be to have vtkPlusOpenIGTLinkServer (as a test app) and PlusServer as a standalone app is that we need to maintain two almost identical app (like we used to do with VolumeReconstructor).
#### By Tamas Ungi on 2012-04-26 18:20
As a user I need a working PlusServer app (for e.g. the current vtkPlusOpenIGTLinkServerTest) in the installer package as soon as possible. If later you make the GUI for it, or improve it in any other way, it's even better. What you have now is good enough.
As a user, I don't care if a program is just a few lines of code. But I care a lot when I need it and it's not there.
#### By Andras Lasso on 2012-04-26 21:16
Let's go with option B:

Now let's just rename vtkOpenIGTlinkServerTest to PlusServer and make it available in the installer.

Later, when PlusServerGui (or PlusServerDaemon, or ... - we need a good name) will be completed we will 1. add PlusServerGui to the installer and 2. remove PlusServer from the installer (but keep it as a small test/example app in PlusLib).
#### By Tamas Ungi on 2012-04-26 21:27
Sounds good.
Tomi, I think the description of ticket #459 is a little outdated, and the title is too general. Maybe we should consider doing one or more new tickets based on this discussion.
#### By Csaba Pinter on 2012-04-27 06:20
I already have a ticket about adding it to fCal (#411). Tomi, if you need a really lightweight app for this then you can make the GUI app, if fCal is fine, then I can do it
#### By Tamas Heffter on 2012-04-27 11:30
Ok, I'll rename the test and close the #459 because it's already done and open a ticket for the new GUI app.
Csaba, I think both would be helpful, because sometimes displaying the US frames twice on the touch is a bit overkill, specially if we just want to broadcast the calibrated images (It was quite interesting I've tested it and it was almost around 100% CPU load all the time when we scanned meat, but if the probe was only in the air it was around 50% load using the command line tool and the exam software).
Also, we have a PlusBroadcasterDaemon application, which is doing similar task, but Plus as a client. I was thinking to add the server mode to this app and than we could choose to run Plus as server or client (just as Slicer OpenIGTLinkIF module), and it could act as a daemon truly - but Andras is right, we need a good name.
#### By Andras Lasso on 2012-04-27 12:12
CPU load may be related image contents if we use image compression Ulterius (probably we do). If the image is simple, then the compressed image is much smaller, therefore less data need to be copied and sent over TCP/IP.

Let's continue the discussion at #459 and #411 to not broadcast further messages to everyone.
#### By Siavash Khallaghi on 2012-04-27 13:24
I don't know how relevant this is, but in ulterius Bmode processing (e.g. scan conversion, de-speckle filter) is done on the CPU, which takes up resources. If you turn the de-speckle filter off, you will free up a lot of CPU load.
Also if you are sending images to Slicer, you can reduce the frame rate, this will free up CPU resources as well.
#### By Andras Lasso on 2012-04-27 15:02
Thanks for the info Siavash. I've added it as a note to https://www.assembla.com/spaces/plus/wiki/Frequently_asked_questions.


## Sonix RP and Ascension TrakSTAR
#### Posted by VaultLab on 2012-04-23 00:14

Hi there,

I am just wondering if it is possible to use fCal with the Ultrasonix SonixRP US system and the Ascension TrakSTAR 3D tracking system?

Many thanks,
Tom.

#### 1 Comments
#### By Andras Lasso on 2012-04-23 07:55
All Ultrasonix devices are supported, just the exam software version has to be compatible with the SDK version that was used to build Plus. If you have any problems then either upgrade your exam software or rebuild Plus with an older Ultrasonix SDK.

The Ascension TRAKStar is similar to the Ascension 3DG, so select the 3DG and see if it works. If not, then you have to rebuild Plus, using the TRAKStar driver files instead of 3DG.

We can give further help if you run into problems, just send the exact error messages and symptoms that you experience.

Andras


## extract ROI from SonixVideoSource
#### Posted by Elvis Chen on 2012-04-20 09:27

I'm trying to follow vtkSonixVideoSourceTest1 to stream video from Sonixtouch. While it works, the received US image does not occupy the entire image data, thus making texture mapping difficult.

how is the ROI extracted from vtkSonixVideoSource? Is there a more concrete example on how this is accomplished?

thanks,

#### 1 Comments
#### By Andras Lasso on 2012-04-20 10:27
Currently cropping the image acquired by vtkSonixVideoSource is implemented at the application level (e.g., fCal ignores the regions that are outside a user-specified region). We could crop the image within the video source. We've already created a ticket for this (#433), but there was no urgent need for implementing this. It would be great if you could implement this feature in the vtkSonixVideoSource.


## ICCapturing frame grabber support
#### Posted by Tamas Heffter on 2012-04-19 16:14

If your using Plus from trunk and enabled PLUS_USE_ICCAPTURING_VIDEO than please update your PlusBuild folder and PLTools repository and build it again (It might happen that you have to rebuild the vtkImageAcquisition project).
Thanks,
Tamas Heffter

#### 0 Comments


## Complete your contact information
#### Posted by Andras Lasso on 2012-04-18 10:47

Please complete your contact information in Assembla.

https://www.assembla.com/user/edit/edit_account_information
- Enter First Name, Last Name
- Show your name to Teammate (or Public)

https://www.assembla.com/user/edit/edit_contact_information
- Enter Organization (name of lab/department and university/institute/company)
- Share Organization with Teammate (or Public)

thanks,
Andras

#### 0 Comments


## Interpreting the calibration matrix from fCal
#### Posted by Siavash Khallaghi on 2012-04-09 01:16

Hi guys,

I have been having trouble with the double N-wire calibration using fCal as the calibration matrix is not orthonormal and seems to be null. I read through the trouble-shooting and tried adding another N-wire to the phantom, following the instructions in https://www.assembla.com/spaces/plus/wiki/Free-hand_probe_calibration

So now I have this calibration matrix, also attached in my calibration configuration file. Let's call it A, as A = [R,T], where R is the rotation and T is the translation component of A.
~~~~
A = -0.0165078 0.0862733 -0.00181328 32.7662
    -0.00120091 0.00160881 0.0882297 2.48945
     0.0870756 0.0166 0.00087307 -30.7244
     0 0 0 1
~~~~
I would assume that R*R' would compute to identity, where R' is the transpose of R. However it equals 0.0078 times identity. Why is this happening?
FreehandCalibration_April_5_2012.xml	7.8 KB

#### 27 Comments
#### By Tamas Ungi on 2012-04-09 07:33
Hi Siavash,

The calibration result will always have some extent of error. The rotation matrix is 'almost' orthogonal, it can be decomposed to diagonal (scale), orthogonal (rotation) and an 'error' component. If you want to do that, it's possible in Matlab, but when we discussed this, we decided to leave the matrix as it is. The error can be minimal with three N-wires, temporal calibration before the spatial, and careful motions during calibration.

The error also depends on what probe are you using. We recently realized that larger probes (e.g. C5-2) have wide beam, so diagonal wires cannot be segmented with a high accuracy. This causes more error in them. I suggest you to put the probe name and depth setting to the config file in the device set part. It's very easy to forget what probe/setting did you compute a calibration for. What probe did you use and what depth setting?

Have a look at the 3D view of the calibration. Test if the image position and its contents make sense as the image intersects the fCal phantom. If you are not satisfied with the result, there are a couple of things you can try to improve your calibration. Including landmark registration in Slicer by recording needle tip positions with LiveUltrasound.

Hth,
Tamas
#### By Siavash Khallaghi on 2012-04-09 08:05
I have a calibration preset that I have saved on the US machine, so I never forget the setting that I used it for. I calibrated it for the EC95 probe, at 4 cm depth. I want to know if having a 0.0078 scale is reasonable?

Also I have seen in the video that you guys do a translational motion for volume reconstruction, is your reconstructed volume still valid of you do a rotational motion? I am asking this because my reconstructed volume is correct if I just do a freehand sweep with just a translation.
#### By Tamas Ungi on 2012-04-09 09:22
I've never used that probe with such a small depth, so I don't know what would be a correct spacing. I can try to calibrate our EC95GPS tomorrow and see what matrix do I get.

The volume reconstruction should be good with any random motion, we have tested it many times. If your calibration (and temporal calibration!) is good. Have you done temporal calibration? It's a quite new feature in Plus. I've uploaded the video just two days ago: https://www.assembla.com/spaces/plus/wiki/Temporal_Calibration
#### By Andras Lasso on 2012-04-09 12:19
Siavash, we have already discussed about why you may have non-orthogonal calibration matrix and what to do about it - see the FAQ section on the https://www.assembla.com/spaces/plus/wiki/Free-hand_probe_calibration page.

Tamas, in the FAQ section this option is not described: "you can try to improve your calibration. Including landmark registration in Slicer by recording needle tip positions with LiveUltrasound." Could you describe the process shortly in the FAQ section or add a link to a page where it is described in detail?
#### By Siavash Khallaghi on 2012-04-09 15:56
Tamas, I didn't do temporal calibration. I just used the 0.2976 time lag that you guys have calculated. If you think 0.0078 is not reasonable, I will give temporal calibration a try.

Andras, I have done all of the steps in the FAQ session and I mentioned it above as well. There is no orthogonality error on fCal, I believe the 3N-wire phantom is correctly wired and 90% of segmentations succeed during free-hand calibration.

The first issue is that I am not sure if the matrix is non-orthogonal, this is why I am asking if a 0.0078 scale reasonable?
#### By Csaba Pinter on 2012-04-09 16:10
0.0078 looks one magnitude smaller than usual for a normal probe.
It means that 0.0078 mm is one pixel in one of the directions, ie. 1 mm is 128 pixels, which implies that the 820x616 pixel image is around 6.4 mm x 4.8 mm (supposing a uniform scaling).
Provided that the probe you're using is not a very high resolution one (probably it's not as you mentioned 4 cm depth), this scaling seems to be wrong.
(Unless you accidentally wrote 0.0078 and meant 0.078 which is about the scaling factor we get.)

About the temporal calibration, I recommend to use it now that we have it, because it improves the results significantly.
#### By Csaba Pinter on 2012-04-09 16:13
I calculated the scaling of the matrix you pasted here using the method VTK uses to get the scaling of a transform (Singular value decomposition), and it turns out to be
~~~~
    0.0887         0         0
         0    0.0883         0
         0         0    0.0879
~~~~

which is very believable.
#### By Siavash Khallaghi on 2012-04-09 16:13
Hi Csaba,

Can someone describe the temporal calibration in the wiki? i.e. what kind of motion, how to move the probe?
#### By Csaba Pinter on 2012-04-09 16:15
Tamas made a video and a wiki page about this:
https://www.assembla.com/spaces/plus/wiki/Temporal_Calibration
#### By Siavash Khallaghi on 2012-04-09 16:16
Well this is embarrassing, I must have made a mistake calculating the scale in Matlab. :)
#### By Csaba Pinter on 2012-04-09 16:17
At least we found that it is correct after all. That's a relief anyway, isn't it? :)
#### By Andras Lasso on 2012-04-09 16:18
The 3x3 rotation part of a transformation matrix contains the unit vectors of a coordinate system described in the other coordinate system. You can easily compute the angles between the axis vectors by computing the arc cos of the scalar product of the normalized vectors.

The length of each each axis vector is about 0.09, which is not too small (about 0.1mm/pixel), assuming it is an Image to Probe transform. Never call a transformation matrix "A" or "calibration matrix", etc., but use the Frame1ToFrame2Transform naming convention (e.g., ProbeToImageTransform or ImageToProbeTransform).

You can check the calibration accuracy in fCal by comparing where the calibration phantom wire intersections appear on the US image and where you see the intersections in the 3D model. Also, you can move a tracked stylus in the field of view and check if the stylus tip appears in the same position in the US image as in the 3D model.

The time lag may depend on many factors (imaging parameters, connection type, speed, etc.), so it has to be measured for each device set.
#### By Siavash Khallaghi on 2012-04-09 16:21
Thank you everyone for helping me with this. I think I know what to do now.
#### By Csaba Pinter on 2012-04-09 16:24
If I have only the saved data, but don't want to/cannot try it on the devices, I add a DisplayableObject of the Axes type for the CoordinateFrame of the Probe.
<DisplayableObject Type="Axes" ObjectCoordinateFrame="Probe" />

Since the probe model is bound to the image coordinate frame using the ImageToProbe transformation, you cannot tell anything from the alignment of the image actor in relation of the probe model. But by adding this object, the probe coordinate frame is displayed, and if it is inside the probe model, approximately at the position where the marker should be, then you can suppose it's good.
If the calibration errors are low, then you have one more reason to believe it's good.
#### By Tamas Ungi on 2012-04-10 14:00
I've added some instructions on how to refine the calibration using fiducial registration in 3D Slicer. I'm not planning to create a beginner level tutorial on that method though, it is for people who know how to use LiveUltrasound and FiducialRegistration modules in Slicer.
#### By Siavash Khallaghi on 2012-04-10 17:15
I thought maybe you would be interested in the result of temporal calibration with the EC95 probe and the magnetic tracker. I performed five temporal calibration trials and the results were the following (reported in seconds): 0.087, 0.071, 0.080 0.084 and 0.069.

I have attached the screenshot of the temporal calibration and the bottom of the water tank.
plot.PNG	263 KB
bottom.PNG	305 KB
#### By Andras Lasso on 2012-04-10 22:49
Thanks for the info!
#### By Tamas Ungi on 2012-04-10 22:51
I really hope that your image calibration will be better with a temporal calibration of 0.076 sec (or so). Let us know.
#### By Siavash Khallaghi on 2012-04-10 23:05
After repeating the experiment a couple of times, it seems that 0.084 seconds is the right number. The best calibration result that I got was a mean of 0.4 mm with a std of 0.2 mm at the depth of 4 cm.

I could not calibrate the probe for a depth of 5 cm, which was my goal, the segmentation algorithm had problems and playing with ImagingInterval and MaxTimeSpentForProcessing did not solve it.

For a depth of 4 cm, it seems the MaxTimeSpentForProcessing and ImagingInterval should be set to 200 and 300 respectively, instead of 70 and 100 in the current configuration file.
#### By Andras Lasso on 2012-04-10 23:57
We've never had problem with processing the images during acquisition in release mode. Maybe you use a very slow computer, an application compiled in debug mode, bad segmentation parameters (that detect many wire point candidates), very high frame rate, or you have bad image quality (with lots of bright pixels that the segmentation algorithm may consider as wire point candidates).

If you cannot resolve the problem based on these suggestions then we can have a look at the issue, just send us a tracked frame sequence and the xml config file.
#### By Tamas Heffter on 2012-04-11 01:16
Siavash,

Don't forget to adjust the pixel spacing on the segmentation parameter window (that's the main difference between 40mm and 50 mm depth).
#### By Csaba Pinter on 2012-04-11 11:45
MaxTimeSpentForProcessing and ImagingInterval parameters should not influence the success of a calibration, they only indicate that the acquisition is not continuous. Despite this warning, the calibration should go all the way.
Check if the green dots are appearing in the image. If they do, then probably the image is noisy and the segmentation is slow due to too many candidates. If they don't appear, then try to fix the segmentation with the segmentation parameter edit dialog.
#### By Siavash Khallaghi on 2012-04-13 17:35
I am thinking that the water from our sink is dirty and has a lot of impurities in it. So I am going to try using bottled water and see if things improve.
#### By Tamas Ungi on 2012-04-13 21:55
Have you tried limiting the region of search in the image to the least necessary size? (Pink rectangle when you set the segmentation parameters.) And reducing the gain and dynamic range as low as to visualize just the wires as tiny white dots on black background?
#### By Siavash Khallaghi on 2012-04-13 22:02
Hi Tamas,

I was showing Purang a demo of my application earlier today. I use a very clean plastic box as the water bath and I wash it regularly, so it is very clean. Also I leave the water for ~10 minutes so that the impurites either rest at the bottom or at the surface.

But if I just hold the probe inside the water bath, I see a number of white dots. So I think the issue is that the water coming out of the sink is not very clean.
#### By Tamas Ungi on 2012-04-13 22:16
But when you are setting dynamic range to about 30, and then turning down the gain gradually from 60 to about 30-20, is there a point when those "noise" dots are not visible anymore, but the wires are still visible? That's the setting you should use for calibration. Also, increase the number of focus points until your framerate drops to about 10. That will leave more computation capacity for fCal, so it won't slow down.
#### By Csaba Pinter on 2012-04-14 09:07
Siavash,
We had the same issue. Probably your imaging setting are just fine, those dots are bubbles in the water. You can't see them, because they are very small, but they show up in the image. Thus, I always have a bucket of "stale" water for calibration. If you wait a day, the bubbles are gone. Try it.


## problem commiting files
#### Posted by Elvis Chen on 2012-04-10 17:06

was trying to commit a change to vtkNDITracker. Using SVN GUI, got the following error (see attached screen capture). Sorry not really familiar with SVN checkout/commit process in Windows. Is updating PLUS necessary?
commit_error.png	95.8 KB

#### 1 Comments
#### By Siavash Khallaghi on 2012-04-10 17:10
Hi Elvis,

Try moving vtkNDITracker.cxx (and other files that you have modified) to a different folder, then delete all the files in PolarisTracking and perform a clean checkout. After that move back the files that you have modified (i.e. vtkNDITracker.cxx) back to PolarisTracking. This is a crude way of doing things, but it should solve your problem.

Siavash


## Application crash if dataCollector is connected and idle for a long time
#### Posted by Siavash Khallaghi on 2012-04-04 18:41

Hi guys,

I don't know if you have seen this, but if I am running fCal (or my own application) and if I leave the dataCollector connected to the software and idle for a long time, the application crashes.

Attached is the screenshot from my own application, but you can reproduce the same thing on fCal as well.

Siavash
error.PNG	337 KB

#### 4 Comments
#### By Siavash Khallaghi on 2012-04-04 21:21
I forgot what a long time is, it is about 30 minutes.
#### By Andras Lasso on 2012-04-04 21:40
It may be a memory leak. Is the process memory consumption increasing continuously (check it with taskmgr or perfmon)? Could you attach the log file of the crash?
#### By Csaba Pinter on 2012-04-05 16:49
Siavash, if you find a bug it would be a good idea to create a bug ticket instead of posting a message.
You can follow this issue here
#### By Siavash Khallaghi on 2012-04-05 20:46
Sure. I will report the bugs in tickets from now on.


## single-wall phantom calibration (Matlab code available)
#### Posted by Elvis Chen on 2012-03-22 11:46

hi all,

I have 2 implementations of single-wall phantom calibration based on Prof. Rohling's papers. The 1st implementation was based on the original paper (i.e. iterative solution), the 2nd one is based on the closed-form solution from the 2012 SPIE paper. Both versions were implemented in MATLAB.

We are a bit short-staffed here. Ideally I would like to assign this to a summer student so we can re-implement this in PLUS as a PLUS-application. If anyone is interested in doing this, please let me know. We can certainly engage conversation in Assembla to see if there is any interests integrate this into PLUS.

#### 5 Comments
#### By Andras Lasso on 2012-03-22 19:23
It would be definitely interesting to have the single-wall calibration here, especially if the results are better or comparable to the multi-N calibration phantom. What is the accuracy of the method? How many frames do you need to acquire? How sensitive are the results for the imaging parameter settings? Could you send the link to the paper?

It's not an urgent task, so I would add it to the list of tickets and whenever there is somebody at Robarts or Queen's to work on this can take it.

We have a quite nice and robust line detection algorithm that we use for temporal calibration. That might be used for feature extraction and then we would just need to integrate the optimization part.
#### By Elvis Chen on 2012-03-23 14:03
The original paper is:

Rapid Calibration for 3D Freehand Ultrasound
R.W. Prager, R.N. Rohling, A.H. Gee, and L. Berman
Ultrasound in Med.&Biol.
vol. 24, no.6,
pp855-869
1998

this is a very good paper and describes everything very well. The single-wall calibration algorithm described in this paper uses an iterative solver. In my experience, it requires more than 100 images to get a stable solution, although if you collect the images carefully, my simulation suggests that about 60 images will suffice.

This year in SPIE (2012) a closed-form solution was presented by:

Single Wall Closed-form Differential Ultrasound Calibration
Mohammad Najafi, Narges Afsham, Purang Abolmaesumi, and Robert Rohling
SPIE Medical Imaging, 2012, San Diego

While this paper presents a closed-form solution, in practice, an iterative solver should be used to get a more robust answer. The closed-form solution will only work if the data collected are good; since this involves a pseudo inverse of a large matrix. If the data corrected were not good, then the matrix won't be full rank.

The advantage of the single-wall calibration is that it is easy to perform. So while it may need a large number of images to get a solution, these images can be collected in relatively short amount of time.

My implementation in matlab also has line detection algorithm (RANSAC based). Integration of it into PLUS shouldn't be too difficult provided the linear algebra part is available. For the closed-form solution, the pseudo inverse can be computed using SVD, which I already implemented in C++. On the other hand, if we want to use the iterative solver, we may have to use ITK extensively.
#### By Andras Lasso on 2012-03-23 14:38
OK, thanks for the information. We'll integrate the iterative algorithm then.

The line detection algorithm that is already available in Plus uses a very similar method to Prager1998: sample along parallel lines, detect peaks, do RANSAC line fitting. There is a slight difference in peak detection: we use the center of gravity of the highest-intensity peak. Very well optimized SVD and all kinds of linear and non-linear solvers are already available in ITK (through VNL). Therefore, we'll just need to port the part of the code that constructs the matrices from the line detection and tracking results.

I've added ticket #456 to track this task.
#### By Mohammad Najafi on 2012-03-31 16:26
Hello everyone,
I would like to clarify on the "Single Wall Closed-form Differential Ultrasound Calibration" method. The pseudo inverse of a non-square matrix is calculated by a simple algebraic formula. {A}^-1= {(A^T*A)}^-1* A^T (http://en.wikipedia.org/wiki/Generalized_inverse)
Therefore even if there are many rows in A, the term that is inversed is the size of the columns of A (in this case 17x17). So it is very fast and easy to compute it.
Also it is not true that the matrix is not full rank. On the contrary we always can get the result but it doesn't mean that it is not sensitive to error. In fact the problem is that with low number of images the solution is very sensitive to measurement error. One reason is perhaps the indirect calculation of the solution using substitute variables.
Since you have optimized SVD algorithms, another approach is by using SVD to solve X. I've attached a MATLAB implantation for this. It simulates 50 poses (1000 trials) by adding axial noise (normal distribution) to each column. The MATLAB implementation is very fast (0.07 s for computation of 50 poses once)

Regards,
Mohammad
4Plus.zip	2.34 KB
#### By Andras Lasso on 2012-03-31 17:01
Thanks for the information, Mohammad. We've already created a ticket for tracking this task - let's continue the discussion there (https://www.assembla.com/spaces/plus/tickets/456).


## Video for Windows
#### Posted by GuillermoCarbajal on 2012-03-21 14:55

Hi all,
I would like to capture US video signal with a framegrabber. I configured PlusLib with Video For Windows enabled but It didn´t work.
The reason is that the class that make the interface with VFW (vtkWin32VideoSource2) inherit from vtkPlusVideoSource but it doesn't override parent class properly. It looks as if it is work in progress. What do you recommend ? It would be great if I could help you in some.

Thanks in advance,
Guillermo

#### 3 Comments
#### By Andras Lasso on 2012-03-21 15:18
We haven't completed the implementation of this video source, as has been no requests for it so far. Could you try to add the missing functions (using the ICCapturing or SonixVideo classes as exmample)? We would be happy to help you with any specific problems.

If you don't have time for completing the class then we can do it, too, but it would take at least a couple of days.
#### By Andras Lasso on 2012-03-21 19:34
I'm working on a quick fix for this. Is it OK to have only grayscale image acquisition?
#### By Andras Lasso on 2012-03-22 19:18
Now you can acquire images through the Video for Windows interface. It supports only the YUY2 pixel format (common for webcams) and converts the acquired images to grayscale, but otherwise it's functional. If you need any enhancements then add it to ticket #454.


## speed-of-sound phantom
#### Posted by Elvis Chen on 2012-03-22 12:17

In 2012 SPIE we have published a paper on testing the speed of sound of an US medium using a simple apparatus. The full citation of the paper is:


@conference{buchanan:83162B,
author = {Susan Buchanan and John Moore and Deanna Lammers and John Baxter and Terry Peters},
editor = {David R. Holmes III and Kenneth H. Wong},
collaboration = {},
title = {Characterization of tissue-simulating phantom materials for ultrasound-guided needle procedures},
publisher = {SPIE},
year = {2012},
journal = {Medical Imaging 2012: Image-Guided Procedures, Robotic Interventions, and Modeling},
volume = {8316},
number = {1},
eid = {83162B},
numpages = {8},
pages = {83162B},
location = {San Diego, California, USA},
url = {http://link.aip.org/link/?PSI/8316/83162B/1},
doi = {10.1117/12.911432}
}

Two pictures of the phantom are attached.

The basic idea is that the plastic straw can be segmented easily in an US image and the distance between the two straws servers as a reference for calculating the speed of sound. The fishing-wires at the top/bottom are to ensure that the US image is in-plane.

Gabor suggested to integrate this into PLUS-apps. This may be an over-kill to implement this in PLUS since no tracked-US is needed. Nonetheless, it will be an useful tool.

any comment is very much welcomed.
DSC_0156s.jpg	213 KB
DSC_0157s.jpg	243 KB

#### 1 Comments
#### By Tamas Ungi on 2012-03-22 14:59
We discussed a little about speed of sound. You were right that it's really a simple thing to measure, and we shouldn't complicate PLUS by adding this. Thank you for the offer though.


## Image buffer and tracked frame list.
#### Posted by Siavash Khallaghi on 2012-03-11 22:40

Hi everyone,

In the following, image data is an image from Sonix without a transform, a frame is an image with a transform. So now that I have the definitions down, let me explain my problem.

We are capturing tracked RF images with high frame rate using vtkDataCollectorHardwareDevice, i.e. something that looks like this:
RFTrackedFrameList->AddTrackedFrame(&_newFrame,vtkTrackedFrameList::ADD_INVALID_FRAME_AND_REPORT_ERROR) //The more frames the better, even if the transform is wrong
RFTrackedFrameList->SaveToSequenceMetafile(this->GetOutputFolder(),(_fileName.str()+"_Tracked").c_str(), vtkTrackedFrameList::SEQ_METAFILE_MHA,false);
RFTrackedFrameList->Clear();

We noticed that with high frame rate we have a frame loss that is not acceptable. So we decided to write the image buffer as well, since the in the buffer has some of the frames that we had missed in the tracked frame list. So we added the following line of code:
vtkVideoBuffer * buff = dataCollector->GetVideoSource()->GetBuffer();
buff->WriteToMetafile(outputFolder, bufferFileName, false);

When we try to write out the buffer, we run out of memory (failed to allocate memory for new frame...) even though we have cleared the RFTrackedFrameList. Can you tell us what we are doing wrong?

Thank you

#### 3 Comments
#### By Andras Lasso on 2012-03-11 22:58
In the VideoSource class the frames are stored in a circular buffer, but the sequence metafile writer requires a TrackedFrameList object as an input. Therefore, in the vtkVideoBuffer::WriteToMetafile method all the frames in the buffer are copied to a TrackedFrameList before writing them to a file. If the buffer is large then there may not be enough memory to duplicate all frames.

I would suggest to use the first (AddTrackedFrame/SaveToSequenceMetafile) method. If you add all the frames from the buffer to the tracked frames list that you acquired since the last frame addition (not just the latest acquired frame) then you will not miss any frame.
#### By Siavash Khallaghi on 2012-03-11 23:10
Andras, by " If you add all the frames from the buffer to the tracked frames list that you acquired since the last frame addition (not just the latest acquired frame) then you will not miss any frame." do you mean something like this?
dataCollector->StartRecording();

//Wait for 4 seconds (pseudo code)

dataCollector->StopRecording();

if( dataCollector->GetMostRecentTimestamp( current_frameTS ) != PLUS_SUCCESS )
	LOG_ERROR("startCaptureBiopsy: Lost most recent time stamp: " << current_frameTS);

dataCollector->GetTrackedFrameList(current_frameTS, RFTrackedFrameList, -1);

RFTrackedFrameList->WriteToSequenceMetaFile();

I think we tried this and it did not work for us. But if this is what you mean, we can give it a try again.
#### By Andras Lasso on 2012-03-12 09:37
You should keep calling GetTrackedFrameList() between StartRecording/StopRecording with a timer, several times per second. This will copy the frames from the circular buffer to a TrackedFrameList. The circular buffer can be quite small (it should be just big enough to store all the acquired frames between GetTrackedFrameList() calls) and only the TrackedFrameList will grow, so there won't be excessive memory use. When you write a TrackedFrameList to metafile you can just pass the TrackedFrameList object to the file writer, so (in contrast to circular buffer writing) there is no internal copying of all the frames.

This is all nicely implemented in fCal, so you can use the CapturingToolbox::Capture() method as an example. This method is called a couple of times per second to get the recently acquired frames from the circular buffer and store them in a TrackedFrameList. It uses the GetTrackedFrameListSampled method, which retrieves frames from the circular buffer with an arbitrary requested frame rate. If the requested frame rate is equal or higher than the acquisition frame rate then it will retrieve all the frames. If the requested frame rate is lower than the acquisition frame then it'll skip frames to achieve uniform sampling corresponding to the requested frame rate. The method also estimates the actual recording frame rate (m_ActualFrameRate) and can detect if you loose frames because there is not enough time for processing and storing the frames ("Recording cannot keep up with aquisition").


## Tracking performance of Ascension on Ultrasonix?
#### Posted by Elvis Chen on 2012-03-09 13:57

hi all,

We are just testing fCal using the SonixGPS system. A picture of our set up is attached. As you can see, it is a fairly clean environment. The cart is made of plastic with no metal objects near by. The only machine/metal in the field is Ultrasonix US machine itself.

However, we are getting VERY bad readings from the Ascension/PLUS. For example, if we place a needle at about 30cm from the field generator, leave it stationary on the table, the reading we get it from fluctuate dramatically by as much as 15mm or so. If the needle is about 10cm from the field generator, the number are a lot better, it only fluctuate in the order of 1mm.

This is with the needles we borrowed from Queen's. Unfortunately we don't have any other Ascension sensors we can repeat this exercise.

Is this the experience you guys have at Queen's? At this tracking performance, it is rather useless. Any idea what might be causing such a bad tracking behavior?
DSC_0125.JPG	2.38 MB

#### 1 Comments
#### By Tamas Ungi on 2012-03-10 12:00
Yes, you guys have the 0.55 mm sensor needle, because that was the only one I could lend right now. It can be operated max. 15 cm from the FG. And even in the optimal range, it has about 1 mm error.
This is the price for the tiny size and immunity to metal.

Please upload smaller images to Assembla next time. It's a drawback of Assembla that it cannot automatically optimize image size.


## segmentation parameters
#### Posted by Elvis Chen on 2012-02-29 10:42

hi all,

We are in the process of using fCal to calibrate an ultrasonix probe with NDI Aurora. We could not adjust the segmentation parameters to recognize the n-wires. We are currently using a 2 N-wire setup. The dots on the screen representing the wires are segmented (red dots), but we cannot get it to turn green.

We have played with a lot of parameters, including adjust the gain on the machine, to no avail.

any tips on how to properly segment the wires? The wires we are using are 0.022" fishing wires, which is roughly 0.5mm in diameter.

thanks,

#### 6 Comments
#### By Andras Lasso on 2012-02-29 10:44
Could you record a couple of tracked frames and attach it, along with the config file?
#### By Csaba Pinter on 2012-02-29 10:48
Usually I use maximum power with low gain (so that the wires are virtually the only visible objects and they are quite bright).
If you have the candidates, then your image settings should be fine.
What can be a problem, is the spacing. Switch to spacing mode (tere is a radio button for that, the default mode is ROI). Then enter the two distances you want to measure (for fCal it is 30mm and 5mm) and drag the endpoints of the two lines that appear over the image to the wire positions (one for horizontal, one for vertical). The pattern settings should be fine.
If the pattern is still not recognized, please send us a recorded image sequence.
#### By Elvis Chen on 2012-03-09 14:29
Here is the screen capture of the fCal segmentation. We took Csaba's suggestion, using maximum power with low gain. Please take a look at it.

thanks,
fCalFreehandCalibrationMar9.PNG	401 KB
#### By Siavash Khallaghi on 2012-03-10 04:15
Elvis, in your snapshot one of the wires is not visible (bottom right). The red dots will turn green only if ALL six wires are visible.
#### By Tamas Ungi on 2012-03-10 11:25
And don't forget to set the spacing as Csaba described. I've shown Matthew the spacing tool when he was here. The green and the blue bar.
#### By Andras Lasso on 2012-03-10 11:41
As Siavash wrote, the problem is that there is almost no reflection from the bottom right wire. If you use a single-filament nylon wire then you can try to roughen the surface of the wire by a sandpaper to make the reflection more diffuse. Alternatively, you can try to use a braided fishing line. You may also improve the visibility by reducing the dynamic range (Dyn).

## NDI flat-bed field generator works
#### Posted by Elvis Chen on 2012-03-09 14:32

just a confirmation that NDI flat-bed field generator (with USB SCU) works with PLUS. Even through SCU is now USB instead of serial connection, Windows will detect it as a serial port. As far as PLUS is concerned, there is no difference between flat-bed and the regular field generator.

#### 0 Comments


## Hole filling is now available in volume reconstructor
#### Posted by Thomas Vaughan on 2012-03-06 10:57

We've implemented a hole filling algorithm in the Volume Reconstructor. For details on how to run the Volume Reconstructor, please refer to the wiki page here: https://www.assembla.com/spaces/plus/wiki/Volume_Reconstruction and to the PDF here: https://www.assembla.com/spaces/plus/documents/aVsooSzwKr4BOHacwqjQWU/download?filename=HoleFillingPPT_March6.pdf

Our algorithm fills a hole by using a weighted average of voxels in the surrounding 3x3x3 cubic neighborhood. The weight currently takes into consideration the number of intersecting slices, and the distance between voxels using a Gaussian kernel. There are some issues, such as blockiness (as seen in areas of low sampling in the screenshot) and not all holes being filled. We hope to achieve a better reconstruction by taking more factors into consideration, such as slice direction. We may try other methods as well. A ticket (#436) has been created to track any further changes.

The attached screenshot shows cross-sections of various prostate phantom reconstructions:
- The "Ground Truth" consists of a series of densely collected US slices directly pasted into the volume
- The "Pasting Slices Only" shows the reconstruction using a subset of slices without hole filling
- The "Pasting Slices and Fill Holes" shows the reconstruction using the same subset of slices with hole filling.

If you experience any problems with the Volume Reconstructor, please let us know.
HoleFillingExampleProstate_March6.PNG	62.6 KB

#### 1 Comments
#### By Tamas Heffter on 2012-03-06 11:26
Nice job Thomas!


## fCal: must probe sensor always be sensed?
#### Posted by Elvis Chen on 2012-03-02 15:08

hi,

a minor suggestion. I noticed that, in fCal, the sensor attached to the US probe must always be present in order to use other sensors. I understand the rational behind it, afterall, we are calibrating the US probe.

However, for example, say we are registering the fCal phantom. In this part of the procedure, only the sensor on the phantom and the stylus are needed. It would be nice if we can register the phantom while not have to worry about keeping the probe inside the field of view.

#### 10 Comments
#### By Csaba Pinter on 2012-03-02 15:38
Elvis,
You don't need to have the probe tracked. You can edit the tracked tools in the configuration file. If you remove the Tool elment of the probe from the Tracker element, you already got rid of the probe.
May I ask how you got to this conclusion that you have to track the probe?
#### By Elvis Chen on 2012-03-02 15:47
if the sensor attached to the probe is moved outside of the viewing volume of the tracker, ALL sensors are reported as missing. That's why I concluded that the probe must always be tracked.
PlusConfiguration_SonixRP_L14-5_NDIAurora_fCal_1.0.xml	6.1 KB
#### By Csaba Pinter on 2012-03-02 16:02
Can you send me the configuration file you used when this occurred?
Do you use fCal when this happens? If yes, then in which step?
#### By Tamas Ungi on 2012-03-02 16:07
This typically happens when the reference is moved outside the tracking range. Obviously nothing can be tracked if the reference is missing.
#### By Elvis Chen on 2012-03-02 16:07
see attachment. This is what you created when I was in Kingston. The modification I made was the serial port number and the IP address of our ultrasonix machine.

yes, it was while using fCal this happened, during the phantom registration step.
PlusConfiguration_NoVideo_NDIAurora.xml	2.88 KB
#### By Csaba Pinter on 2012-03-02 16:08
Tamas, there is no reference in fCal any more.
#### By Elvis Chen on 2012-03-02 16:09
sorry, wrong xml attached previously. The correct one is attached now.
PlusConfiguration_SonixRP_L14-5_NDIAurora_fCal_1.0.xml	6.1 KB
#### By Tamas Ungi on 2012-03-02 16:13
When we last talked you said you don't have Ascension sensors other than the one integrated in the probe. I've given you two, so you have three now. This config file lists four tools, that you cannot do with 3 sensors. You don't need a "Needle" tool. Just use your needle in the "Stylus" position.
#### By Csaba Pinter on 2012-03-02 16:15
Elvis,
In your configuration file, the Probe tool is not a special tool in any way (for example if you didn't have a separate Reference and you defined a ProbeToReference identity matrix in the CoordinateDefinitions section, then your probe would act like a reference because in the Rendering, the reference coordinate frame is set to Reference).
So there's no apparent reason to all the tools disappear if the probe gets out of range. What happens if you disconnect your probe and delete it from the configuration too? Just start fCal that way and turn on show devices mode (eye icon on the top of the toolbox)
#### By Elvis Chen on 2012-03-02 16:21
Tamas, this is with NDI Aurora.

Csaba, will make the modification and try next Monday.

thanks,


## Problems with Connecting to Ascension Tracking
#### Posted by Matthew Holden on 2012-03-02 14:44

We are having difficulties connecting to the tracker in fCal when using our SonixTouch machine. We are using SonixTouch version 5.7.3, and have disabled the SonixGPS licence.

The following error appears when we try to connect:

[ERROR] [023.052000] Board # 0: Time out before response from target board [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(392)]
[ERROR] [023.056000] System : InitializeBIRDSystem() not called yet [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(392)]
[ERROR] [023.060000] Connection initialization failed [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(88)]
[ERROR] [023.063000] Unable to initialize tracker! [in ..\..\..\PlusLib\src\DataCollection\vtkDataCollectorHardwareDevice.cxx(120)]
[ERROR] [023.065000] Unable to start collecting data! [in ..\..\PlusApp\fCal\Toolboxes\ConfigurationToolbox.cxx(169)]

I have attached the configuration file that we are using.

Thanks.
PlusConfiguration_SonixTouch_Ascension3DG_L14_fCal1.xml	5.9 KB

#### 2 Comments
#### By Elvis Chen on 2012-03-02 15:35
We have confirmed that Ascension system works inside the SonixTouch software, so we can rule out the hardware issue.
#### By Tamas Ungi on 2012-03-02 16:05
Please check again that you reconnected all cables after you tried the other tracker by disconnecting Ascension. Make sure you disabled SonixGPS license after you enabled it to try with the Ultrasonix exam software.
These error messages make me think that some cable is not well connected.


## Polaris Spectra and passive markers
#### Posted by GuillermoCarbajal on 2012-02-29 14:43

Hi all,

We are trying PLUS library with the Polaris Spectra sensor and passive markers.
We followed build instructions and after checking out from https://subversion.assembla.com/svn/plus/trunk/PlusBuild
we built the project.
When running fcal.exe, we couldn't to communicate with Polaris Sensor. The reason is that the application do not read the serial port from configuration file. When the serial port was set in vtkPolarisTracker.cxx (hard coded ) we communicated successfully. Which is the right way of doing this?
Even when we communicated properly, sensor didn´t recognize passive markers. We couldn't find how to provide the application with tool's configuration .rom files.

Thanks in advance.
Best regards,
Guillermo Carbajal
Facultad de Ingeniería
Montevideo, Uruguay

#### 2 Comments
#### By Csaba Pinter on 2012-02-29 14:49
Hi Guillermo,

Try to use the configuration file PlusLib/data/ConfigFiles/PlusConfiguration_NoVideo_NDIPolaris.xml.
You can do that by selecting the ConfigFiles directory in fCal's Configuration toolbox. The application parses up the config files, and they appear in the list. Select the configuration 'No video + NDI Polaris'. You can edit it by clicking the Edit configuration button (notepad icon) and when you're done, you can Connect.

You can set the serial port number to the SerialPort attribute of the Tracker element.
You can specify the .rom files for the passive markers by adding the file name in the RomFile attribute of the Tracker/Tool element.

Do you want to use video input too?
#### By Elvis Chen on 2012-02-29 15:38
the support for Polaris/Aurora was added in late January, so please make sure you have a version of PLUS of later date.

for passive tools, make sure you specify a port number >4, as port 0-3 are reserved for the active tools in the NDI's API.


## RE: Changeset [1500]: TemporalCalibrationAlgoTest build fixed (faulty code commented out)
#### Posted by Andras Lasso on 2012-02-27 20:19

Hi Csaba,

The nightly and continuous builds are all OK and you don't mention any specific issue in the commit comment either.

What was the problem with TemporalCalibrationAlgoTest?

Andras

From: Csaba Pinter [mailto:plus@alerts.assembla.com] 
Sent: 2012-February-27 5:36 PM 
To: Andras Lasso 
Subject: [Plus] Changeset [1500]: TemporalCalibrationAlgoTest build fixed (faulty code commented out)

Changeset alert by Csaba Pinter https://www.assembla.com/profile/pinter in space Plus https://www.assembla.com/spaces/plus

TemporalCalibrationAlgoTest build fixed (faulty code commented out)

Affected files:

M trunk/PlusLib/src/CalibrationAlgo/Testing/ 
M trunk/PlusLib/src/CalibrationAlgo/Testing/TemporalCalibrationAlgoTest.cxx

Commit from user: pinter

More details https://www.assembla.com/code/plus/subversion/changesets/1500

If you no longer wish to receive these emails or if you would like to change the default frequency, click here to change your email notification settings for Plus https://www.assembla.com/spaces/plus/users/alert_settings

Assembla | Workspaces to accelerate software teams


#### 2 Comments
#### By Csaba Pinter on 2012-02-28 08:49
It didn't link so I could not run the BuildAndTest. I had to comment out the problematic code so that it builds
#### By Andras Lasso on 2012-02-28 09:13
There was no build error on the continuous build PC (PROSTATE), on the nightly build machines (BLADDER, SPLEEN) and on my laptop. Do you have any locally modified files that could cause conflicts?


## Faketracker cannot GetMostRecentTimestamp
#### Posted by Siavash Khallaghi on 2012-02-23 23:12

Hi guys,

Faketracker does not return the most recent time stamp with the following configuration:

		<Tracker Type="FakeTracker" BufferSize="400" Frequency="50" LocalTimeOffset="0.0" AveragedItemsForFiltering="20" >
		  <Tool Name="Probe" PortName="0" />
		  <Tool Name="Reference" PortName="1" />
		</Tracker>


When I call the most recent time stamp:

		if( threadData->DataCollectorInstance->GetMostRecentTimestamp( ts ) != PLUS_SUCCESS )
			LOG_INFO("Cannot retreive the most recent tiem stamp.);


Where DataCollectorInstance is a pointer type vtkDataCollectorHardwareDevice.

#### 10 Comments
#### By Tamas Heffter on 2012-02-24 09:39
Hi Siavash,

Fake tracker in default mode (if you don't set Mode="[trackerMode]" attribute) expects the following tools on connect:
- Reference
- Stylus
- Stylus-2
- Stylus-3
If it cannot find these tools, it will return with PLUS_FAIL. You should always check the return value of your connect function, probably it just didn't connect.

You can check the required tools in the vtkFakeTracker::Connect() function. Also, you should find the other modes in vtkFakeTracker::ReadConfiguration function.

Hope it helps.
#### By Csaba Pinter on 2012-02-24 11:00
What kind of motion do you expect from fake tracker? It has the following modes:
Default,
SmoothMove,
PivotCalibration,
RecordPhantomLandmarks,
ToolState

Among these, SmoothMove could be the one you want to use. Then you need to modify the configuration like this

<Tracker Type="FakeTracker" BufferSize="400" Frequency="50" LocalTimeOffset="0.0" AveragedItemsForFiltering="20" Mode="SmoothMove" >
  <Tool Name="Probe" PortName="0" />
  <Tool Name="Reference" PortName="1" />
  <Tool Name="MissingTool" PortName="2" />
</Tracker>
#### By Tamas Heffter on 2012-02-24 11:27
We might need to change the default mode to a generic setup, like Probe, Stylus, Reference if we don't use it for anything else. Also in default mode, I would just check if the tool is available (defined in the config file) and simulate the movement of those tools are available (instead of returning false if it's not defined). Or not even checking the tool names, just make random movements on the defined tools.
#### By Andras Lasso on 2012-02-24 13:20
Siavash, instead of FakeTracker I would recommend to playback pre-recorded (or artifically generated) sequence metafile for testing. Just specify "SavedDataSet" type for the Tracker and ImageAcquisition - see PlusConfiguration_SavedDataset_fCal_1.0.xml for an example.
#### By Tamas Ungi on 2012-02-24 14:39
There is another example:
PlusBuild\PlusLib\data\ConfigFiles\PlusConfiguration_SavedDataBroadcaster.xml
This uses a saved dataset from the TestImages folder which is a short ultrasound guided needle insertion. It replays a B-mode image, the probe position and the needle tip position.
I use this with OpenIGTLinkBroadcaster to test my Slicer applications.
#### By Tamas Ungi on 2012-02-24 14:48
BTW, I just fixed this config file to use the new "File" style DataCollector. This is a clean solution to replay saved datastreams.
#### By Siavash Khallaghi on 2012-02-24 18:19
Thank you guys for your
####  comments. I would like to make the following points:

1. Between Plus 1.3 and 1.4, there were major changes to vtkDatacCollector. Since then we have been using vtkDataCollectorHardwareDevice. From a quick chat that I had with Tamas (Ungi) yesterday, it seems that vtkDataCollectorHardwareDevice does not support SavedDataSets. It will take some digging to use vtkDataCollector, which hopefully our new software developer will do.

2. I am using the fake tracker for development purposes, since it connects faster to the Touch and does not require the GPS hardware. We have a number of threads running in parallel and we are trying to remove a number of bugs in our application (mostly deadlocks).

3. I just need to make sure that the fake tracker can write out the sequence of frames in the following format (using TrackedFrameList->WriteToMetaFile() ). Since the ultimate goal of my app is to save freehand RF and Bmode frames, I would think that "smoothMove" should be the correct option?

Seq_Frame_ProbeToTrackerTransform = -0.985454 0.169897 0.0038398 729.966 0.153656 0.900449 -0.406916 -77.7638 -0.0725915 -0.400407 -0.913457 5.35781 0 0 0 1
Seq_Frame_ProbeToTrackerTransformStatus = OK
Seq_Frame_ReferenceToTrackerTransform = 0.925456 0.0454549 0.376119 498.5 -0.183464 -0.814835 0.549895 -62.2846 0.331471 -0.577908 -0.745754 11.6086 0 0 0 1
Seq_Frame_ReferenceToTrackerTransformStatus = OK
Seq_Frame_Timestamp = 1123.147571
#### By Csaba Pinter on 2012-02-24 18:48
1. If it is crucial to use DataCollectorHardwareDevice instead of the generic DataCollector interface, then you can use "SavedDataset" type for tracking, it's in DataCollectorHardwareDevice.
3. If you just want to save data, why don't you use fCal for that (Capturing tab does the recording and saving)? Or if you have to develop an application that will do other stuff too, steal some code from it :)
#### By Siavash Khallaghi on 2012-02-24 19:43
1. Originally we had developed everything on vtkDataCollector, but between Plus 1.3 and 1.4, you guys removed most of the functions from it and put them in DataCollectorHardwareDevice and we don't want to migrate again. :(

3. Csaba, thank you for the suggestion. My application, apart from saving data, supports realtime elastography, RF time series tissue typing and 3D navigation (under development).
#### By Andras Lasso on 2012-02-24 21:43
1 => You can still easily access all the functions of the vtkDataCollectorHardwareDevice, you just have to cast your vtkDataCollector pointer to vtkDataCollectorHardwareDevice ( vtkDataCollectorHardwareDevice *dataCollectorHw = vtkDataCollectorHardwareDevice::SafeDownCast(dataCollector) ).


## Correct image orientation for the EC95 probe
#### Posted by Siavash Khallaghi on 2012-02-16 18:57

Hi guys,

I have been calibrating our EC95 probe with fCal. I believe the conditions were optimal, the fewest feromagnetic objects possible in the magnetic field and I was moving slowly. I have attached the calibration result and the RMS error is 2.18 mm. Purang believes that I cannot decrease the calibration error due to the lever arm effect. (the sensor is ~20 cm away from the probe tip).

I am using the Urology-prostate preset on the touch machine and am using the UF image orientation. The first question is if this is the correct orientation (I have read the wiki page on US image orientations). The second question is, if this orientation is causing the calibration error? The third question is if you guys have less error than 2.18 mm?

Siavash
FreehandCalibration_2.18_Feb_15_2012.xml	8.22 KB

#### 7 Comments
#### By Andras Lasso on 2012-02-16 20:01
I've added some instructions on the wiki for checking the correct UsImageOrientation value in the XML config file ( https://www.assembla.com/spaces/plus/wiki/Ultrasound_image_orientation).

2.18mm is somewhat larger than what we usually get.
Check the followings:
wiring (loose wire, wire not aligned to the correct side of the hole, ...)
segmentation parameters (change the imaging parameters so that the fiducial line intersection points appear as small circular shape)
temporal calibration (if you don't have accurate time offset value then move the transducer slowly)

You can also try the new 3N phantom wiring (version 1.1), we get more reliable results with that compared to the 2N pattern.
#### By Tamas Ungi on 2012-02-16 20:08
The RMS error displayed after calibration is one thing. You can get more direct result on calibration accuracy if you put a tracked stylus (needle) in water and place the probe head in the water so the needle is in the image plane. The 3D view gives a very good idea of the calibration accuracy. If the needle model is out of plane, you probably have to correct it.

We lately experienced that calibration is much more accurate if you use 3 N-wires instead of 2, as Andras mentioned.

If you broadcast the tracked image and the needle position to Slicer, you can actually record extra fiducial points with the needle model and by putting fiducials on the US image (using LiveUltrasound module, Add Frame snapshot function). This way you can further correct the calibration accuracy by fiducial registration.

Getting a perfect calibration and thoroughly verifying it took a couple of hours for me, but it needs to be done only once for one probe, and it pays off really well in the later experiments.
#### By Tamas Ungi on 2012-02-16 20:12
One more thing. EM tracking accuracy decreases about linearly as you take the sensor farther from the transmitter. Even within the operating range given by the manufacturer. The ideal distance is at 10-15 cm, with an error about 1 mm. At 25-30 cm the error is about 2-3 mm, depending on the sensor size. So make sure your sensors are all close to the transmitter during calibration.
#### By Csaba Pinter on 2012-02-16 22:26
You can check the Probe coordinate frame against the Image frame by adding a Probe AxesDisplayableObject to the configuration file (see example in section 'Display of coordinate frames' of the wiki page https://www.assembla.com/spaces/plus/wiki/Troubleshooting_for_Plus_users). That way you are supposed to see the axes actor just where the marker in the probe is. You can verify the inclination and/or displacement of the computed image plane related to the probe (because the probe model is fixed to the image, not the probe tool),
#### By Siavash Khallaghi on 2012-02-18 19:23
Thank you everyone. Actually the new description that Andras included is very informative. Thank you Tamas for your
####  comments and also Csaba.
#### By Siavash Khallaghi on 2012-02-24 18:02
I removed the sensor from its sleeve and taped it closer to the tip (from blue to red). After three trials, the calibration error dropped from 2.2 mm (~20 trials) down to 1.8 mm.
probe_sensor.png	825 KB
#### By Andras Lasso on 2012-02-24 18:56
Thanks for the update. You could also consider using larger sensors, they are much more accurate than the small ones.


## meaning of ModelToObjectTransform and how to derive them
#### Posted by Elvis Chen on 2012-02-24 15:05

hi all,

I'm trying to use fCal and intend to use it as a quick demo to convince other institutions to use PLUS. We have SonixTouch with GPS addon but we have further augmented it with NDI Aurora. In the process of adapting an xml for our system, I would like to understand the inner detail of certain parameters.

For example, take PlusLib/data/ConfigFiles/PlusConfiguration_SonixRP_L15-5_NDI_Certus_fCal_1.0.xml, a section with the following code:

~~~~
<Rendering WorldCoordinateFrame="Reference">
<DisplayableObject Type="Model" ObjectCoordinateFrame="TransducerOrigin"
File="L14-5_38_ProbeModel.stl"
ModelToObjectTransform="
1 0 0 34.5
0 -1 0 1.5
0 0 -1 14
0 0 0 1"
/>
<DisplayableObject Type="Model" ObjectCoordinateFrame="StylusTip"
File="Stylus_Example.stl"
ModelToObjectTransform="
1 0 0 -210.0
0 1 0 0
0 0 1 0
0 0 0 1"
/>
<DisplayableObject Type="Model" ObjectCoordinateFrame="Phantom"
Opacity="0.6"
File="FCal_1.0.stl"
ModelToObjectTransform="
1 0 0 -15.0
0 1 0 10.0
0 0 1 -5.0
0 0 0 1"
/>
<DisplayableObject Type="Image" ObjectCoordinateFrame="Image" />
</Rendering>
~~~~

I assume these are the transforms associated with each respective vtkActors so they would appear to be in the right place. Can some please explain exact what these transforms are and how one determines them?

thanks,

#### 3 Comments
#### By Csaba Pinter on 2012-02-24 15:17
Elvis,

You can find a basic description about the configuration file here:
https://www.assembla.com/spaces/plus/wiki/Configuration_file_structure

About the transforms, their purpose is to move the model in the 'hot spot', to the exact location where they shoud appear.
The models usually have an origin that's not where you want to align the model (eg. the tip of the stylus, or the middle of the transducer of the probe).
You can determine them using SolidEdge or Paraview, basically any application that can read STL models and measure distances. Using the application, measure the distances between the origin and the hot spot axis by axis. If you have to rotate, incorporate it in the matrix too.
#### By Andras Lasso on 2012-02-24 15:19
You also have to determine the ObjectCoordinateFrame to MarkerCoordinateFrame transforms by performing landmark registration as described here:
https://www.assembla.com/spaces/plus/wiki/ProbeModel-To-Probe_Registration_Tutorial
#### By Csaba Pinter on 2012-02-24 15:26
Yes, landmark registration is a possibility, but I found it time-consuming in simpler cases, and more inaccurate in cases where I want to rotate the model by exactly 90 degrees or I know the exact offests between the origin and the hot-spot.
However in complicated cases landmark registration is the only good solution.


## Calibration Matrix
#### Posted by Abtin Rasoulian on 2012-02-23 16:31

Hi,

I was calibrating the curvilinear probe C5-2. The ImageToProbe transform I got is as follows:

0.00275834 0.130555 -0.0275825 18.8246
-0.0820494 -0.0250518 0.0459299 39.9183
0.0375556 0.0464162 0.102371 -33.656
0 0 0 1

It seems that the rotation+scale part is not orthogonal, meaning that the right angle in the images are not preserved.

I attached the config file of the calibration.

Thanks,
Abtin
FreehandCalibration_C52_Feb_19_2012.xml	8.21 KB

#### 2 Comments
#### By Andras Lasso on 2012-02-23 17:04
This is a known limitation of the calibration method. If this happens fCal even displays a warning message. See more details about the potential root causes and the resolution in the "The axes of the ImageToProbeTransform (calibration matrix) are not orthogonal" section of this page: https://www.assembla.com/spaces/plus/wiki/Free-hand_probe_calibration.
#### By Andras Lasso on 2012-02-24 14:06
Check out also the "I get large (>2-3mm) calibration error - what's wrong?" section in the https://www.assembla.com/spaces/plus/wiki/Free-hand_probe_calibration page.


## RE: Introduction
#### Posted by Tamas Ungi on 2012-02-20 17:31

Hi Samiras, welcome :-)

Please register a user account on www.assembla.com and send your username to 
me (for LiveUltrasound) and Csaba (for PLUS).

Thanks,

Tamas

From: Purang Abolmaesumi [mailto:purang@ece.ubc.ca] 
Sent: February-20-12 3:32 PM 
To: Andras Lasso; Tamas Ungi; Csaba Pinter 
Cc: samiras@ece.ubc.ca; Parvin Mousavi 
Subject: Introduction

Dear Queen's Gang,

Hope everything is going great. I would like to introduce our new research 
engineer, Ms. Samira Sojoudi, who will be supervising the software 
development efforts at UBC. She has joined us as of today and she will be 
working closely with Siavash initially, and then moving to the Slicer 
integration for spine. Could you please add her to Assembla spaces for Live 
Ultrasound and PLUS? She will contact you directly if she has any questions.

Thank you,

Purang


#### 0 Comments


## A suggestion for vtkVolumeReconstructor
#### Posted by Siavash Khallaghi on 2012-02-18 19:36

Hi guys,

Is it a good idea to display a warning if AddTrackedFrame is called before SetOutputExtentFromFrameList is executed?

This is the pseudo code that I was using:

for (int i=0; i < numberOfFrames; ++i)
        reconstructor->AddTrackedFrame(frame, transformRepository, imageToReferenceTransformName, &insertedIntoVolume );
reconstructor->SetOutputExtentFromFrameList(trackedFrameList, transformRepository, imageToReferenceTransformName);
reconstructor->GetReconstructedVolume(reconstructedVolume);


Which always gave me an empty volume. When I changed the order of blocks to the following:

reconstructor->SetOutputExtentFromFrameList(trackedFrameList, transformRepository, imageToReferenceTransformName);
for (int i=0; i < numberOfFrames; ++i)
        reconstructor->AddTrackedFrame(frame, transformRepository, imageToReferenceTransformName, &insertedIntoVolume );
reconstructor->GetReconstructedVolume(reconstructedVolume);


Everything worked just fine. The thing is since there is no error or warning in the first case, it took me a while to realize what was wrong.

#### 2 Comments
#### By Tamas Ungi on 2012-02-18 20:38
Sounds like a good idea. Even maybe error if the output extent is not set at all.
#### By Andras Lasso on 2012-02-20 15:20
Added error message display when extent is not set + more detailed documentation for the slice insertion method (https://www.assembla.com/code/plus/subversion/changesets/1462).


## How to compress mha files?
#### Posted by Tamas Ungi on 2012-02-18 11:09

I'd like to add a test data. Is there a way to create a compressed .mha file from my recorded .mha file which holds the tracked frame list?

#### 4 Comments
#### By Csaba Pinter on 2012-02-18 11:43
There is. You can use the EditSeqMetaFile.exe tool from PlusLib (PlusCommon/Testing) like this:
EditSeqMetafile.exe --input-file-name=[inputFilePath] --output-file-name=[outputFilePath] --use-compression
#### By Tamas Ungi on 2012-02-18 12:04
Thanks. It worked.
#### By Andras Lasso on 2012-02-18 12:19
Tamas, I guess others might have this same question. Could you please add the solution to the Users guide? (maybe to this page: https://www.assembla.com/spaces/plus/wiki/Sequence_metafile_format)
thanks
Andras
#### By Tamas Ungi on 2012-02-18 12:25
OK. Done.


## RE: Changeset [1441]: Added papers relevant to Volume Reconstruction
#### Posted by Andras Lasso on 2012-02-07 23:11

Hi Thomas,

Thanks for uploading the papers, they are very useful and relevant. I've also found a more recent paper from Solberg (see Solberg2011.pdf).

Please save all papers as AuthorlastnameYYYY.pdf, as this is the bibtex key and this way the pairing of bibtex entries and full-text paper files is trivial. Please also add the papers that may be relevant to the bibtex file, as this allows searching, grouping, commenting the papers and later the biblio information will be useful for paper writing. I've done this for the current papers, using JabRef - see some more information about this here: http://media.cs.queensu.ca/media/wiki/index.php/Managing_bibliography_references.

One last thing: please start all your commits that are related to the volume reconstruction/hole filling with

re #285:

this will link your commit with the referenced ticket #285 and you can follow all the changes related to this task at one place (https://www.assembla.com/spaces/plus/tickets/285). It's not critical, but it helps everybody in following the progress of the project.

It may be a lot of information to process at the beginning, but don't worry, you'll soon get familiar with all the tools and processes. You're doing great so far.

Andras

From: Thomas Vaughan [mailto:plus@alerts.assembla.com] 
Sent: 2012-February-07 6:29 PM 
To: Andras Lasso 
Subject: [Plus] Changeset [1441]: Added papers relevant to Volume Reconstruction

Changeset alert by Thomas Vaughan https://www.assembla.com/profile/thomasvaughan in space Plus https://www.assembla.com/spaces/plus

Added papers relevant to Volume Reconstruction

Affected files:

M trunk/PlusLib/docs/VolumeReconstruction/ 
A trunk/PlusLib/docs/VolumeReconstruction/Gobbi_MICCAI2002.pdf 
A trunk/PlusLib/docs/VolumeReconstruction/Rohling_Comparison_Reconstruction_1999.pdf 
A trunk/PlusLib/docs/VolumeReconstruction/Solberg_Reconstruction_Review_2007.pdf

Commit from user: thomasvaughan

More details https://www.assembla.com/code/plus/subversion/changesets/1441

If you no longer wish to receive these emails or if you would like to change the default frequency, click here to change your email notification settings for Plus https://www.assembla.com/spaces/plus/users/alert_settings

Assembla | Workspaces to accelerate software teams


#### 0 Comments


## RE: Wiki Page "Project management" updated
#### Posted by Andras Lasso on 2012-02-07 19:28

Thanks for noticing that the Plus main “Project management” page is outdated. We used to have a weekly Plus meeting (separate from the weekly lab meeting) on Fridays, but we don’t have it anymore (the framework is ready now, so individual developers can work quite independently, there is no need for a regular personal meeting anymore). I’ll update the page accordingly.

The weekly lab meetings are tracked on our internal wiki:

http://media.cs.queensu.ca/media/wiki/index.php/BMC_Lab_Meetings

Andras

From: Thomas Vaughan [mailto:plus@alerts.assembla.com] 
Sent: Tuesday, February 07, 2012 6:09 PM 
To: Andras Lasso 
Subject: [Plus] Wiki Page "Project management" updated

Wiki Page alert by Thomas Vaughan https://www.assembla.com/profile/thomasvaughan in space Plus https://www.assembla.com/spaces/plus

Project management

Version: 19

Comment:

More details https://www.assembla.com/spaces/plus/wiki/Project_management

If you no longer wish to receive these emails or if you would like to change the default frequency, click here to change your email notification settings for Plus https://www.assembla.com/spaces/plus/users/alert_settings

Assembla | Workspaces to accelerate software teams


#### 0 Comments


## VolumeReconstruction
#### Posted by caitlins on 2012-02-02 19:46

I am trying to use the volume reconstructor, but I am slightly confused about the transform names that it is searching for. Is there anywhere where this is explained?

Also, I would like to reconstruct volumes of float data. I am getting an error in which the scalar types of the input and output do not match. Is there anyway to reconstruct a volume of floats?

thank you,
Caitlin

#### 5 Comments
#### By Tamas Ungi on 2012-02-02 22:06
Hi Caitlin,

As far as I remember last time I used the volume reconstructor, it was using the Probe-to-Reference (or Probe-to-Tracker if there is no reference) transforms for each single slice as stored in the .mha file; and those were concateneted with the Image-to-Probe calibration transform stored in the .xml config file. The result is Image-to-Reference for each image.

Which executable program are you trying to use?
What do you mean it is searching for transforms?

Tamas
#### By Andras Lasso on 2012-02-03 12:39
Hi Caitlin,

We haven't tested the volume reconstructor with float data. If you can send us a small sample data set then we can test and fix the problem. I've added ticket #426 to track the resolution of this issue.

See volume reconstruction instructions here: https://www.assembla.com/spaces/plus/wiki/Volume_Reconstruction.

Andras
#### By Caitlins on 2012-02-07 03:03
I think that one issue with finding the transforms was due to my numbering, I was starting the frames at 1, instead of 0.

I was able to cast my data to shorts, to solve the problem with using floats, though I still have to change the output constructor to VTK SHORT.

I looked over the wiki info on volume reconstruction, using ParaView and the CreateSliceModels, I realize I might have more problems than I had thought.

I am trying to visualize my transforms. Since I am not getting what I expect, I would like to ask some additional questions. Just to be sure, in the *.mha file the transforms should be written as, row1 (of rotation matrix), pos(x), row2, pos(y), row3, pos(z), 0 0 0 1.

Is there any transformation between the *.mha file and paraview that are inherent in the files?
#### By Tamas Ungi on 2012-02-07 10:17
What you wrote about the element order of the transform matrix is right. It would be easier to understand the problem if you attached a few screenshots. You could try to move the probe along a simple curve, like a C. And then see where the slice models get after reconstruction.
#### By Andras Lasso on 2012-02-07 10:53
See specification of the transforms in the metafile in https://www.assembla.com/spaces/plus/wiki/Sequence_metafile_format.

The only transformation that is applied to the slice is the ImageToReference transform (or something similar) that you define in the --input-transform-name parameter.

Example: If you don't have a reference sensor attached to the object (and the object doesn't move) then you can use the tracker as reference. In the metafile you have ProbeToTrackerTransform available for each frame. You have the computed ImageToProbe transform in the configuration XML file (in the CoordinateDefinitions element, defined as <Transform From="Image" To="Probe" Matrix=... />). The transform that you have to give to the volume reconstructor is --input-transform=ImageToTracker. The pixels will be transformed with the ImageToTracker = ProbeToTracker * ImageToProbe transform.


## Re: Changeset [1431]: Re #336: Fixed pattern localization algorithm for 3 NWires
#### Posted by Tamas Heffter on 2012-01-28 10:34

Great! :-) And how was the calibration? Have you tried it? 
Tomi

On Fri, Jan 27, 2012 at 7:54 PM, Csaba Pinter <plus@alerts.assembla.com>wrote:

> *Changeset* alert by Csaba Pinter https://www.assembla.com/profile/pinter in space 
> Plus https://www.assembla.com/spaces/plus 
> Re #336 https://www.assembla.com/spaces/plus/tickets/336 : Fixed pattern 
> localization algorithm for 3 NWires 
> 
> *Affected files:* 
> 
> M trunk/PlusLib/data/ConfigFiles/ 
> M trunk/PlusLib/data/ConfigFiles/PlusConfiguration_File_fCal_1.2.xml 
> M trunk/PlusLib/src/CalibrationAlgo/ 
> M trunk/PlusLib/src/CalibrationAlgo/vtkProbeCalibrationAlgo.h 
> M trunk/PlusLib/src/PatternLocAlgo/ 
> M trunk/PlusLib/src/PatternLocAlgo/FidLabeling.cxx 
> M trunk/PlusLib/src/PatternLocAlgo/FidLabeling.h 
> M trunk/PlusLib/src/PatternLocAlgo/FidPatternRecognition.cxx 
> M trunk/PlusLib/src/PatternLocAlgo/FidPatternRecognitionCommon.h 
> 
> 
> Commit from user: pinter 
> 
> More details https://www.assembla.com/code/plus/subversion/changesets/1431 
> 
> If you no longer wish to receive these emails or if you would like to 
> change the default frequency, click here to change your email 
> notification settings for Plus https://www.assembla.com/spaces/plus/users/alert_settings 
> 
> *Assembla* | Workspaces to accelerate software teams 
>


#### 1 Comments
#### By Csaba Pinter on 2012-01-28 13:01
The test runs fine, gives a very similar matrix as with 2 NWires. More details coming up on Monday :)


## Problems with Ascension
#### Posted by Siavash Khallaghi on 2011-12-16 18:54

Hi guys,

I have two problems when I initialize the tracker on two of our Sonix-Touch machines:

1. On MIDAS (one of our machines) I get the following error:

"BOARD # 0: Indeterminate failure on PCB [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(392)]"

I am guessing that there is a hardware problem with our Ascension tracker in this case (e.g. burned out circuit). What do you guys think?

2. Our other machine (R2D2) was stripped off its magnetic tracker, so I reattached it (i.e. I plugged in the Ascension tracker to the first port from the right). The light turns green and is flashing, but I get the following error:

"System: No birds were found anywhere [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(392)]"

In this case I am guessing that I have not properly attached or turned on the Ascension tracker. Should I do anything else to turn the tracker on?

In both scenarios I have disabled the SonixGPS license in the exam software and am running my software on the Sonix-Touch (i.e. not from a remote computer).

Thank you

#### 6 Comments
#### By Siavash Khallaghi on 2011-12-16 19:09
I also tried attaching the magnetic tracker from R2D2 to MIDAS, in order to see if the problem is with the tracker. But I still get the same error:

"BOARD # 0: Indeterminate failure on PCB [in ..\..\..\PlusLib\src\Tracking\Ascension3DGTracking\vtkAscension3DGTracker.cxx(392)]"
#### By Andras Lasso on 2011-12-17 04:13
Try the demos/tests in the Ascension SDK to see if they work (to see if the problem is with Plus/Ultrasonix/Ascension). Also, check if you see any errors in the device manager (maybe you need to reinstall the Ascension driver). You can also try to connect the tracker's USB plug to a laptop, install the SDK on the laptop and see if it from the Touch and connect (in case there is a hardware/configuration problem in the SonixTouch PC).
#### By Tamas Ungi on 2011-12-21 13:59
What's the status on this?
Siavash, could you figure out what caused your problems, and how could they be solved?
#### By Siavash Khallaghi on 2011-12-25 05:38
Regarding Andras comment, I looked through the files on our Touch machines, but I failed to find the Ascension tracker sdk files. I did look through PLTools, but I only saw a header file and static/shared libraries for Ascension.
The problem is that the error is not consistent, sometimes it happens, other times it does not happen which is very peculiar. I don't know the exact conditions when this error happens. Also, with the same code, I see different errors on different machines as I mentioned in my earlier
####  comments.
Right now I am cleaning up other bugs in my development, since I know how to solve those problems, but I do not know the exact root of this issue. I am half hoping that when I am done with developing (with the fake tracker) and cleaning up my code the error is magically resolved!
#### By Siavash Khallaghi on 2012-01-21 01:01
This is embarrassing. It turns out that the USB port for the Ascension tracker on R2D2 (one of our Touch machines) was a little loose. So this was the reason for "Error: No Birds were found anywhere...".
#### By Tamas Ungi on 2012-01-22 01:10
This is interesting to hear, and good to know. We have the same hardware, so it may happen to us too.


## VTKImageToImageFilter
#### Posted by hussam.ashab on 2011-12-15 21:48

Hi,

Can I know how to use VTKImageToImageFilter in PLUS.

regards
Hussam

#### 2 Comments
#### By Tamas Ungi on 2011-12-15 23:47
Hi Hussam,

There is nothing special in PLUS that would change the usage of vtkImageToImageFilter, which is part of standard VTK. Although most people use ITK for image processing. It depends on what would you like to add to PLUS.

Tamas
#### By Hussam.Ashab on 2011-12-16 00:30
Hi Tamas,

Thank you, I was getting a strange error, I think I figured the problem.

Thank you again

regards
Hussam


## Ascension 3DG to 50 fps
#### Posted by Tamas Ungi on 2011-12-15 09:41

For those using Touch GPS: I've noticed that the usual default setting for Ascension 3DG trackers is 20 fps in the config files. The tracking looks more smooth and has less delay if you increase this to 50 fps. Even when the image acquisition frequency is less than 20. I will update the config files in the repository.

#### 1 Comments
#### By Csaba Pinter on 2011-12-15 09:42
That's interesting. Thanks for updating the files.


## PlusLib API documentation now can be downloaded as one single file
#### Posted by Andras Lasso on 2011-12-13 10:32

The up-to-date (nightly refreshed) PlusLib API documentation can now be downloaded as one single chm help file (just open the https://www.assembla.com/spaces/plus/wiki/Developers_guide wiki page and click download). You can generate documentation on your own PC by running PlusLib-bin\CreateDoc.bat.

#### 5 Comments
#### By Siavash Khallaghi on 2011-12-13 19:54
Hi Andras,

This is what I see when I open it please look at screenshot.png (disregard screens.png. It was a mistake and for some reason I can't remove the attachment).
screenshot.PNG	88.3 KB
screens.PNG	211 KB
#### By Andras Lasso on 2011-12-13 20:02
When you download a html on Windows7 with IE9 (maybe it applies to other OS browser versions as well) then the file content may be blocked for security reasons. Right-click on the file, click Properties, click "Unblock" (in the bottom right corner), then open the file again.
#### By Siavash Khallaghi on 2011-12-13 20:26
This solved it. Thank you.
#### By Siavash Khallaghi on 2011-12-13 20:28
How much longer before we see this on a website? (similar to http://www.itk.org/Doxygen/html/classitk_1_1BSplineDeformableTransform.html)
#### By Andras Lasso on 2011-12-13 20:33
Click "PlusLib API documentation" at https://www.assembla.com/spaces/plus/wiki/Developers_guide


## Converting raw pointers from/to vtkImagedata and rendering it in a vtk window
#### Posted by Siavash Khallaghi on 2011-12-08 19:44

Hi Guys,

I am trying to fit a *c*ustom *b*lock (let's call it CB) into my code and visualize the output of it in a vtk window. CB requires a short RF pointer from Ulterius and its output is floating pointer.

Since this is a complicated problem, the first thing that I tried was just to grab the raw Bmode pointer from vtkSoinxVideoSource and convert it to a short pointer. Then I passed this short pointer to a vtkImageImporter and passed the output of it to the viewer and called update. In other words the following lines:

//-------------------------------------------------------------------------------------------------------------------------
m_ByteImageData = reinterpret_cast<short*>( m_SonixVideoSource->GetOutput() );

vtkImageImport *importer = vtkImageImport::New();
importer->SetDataExtent(1,m_FrameSize[0],1,m_FrameSize[1],1,1);
importer->SetWholeExtent(1,m_FrameSize[0],1,m_FrameSize[1],1,1);
importer->SetDataScalarTypeToShort();
importer->SetImportVoidPointer(m_ByteImageData);
importer->Update();

m_Viewer->SetInput( importer->GetOutput() );
m_Viewer->Render();
//-------------------------------------------------------------------------------------------------------------------------

All of this is called within the vtkCallback. But when the viewer wants to render, it produces a memory allocation error.

Could you please take a look at it and give me a comment if it is not too much trouble?

Thank you,

Siavash

#### 7 Comments
#### By Tamas Ungi on 2011-12-08 20:43
You say you tired it with Bmode images.
Bmode images have pixel type char (1 byte). If you cast it's pointer to short (2 bytes) and try to read the same extent, you will access illegal memory after half the image is read. Won't you?
I'm not very good at memory debugging, so it's just a thought. These problems required a lot of C++ and VTK experience (compared to my experience level).
#### By Siavash Khallaghi on 2011-12-08 21:38
I see! Thank you Tamas. I will try casting it to char and try it again. Other than that, am I casting things correctly? Any thoughts?

P.S I am hoping for a Christmas miracle on this :-)
#### By Tamas Ungi on 2011-12-08 22:03
Another thought:
vtkSonixVideoSource->GetOutput() returns a vtkImageData*, not a raw array of image pixels. I don't think the actual data in the memory for a vtkImageData would start directly with the pixels. So it doesn't really make sense to cast a vtkImageData* to short* or even char*.
See the example for vtkImageImport, and try to use it as they use it: http://www.vtk.org/doc/release/3/html/page_ex4.html#ex_vtkImageImport
#### By Andras Lasso on 2011-12-08 23:42
You can get a pointer to the raw pixel data by calling the vtkImageData::GetScalarPointer() method.
#### By Andras Lasso on 2011-12-08 23:55
#### By the way, probably it's not a good idea to extract the raw buffer pointer from the vtkImageData and pass the pointer, image size, pixel type etc. information separately to the processing algorithm, while you already have all these information conveniently in one single object. It's much simpler to keep the image data in a vtkImageData object, perform the processing, store the processing result in vtkImageData object, then send this object to the viewer.
There are many built-in VTK filters for simple conversion and processing (vtkImageShiftScale, vtkImageCast.h, ...). If you need some custom conversion then you can very simply create a new filter for that (following the vtkSimpleImageFilterExample class as an example). Even if you have an external algorithm it's much nicer to create a filter that hides the custom interface and works as a regular VTK filter.
#### By Siavash Khallaghi on 2011-12-09 17:26
Hi Andras,

Thank you for your
####  comments. I strongly believe that keeping the image data intact within vtkImageData is a good idea, and extracting the raw buffer is a bad idea. But one of our co-developers does not share source code, and the input to his block is a raw pointer.
#### By Tamas Ungi on 2011-12-09 19:52
Well, good luck with that.


## Phantom Model
#### Posted by hussam.ashab on 2011-12-08 17:49

Hi,

Can I get the phantom model file in one of these formates. .prt , .sldprt , .asm , .sldasm , .igs or .iges.

regards
Hussam

#### 5 Comments
#### By Csaba Pinter on 2011-12-08 17:52
Hi Hussam,
Only STL is supported now. Aren't you using the fCal phantom for calibration?
-csaba
#### By Csaba Pinter on 2011-12-08 17:56
I misunderstood, sorry! Yes we have it in par file, we'll attach it soon.
#### By Andras Lasso on 2011-12-08 17:58
Maybe it's not very intuitive, but the model is in the doc directory (in SolidEdge format): https://www.assembla.com/code/plus/subversion/nodes/trunk/PlusLib/docs/fCAL/CAD
#### By Hussam.Ashab on 2011-12-08 17:58
Yes, I am using it. But I was planing to add some parts to the phantom and print it again.
I want to add an extention to on of the edges so I can attach marker to it. Therefore, I need the file in the those formates so I can manipulate the phantom in solid works.
#### By Hussam.Ashab on 2011-12-08 18:15
I found it and it works. Thank you very much.


## Re: : models.event.related_verbs.commented_on [changeset] Modified the authorship and copyright issu
#### Posted by Siavash Khallaghi on 2011-12-05 20:38

Hi Andras,

Thank you for the quick reply. Actually Hani brought the copyright issue 
to my attention earlier today, Hani are you OK with the following header?

Siavash
~~~~
On 12/5/2011 5:34 PM, Andras Lasso wrote: 
> *Changeset Comment* alert by Andras Lasso 
> https://www.assembla.com/profile/lassoan in space Plus 
> https://www.assembla.com/spaces/plus 
> Contents between =Plus=header=begin= ... =Plus=header=end should not 
> be changed in individual files, because it will be kept updated with a 
> script globally and any custom modification will be overwritten at the 
> automatic update. To add any notes on the authorship or copyright you 
> can add an additional comment block (as we did at several occasions 
> when the files already had some copyright notes): 
> /*========================================================================= 
> The following copyright notice is applicable to parts of this file: 
> Copyright ... Authors include: ... 
> =========================================================================*/ 
> Would you be OK with this format? If yes, then could you update the 
> file headers accordingly? It's not feasible to maintain an accurate 
> authors list in each file, therefore I wouldn't recommend to have an 
> "Author(s)" field (just rely on SVN instead for the full list of 
> authors), but of course highlighting a few key contributors is not a 
> problem at all, it may even be useful sometimes. If you have any 
> specific concern with the global Plus header or license then we can 
> discuss that as well. 
> 
> More details 
> https://www.assembla.com/code/plus/subversion/changesets/1279 
> 
> *Assembla* | Knowledge, Tools, and Talent for agile teams 
>

-- 
---------------------------------------------- 
PhD Student 
Robotics and Control Laboratory, Room 3090 
Electrical and Computer Engineering, UBC 
2332 Main Mall, Vancouver, BC, Canada, V6T 1Z4 
www.ece.ubc.ca/~siavashk/ 
Tel: (604)822-9215 
----------------------------------------------
~~~~


#### 0 Comments


## Time lag between MicronTracker and Ultrasound Image acquisition
#### Posted by hussam.ashab on 2011-12-01 19:50

Dear all,

Since I am running fCal on PC (which has MicronTracker connected to it) how I can measure the time lag between Micron Tracker data and Image Aquisition from ultrasound machine. Also how much it will effect the results of calibration.

Best regards
Hussam

#### 1 Comments
#### By Andras Lasso on 2011-12-01 20:33
Hi Hussam,

The effect of inaccurate temporal calibration on the spatial accuracy depends on the speed of probe motion. Just move your probe slowly if you are unsure about the time delay. You can visualize the spatial error if you make a 3D reconstruction of a single object (such as a straight rod) from a single sweep acquisition.

A change-detection based temporal calibration is implemented in Plus. It's not ideal, but it works, ask Tomi about how to use it.
A new, simpler-to use, correlation-based method is under development (see https://www.assembla.com/spaces/plus/tickets/346), which is expected to be ready by January 2012.

Andras


## WriteVideoBufferToMetaFile removed from DataCollector
#### Posted by Siavash Khallaghi on 2011-11-30 22:28

Hi guys,

We have an app that saves RF data to the hard drive. We have a line that does the following:

DataCollectorInstance->WriteVideoBufferToMetafile(buff, OutputFolder,_fileName.str().c_str(), false); //compression false

Between revisions 1195 and 1220 the WriteVideoBufferToMetaFile and vtkGetObjectMacro(VideoSource,vtkPlusVideoSource) were removed from vtkDataCollector.h. We did a little search and it turns out that vtkDataCollectorHardwareDevice class has vtkPlusVideoSource and these members.

I looked through TrackedUltrasoundCapturing and it seems that you guys use vtkTrackedFrameList and use your own custom function SaveToSequenceMetafile (defined in line 422 of vtkTrackedFrameList.h ).

Give this long intro, we have the following questions:

1. Why were these members removed from vtkDataColector.h ?
2. Since we need to revise our code to be compliant with the new Plus, do you recommend using SaveToSequenceMetafile as an example?
3. How much is vtkTracking and vtkDataCollection going to change in the near future?

Thank you,

Siavash

#### 2 Comments
#### By Tamas Heffter on 2011-11-30 23:55
Hi Siavash,

Just a quick answer:
1. We recently changed the TrackerTool structure (#310) and DataCollector (#313) classes, you can follow those tickets. This is the last step step of our planned re-factoring task before the stable release.
2. You can save the video buffer like this: dataCollectorHardwareDevice->GetVideoSource()->GetBuffer()->WriteToMetafile(...)
3. We're planning to release the Plus 1.4.0 next week which going to be the first stable release, therefore we won't plan any major modifications in the near future.
Sorry for any inconveniences, hope you will enjoy the new, more comfortable Plus version.
#### By Andras Lasso on 2011-12-01 00:19
Some more details:

1. vtkDataCollector now hides all the complexities of the data acquisition from the rest of the application. It makes the applications simpler and allows easier and more reproducible hardware-less testing. Now vtkDataCollector can replay a recorded sequence metafile and the output is exactly the same as you would get with a real hardware setup.

2. If you want to get the raw buffer then you can use the method Tomi described (using vtkDataCollectorHardwareDevice* dataCollectorHardwareDevice = dynamic_cast<vtkDataCollectorHardwareDevice*>(dataCollector.GetPointer())).
If you need to save the tracked image data to metafile then you can just call vtkDataCollector::GetTrackedFrameList to get a list of tracked frames then write them to file using vtkTrackedFrameList::SaveToSequenceMetafile.

3. We haven't communicated these rather large design changes properly, because we thought that the rework won't affect you (as they impact data collection internals only). In the future we'll plan and communicate all larger changes well in advance and provide guidance for updating custom apps.


## Setting the sector size through vtkSonixVideoSource
#### Posted by Siavash Khallaghi on 2011-11-21 22:29

Hi guys,

We want to change the image sector size during the image acquisition. For example we want to capture 4 seconds of RF data in 100% sector size and 4 seconds of RF data with 50% sector size. Here is what we did:

vtkSonixVideoSource* b = static_cast<vtkSonixVideoSource*> (dataCollector->GetVideoSource() );
b->SetSector(50);

We have the following problems:

1. If we do a GetSector prior to SetSector(50), it returns 0xffffffff which corresponds to -1. This is normal.
2. After doing SetSector(50), GetSector() returns 0x0000032 which corresponds to 50. But the sector value does not change on the exam software.
3. If we do b->GetFrameRate() it returns -1 which is not informative.
4. We tried this with and without using b->Modified(). There was no difference.

Are we doing something wrong here? Could you please comment on this?

Thank you

#### 1 Comments
#### By Andras Lasso on 2011-11-22 11:43
The current imlementation is to set the parameters only once, when the connection is established. Added a ticket for implementing real-time parameter update: #392. It should be ready today.


## Function of Synchronize button in TrackedUltrasoundCapturing
#### Posted by Siavash Khallaghi on 2011-11-04 21:32

Hi Guys,

What does the synchronize button exactly do in TrackedUltrasoundCapturing ? It ultimately calls vtkDataCollector::Synchronize (defined in line 728 of *vtkDataCollector.cxx*), but what is the exact function of this?

We have our own data collector app, which captures tracked RF+Bmode data. We are wondering if we need to implement this in our own app.

Thank you

#### 3 Comments
#### By Tamas Ungi on 2011-11-04 22:47
Hi Siavash, 

That function captures a certain amount of video and tracker data, and tries to compute the time offset between the two, based on sudden motions. It is very important to accurately compute this offset, and synchronize the video and tracker data with it. Otherwise the reconstruction will be noisy. 

The current synchronization algorithm is not too robust. Your hand should stay really steady between two sudden motions. One of the ongoing projects is to create a more robust synchronization algorithms, that will work with freehand motion. I think it will be published (put open-source) in a few months. 

Tamas 


From: Siavash Khallaghi [mailto:plus@alerts.assembla.com] 
Sent: November-04-11 9:33 PM

#### By Andras Lasso on 2011-11-05 08:33
You can track the development of the new synchronization method by monitoring this ticket: https://www.assembla.com/spaces/plus/tickets/346
#### By Siavash Khallaghi on 2011-11-05 13:14
"That function captures a certain amount of video and tracker data, and tries to compute the time offset between the two, based on sudden motions."

If I understood you correctly, this means that the two sudden motions correspond to a landmark displacement in the video data. Do you use a special phantom for this?


## MicronTracker Calibration
#### Posted by hussam.ashab on 2011-10-26 23:40

I want to calibrate a probe using MicronTracker. Can I know what I have to set the parameters to in the config File. (I attached the config file)
PlusConfiguration_MicronTracker_L14_fCal1.xml	7.71 KB

#### 16 Comments
#### By Andras Lasso on 2011-10-27 15:24
We haven't tried to use Plus with a MicronTracker yet. To use a MicronTracker you have to create a PlusStatus vtkMicronTracker::ReadConfiguration(vtkXMLDataElement* config) method and set all the required parameters (such as serial port name, baud rate, etc.) from the XML data element, as it is done for other trackers (see e.g., vtkBrachyTracker::ReadConfiguration).
#### By Hussam.Ashab on 2011-10-27 18:14
Thank you. if I make PLUS_USE_MICRONTRACKER ON I got a lot of linking errors. I found Dist folder in MicronTracker/Utils. it contains the .lib files. but I have linking errors regrding functions in microntracker.

regards
Hussam
#### By Hussam.Ashab on 2011-10-28 00:44
I change "OPTION(PLUS_USE_MICRONTRACKER "Provide support for the Claron MicronTracker" ON)" in the PlusExperimental folder. use Cmake, build plus I get a lot of link errors related to Microntracker functions.

I opened the cmake file in "PlusExperimental-bin\PlusLib\src\Tracking" and found "OPTION (PLUS_USE_MICRONTRACKER "Provide support for the Claron MicronTracker" )" is set to OFF, I changed it to ON and build plus_lib again.

I got the following errors:

Error 1 error PRJ0019: A tool returned an error code from "Checking Build System" ZERO_CHECK
Error 2 error PRJ0019: A tool returned an error code from "Building Custom Rule C:/Users/shishany/devel/PlusExperimental-bin/PlusLib/src/Tracking/MicronTracking/Utils/CMakeLists.txt" vtkMicrontrackerfiles
Error 3 error PRJ0019: A tool returned an error code from "Building Custom Rule C:/Users/shishany/devel/PlusExperimental-bin/PlusLib/src/Tracking/CMakeLists.txt" vtkTracking
Error 4 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' TransformInterpolationTest
Error 5 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' CivcoBrachyStepperTest
Error 6 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' TimestampFilteringTest
Error 7 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' vtkVolumeReconstruction
Error 8 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' CmsBrachyStepperTest
Error 9 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' vtkCenterOfRotationCalibAlgoTest
Error 10 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' vtkSpacingCalibAlgoTest
Error 11 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkVolumeReconstruction.lib' vtkVolumeReconstructorTest
Error 12 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkVolumeReconstruction.lib' CreateSliceModels
Error 13 fatal error C1083: Cannot open include file: 'vtkFrameToTimeConverter.h': No such file or directory c:\users\shishany\devel\plusexperimental-bin\pluslib\src\tracking\microntracking\vtkMicronTracker.h 74
Error 14 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkPhantomRegistrationTest
Error 15 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkOpenIGTLinkBroadcasterTest1
Error 16 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkPlusOpenIGTLinkServerTest
Error 17 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkFreehandCalibrationTest
Error 18 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkDataCollectorVideoAcqTest
Error 19 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkDataCollectorTrackingTest
Error 20 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkDataCollectorTest2
Error 21 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkDataCollectorTest1
Error 22 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkDataCollectorSynchronizerTest
Error 23 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkStylusCalibrationTest
Error 24 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkTracking.lib' UsFidSegTest
Error 25 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' vtkUSCalibrationControllerTest1
Error 26 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' ReplayRecordedDataTest
Error 27 fatal error LNK1104: cannot open file 'C:\Users\shishany\devel\PlusExperimental-bin\bin\Debug\vtkDataCollection.lib' LineDetectionTest
#### By Hussam.Ashab on 2011-10-28 13:09
I do not have link errors any more. THank you. But I changed "OPTION(PLUS_USE_MICRONTRACKER "Provide support for the Claron MicronTracker" OFF)" and set it to ON in the PlusExperimental folder, configure and generate using CMake and Build using C++ compiler. Then I still have "OPTION (PLUS_USE_MICRONTRACKER "Provide support for the Claron MicronTracker" )" is set to OFF" in "PlusExperimental-bin\PlusLib\src\Tracking" .
#### By Hussam.Ashab on 2011-10-28 13:53
Thank you. I changed the CMAKEFILE in PlusExperimental folder and as you said it should change all of the cmakes in PlusExperimental_bin. but that is not happening with me
#### By Andras Lasso on 2011-10-28 14:53
I've done the followings:
Start CMake, where to build the binaries: C:/devel/PlusNightly-bin, where is the source code: C:/devel/PlusNightly-build
Enable PLUS_USE_MICRONTRACKER option
Configure, Generate
Open c:\devel\PlusNightly-bin\PlusLib-bin\PlusLib.sln in Visual Studio
Build the ALL_BUILD solution

Result: MicronTracker option become enabled throughout PlusLib
c:\devel\PlusNightly-bin\PlusLib-bin\CMakeCache.txt contains PLUS_USE_MICRONTRACKER:BOOL=ON
c:\devel\PlusNightly-bin\PlusLib-bin\src\PlusConfigure.h contains #define PLUS_USE_MICRONTRACKER
#### By Hussam.Ashab on 2011-10-28 18:01
I di the same but in the cmakefile PlusExperimental-bin\PlusLib\src\Tracking it is set to OFF. So when I buid it I do not have microntracker project also.
#### By Hussam.Ashab on 2011-10-28 18:16
the above step is done following what you told me
#### By Andras Lasso on 2011-10-28 18:28
Call me through skype (my skype name is lassoan) and we can have a look at the problem together using desktop sharing.
#### By Hussam.Ashab on 2011-10-28 22:59
when I build PLUS using the Microntracker option set on, I do not have DevEnv_Debug or release in PlusApp_bin and PLUSLIB-Bin. is it related to setting microntracker on
#### By Andras Lasso on 2011-10-28 23:03
DevEnv_...bat files are not needed anymore. Just open the PlusLib.sln or PlusApp.sln file in Visual Studio and you can simply run/debug the applications in debug or release mode.
#### By Hussam.Ashab on 2011-10-28 23:16
OK, thanks but I think the problem is not solved.
OPTION (PLUS_USE_MICRONTRACKER "Provide support for the Claron MicronTracker" OFF) is still off in PlusExperimental-bin\PlusLib\src\Tracking any suggestions
#### By Andras Lasso on 2011-10-28 23:19
Please contact me on skype either now or tomorrow morning.
#### By Hussam.Ashab on 2011-10-29 15:02
Hi,

When I build PLUS I am still getting the same issue I do not have the MicornTracker option set to ON, Also in PLUSLib I do not have project for MicronTracker, like other sensors for example Brachystepper
#### By Hussam.Ashab on 2011-10-29 16:04
I got this link errors when I want to access any MicronTracker functions
1>vtkMicronTracker.obj : error LNK2001: unresolved external symbol "public: int __thiscall MCamera::getXRes(void)" (?getXRes@MCamera@@QAEHXZ)

1>vtkMicronTracker.obj : error LNK2001: unresolved external symbol "public: int __thiscall Cameras::AttachAvailableCameras(void)" (?AttachAvailableCameras@Cameras@@QAEHXZ)

1>vtkMicronTracker.obj : error LNK2001: unresolved external symbol "public: __thiscall Cameras::Cameras(void)" (??0Cameras@@QAE@XZ)
#### By Andras Lasso on 2011-10-29 16:29
Let's continue the discussion at the relevant ticket: #348


## Build system changed - clean build recommended
#### Posted by Andras Lasso on 2011-10-28 12:49

We had to do a couple of changes in the build system as a preparation for the open source release (related to how the ultrasonix and NDI SDKs are obtained, as they are not public). The simplest way to update to the latest Plus version is to start the build from scratch and follow the updated build instructions described here: https://www.assembla.com/spaces/plus/wiki/Developers_guide.

#### 0 Comments


## Nightly tests for NSIS packaging
#### Posted by Siavash Khallaghi on 2011-10-19 23:38

Hi guys,

I was talking to Tamas earlier today. He explained to me that currently there are currently no nightly tests for Plus-App as it is too complicated to simulate mouse clicks and keyboard strokes. I was thinking, given that it is not common to build packages and packaging does not require mouse simulation, is it possible to add automatic nightly tests for packaging?

#### 8 Comments
#### By Csaba Pinter on 2011-10-20 10:35
Hi Siavash,
I am now working on the automatic GUI testing for PlusApp using Sikuli, maybe Tamas didn't know that. It is not complicated at all, although there are some difficulties as it was originally developed for Mac systems. Hopefully I will have the first test today or tomorrow for SegmentationParameterDialog CommonWidget.
#### By Tamas Heffter on 2011-10-20 11:22
Hi Siavash,
It would be good to know what do you want to test with the package generation. There are three main things that we could test for package generation:
Package generation was successful (there are no missing files)
Package generating automation (generate package every time we run nightly tests)
Check that there is no missing dlls (all binaries could run from the package bin folder)
#### By Siavash Khallaghi on 2011-10-20 22:23
Hi guys,

Thank you for your
####  comments. What I am aiming for is exactly what Tommy says, because once I had setup an experiment, but packaging was not working (it could not find a config file.). As a result, I lost my time slot with the machine and had to reschedule the test.
#### By Tamas Heffter on 2011-10-22 15:25
Siavash,
You can follow this request at #340
#### By Siavash Khallaghi on 2011-10-22 16:13
Thank you Tommy. I will follow the conversation on the ticket from now on.
#### By Csaba Pinter on 2011-10-22 18:32
Siavash,
So you're not interested in the automatized GUI testing after all?
#### By Siavash Khallaghi on 2011-10-27 17:35
Csaba,
Actually I am very interested in automatic GUI testing, as I am approaching clinical studies for my own app, but that was not the focus of this message. What I meant was to include testing for the packaging, no the GUI, since I thought GUI testing was harder to do.
But I would like to thank you for implementing GUI testing, I am looking through your example and I am writing my own tests for the GUI.
#### By Csaba Pinter on 2011-10-27 17:40
All right,
If you have any questions, don't hesitate to ask!


## Do not use STL support in QT
#### Posted by Andras Lasso on 2011-10-26 09:46

STL support in QT is flawed, which causes crash if you call QString::toStdString or QString::fromStdString methods (when building with VS2010 and using Qt-4.7.3 pre-built binaries, see #162).

Use the following methods instead:
aQtString.toStdString() => aString.toAscii().data()
fromStdString(aStdString) => aStdString.c_str()

#### 0 Comments


## Subversion 1.7
#### Posted by Csaba Pinter on 2011-10-24 16:45

Guys,

Subversion 1.7 has been released, and I'm writing to you because I tried it and it works nicely (the TortoiseSVN x64 integration too).
It worth updating, partly because instead of a .svn directory in every directory in the working copy, Subversion 1.7 working copies have just one .svn directory - in the root of the working copy. It can save us some time and prevent headache.
(The full list of changes can be found here: http://subversion.apache.org/docs/release-notes/1.7.html)

Note that this process will take much time because it requires a restart and two re-builds of everything (including VTK and ITK)

Instructions:
Download and install SlikSVN for the scripts: http://www.sliksvn.com/en/download
Note that the one shall be downloaded that matches your operating system (32 or 64 bit)
Download and install TortoiseSVN for ourselves: http://tortoisesvn.net/downloads.html
Probably restart will be needed at this point
Checkout and re-build Plus (and iCalBrachy) the usual way (checkout PlusBuild, CMake, run PlusBuild.sln, build).
Remember to do the same for your nightly tests too.

#### 0 Comments


## Upgrade to vtk 5.8.0
#### Posted by Tamas Heffter on 2011-10-21 00:11

Please update your PlusBuild source for experimental and nightly builds (https://subversion.assembla.com/svn/plus/trunk/PlusBuild) in order to the vtk 5.8.0 upgrade take effect.

#### 0 Comments


## RE: Changeset [921]: Compile project before experimental test and notify user if the build failed.
#### Posted by Andras Lasso on 2011-10-12 14:10

Hi Tomi,

Experimental build compiles PlusLib anyway and reports build results on the dashboard. If you build it in advance then it is just an extra step + it also hides all compilation warnings.

What is the advantage of having this extra build step?

Andras

From: Tamas Heffter [mailto:plus@alerts.assembla.com] 
Sent: 2011-October-11 3:22 PM 
To: Andras Lasso 
Subject: [Plus] Changeset [921]: Compile project before experimental test and notify user if the build failed.

Changeset alert by Tamas Heffter https://www.assembla.com/profile/heffter in space Plus https://www.assembla.com/spaces/plus

Compile project before experimental test and notify user if the build failed.

Affected files:

M trunk/PlusLib/ 
M trunk/PlusLib/BuildAndTest.bat.in

Commit from user: Tamas Heffter

More details https://www.assembla.com/code/plus/subversion/changesets/921

Assembla | Knowledge, Tools, and Talent for agile teams


#### 1 Comments
#### By Tamas Heffter on 2011-10-12 15:32
Yes, I know, but Csaba asked it, because sometime he checks the test results only, but if the build fails the binaries will be still there and the test output can be all passed like:
http://crunch.cs.queensu.ca/CDash/viewTest.php?onlypassed&buildid=2908 => Tests passed
but
http://crunch.cs.queensu.ca/CDash/viewBuildError.php?buildid=2911 => compilation failed

If we check the build results before cmake experimental test, it could notify the user that the compilation was failed.
We can change it back, for me it's irrelevant, because usually I start the experimental tests if every project compiles.


## Ultrasonix Porta SDK support added - update your PlusBuild directory
#### Posted by Andras Lasso on 2011-10-05 14:04

Support was added for Ultrasonix Porta SDK, which changed the build scripts. Please update your PlusBuild directory and re-build PlusBuild.sln.

Andras

#### 0 Comments


## Run PlusBuild to refresh OpenIGTLink.
#### Posted by Tamas Ungi on 2011-09-29 09:41

The latest OpenIGTLink is needed for the current version of PlusLib. If you haven't done so in the past two days, run PlusBuild to update your libs please. It should be done on machines with nightly testing too.

Thanks,
Tamas

#### 1 Comments
#### By Siavash Khallaghi on 2011-09-29 17:33
Not to sound over eager, but does this mean that it is ready for use with the Ascension tracker? :-D


## Re: Wiki Page "Developers guide" updated
#### Posted by hussam.ashab on 2011-09-13 22:09

Thanks it is done now.

On 9/14/2011, "Siavash Khallaghi" <plus@alerts.assembla.com> wrote:

>Wiki Page alert by Siavash Khallaghi in space Plus 
> 
>............................................................................. 
> 
>*Developers guide* 
> 
>Version: 50 
> 
>Comment: Added the firewall exception procedure so that BuildAndTest.bat can communicate with CDash. 
> 
> 
>............................................................................. 
>More details at: 
>https://www.assembla.com/spaces/plus/wiki/Developers_guide 
> 
>******************** 
>Please follow this URL to set your alert preferences for this space: 
>https://www.assembla.com/spaces/new_items/plus?settings=show 
>You can change or reduce the number of email alerts that you receive. 
>******************** 
> 
>-- 
>Assembla | Knowledge and Tools for agile teams 
> 
>


#### 0 Comments


## Re: Things to do:
#### Posted by hussam.ashab on 2011-09-11 21:59

I am getting these errors when I buid plus.

" 
3>No install step for 'OpenIGTLink' 
3>Completed 'OpenIGTLink' 
3>Build log was saved at 
"file://e:\devel\Plus-bin\OpenIGTLink.dir\Debug\BuildLog.htm"; 
3>OpenIGTLink - 0 error(s), 0 warning(s) 
4>HEAD is now at c3459c3... ENH: Increase VTK's version to 5.6.1 
4>Performing configure step for 'vtk' 
4>-- Configuring done 
4>-- Generating done 
4>-- Build files have been written to: E:/devel/Plus-bin/vtk-bin 
4>Performing build step for 'vtk' 
4>Microsoft (R) Visual C++ Express Edition Version 9.0.30729.1. 
4>Copyright (C) Microsoft Corp 2007. All rights reserved. 
4>1>------ Build started: Project: vtkFiltering, Configuration: Debug 
Win32 ------ 
4>1>Linking... 
4>1> Creating library 
E:\devel\Plus-bin\vtk-bin\bin\Debug\vtkFiltering.lib and object 
E:\devel\Plus-bin\vtk-bin\bin\Debug\vtkFiltering.exp 
4>1>CVTRES : fatal error CVT1107: 
'e:\devel\Plus-bin\vtk-bin\Filtering\vtkFiltering.dir\Debug\vtkStructuredGridToPolyDataFilter.obj' 
is corrupt 
4>1>LINK : fatal error LNK1123: failure during conversion to COFF: file 
invalid or corrupt 
4>1>Build log was saved at 
"file://e:\devel\Plus-bin\vtk-bin\Filtering\vtkFiltering.dir\Debug\BuildLog.htm"; 
4>1>vtkFiltering - 2 error(s), 0 warning(s) 
4>2>------ Build started: Project: vtkIO, Configuration: Debug Win32 
------ 
4>3>------ Build started: Project: vtkImaging, Configuration: Debug Win32 
------ 
4>3>Linking... 
4>2>Linking... 
4>3> Creating library 
E:\devel\Plus-bin\vtk-bin\bin\Debug\vtkImaging.lib and object 
E:\devel\Plus-bin\vtk-bin\bin\Debug\vtkImaging.exp 
4>3>vtkImageWeightedSum.obj : error LNK2019: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) referenced in function 
__ehhandler$?New@vtkImageWeightedSum@@SAPAV1@XZ 
4>3>vtkImageStencil.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageThreshold.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageVariance3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageWrapPad.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageShrink3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageSobel2D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageSobel3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageSpatialAlgorithm.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageRange3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageRectilinearWipe.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageReslice.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageShiftScale.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageOpenClose3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImagePadFilter.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageRGBToHSI.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageRGBToHSV.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMedian3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMirrorPad.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageNonMaximumSuppression.obj : error LNK2001: unresolved 
external symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageNormalize.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMapToColors.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMask.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMaskBits.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMathematics.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageLogic.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageLuminance.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMagnify.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageMagnitude.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageIdealLowPass.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageIterateFilter.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageLaplacian.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageLogarithmicScale.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageHSIToRGB.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageHSVToRGB.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageHybridMedian2D.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageIdealHighPass.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageExtractComponents.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageGaussianSmooth.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageGradient.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageGradientMagnitude.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageDilateErode3D.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageDivergence.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageDotProduct.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageEuclideanToPolar.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageContinuousErode3D.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageConvolve.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageCorrelation.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageDifference.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageCast.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageCheckerboard.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageConstantPad.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageContinuousDilate3D.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageBlend.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageButterworthHighPass.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageButterworthLowPass.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageCanvasSource2D.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageAnisotropicDiffusion2D.obj : error LNK2001: unresolved 
external symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageAnisotropicDiffusion3D.obj : error LNK2001: unresolved 
external symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageAppend.obj : error LNK2001: unresolved external symbol 
"__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageAppendComponents.obj : error LNK2001: unresolved external 
symbol "__declspec(dllimport) protected: virtual __thiscall 
vtkThreadedImageAlgorithm::~vtkThreadedImageAlgorithm(void)" 
(__imp_??1vtkThreadedImageAlgorithm@@MAE@XZ) 
4>3>vtkImageThreshold.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageVariance3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageWrapPad.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageWeightedSum.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageSobel2D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageSobel3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageSpatialAlgorithm.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageStencil.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageResample.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageReslice.obj : error LNK2019: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
referenced in function "public: virtual void __thiscall 
vtkImageReslice::SetTransformInputSampling(int)" 
(?SetTransformInputSampling@vtkImageReslice@@UAEXH@Z) 
4>3>vtkImageShiftScale.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageShrink3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageRGBToHSI.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageRGBToHSV.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageRange3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageRectilinearWipe.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageNormalize.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageOpenClose3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImagePadFilter.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImagePermute.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMathematics.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMedian3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMirrorPad.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageNonMaximumSuppression.obj : error LNK2001: unresolved 
external symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMagnify.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMagnitude.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMask.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageMaskBits.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageLaplacian.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageLogarithmicScale.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageLogic.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageLuminance.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageHSVToRGB.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageHybridMedian2D.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageIdealHighPass.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageIdealLowPass.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageFlip.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageGaussianSmooth.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageGradientMagnitude.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageHSIToRGB.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageDivergence.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageDotProduct.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageEuclideanToPolar.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageExtractComponents.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageConvolve.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageCorrelation.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageDifference.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageDilateErode3D.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageCheckerboard.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageConstantPad.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageContinuousDilate3D.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageContinuousErode3D.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageButterworthHighPass.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageButterworthLowPass.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageCanvasSource2D.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageCast.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageAnisotropicDiffusion2D.obj : error LNK2001: unresolved 
external symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageAnisotropicDiffusion3D.obj : error LNK2001: unresolved 
external symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageAppend.obj : error LNK2001: unresolved external symbol 
"protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageAppendComponents.obj : error LNK2001: unresolved external 
symbol "protected: virtual int __thiscall 
vtkThreadedImageAlgorithm::RequestData(class vtkInformation *,class 
vtkInformationVector * *,class vtkInformationVector *)" 
(?RequestData@vtkThreadedImageAlgorithm@@MAEHPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@@Z) 
4>3>vtkImageVariance3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageWrapPad.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageSkeleton2D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageSobel2D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageSobel3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageSpatialAlgorithm.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageRGBToHSI.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageRGBToHSV.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageRange3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageSeparableConvolution.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageNormalize.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageOpenClose3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImagePadFilter.obj : error LNK2019: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
referenced in function "class std::basic_ostream<char,struct 
std::char_traits<char> > & __cdecl std::operator<<<struct 
std::char_traits<char> >(class std::basic_ostream<char,struct 
std::char_traits<char> > &,char const *)" 
(??$?6U?$char_traits@D@std@@@std@@YAAAV?$basic_ostream@DU?$char_traits@D@std@@@0@AAV10@PBD@Z) 
4>3>vtkImageRFFT.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageMagnitude.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageMaskBits.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageMedian3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageMirrorPad.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageHybridMedian2D.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageIterateFilter.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageLogarithmicScale.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageLuminance.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageFourierFilter.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageGradientMagnitude.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageHSIToRGB.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageHSVToRGB.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageEuclideanToPolar.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageExtractComponents.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageFFT.obj : error LNK2001: unresolved external symbol "public: 
virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageFourierCenter.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageDecomposeFilter.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageDilateErode3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageDivergence.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageEuclideanDistance.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageCityBlockDistance.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageConstantPad.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageContinuousDilate3D.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageContinuousErode3D.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageAnisotropicDiffusion2D.obj : error LNK2001: unresolved 
external symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageAnisotropicDiffusion3D.obj : error LNK2001: unresolved 
external symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageCanvasSource2D.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageCast.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedRequestData(class vtkInformation 
*,class vtkInformationVector * *,class vtkInformationVector *,class 
vtkImageData * * *,class vtkImageData * *,int * const,int)" 
(?ThreadedRequestData@vtkThreadedImageAlgorithm@@UAEXPAVvtkInformation@@PAPAVvtkInformationVector@@PAV3@PAPAPAVvtkImageData@@PAPAV4@QAHH@Z) 
4>3>vtkImageThreshold.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageVariance3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageWrapPad.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageWeightedSum.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageSobel2D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageSobel3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageSpatialAlgorithm.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageStencil.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageReslice.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageSeparableConvolution.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageShiftScale.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageShrink3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageRFFT.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageRange3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageRectilinearWipe.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageResample.obj : error LNK2019: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
referenced in function "public: virtual void __thiscall 
vtkImageReslice::SetMirror(int)" (?SetMirror@vtkImageReslice@@UAEXH@Z) 
4>3>vtkImageNonMaximumSuppression.obj : error LNK2001: unresolved 
external symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageOpenClose3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImagePadFilter.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImagePermute.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMaskBits.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMathematics.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMedian3D.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMirrorPad.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMapToColors.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMapToRGBA.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMapToWindowLevelColors.obj : error LNK2001: unresolved 
external symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMask.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageIterateFilter.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageLaplacian.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageLogic.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageMagnify.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageGradient.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageHybridMedian2D.obj : error LNK2001: unresolved external 
symbol "public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImageData *,int * const,int)" 
(?ThreadedExecute@vtkThreadedImageAlgorithm@@UAEXPAVvtkImageData@@0QAHH@Z) 
4>3>vtkImageIdealHighPass.obj : error LNK2001: unresolved external symbol 
"public: virtual void __thiscall 
vtkThreadedImageAlgorithm::ThreadedExecute(class vtkImageData *,class 
vtkImage


#### 0 Comments


## Plus-1.2.2 for iCalBrachy demo
#### Posted by Tamas Heffter on 2011-08-23 14:16

Released Plus 1.2.2 for iCalBrachy demo for med physicist and Civco at AMS.

#### 0 Comments


## OpenIGTLink communication test
#### Posted by Tamas Ungi on 2011-08-13 00:15

It has been an unsolved problem to add automatic tests with actual OpenIGTLink communication. Previously, we talked about having CTest start another program in the background to provide the other end of the communication channel. Today, I've added a test that implements OpenIGTLink communication between two threads. This seems to be a simple and good solution, but Windows firewall blocks the port by default. I don't know if unblocking the firewall on test machines is feasible. We will see in a couple of days...
I'm just letting you know because OpenIGTLinkBroadcaster tests may fail tomorrow because of firewall blocked communication.

#### 0 Comments


## FYI, fCal works
#### Posted by Tamas Ungi on 2011-07-31 18:14

I have tried the calibration of the L14-5gps probe with fCal and volume recording with the TrackedUltrasoundCapturing app, source code revision 467 (this morning). On the Touch with the GPS tracker. It works, and gives similar results as on Friday.
A lot of error handling is still needed for robust operation, but the main functionality is promising.

#### 0 Comments


## Nightly tests
#### Posted by Tamas Heffter on 2011-07-29 09:04

All,
Please update and configure your Nightly PlusBuild then compile it (it will update PLTools).
Thanks

#### 0 Comments


## Move back PlusApp to PlusLib solution
#### Posted by Tamas Heffter on 2011-07-09 10:32

Guys,

I've included PlusLib as an external project for PlusApp, so we could build all the libs and apps from the same solution and also we could avoid the move back PlusApp (and separate again) tasks in the future with this modification.
Could you try the this (#99) idea and let me know your opinions?

Thanks,
Tomi

#### 0 Comments


## How to run individual tests
#### Posted by Tamas Heffter on 2011-06-30 16:32

I've added a new argument to BuildAndTest.bat so you can start individual tests like this (where the -I is capital "i"):

> BuildAndTest.bat -I vtkUSCalibrationControllerTest

Test project C:/devel/Plus-BUILD/PlusLib-bin
Test #9: vtkUSCalibrationControllerTest-Exact
Test #10: vtkUSCalibrationControllerTest
Test #11: vtkUSCalibrationControllerTest_FrameGrabber-Exact
Test #12: vtkUSCalibrationControllerTest_FrameGrabber

#### 0 Comments


## RE: Changeset [149]: Some fixes in fCal freehand calibration
#### Posted by Andras Lasso on 2011-06-15 20:37

Hi Csaba,

I try to follow the developments in the Plus code but when I see a commit comment such as "Some fixes in fCal freehand calibration" I really have no idea what the change is about.

Please refer to a ticket whenever it's possible ("re #99") and try to be a bit more specific ("Fixed button size on fCal toolbox").

Thanks!

Andras

From: Csaba Pinter [mailto:plus@alerts.assembla.com] 
Sent: 2011-June-15 4:53 PM 
To: Andras Lasso 
Subject: [Plus] Changeset [149]: Some fixes in fCal freehand calibration

Changeset alert by Csaba Pinter https://www.assembla.com/profile/pinter in space Plus https://www.assembla.com/spaces/plus

Some fixes in fCal freehand calibration

Affected files:

M trunk/PlusApp/FreehandCalibration/Toolboxes/ 
M trunk/PlusApp/FreehandCalibration/Toolboxes/FreehandCalibrationToolbox.cxx

Commit from user: pinter

More details https://www.assembla.com/code/plus/subversion/changesets/149

Assembla | Knowledge, Tools, and Talent for agile teams


#### 0 Comments


## Plus with 3D Slicer
#### Posted by Tamas Heffter on 2011-06-05 00:50

You can build Plus with 3D Slicer by turning on PLUSBUILD_USE_3DSlicer option and setting the PLUSBUILD_SLICER_BIN_DIRECTORY to your 3D Slicer binary folder.
In this case, you can use PlusLib with 3D Slicer and you don't have to build ITK, VTK, OpenIGTLink again. This version supports both Slicer 3 and Slicer 4.
For more information, please visit https://www.assembla.com/spaces/plus/wiki/Developers_guide
Please update your PlusBuild folder in order to get this new feature.

#### 0 Comments


## Agree on error handling style -- urgent!
#### Posted by Tamas Ungi on 2011-05-28 23:14

In many (most!?) places inside the PlusLib code, errors are handled in the following fashion:
- Log an error message.
- Call exit() to stop running the application.
This prevents the development of robust applications, handling unconnected devices, report mistakes in config files, etc. So this should immediately be changed!

There are multiple ways of handling errors. There are much more arguments on Google supporting the usage of throw/catch over returning error codes or using error flags.

Should we vote? (I vote exceptions.)

#### 2 Comments
#### By Andras Lasso on 2011-05-29 10:00
That's a very important issue indeed. We need to handle errors better. Tho two main options are exceptions or return values. Exceptions make the code more likely to crash (each thrown exception creates a chance for an application crash), so it doesn't increase it's robustness. I would suggest to: 
-replace exit()-s with error status returns (add a PlusStatus enum with SUCCESS and FAIL values) 
-add more checks for valid pointers and input values (log error and return error status if failure)

Design a somewhat robust exception handling strategy is very difficult, definitely not a quick decision or implementation.

Andras

-original message- 
Subject: [Plus] Agree on error handling style -- urgent! 
From: Tamas Ungi <plus@alerts.assembla.com> 
Date: 05/28/2011 23:15

#### By Andras Lasso on 2011-05-30 14:18
Discussed the possible options and updated coding conventions accordingly (https://www.assembla.com/spaces/plus/wiki/Developers_guide).


## Project rename: PlusLib
#### Posted by Tamas Heffter on 2011-05-13 16:20

As we discussed before (#24), I've renamed the Plus folder and the project to PlusLib.
Please build again your PlusBuild solution (just Build Solution, no need to rebuild itk, vtk).

#### 1 Comments
#### By Csaba Pinter on 2011-05-13 16:50
Updating the PlusBuild is necessary before building


## Green dashboard
#### Posted by Andras Lasso on 2011-05-13 14:45

The dashboard is green at last: http://crunch.cs.queensu.ca/CDash/index.php?project=PLUS
Keep it like that (and add more tests whenever it's possible)!

#### 0 Comments


## When committing a partial fix
#### Posted by Andras Lasso on 2011-05-05 20:03

When you commit changes related to a bug (partial fix, etc.) then please add a reference to the ticket id to the commit log in the format:

re #123: description of the changes

This will automatically link the changeset to the ticket: making it clear why the changes was introduced and easy to review all changes related to a fix or enhancement.

#### 1 Comments
#### By Tamas Heffter on 2011-05-06 11:36
Here is the detailed instruction:
https://www.assembla.com/code/plus/subversion/repo/instructions


## Start removed from Initialize in vtkDataCollector
#### Posted by Tamas Ungi on 2011-05-04 20:34

As we discussed I have removed the automatic Start call from the Initialize function of vtkDataCollector. I tried to add a Start() after every Initialize() in the existing files, but maybe I didn't find all places. If you notice that something doesn't work from revision #9 of PlusLib, check if you are missing a Start() call of your data collector.

Thanks,
Tamas

#### 0 Comments